{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools import config\n",
    "\n",
    "if not os.path.exists(config.DEFECTS_PATH):\n",
    "    !python \"tools/extracted_defetcs.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenAug = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "\tzoom_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tvalidation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 6 classes.\n",
      "Found 2001 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"training\")\n",
    "\n",
    "testGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet101(weights='imagenet', include_top=False,  input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "for layer in resnet_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "head = resnet_model.output\n",
    "head = AveragePooling2D(pool_size=(7, 7))(head)\n",
    "flatten = Flatten()(head)\n",
    "fc = Dense(512, activation = \"relu\")(flatten)\n",
    "fc = Dropout(0.5)(fc)\n",
    "output = Dense(len(trainGen.class_indices), activation = \"softmax\")(fc)\n",
    "\n",
    "model = Model(inputs=resnet_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(os.path.sep.join([config.OUTPUT_PATH, \"resnet101.h5\"]), monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.25000, saving model to output\\resnet101.h5\n",
      "  1/250 [..............................] - ETA: 41:04 - loss: 3.3715 - accuracy: 0.2500\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  2/250 [..............................] - ETA: 42s - loss: 3.3272 - accuracy: 0.2188  \n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  3/250 [..............................] - ETA: 56s - loss: 3.1903 - accuracy: 0.2188\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  4/250 [..............................] - ETA: 1:00 - loss: 2.9517 - accuracy: 0.2188\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  5/250 [..............................] - ETA: 1:02 - loss: 2.8587 - accuracy: 0.2250\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  6/250 [..............................] - ETA: 1:04 - loss: 2.7412 - accuracy: 0.2135\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  7/250 [..............................] - ETA: 1:04 - loss: 2.6456 - accuracy: 0.2232\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  8/250 [..............................] - ETA: 1:05 - loss: 2.6984 - accuracy: 0.2031\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      "  9/250 [>.............................] - ETA: 1:05 - loss: 2.6170 - accuracy: 0.2257\n",
      "Epoch 1: accuracy did not improve from 0.25000\n",
      " 10/250 [>.............................] - ETA: 1:04 - loss: 2.5463 - accuracy: 0.2344\n",
      "Epoch 1: accuracy improved from 0.25000 to 0.25284, saving model to output\\resnet101.h5\n",
      " 11/250 [>.............................] - ETA: 1:27 - loss: 2.4756 - accuracy: 0.2528\n",
      "Epoch 1: accuracy improved from 0.25284 to 0.25781, saving model to output\\resnet101.h5\n",
      " 12/250 [>.............................] - ETA: 1:40 - loss: 2.4246 - accuracy: 0.2578\n",
      "Epoch 1: accuracy improved from 0.25781 to 0.26923, saving model to output\\resnet101.h5\n",
      " 13/250 [>.............................] - ETA: 1:48 - loss: 2.3649 - accuracy: 0.2692\n",
      "Epoch 1: accuracy improved from 0.26923 to 0.27232, saving model to output\\resnet101.h5\n",
      " 14/250 [>.............................] - ETA: 1:55 - loss: 2.3322 - accuracy: 0.2723\n",
      "Epoch 1: accuracy improved from 0.27232 to 0.28750, saving model to output\\resnet101.h5\n",
      " 15/250 [>.............................] - ETA: 2:02 - loss: 2.2794 - accuracy: 0.2875\n",
      "Epoch 1: accuracy improved from 0.28750 to 0.29492, saving model to output\\resnet101.h5\n",
      " 16/250 [>.............................] - ETA: 2:09 - loss: 2.2419 - accuracy: 0.2949\n",
      "Epoch 1: accuracy improved from 0.29492 to 0.30147, saving model to output\\resnet101.h5\n",
      " 17/250 [=>............................] - ETA: 2:13 - loss: 2.2089 - accuracy: 0.3015\n",
      "Epoch 1: accuracy improved from 0.30147 to 0.30556, saving model to output\\resnet101.h5\n",
      " 18/250 [=>............................] - ETA: 2:16 - loss: 2.1853 - accuracy: 0.3056\n",
      "Epoch 1: accuracy improved from 0.30556 to 0.30757, saving model to output\\resnet101.h5\n",
      " 19/250 [=>............................] - ETA: 2:19 - loss: 2.1608 - accuracy: 0.3076\n",
      "Epoch 1: accuracy did not improve from 0.30757\n",
      " 20/250 [=>............................] - ETA: 2:13 - loss: 2.1406 - accuracy: 0.3063\n",
      "Epoch 1: accuracy improved from 0.30757 to 0.31399, saving model to output\\resnet101.h5\n",
      " 21/250 [=>............................] - ETA: 2:18 - loss: 2.1182 - accuracy: 0.3140\n",
      "Epoch 1: accuracy improved from 0.31399 to 0.31534, saving model to output\\resnet101.h5\n",
      " 22/250 [=>............................] - ETA: 2:21 - loss: 2.0956 - accuracy: 0.3153\n",
      "Epoch 1: accuracy improved from 0.31534 to 0.32745, saving model to output\\resnet101.h5\n",
      " 23/250 [=>............................] - ETA: 2:25 - loss: 2.0512 - accuracy: 0.3274\n",
      "Epoch 1: accuracy improved from 0.32745 to 0.33203, saving model to output\\resnet101.h5\n",
      " 24/250 [=>............................] - ETA: 2:27 - loss: 2.0338 - accuracy: 0.3320\n",
      "Epoch 1: accuracy improved from 0.33203 to 0.33875, saving model to output\\resnet101.h5\n",
      " 25/250 [==>...........................] - ETA: 2:28 - loss: 2.0064 - accuracy: 0.3388\n",
      "Epoch 1: accuracy improved from 0.33875 to 0.34736, saving model to output\\resnet101.h5\n",
      " 26/250 [==>...........................] - ETA: 2:30 - loss: 1.9748 - accuracy: 0.3474\n",
      "Epoch 1: accuracy improved from 0.34736 to 0.34954, saving model to output\\resnet101.h5\n",
      " 27/250 [==>...........................] - ETA: 2:31 - loss: 1.9588 - accuracy: 0.3495\n",
      "Epoch 1: accuracy improved from 0.34954 to 0.35714, saving model to output\\resnet101.h5\n",
      " 28/250 [==>...........................] - ETA: 2:33 - loss: 1.9333 - accuracy: 0.3571\n",
      "Epoch 1: accuracy improved from 0.35714 to 0.36530, saving model to output\\resnet101.h5\n",
      " 29/250 [==>...........................] - ETA: 2:34 - loss: 1.9057 - accuracy: 0.3653\n",
      "Epoch 1: accuracy improved from 0.36530 to 0.36771, saving model to output\\resnet101.h5\n",
      " 30/250 [==>...........................] - ETA: 2:35 - loss: 1.8923 - accuracy: 0.3677\n",
      "Epoch 1: accuracy improved from 0.36771 to 0.37097, saving model to output\\resnet101.h5\n",
      " 31/250 [==>...........................] - ETA: 2:36 - loss: 1.8707 - accuracy: 0.3710\n",
      "Epoch 1: accuracy improved from 0.37097 to 0.37891, saving model to output\\resnet101.h5\n",
      " 32/250 [==>...........................] - ETA: 2:44 - loss: 1.8514 - accuracy: 0.3789\n",
      "Epoch 1: accuracy improved from 0.37891 to 0.38731, saving model to output\\resnet101.h5\n",
      " 33/250 [==>...........................] - ETA: 2:46 - loss: 1.8272 - accuracy: 0.3873\n",
      "Epoch 1: accuracy improved from 0.38731 to 0.39522, saving model to output\\resnet101.h5\n",
      " 34/250 [===>..........................] - ETA: 2:46 - loss: 1.8083 - accuracy: 0.3952\n",
      "Epoch 1: accuracy improved from 0.39522 to 0.39911, saving model to output\\resnet101.h5\n",
      " 35/250 [===>..........................] - ETA: 2:47 - loss: 1.7879 - accuracy: 0.3991\n",
      "Epoch 1: accuracy improved from 0.39911 to 0.40017, saving model to output\\resnet101.h5\n",
      " 36/250 [===>..........................] - ETA: 2:47 - loss: 1.7830 - accuracy: 0.4002\n",
      "Epoch 1: accuracy improved from 0.40017 to 0.40203, saving model to output\\resnet101.h5\n",
      " 37/250 [===>..........................] - ETA: 2:47 - loss: 1.7700 - accuracy: 0.4020\n",
      "Epoch 1: accuracy improved from 0.40203 to 0.41036, saving model to output\\resnet101.h5\n",
      " 38/250 [===>..........................] - ETA: 2:48 - loss: 1.7419 - accuracy: 0.4104\n",
      "Epoch 1: accuracy improved from 0.41036 to 0.41266, saving model to output\\resnet101.h5\n",
      " 39/250 [===>..........................] - ETA: 2:47 - loss: 1.7293 - accuracy: 0.4127\n",
      "Epoch 1: accuracy improved from 0.41266 to 0.41953, saving model to output\\resnet101.h5\n",
      " 40/250 [===>..........................] - ETA: 2:47 - loss: 1.7050 - accuracy: 0.4195\n",
      "Epoch 1: accuracy improved from 0.41953 to 0.42530, saving model to output\\resnet101.h5\n",
      " 41/250 [===>..........................] - ETA: 2:47 - loss: 1.6900 - accuracy: 0.4253\n",
      "Epoch 1: accuracy improved from 0.42530 to 0.43006, saving model to output\\resnet101.h5\n",
      " 42/250 [====>.........................] - ETA: 2:47 - loss: 1.6734 - accuracy: 0.4301\n",
      "Epoch 1: accuracy improved from 0.43006 to 0.43459, saving model to output\\resnet101.h5\n",
      " 43/250 [====>.........................] - ETA: 2:48 - loss: 1.6540 - accuracy: 0.4346\n",
      "Epoch 1: accuracy improved from 0.43459 to 0.43537, saving model to output\\resnet101.h5\n",
      " 44/250 [====>.........................] - ETA: 2:48 - loss: 1.6460 - accuracy: 0.4354\n",
      "Epoch 1: accuracy improved from 0.43537 to 0.44097, saving model to output\\resnet101.h5\n",
      " 45/250 [====>.........................] - ETA: 2:48 - loss: 1.6309 - accuracy: 0.4410\n",
      "Epoch 1: accuracy improved from 0.44097 to 0.44497, saving model to output\\resnet101.h5\n",
      " 46/250 [====>.........................] - ETA: 2:48 - loss: 1.6233 - accuracy: 0.4450\n",
      "Epoch 1: accuracy improved from 0.44497 to 0.44614, saving model to output\\resnet101.h5\n",
      " 47/250 [====>.........................] - ETA: 2:47 - loss: 1.6164 - accuracy: 0.4461\n",
      "Epoch 1: accuracy improved from 0.44614 to 0.44792, saving model to output\\resnet101.h5\n",
      " 48/250 [====>.........................] - ETA: 2:48 - loss: 1.6106 - accuracy: 0.4479\n",
      "Epoch 1: accuracy improved from 0.44792 to 0.45026, saving model to output\\resnet101.h5\n",
      " 49/250 [====>.........................] - ETA: 2:48 - loss: 1.6025 - accuracy: 0.4503\n",
      "Epoch 1: accuracy improved from 0.45026 to 0.45312, saving model to output\\resnet101.h5\n",
      " 50/250 [=====>........................] - ETA: 2:47 - loss: 1.5903 - accuracy: 0.4531\n",
      "Epoch 1: accuracy improved from 0.45312 to 0.45466, saving model to output\\resnet101.h5\n",
      " 51/250 [=====>........................] - ETA: 2:46 - loss: 1.5822 - accuracy: 0.4547\n",
      "Epoch 1: accuracy improved from 0.45466 to 0.45974, saving model to output\\resnet101.h5\n",
      " 52/250 [=====>........................] - ETA: 2:45 - loss: 1.5672 - accuracy: 0.4597\n",
      "Epoch 1: accuracy improved from 0.45974 to 0.46403, saving model to output\\resnet101.h5\n",
      " 53/250 [=====>........................] - ETA: 2:46 - loss: 1.5530 - accuracy: 0.4640\n",
      "Epoch 1: accuracy improved from 0.46403 to 0.46701, saving model to output\\resnet101.h5\n",
      " 54/250 [=====>........................] - ETA: 2:45 - loss: 1.5432 - accuracy: 0.4670\n",
      "Epoch 1: accuracy improved from 0.46701 to 0.46989, saving model to output\\resnet101.h5\n",
      " 55/250 [=====>........................] - ETA: 2:45 - loss: 1.5351 - accuracy: 0.4699\n",
      "Epoch 1: accuracy improved from 0.46989 to 0.47489, saving model to output\\resnet101.h5\n",
      " 56/250 [=====>........................] - ETA: 2:44 - loss: 1.5205 - accuracy: 0.4749\n",
      "Epoch 1: accuracy improved from 0.47489 to 0.47752, saving model to output\\resnet101.h5\n",
      " 57/250 [=====>........................] - ETA: 2:43 - loss: 1.5086 - accuracy: 0.4775\n",
      "Epoch 1: accuracy improved from 0.47752 to 0.48060, saving model to output\\resnet101.h5\n",
      " 58/250 [=====>........................] - ETA: 2:43 - loss: 1.4994 - accuracy: 0.4806\n",
      "Epoch 1: accuracy improved from 0.48060 to 0.48411, saving model to output\\resnet101.h5\n",
      " 59/250 [======>.......................] - ETA: 2:42 - loss: 1.4906 - accuracy: 0.4841\n",
      "Epoch 1: accuracy improved from 0.48411 to 0.48646, saving model to output\\resnet101.h5\n",
      " 60/250 [======>.......................] - ETA: 2:42 - loss: 1.4803 - accuracy: 0.4865\n",
      "Epoch 1: accuracy improved from 0.48646 to 0.49129, saving model to output\\resnet101.h5\n",
      " 61/250 [======>.......................] - ETA: 2:41 - loss: 1.4684 - accuracy: 0.4913\n",
      "Epoch 1: accuracy improved from 0.49129 to 0.49496, saving model to output\\resnet101.h5\n",
      " 62/250 [======>.......................] - ETA: 2:40 - loss: 1.4598 - accuracy: 0.4950\n",
      "Epoch 1: accuracy improved from 0.49496 to 0.49554, saving model to output\\resnet101.h5\n",
      " 63/250 [======>.......................] - ETA: 2:40 - loss: 1.4519 - accuracy: 0.4955\n",
      "Epoch 1: accuracy improved from 0.49554 to 0.49854, saving model to output\\resnet101.h5\n",
      " 64/250 [======>.......................] - ETA: 2:40 - loss: 1.4429 - accuracy: 0.4985\n",
      "Epoch 1: accuracy improved from 0.49854 to 0.50144, saving model to output\\resnet101.h5\n",
      " 65/250 [======>.......................] - ETA: 2:40 - loss: 1.4323 - accuracy: 0.5014\n",
      "Epoch 1: accuracy improved from 0.50144 to 0.50473, saving model to output\\resnet101.h5\n",
      " 66/250 [======>.......................] - ETA: 2:39 - loss: 1.4224 - accuracy: 0.5047\n",
      "Epoch 1: accuracy improved from 0.50473 to 0.50700, saving model to output\\resnet101.h5\n",
      " 67/250 [=======>......................] - ETA: 2:38 - loss: 1.4133 - accuracy: 0.5070\n",
      "Epoch 1: accuracy improved from 0.50700 to 0.51103, saving model to output\\resnet101.h5\n",
      " 68/250 [=======>......................] - ETA: 2:37 - loss: 1.4037 - accuracy: 0.5110\n",
      "Epoch 1: accuracy improved from 0.51103 to 0.51359, saving model to output\\resnet101.h5\n",
      " 69/250 [=======>......................] - ETA: 2:37 - loss: 1.3953 - accuracy: 0.5136\n",
      "Epoch 1: accuracy improved from 0.51359 to 0.51562, saving model to output\\resnet101.h5\n",
      " 70/250 [=======>......................] - ETA: 2:37 - loss: 1.3890 - accuracy: 0.5156\n",
      "Epoch 1: accuracy improved from 0.51562 to 0.51717, saving model to output\\resnet101.h5\n",
      " 71/250 [=======>......................] - ETA: 2:36 - loss: 1.3817 - accuracy: 0.5172\n",
      "Epoch 1: accuracy improved from 0.51717 to 0.51736, saving model to output\\resnet101.h5\n",
      " 72/250 [=======>......................] - ETA: 2:35 - loss: 1.3763 - accuracy: 0.5174\n",
      "Epoch 1: accuracy improved from 0.51736 to 0.51755, saving model to output\\resnet101.h5\n",
      " 73/250 [=======>......................] - ETA: 2:35 - loss: 1.3731 - accuracy: 0.5176\n",
      "Epoch 1: accuracy improved from 0.51755 to 0.51943, saving model to output\\resnet101.h5\n",
      " 74/250 [=======>......................] - ETA: 2:34 - loss: 1.3674 - accuracy: 0.5194\n",
      "Epoch 1: accuracy improved from 0.51943 to 0.52333, saving model to output\\resnet101.h5\n",
      " 75/250 [========>.....................] - ETA: 2:33 - loss: 1.3570 - accuracy: 0.5233\n",
      "Epoch 1: accuracy improved from 0.52333 to 0.52673, saving model to output\\resnet101.h5\n",
      " 76/250 [========>.....................] - ETA: 2:32 - loss: 1.3475 - accuracy: 0.5267\n",
      "Epoch 1: accuracy improved from 0.52673 to 0.52881, saving model to output\\resnet101.h5\n",
      " 77/250 [========>.....................] - ETA: 2:31 - loss: 1.3424 - accuracy: 0.5288\n",
      "Epoch 1: accuracy improved from 0.52881 to 0.53005, saving model to output\\resnet101.h5\n",
      " 78/250 [========>.....................] - ETA: 2:30 - loss: 1.3352 - accuracy: 0.5300\n",
      "Epoch 1: accuracy improved from 0.53005 to 0.53006, saving model to output\\resnet101.h5\n",
      " 79/250 [========>.....................] - ETA: 2:29 - loss: 1.3332 - accuracy: 0.5301\n",
      "Epoch 1: accuracy improved from 0.53006 to 0.53164, saving model to output\\resnet101.h5\n",
      " 80/250 [========>.....................] - ETA: 2:29 - loss: 1.3282 - accuracy: 0.5316\n",
      "Epoch 1: accuracy improved from 0.53164 to 0.53395, saving model to output\\resnet101.h5\n",
      " 81/250 [========>.....................] - ETA: 2:28 - loss: 1.3223 - accuracy: 0.5340\n",
      "Epoch 1: accuracy improved from 0.53395 to 0.53620, saving model to output\\resnet101.h5\n",
      " 82/250 [========>.....................] - ETA: 2:27 - loss: 1.3145 - accuracy: 0.5362\n",
      "Epoch 1: accuracy improved from 0.53620 to 0.53727, saving model to output\\resnet101.h5\n",
      " 83/250 [========>.....................] - ETA: 2:26 - loss: 1.3098 - accuracy: 0.5373\n",
      "Epoch 1: accuracy did not improve from 0.53727\n",
      " 84/250 [=========>....................] - ETA: 2:24 - loss: 1.3060 - accuracy: 0.5372\n",
      "Epoch 1: accuracy improved from 0.53727 to 0.53741, saving model to output\\resnet101.h5\n",
      " 85/250 [=========>....................] - ETA: 2:24 - loss: 1.3048 - accuracy: 0.5374\n",
      "Epoch 1: accuracy improved from 0.53741 to 0.53880, saving model to output\\resnet101.h5\n",
      " 86/250 [=========>....................] - ETA: 2:23 - loss: 1.3005 - accuracy: 0.5388\n",
      "Epoch 1: accuracy improved from 0.53880 to 0.54016, saving model to output\\resnet101.h5\n",
      " 87/250 [=========>....................] - ETA: 2:22 - loss: 1.2955 - accuracy: 0.5402\n",
      "Epoch 1: accuracy improved from 0.54016 to 0.54220, saving model to output\\resnet101.h5\n",
      " 88/250 [=========>....................] - ETA: 2:21 - loss: 1.2904 - accuracy: 0.5422\n",
      "Epoch 1: accuracy improved from 0.54220 to 0.54526, saving model to output\\resnet101.h5\n",
      " 89/250 [=========>....................] - ETA: 2:20 - loss: 1.2818 - accuracy: 0.5453\n",
      "Epoch 1: accuracy improved from 0.54526 to 0.54580, saving model to output\\resnet101.h5\n",
      " 90/250 [=========>....................] - ETA: 2:19 - loss: 1.2790 - accuracy: 0.5458\n",
      "Epoch 1: accuracy improved from 0.54580 to 0.54772, saving model to output\\resnet101.h5\n",
      " 91/250 [=========>....................] - ETA: 2:18 - loss: 1.2728 - accuracy: 0.5477\n",
      "Epoch 1: accuracy improved from 0.54772 to 0.54959, saving model to output\\resnet101.h5\n",
      " 92/250 [==========>...................] - ETA: 2:17 - loss: 1.2687 - accuracy: 0.5496\n",
      "Epoch 1: accuracy improved from 0.54959 to 0.55007, saving model to output\\resnet101.h5\n",
      " 93/250 [==========>...................] - ETA: 2:16 - loss: 1.2680 - accuracy: 0.5501\n",
      "Epoch 1: accuracy improved from 0.55007 to 0.55187, saving model to output\\resnet101.h5\n",
      " 94/250 [==========>...................] - ETA: 2:16 - loss: 1.2624 - accuracy: 0.5519\n",
      "Epoch 1: accuracy improved from 0.55187 to 0.55232, saving model to output\\resnet101.h5\n",
      " 95/250 [==========>...................] - ETA: 2:15 - loss: 1.2603 - accuracy: 0.5523\n",
      "Epoch 1: accuracy improved from 0.55232 to 0.55472, saving model to output\\resnet101.h5\n",
      " 96/250 [==========>...................] - ETA: 2:14 - loss: 1.2540 - accuracy: 0.5547\n",
      "Epoch 1: accuracy improved from 0.55472 to 0.55642, saving model to output\\resnet101.h5\n",
      " 97/250 [==========>...................] - ETA: 2:13 - loss: 1.2493 - accuracy: 0.5564\n",
      "Epoch 1: accuracy improved from 0.55642 to 0.55712, saving model to output\\resnet101.h5\n",
      " 98/250 [==========>...................] - ETA: 2:12 - loss: 1.2459 - accuracy: 0.5571\n",
      "Epoch 1: accuracy improved from 0.55712 to 0.55877, saving model to output\\resnet101.h5\n",
      " 99/250 [==========>...................] - ETA: 2:12 - loss: 1.2405 - accuracy: 0.5588\n",
      "Epoch 1: accuracy improved from 0.55877 to 0.56069, saving model to output\\resnet101.h5\n",
      "100/250 [===========>..................] - ETA: 2:11 - loss: 1.2343 - accuracy: 0.5607\n",
      "Epoch 1: accuracy improved from 0.56069 to 0.56196, saving model to output\\resnet101.h5\n",
      "101/250 [===========>..................] - ETA: 2:10 - loss: 1.2288 - accuracy: 0.5620\n",
      "Epoch 1: accuracy improved from 0.56196 to 0.56412, saving model to output\\resnet101.h5\n",
      "102/250 [===========>..................] - ETA: 2:09 - loss: 1.2229 - accuracy: 0.5641\n",
      "Epoch 1: accuracy improved from 0.56412 to 0.56654, saving model to output\\resnet101.h5\n",
      "103/250 [===========>..................] - ETA: 2:09 - loss: 1.2185 - accuracy: 0.5665\n",
      "Epoch 1: accuracy improved from 0.56654 to 0.56832, saving model to output\\resnet101.h5\n",
      "104/250 [===========>..................] - ETA: 2:08 - loss: 1.2141 - accuracy: 0.5683\n",
      "Epoch 1: accuracy improved from 0.56832 to 0.56976, saving model to output\\resnet101.h5\n",
      "105/250 [===========>..................] - ETA: 2:07 - loss: 1.2110 - accuracy: 0.5698\n",
      "Epoch 1: accuracy improved from 0.56976 to 0.57117, saving model to output\\resnet101.h5\n",
      "106/250 [===========>..................] - ETA: 2:06 - loss: 1.2067 - accuracy: 0.5712\n",
      "Epoch 1: accuracy improved from 0.57117 to 0.57227, saving model to output\\resnet101.h5\n",
      "107/250 [===========>..................] - ETA: 2:06 - loss: 1.2018 - accuracy: 0.5723\n",
      "Epoch 1: accuracy improved from 0.57227 to 0.57451, saving model to output\\resnet101.h5\n",
      "108/250 [===========>..................] - ETA: 2:06 - loss: 1.1954 - accuracy: 0.5745\n",
      "Epoch 1: accuracy improved from 0.57451 to 0.57526, saving model to output\\resnet101.h5\n",
      "109/250 [============>.................] - ETA: 2:05 - loss: 1.1929 - accuracy: 0.5753\n",
      "Epoch 1: accuracy improved from 0.57526 to 0.57714, saving model to output\\resnet101.h5\n",
      "110/250 [============>.................] - ETA: 2:04 - loss: 1.1900 - accuracy: 0.5771\n",
      "Epoch 1: accuracy improved from 0.57714 to 0.57899, saving model to output\\resnet101.h5\n",
      "111/250 [============>.................] - ETA: 2:03 - loss: 1.1849 - accuracy: 0.5790\n",
      "Epoch 1: accuracy improved from 0.57899 to 0.58053, saving model to output\\resnet101.h5\n",
      "112/250 [============>.................] - ETA: 2:02 - loss: 1.1811 - accuracy: 0.5805\n",
      "Epoch 1: accuracy improved from 0.58053 to 0.58120, saving model to output\\resnet101.h5\n",
      "113/250 [============>.................] - ETA: 2:01 - loss: 1.1776 - accuracy: 0.5812\n",
      "Epoch 1: accuracy improved from 0.58120 to 0.58214, saving model to output\\resnet101.h5\n",
      "114/250 [============>.................] - ETA: 2:01 - loss: 1.1758 - accuracy: 0.5821\n",
      "Epoch 1: accuracy improved from 0.58214 to 0.58361, saving model to output\\resnet101.h5\n",
      "115/250 [============>.................] - ETA: 2:00 - loss: 1.1712 - accuracy: 0.5836\n",
      "Epoch 1: accuracy improved from 0.58361 to 0.58478, saving model to output\\resnet101.h5\n",
      "116/250 [============>.................] - ETA: 1:59 - loss: 1.1683 - accuracy: 0.5848\n",
      "Epoch 1: accuracy improved from 0.58478 to 0.58593, saving model to output\\resnet101.h5\n",
      "117/250 [=============>................] - ETA: 1:58 - loss: 1.1645 - accuracy: 0.5859\n",
      "Epoch 1: accuracy improved from 0.58593 to 0.58733, saving model to output\\resnet101.h5\n",
      "118/250 [=============>................] - ETA: 1:57 - loss: 1.1600 - accuracy: 0.5873\n",
      "Epoch 1: accuracy improved from 0.58733 to 0.58870, saving model to output\\resnet101.h5\n",
      "119/250 [=============>................] - ETA: 1:57 - loss: 1.1556 - accuracy: 0.5887\n",
      "Epoch 1: accuracy improved from 0.58870 to 0.58979, saving model to output\\resnet101.h5\n",
      "120/250 [=============>................] - ETA: 1:56 - loss: 1.1525 - accuracy: 0.5898\n",
      "Epoch 1: accuracy did not improve from 0.58979\n",
      "121/250 [=============>................] - ETA: 1:54 - loss: 1.1513 - accuracy: 0.5893\n",
      "Epoch 1: accuracy improved from 0.58979 to 0.59089, saving model to output\\resnet101.h5\n",
      "122/250 [=============>................] - ETA: 1:54 - loss: 1.1463 - accuracy: 0.5909\n",
      "Epoch 1: accuracy improved from 0.59089 to 0.59219, saving model to output\\resnet101.h5\n",
      "123/250 [=============>................] - ETA: 1:53 - loss: 1.1427 - accuracy: 0.5922\n",
      "Epoch 1: accuracy did not improve from 0.59219\n",
      "124/250 [=============>................] - ETA: 1:51 - loss: 1.1421 - accuracy: 0.5919\n",
      "Epoch 1: accuracy improved from 0.59219 to 0.59347, saving model to output\\resnet101.h5\n",
      "125/250 [==============>...............] - ETA: 1:51 - loss: 1.1387 - accuracy: 0.5935\n",
      "Epoch 1: accuracy improved from 0.59347 to 0.59646, saving model to output\\resnet101.h5\n",
      "126/250 [==============>...............] - ETA: 1:50 - loss: 1.1321 - accuracy: 0.5965\n",
      "Epoch 1: accuracy improved from 0.59646 to 0.59792, saving model to output\\resnet101.h5\n",
      "127/250 [==============>...............] - ETA: 1:49 - loss: 1.1290 - accuracy: 0.5979\n",
      "Epoch 1: accuracy improved from 0.59792 to 0.59936, saving model to output\\resnet101.h5\n",
      "128/250 [==============>...............] - ETA: 1:48 - loss: 1.1253 - accuracy: 0.5994\n",
      "Epoch 1: accuracy improved from 0.59936 to 0.60102, saving model to output\\resnet101.h5\n",
      "129/250 [==============>...............] - ETA: 1:47 - loss: 1.1210 - accuracy: 0.6010\n",
      "Epoch 1: accuracy improved from 0.60102 to 0.60193, saving model to output\\resnet101.h5\n",
      "130/250 [==============>...............] - ETA: 1:46 - loss: 1.1195 - accuracy: 0.6019\n",
      "Epoch 1: accuracy improved from 0.60193 to 0.60283, saving model to output\\resnet101.h5\n",
      "131/250 [==============>...............] - ETA: 1:46 - loss: 1.1162 - accuracy: 0.6028\n",
      "Epoch 1: accuracy improved from 0.60283 to 0.60395, saving model to output\\resnet101.h5\n",
      "132/250 [==============>...............] - ETA: 1:45 - loss: 1.1130 - accuracy: 0.6039\n",
      "Epoch 1: accuracy improved from 0.60395 to 0.60529, saving model to output\\resnet101.h5\n",
      "133/250 [==============>...............] - ETA: 1:44 - loss: 1.1092 - accuracy: 0.6053\n",
      "Epoch 1: accuracy improved from 0.60529 to 0.60661, saving model to output\\resnet101.h5\n",
      "134/250 [===============>..............] - ETA: 1:43 - loss: 1.1061 - accuracy: 0.6066\n",
      "Epoch 1: accuracy improved from 0.60661 to 0.60767, saving model to output\\resnet101.h5\n",
      "135/250 [===============>..............] - ETA: 1:42 - loss: 1.1030 - accuracy: 0.6077\n",
      "Epoch 1: accuracy improved from 0.60767 to 0.60849, saving model to output\\resnet101.h5\n",
      "136/250 [===============>..............] - ETA: 1:41 - loss: 1.1008 - accuracy: 0.6085\n",
      "Epoch 1: accuracy improved from 0.60849 to 0.60976, saving model to output\\resnet101.h5\n",
      "137/250 [===============>..............] - ETA: 1:40 - loss: 1.0972 - accuracy: 0.6098\n",
      "Epoch 1: accuracy improved from 0.60976 to 0.61146, saving model to output\\resnet101.h5\n",
      "138/250 [===============>..............] - ETA: 1:40 - loss: 1.0937 - accuracy: 0.6115\n",
      "Epoch 1: accuracy improved from 0.61146 to 0.61292, saving model to output\\resnet101.h5\n",
      "139/250 [===============>..............] - ETA: 1:39 - loss: 1.0896 - accuracy: 0.6129\n",
      "Epoch 1: accuracy did not improve from 0.61292\n",
      "140/250 [===============>..............] - ETA: 1:37 - loss: 1.0880 - accuracy: 0.6128\n",
      "Epoch 1: accuracy improved from 0.61292 to 0.61398, saving model to output\\resnet101.h5\n",
      "141/250 [===============>..............] - ETA: 1:37 - loss: 1.0846 - accuracy: 0.6140\n",
      "Epoch 1: accuracy improved from 0.61398 to 0.61583, saving model to output\\resnet101.h5\n",
      "142/250 [================>.............] - ETA: 1:36 - loss: 1.0804 - accuracy: 0.6158\n",
      "Epoch 1: accuracy improved from 0.61583 to 0.61721, saving model to output\\resnet101.h5\n",
      "143/250 [================>.............] - ETA: 1:35 - loss: 1.0775 - accuracy: 0.6172\n",
      "Epoch 1: accuracy improved from 0.61721 to 0.61770, saving model to output\\resnet101.h5\n",
      "144/250 [================>.............] - ETA: 1:34 - loss: 1.0743 - accuracy: 0.6177\n",
      "Epoch 1: accuracy improved from 0.61770 to 0.61883, saving model to output\\resnet101.h5\n",
      "145/250 [================>.............] - ETA: 1:33 - loss: 1.0704 - accuracy: 0.6188\n",
      "Epoch 1: accuracy improved from 0.61883 to 0.61952, saving model to output\\resnet101.h5\n",
      "146/250 [================>.............] - ETA: 1:32 - loss: 1.0672 - accuracy: 0.6195\n",
      "Epoch 1: accuracy improved from 0.61952 to 0.62062, saving model to output\\resnet101.h5\n",
      "147/250 [================>.............] - ETA: 1:32 - loss: 1.0642 - accuracy: 0.6206\n",
      "Epoch 1: accuracy improved from 0.62062 to 0.62235, saving model to output\\resnet101.h5\n",
      "148/250 [================>.............] - ETA: 1:31 - loss: 1.0593 - accuracy: 0.6223\n",
      "Epoch 1: accuracy improved from 0.62235 to 0.62321, saving model to output\\resnet101.h5\n",
      "149/250 [================>.............] - ETA: 1:30 - loss: 1.0560 - accuracy: 0.6232\n",
      "Epoch 1: accuracy improved from 0.62321 to 0.62385, saving model to output\\resnet101.h5\n",
      "150/250 [=================>............] - ETA: 1:29 - loss: 1.0545 - accuracy: 0.6238\n",
      "Epoch 1: accuracy improved from 0.62385 to 0.62469, saving model to output\\resnet101.h5\n",
      "151/250 [=================>............] - ETA: 1:28 - loss: 1.0517 - accuracy: 0.6247\n",
      "Epoch 1: accuracy improved from 0.62469 to 0.62572, saving model to output\\resnet101.h5\n",
      "152/250 [=================>............] - ETA: 1:27 - loss: 1.0493 - accuracy: 0.6257\n",
      "Epoch 1: accuracy improved from 0.62572 to 0.62715, saving model to output\\resnet101.h5\n",
      "153/250 [=================>............] - ETA: 1:27 - loss: 1.0451 - accuracy: 0.6272\n",
      "Epoch 1: accuracy improved from 0.62715 to 0.62734, saving model to output\\resnet101.h5\n",
      "154/250 [=================>............] - ETA: 1:26 - loss: 1.0433 - accuracy: 0.6273\n",
      "Epoch 1: accuracy improved from 0.62734 to 0.62895, saving model to output\\resnet101.h5\n",
      "155/250 [=================>............] - ETA: 1:25 - loss: 1.0389 - accuracy: 0.6289\n",
      "Epoch 1: accuracy improved from 0.62895 to 0.62993, saving model to output\\resnet101.h5\n",
      "156/250 [=================>............] - ETA: 1:24 - loss: 1.0354 - accuracy: 0.6299\n",
      "Epoch 1: accuracy improved from 0.62993 to 0.63090, saving model to output\\resnet101.h5\n",
      "157/250 [=================>............] - ETA: 1:23 - loss: 1.0335 - accuracy: 0.6309\n",
      "Epoch 1: accuracy improved from 0.63090 to 0.63245, saving model to output\\resnet101.h5\n",
      "158/250 [=================>............] - ETA: 1:22 - loss: 1.0294 - accuracy: 0.6324\n",
      "Epoch 1: accuracy improved from 0.63245 to 0.63398, saving model to output\\resnet101.h5\n",
      "159/250 [==================>...........] - ETA: 1:22 - loss: 1.0261 - accuracy: 0.6340\n",
      "Epoch 1: accuracy improved from 0.63398 to 0.63431, saving model to output\\resnet101.h5\n",
      "160/250 [==================>...........] - ETA: 1:21 - loss: 1.0249 - accuracy: 0.6343\n",
      "Epoch 1: accuracy improved from 0.63431 to 0.63562, saving model to output\\resnet101.h5\n",
      "161/250 [==================>...........] - ETA: 1:20 - loss: 1.0215 - accuracy: 0.6356\n",
      "Epoch 1: accuracy improved from 0.63562 to 0.63652, saving model to output\\resnet101.h5\n",
      "162/250 [==================>...........] - ETA: 1:19 - loss: 1.0194 - accuracy: 0.6365\n",
      "Epoch 1: accuracy improved from 0.63652 to 0.63780, saving model to output\\resnet101.h5\n",
      "163/250 [==================>...........] - ETA: 1:18 - loss: 1.0174 - accuracy: 0.6378\n",
      "Epoch 1: accuracy improved from 0.63780 to 0.63925, saving model to output\\resnet101.h5\n",
      "164/250 [==================>...........] - ETA: 1:17 - loss: 1.0142 - accuracy: 0.6393\n",
      "Epoch 1: accuracy improved from 0.63925 to 0.64011, saving model to output\\resnet101.h5\n",
      "165/250 [==================>...........] - ETA: 1:16 - loss: 1.0111 - accuracy: 0.6401\n",
      "Epoch 1: accuracy improved from 0.64011 to 0.64135, saving model to output\\resnet101.h5\n",
      "166/250 [==================>...........] - ETA: 1:16 - loss: 1.0082 - accuracy: 0.6413\n",
      "Epoch 1: accuracy improved from 0.64135 to 0.64237, saving model to output\\resnet101.h5\n",
      "167/250 [===================>..........] - ETA: 1:15 - loss: 1.0048 - accuracy: 0.6424\n",
      "Epoch 1: accuracy improved from 0.64237 to 0.64376, saving model to output\\resnet101.h5\n",
      "168/250 [===================>..........] - ETA: 1:14 - loss: 1.0007 - accuracy: 0.6438\n",
      "Epoch 1: accuracy improved from 0.64376 to 0.64421, saving model to output\\resnet101.h5\n",
      "169/250 [===================>..........] - ETA: 1:13 - loss: 0.9987 - accuracy: 0.6442\n",
      "Epoch 1: accuracy improved from 0.64421 to 0.64446, saving model to output\\resnet101.h5\n",
      "170/250 [===================>..........] - ETA: 1:12 - loss: 0.9973 - accuracy: 0.6445\n",
      "Epoch 1: accuracy improved from 0.64446 to 0.64563, saving model to output\\resnet101.h5\n",
      "171/250 [===================>..........] - ETA: 1:11 - loss: 0.9934 - accuracy: 0.6456\n",
      "Epoch 1: accuracy improved from 0.64563 to 0.64661, saving model to output\\resnet101.h5\n",
      "172/250 [===================>..........] - ETA: 1:10 - loss: 0.9912 - accuracy: 0.6466\n",
      "Epoch 1: accuracy improved from 0.64661 to 0.64739, saving model to output\\resnet101.h5\n",
      "173/250 [===================>..........] - ETA: 1:09 - loss: 0.9881 - accuracy: 0.6474\n",
      "Epoch 1: accuracy improved from 0.64739 to 0.64798, saving model to output\\resnet101.h5\n",
      "174/250 [===================>..........] - ETA: 1:08 - loss: 0.9860 - accuracy: 0.6480\n",
      "Epoch 1: accuracy improved from 0.64798 to 0.64875, saving model to output\\resnet101.h5\n",
      "175/250 [====================>.........] - ETA: 1:07 - loss: 0.9844 - accuracy: 0.6487\n",
      "Epoch 1: accuracy improved from 0.64875 to 0.64986, saving model to output\\resnet101.h5\n",
      "176/250 [====================>.........] - ETA: 1:06 - loss: 0.9810 - accuracy: 0.6499\n",
      "Epoch 1: accuracy improved from 0.64986 to 0.65113, saving model to output\\resnet101.h5\n",
      "177/250 [====================>.........] - ETA: 1:05 - loss: 0.9777 - accuracy: 0.6511\n",
      "Epoch 1: accuracy improved from 0.65113 to 0.65187, saving model to output\\resnet101.h5\n",
      "178/250 [====================>.........] - ETA: 1:05 - loss: 0.9761 - accuracy: 0.6519\n",
      "Epoch 1: accuracy improved from 0.65187 to 0.65312, saving model to output\\resnet101.h5\n",
      "179/250 [====================>.........] - ETA: 1:04 - loss: 0.9732 - accuracy: 0.6531\n",
      "Epoch 1: accuracy improved from 0.65312 to 0.65401, saving model to output\\resnet101.h5\n",
      "180/250 [====================>.........] - ETA: 1:03 - loss: 0.9718 - accuracy: 0.6540\n",
      "Epoch 1: accuracy improved from 0.65401 to 0.65489, saving model to output\\resnet101.h5\n",
      "181/250 [====================>.........] - ETA: 1:02 - loss: 0.9690 - accuracy: 0.6549\n",
      "Epoch 1: accuracy improved from 0.65489 to 0.65541, saving model to output\\resnet101.h5\n",
      "182/250 [====================>.........] - ETA: 1:01 - loss: 0.9668 - accuracy: 0.6554\n",
      "Epoch 1: accuracy improved from 0.65541 to 0.65610, saving model to output\\resnet101.h5\n",
      "183/250 [====================>.........] - ETA: 1:00 - loss: 0.9646 - accuracy: 0.6561\n",
      "Epoch 1: accuracy improved from 0.65610 to 0.65627, saving model to output\\resnet101.h5\n",
      "184/250 [=====================>........] - ETA: 59s - loss: 0.9635 - accuracy: 0.6563 \n",
      "Epoch 1: accuracy improved from 0.65627 to 0.65695, saving model to output\\resnet101.h5\n",
      "185/250 [=====================>........] - ETA: 58s - loss: 0.9615 - accuracy: 0.6569\n",
      "Epoch 1: accuracy did not improve from 0.65695\n",
      "186/250 [=====================>........] - ETA: 57s - loss: 0.9606 - accuracy: 0.6566\n",
      "Epoch 1: accuracy improved from 0.65695 to 0.65778, saving model to output\\resnet101.h5\n",
      "187/250 [=====================>........] - ETA: 56s - loss: 0.9576 - accuracy: 0.6578\n",
      "Epoch 1: accuracy improved from 0.65778 to 0.65811, saving model to output\\resnet101.h5\n",
      "188/250 [=====================>........] - ETA: 56s - loss: 0.9566 - accuracy: 0.6581\n",
      "Epoch 1: accuracy improved from 0.65811 to 0.65892, saving model to output\\resnet101.h5\n",
      "189/250 [=====================>........] - ETA: 55s - loss: 0.9542 - accuracy: 0.6589\n",
      "Epoch 1: accuracy improved from 0.65892 to 0.66023, saving model to output\\resnet101.h5\n",
      "190/250 [=====================>........] - ETA: 54s - loss: 0.9506 - accuracy: 0.6602\n",
      "Epoch 1: accuracy improved from 0.66023 to 0.66103, saving model to output\\resnet101.h5\n",
      "191/250 [=====================>........] - ETA: 53s - loss: 0.9487 - accuracy: 0.6610\n",
      "Epoch 1: accuracy improved from 0.66103 to 0.66199, saving model to output\\resnet101.h5\n",
      "192/250 [======================>.......] - ETA: 52s - loss: 0.9471 - accuracy: 0.6620\n",
      "Epoch 1: accuracy improved from 0.66199 to 0.66293, saving model to output\\resnet101.h5\n",
      "193/250 [======================>.......] - ETA: 51s - loss: 0.9444 - accuracy: 0.6629\n",
      "Epoch 1: accuracy improved from 0.66293 to 0.66387, saving model to output\\resnet101.h5\n",
      "194/250 [======================>.......] - ETA: 50s - loss: 0.9423 - accuracy: 0.6639\n",
      "Epoch 1: accuracy improved from 0.66387 to 0.66415, saving model to output\\resnet101.h5\n",
      "195/250 [======================>.......] - ETA: 49s - loss: 0.9404 - accuracy: 0.6641\n",
      "Epoch 1: accuracy improved from 0.66415 to 0.66459, saving model to output\\resnet101.h5\n",
      "196/250 [======================>.......] - ETA: 48s - loss: 0.9385 - accuracy: 0.6646\n",
      "Epoch 1: accuracy improved from 0.66459 to 0.66566, saving model to output\\resnet101.h5\n",
      "197/250 [======================>.......] - ETA: 48s - loss: 0.9355 - accuracy: 0.6657\n",
      "Epoch 1: accuracy improved from 0.66566 to 0.66624, saving model to output\\resnet101.h5\n",
      "198/250 [======================>.......] - ETA: 47s - loss: 0.9335 - accuracy: 0.6662\n",
      "Epoch 1: accuracy improved from 0.66624 to 0.66698, saving model to output\\resnet101.h5\n",
      "199/250 [======================>.......] - ETA: 46s - loss: 0.9308 - accuracy: 0.6670\n",
      "Epoch 1: accuracy improved from 0.66698 to 0.66771, saving model to output\\resnet101.h5\n",
      "200/250 [=======================>......] - ETA: 45s - loss: 0.9292 - accuracy: 0.6677\n",
      "Epoch 1: accuracy improved from 0.66771 to 0.66828, saving model to output\\resnet101.h5\n",
      "201/250 [=======================>......] - ETA: 44s - loss: 0.9278 - accuracy: 0.6683\n",
      "Epoch 1: accuracy improved from 0.66828 to 0.66915, saving model to output\\resnet101.h5\n",
      "202/250 [=======================>......] - ETA: 43s - loss: 0.9255 - accuracy: 0.6691\n",
      "Epoch 1: accuracy improved from 0.66915 to 0.66970, saving model to output\\resnet101.h5\n",
      "203/250 [=======================>......] - ETA: 42s - loss: 0.9244 - accuracy: 0.6697\n",
      "Epoch 1: accuracy improved from 0.66970 to 0.67041, saving model to output\\resnet101.h5\n",
      "204/250 [=======================>......] - ETA: 41s - loss: 0.9222 - accuracy: 0.6704\n",
      "Epoch 1: accuracy improved from 0.67041 to 0.67141, saving model to output\\resnet101.h5\n",
      "205/250 [=======================>......] - ETA: 40s - loss: 0.9191 - accuracy: 0.6714\n",
      "Epoch 1: accuracy improved from 0.67141 to 0.67164, saving model to output\\resnet101.h5\n",
      "206/250 [=======================>......] - ETA: 40s - loss: 0.9178 - accuracy: 0.6716\n",
      "Epoch 1: accuracy improved from 0.67164 to 0.67262, saving model to output\\resnet101.h5\n",
      "207/250 [=======================>......] - ETA: 39s - loss: 0.9154 - accuracy: 0.6726\n",
      "Epoch 1: accuracy improved from 0.67262 to 0.67300, saving model to output\\resnet101.h5\n",
      "208/250 [=======================>......] - ETA: 38s - loss: 0.9136 - accuracy: 0.6730\n",
      "Epoch 1: accuracy improved from 0.67300 to 0.67337, saving model to output\\resnet101.h5\n",
      "209/250 [========================>.....] - ETA: 37s - loss: 0.9126 - accuracy: 0.6734\n",
      "Epoch 1: accuracy improved from 0.67337 to 0.67403, saving model to output\\resnet101.h5\n",
      "210/250 [========================>.....] - ETA: 36s - loss: 0.9111 - accuracy: 0.6740\n",
      "Epoch 1: accuracy improved from 0.67403 to 0.67424, saving model to output\\resnet101.h5\n",
      "211/250 [========================>.....] - ETA: 35s - loss: 0.9096 - accuracy: 0.6742\n",
      "Epoch 1: accuracy improved from 0.67424 to 0.67431, saving model to output\\resnet101.h5\n",
      "212/250 [========================>.....] - ETA: 34s - loss: 0.9087 - accuracy: 0.6743\n",
      "Epoch 1: accuracy improved from 0.67431 to 0.67466, saving model to output\\resnet101.h5\n",
      "213/250 [========================>.....] - ETA: 33s - loss: 0.9074 - accuracy: 0.6747\n",
      "Epoch 1: accuracy improved from 0.67466 to 0.67516, saving model to output\\resnet101.h5\n",
      "214/250 [========================>.....] - ETA: 32s - loss: 0.9059 - accuracy: 0.6752\n",
      "Epoch 1: accuracy improved from 0.67516 to 0.67536, saving model to output\\resnet101.h5\n",
      "215/250 [========================>.....] - ETA: 31s - loss: 0.9050 - accuracy: 0.6754\n",
      "Epoch 1: accuracy improved from 0.67536 to 0.67629, saving model to output\\resnet101.h5\n",
      "216/250 [========================>.....] - ETA: 31s - loss: 0.9033 - accuracy: 0.6763\n",
      "Epoch 1: accuracy improved from 0.67629 to 0.67663, saving model to output\\resnet101.h5\n",
      "217/250 [=========================>....] - ETA: 30s - loss: 0.9021 - accuracy: 0.6766\n",
      "Epoch 1: accuracy improved from 0.67663 to 0.67783, saving model to output\\resnet101.h5\n",
      "218/250 [=========================>....] - ETA: 29s - loss: 0.8996 - accuracy: 0.6778\n",
      "Epoch 1: accuracy improved from 0.67783 to 0.67816, saving model to output\\resnet101.h5\n",
      "219/250 [=========================>....] - ETA: 28s - loss: 0.8980 - accuracy: 0.6782\n",
      "Epoch 1: accuracy improved from 0.67816 to 0.67863, saving model to output\\resnet101.h5\n",
      "220/250 [=========================>....] - ETA: 27s - loss: 0.8962 - accuracy: 0.6786\n",
      "Epoch 1: accuracy improved from 0.67863 to 0.67924, saving model to output\\resnet101.h5\n",
      "221/250 [=========================>....] - ETA: 26s - loss: 0.8942 - accuracy: 0.6792\n",
      "Epoch 1: accuracy improved from 0.67924 to 0.67984, saving model to output\\resnet101.h5\n",
      "222/250 [=========================>....] - ETA: 25s - loss: 0.8922 - accuracy: 0.6798\n",
      "Epoch 1: accuracy did not improve from 0.67984\n",
      "223/250 [=========================>....] - ETA: 24s - loss: 0.8912 - accuracy: 0.6797\n",
      "Epoch 1: accuracy improved from 0.67984 to 0.68047, saving model to output\\resnet101.h5\n",
      "224/250 [=========================>....] - ETA: 23s - loss: 0.8892 - accuracy: 0.6805\n",
      "Epoch 1: accuracy did not improve from 0.68047\n",
      "225/250 [==========================>...] - ETA: 22s - loss: 0.8895 - accuracy: 0.6804\n",
      "Epoch 1: accuracy improved from 0.68047 to 0.68136, saving model to output\\resnet101.h5\n",
      "226/250 [==========================>...] - ETA: 21s - loss: 0.8872 - accuracy: 0.6814\n",
      "Epoch 1: accuracy improved from 0.68136 to 0.68194, saving model to output\\resnet101.h5\n",
      "227/250 [==========================>...] - ETA: 20s - loss: 0.8850 - accuracy: 0.6819\n",
      "Epoch 1: accuracy improved from 0.68194 to 0.68252, saving model to output\\resnet101.h5\n",
      "228/250 [==========================>...] - ETA: 20s - loss: 0.8833 - accuracy: 0.6825\n",
      "Epoch 1: accuracy improved from 0.68252 to 0.68322, saving model to output\\resnet101.h5\n",
      "229/250 [==========================>...] - ETA: 19s - loss: 0.8816 - accuracy: 0.6832\n",
      "Epoch 1: accuracy improved from 0.68322 to 0.68406, saving model to output\\resnet101.h5\n",
      "230/250 [==========================>...] - ETA: 18s - loss: 0.8803 - accuracy: 0.6841\n",
      "Epoch 1: accuracy improved from 0.68406 to 0.68462, saving model to output\\resnet101.h5\n",
      "231/250 [==========================>...] - ETA: 17s - loss: 0.8785 - accuracy: 0.6846\n",
      "Epoch 1: accuracy improved from 0.68462 to 0.68531, saving model to output\\resnet101.h5\n",
      "232/250 [==========================>...] - ETA: 16s - loss: 0.8767 - accuracy: 0.6853\n",
      "Epoch 1: accuracy improved from 0.68531 to 0.68585, saving model to output\\resnet101.h5\n",
      "233/250 [==========================>...] - ETA: 15s - loss: 0.8746 - accuracy: 0.6859\n",
      "Epoch 1: accuracy did not improve from 0.68585\n",
      "234/250 [===========================>..] - ETA: 14s - loss: 0.8750 - accuracy: 0.6852\n",
      "Epoch 1: accuracy improved from 0.68585 to 0.68587, saving model to output\\resnet101.h5\n",
      "235/250 [===========================>..] - ETA: 13s - loss: 0.8732 - accuracy: 0.6859\n",
      "Epoch 1: accuracy improved from 0.68587 to 0.68654, saving model to output\\resnet101.h5\n",
      "236/250 [===========================>..] - ETA: 12s - loss: 0.8718 - accuracy: 0.6865\n",
      "Epoch 1: accuracy improved from 0.68654 to 0.68707, saving model to output\\resnet101.h5\n",
      "237/250 [===========================>..] - ETA: 11s - loss: 0.8706 - accuracy: 0.6871\n",
      "Epoch 1: accuracy improved from 0.68707 to 0.68747, saving model to output\\resnet101.h5\n",
      "238/250 [===========================>..] - ETA: 11s - loss: 0.8692 - accuracy: 0.6875\n",
      "Epoch 1: accuracy improved from 0.68747 to 0.68773, saving model to output\\resnet101.h5\n",
      "239/250 [===========================>..] - ETA: 10s - loss: 0.8681 - accuracy: 0.6877\n",
      "Epoch 1: accuracy improved from 0.68773 to 0.68812, saving model to output\\resnet101.h5\n",
      "240/250 [===========================>..] - ETA: 9s - loss: 0.8667 - accuracy: 0.6881 \n",
      "Epoch 1: accuracy improved from 0.68812 to 0.68864, saving model to output\\resnet101.h5\n",
      "241/250 [===========================>..] - ETA: 8s - loss: 0.8649 - accuracy: 0.6886\n",
      "Epoch 1: accuracy improved from 0.68864 to 0.68902, saving model to output\\resnet101.h5\n",
      "242/250 [============================>.] - ETA: 7s - loss: 0.8633 - accuracy: 0.6890\n",
      "Epoch 1: accuracy improved from 0.68902 to 0.68979, saving model to output\\resnet101.h5\n",
      "243/250 [============================>.] - ETA: 6s - loss: 0.8617 - accuracy: 0.6898\n",
      "Epoch 1: accuracy improved from 0.68979 to 0.69055, saving model to output\\resnet101.h5\n",
      "244/250 [============================>.] - ETA: 5s - loss: 0.8601 - accuracy: 0.6905\n",
      "Epoch 1: accuracy improved from 0.69055 to 0.69130, saving model to output\\resnet101.h5\n",
      "245/250 [============================>.] - ETA: 4s - loss: 0.8581 - accuracy: 0.6913\n",
      "Epoch 1: accuracy improved from 0.69130 to 0.69205, saving model to output\\resnet101.h5\n",
      "246/250 [============================>.] - ETA: 3s - loss: 0.8569 - accuracy: 0.6921\n",
      "Epoch 1: accuracy improved from 0.69205 to 0.69229, saving model to output\\resnet101.h5\n",
      "247/250 [============================>.] - ETA: 2s - loss: 0.8556 - accuracy: 0.6923\n",
      "Epoch 1: accuracy improved from 0.69229 to 0.69277, saving model to output\\resnet101.h5\n",
      "248/250 [============================>.] - ETA: 1s - loss: 0.8548 - accuracy: 0.6928\n",
      "Epoch 1: accuracy improved from 0.69277 to 0.69351, saving model to output\\resnet101.h5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.8531 - accuracy: 0.6935\n",
      "Epoch 1: accuracy improved from 0.69351 to 0.69424, saving model to output\\resnet101.h5\n",
      "250/250 [==============================] - 265s 1s/step - loss: 0.8513 - accuracy: 0.6942 - val_loss: 0.3030 - val_accuracy: 0.9244\n",
      "Epoch 2/15\n",
      "\n",
      "Epoch 2: accuracy improved from 0.69424 to 0.84375, saving model to output\\resnet101.h5\n",
      "  1/250 [..............................] - ETA: 4:47 - loss: 0.3915 - accuracy: 0.8438\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  2/250 [..............................] - ETA: 40s - loss: 0.3949 - accuracy: 0.8438 \n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  3/250 [..............................] - ETA: 56s - loss: 0.4131 - accuracy: 0.8333\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  4/250 [..............................] - ETA: 1:00 - loss: 0.4089 - accuracy: 0.8438\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  5/250 [..............................] - ETA: 1:03 - loss: 0.4175 - accuracy: 0.8438\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  6/250 [..............................] - ETA: 1:03 - loss: 0.4442 - accuracy: 0.8333\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  7/250 [..............................] - ETA: 1:04 - loss: 0.4352 - accuracy: 0.8348\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  8/250 [..............................] - ETA: 1:05 - loss: 0.4607 - accuracy: 0.8281\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "  9/250 [>.............................] - ETA: 1:05 - loss: 0.4733 - accuracy: 0.8299\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 10/250 [>.............................] - ETA: 1:04 - loss: 0.4917 - accuracy: 0.8219\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 11/250 [>.............................] - ETA: 59s - loss: 0.4910 - accuracy: 0.8253 \n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 12/250 [>.............................] - ETA: 1:02 - loss: 0.4730 - accuracy: 0.8352\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 13/250 [>.............................] - ETA: 1:02 - loss: 0.4943 - accuracy: 0.8283\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 14/250 [>.............................] - ETA: 1:02 - loss: 0.4821 - accuracy: 0.8294\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 15/250 [>.............................] - ETA: 1:02 - loss: 0.4995 - accuracy: 0.8261\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 16/250 [>.............................] - ETA: 1:02 - loss: 0.5042 - accuracy: 0.8211\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 17/250 [=>............................] - ETA: 1:03 - loss: 0.4919 - accuracy: 0.8244\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.4905 - accuracy: 0.8237\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.4891 - accuracy: 0.8231\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.4961 - accuracy: 0.8194\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 21/250 [=>............................] - ETA: 1:03 - loss: 0.4953 - accuracy: 0.8206\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.4903 - accuracy: 0.8231\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.4902 - accuracy: 0.8198\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 24/250 [=>............................] - ETA: 1:02 - loss: 0.4968 - accuracy: 0.8195\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.4978 - accuracy: 0.8218\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.5014 - accuracy: 0.8202\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.4987 - accuracy: 0.8199\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.4974 - accuracy: 0.8208\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.5005 - accuracy: 0.8172\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.5021 - accuracy: 0.8181\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.5024 - accuracy: 0.8169\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.5036 - accuracy: 0.8167\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.5035 - accuracy: 0.8166\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 0.5027 - accuracy: 0.8174\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.5008 - accuracy: 0.8209\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.4960 - accuracy: 0.8233\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.5007 - accuracy: 0.8222\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.4950 - accuracy: 0.8253\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.4940 - accuracy: 0.8249 \n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.4895 - accuracy: 0.8270\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.4928 - accuracy: 0.8243\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.4908 - accuracy: 0.8248\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.4897 - accuracy: 0.8245\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.4898 - accuracy: 0.8235\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.4881 - accuracy: 0.8246\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.4836 - accuracy: 0.8271\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.4823 - accuracy: 0.8268\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.4887 - accuracy: 0.8245\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.4860 - accuracy: 0.8262\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.4836 - accuracy: 0.8266\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 51/250 [=====>........................] - ETA: 57s - loss: 0.4852 - accuracy: 0.8263\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 52/250 [=====>........................] - ETA: 57s - loss: 0.4892 - accuracy: 0.8248\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 53/250 [=====>........................] - ETA: 57s - loss: 0.4828 - accuracy: 0.8282\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.4801 - accuracy: 0.8290\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 55/250 [=====>........................] - ETA: 56s - loss: 0.4773 - accuracy: 0.8299\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 56/250 [=====>........................] - ETA: 56s - loss: 0.4737 - accuracy: 0.8318\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 57/250 [=====>........................] - ETA: 55s - loss: 0.4708 - accuracy: 0.8326\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 58/250 [=====>........................] - ETA: 55s - loss: 0.4733 - accuracy: 0.8317\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 59/250 [======>.......................] - ETA: 55s - loss: 0.4718 - accuracy: 0.8324\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 60/250 [======>.......................] - ETA: 54s - loss: 0.4694 - accuracy: 0.8337\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 61/250 [======>.......................] - ETA: 54s - loss: 0.4715 - accuracy: 0.8333\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 62/250 [======>.......................] - ETA: 54s - loss: 0.4708 - accuracy: 0.8335\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 63/250 [======>.......................] - ETA: 54s - loss: 0.4681 - accuracy: 0.8347\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.4684 - accuracy: 0.8343\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 65/250 [======>.......................] - ETA: 53s - loss: 0.4676 - accuracy: 0.8345\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 66/250 [======>.......................] - ETA: 53s - loss: 0.4665 - accuracy: 0.8346\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 67/250 [=======>......................] - ETA: 53s - loss: 0.4651 - accuracy: 0.8352\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.4669 - accuracy: 0.8349\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 69/250 [=======>......................] - ETA: 52s - loss: 0.4650 - accuracy: 0.8359\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.4635 - accuracy: 0.8365\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.4636 - accuracy: 0.8366\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 72/250 [=======>......................] - ETA: 51s - loss: 0.4620 - accuracy: 0.8371\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.4642 - accuracy: 0.8368\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.4657 - accuracy: 0.8369\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.4635 - accuracy: 0.8382\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 76/250 [========>.....................] - ETA: 50s - loss: 0.4666 - accuracy: 0.8375\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.4647 - accuracy: 0.8388\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.4678 - accuracy: 0.8372\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 79/250 [========>.....................] - ETA: 49s - loss: 0.4669 - accuracy: 0.8369\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.4649 - accuracy: 0.8374\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.4637 - accuracy: 0.8375\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 82/250 [========>.....................] - ETA: 48s - loss: 0.4642 - accuracy: 0.8379\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 83/250 [========>.....................] - ETA: 49s - loss: 0.4626 - accuracy: 0.8388\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.4641 - accuracy: 0.8377\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.4650 - accuracy: 0.8374\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.4658 - accuracy: 0.8375\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 87/250 [=========>....................] - ETA: 48s - loss: 0.4650 - accuracy: 0.8376\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 88/250 [=========>....................] - ETA: 48s - loss: 0.4626 - accuracy: 0.8387\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 89/250 [=========>....................] - ETA: 48s - loss: 0.4621 - accuracy: 0.8391\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.4634 - accuracy: 0.8378\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 91/250 [=========>....................] - ETA: 47s - loss: 0.4645 - accuracy: 0.8371\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 92/250 [==========>...................] - ETA: 47s - loss: 0.4639 - accuracy: 0.8379\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 93/250 [==========>...................] - ETA: 47s - loss: 0.4626 - accuracy: 0.8380\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.4603 - accuracy: 0.8390\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 95/250 [==========>...................] - ETA: 46s - loss: 0.4622 - accuracy: 0.8384\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 96/250 [==========>...................] - ETA: 46s - loss: 0.4618 - accuracy: 0.8381\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.4605 - accuracy: 0.8388\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 98/250 [==========>...................] - ETA: 45s - loss: 0.4637 - accuracy: 0.8386\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      " 99/250 [==========>...................] - ETA: 45s - loss: 0.4665 - accuracy: 0.8380\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "100/250 [===========>..................] - ETA: 45s - loss: 0.4674 - accuracy: 0.8377\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.4650 - accuracy: 0.8387\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "102/250 [===========>..................] - ETA: 44s - loss: 0.4640 - accuracy: 0.8400\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "103/250 [===========>..................] - ETA: 44s - loss: 0.4647 - accuracy: 0.8400\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.4628 - accuracy: 0.8404\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.4638 - accuracy: 0.8395\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.4633 - accuracy: 0.8399\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "107/250 [===========>..................] - ETA: 43s - loss: 0.4631 - accuracy: 0.8396\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.4644 - accuracy: 0.8393\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.4616 - accuracy: 0.8405\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "110/250 [============>.................] - ETA: 42s - loss: 0.4625 - accuracy: 0.8409\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.4629 - accuracy: 0.8406\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "112/250 [============>.................] - ETA: 41s - loss: 0.4635 - accuracy: 0.8403\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.4619 - accuracy: 0.8412\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "114/250 [============>.................] - ETA: 41s - loss: 0.4613 - accuracy: 0.8415\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "115/250 [============>.................] - ETA: 40s - loss: 0.4597 - accuracy: 0.8421\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.4592 - accuracy: 0.8421\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "117/250 [=============>................] - ETA: 40s - loss: 0.4585 - accuracy: 0.8418\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "118/250 [=============>................] - ETA: 39s - loss: 0.4575 - accuracy: 0.8424\n",
      "Epoch 2: accuracy did not improve from 0.84375\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.4559 - accuracy: 0.8432\n",
      "Epoch 2: accuracy improved from 0.84375 to 0.84398, saving model to output\\resnet101.h5\n",
      "120/250 [=============>................] - ETA: 40s - loss: 0.4545 - accuracy: 0.8440\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "121/250 [=============>................] - ETA: 40s - loss: 0.4543 - accuracy: 0.8440\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "122/250 [=============>................] - ETA: 39s - loss: 0.4548 - accuracy: 0.8435\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "123/250 [=============>................] - ETA: 39s - loss: 0.4554 - accuracy: 0.8437\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "124/250 [=============>................] - ETA: 39s - loss: 0.4561 - accuracy: 0.8435\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "125/250 [==============>...............] - ETA: 38s - loss: 0.4570 - accuracy: 0.8435\n",
      "Epoch 2: accuracy did not improve from 0.84398\n",
      "126/250 [==============>...............] - ETA: 38s - loss: 0.4555 - accuracy: 0.8440\n",
      "Epoch 2: accuracy improved from 0.84398 to 0.84421, saving model to output\\resnet101.h5\n",
      "127/250 [==============>...............] - ETA: 39s - loss: 0.4540 - accuracy: 0.8442\n",
      "Epoch 2: accuracy improved from 0.84421 to 0.84446, saving model to output\\resnet101.h5\n",
      "128/250 [==============>...............] - ETA: 39s - loss: 0.4535 - accuracy: 0.8445\n",
      "Epoch 2: accuracy did not improve from 0.84446\n",
      "129/250 [==============>...............] - ETA: 39s - loss: 0.4527 - accuracy: 0.8444\n",
      "Epoch 2: accuracy improved from 0.84446 to 0.84493, saving model to output\\resnet101.h5\n",
      "130/250 [==============>...............] - ETA: 39s - loss: 0.4515 - accuracy: 0.8449\n",
      "Epoch 2: accuracy did not improve from 0.84493\n",
      "131/250 [==============>...............] - ETA: 38s - loss: 0.4523 - accuracy: 0.8447\n",
      "Epoch 2: accuracy did not improve from 0.84493\n",
      "132/250 [==============>...............] - ETA: 38s - loss: 0.4528 - accuracy: 0.8444\n",
      "Epoch 2: accuracy did not improve from 0.84493\n",
      "133/250 [==============>...............] - ETA: 38s - loss: 0.4510 - accuracy: 0.8449\n",
      "Epoch 2: accuracy improved from 0.84493 to 0.84513, saving model to output\\resnet101.h5\n",
      "134/250 [===============>..............] - ETA: 38s - loss: 0.4520 - accuracy: 0.8451\n",
      "Epoch 2: accuracy improved from 0.84513 to 0.84581, saving model to output\\resnet101.h5\n",
      "135/250 [===============>..............] - ETA: 38s - loss: 0.4516 - accuracy: 0.8458\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "136/250 [===============>..............] - ETA: 38s - loss: 0.4518 - accuracy: 0.8453\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "137/250 [===============>..............] - ETA: 37s - loss: 0.4530 - accuracy: 0.8453\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "138/250 [===============>..............] - ETA: 37s - loss: 0.4534 - accuracy: 0.8451\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "139/250 [===============>..............] - ETA: 36s - loss: 0.4522 - accuracy: 0.8453\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "140/250 [===============>..............] - ETA: 36s - loss: 0.4511 - accuracy: 0.8455\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "141/250 [===============>..............] - ETA: 36s - loss: 0.4521 - accuracy: 0.8453\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "142/250 [================>.............] - ETA: 35s - loss: 0.4517 - accuracy: 0.8453\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "143/250 [================>.............] - ETA: 35s - loss: 0.4527 - accuracy: 0.8446\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "144/250 [================>.............] - ETA: 35s - loss: 0.4523 - accuracy: 0.8448\n",
      "Epoch 2: accuracy did not improve from 0.84581\n",
      "145/250 [================>.............] - ETA: 34s - loss: 0.4520 - accuracy: 0.8455\n",
      "Epoch 2: accuracy improved from 0.84581 to 0.84609, saving model to output\\resnet101.h5\n",
      "146/250 [================>.............] - ETA: 34s - loss: 0.4505 - accuracy: 0.8461\n",
      "Epoch 2: accuracy improved from 0.84609 to 0.84629, saving model to output\\resnet101.h5\n",
      "147/250 [================>.............] - ETA: 34s - loss: 0.4504 - accuracy: 0.8463\n",
      "Epoch 2: accuracy did not improve from 0.84629\n",
      "148/250 [================>.............] - ETA: 34s - loss: 0.4508 - accuracy: 0.8463\n",
      "Epoch 2: accuracy did not improve from 0.84629\n",
      "149/250 [================>.............] - ETA: 34s - loss: 0.4505 - accuracy: 0.8460\n",
      "Epoch 2: accuracy did not improve from 0.84629\n",
      "150/250 [=================>............] - ETA: 33s - loss: 0.4506 - accuracy: 0.8458\n",
      "Epoch 2: accuracy did not improve from 0.84629\n",
      "151/250 [=================>............] - ETA: 33s - loss: 0.4507 - accuracy: 0.8456\n",
      "Epoch 2: accuracy did not improve from 0.84629\n",
      "152/250 [=================>............] - ETA: 33s - loss: 0.4494 - accuracy: 0.8462\n",
      "Epoch 2: accuracy improved from 0.84629 to 0.84639, saving model to output\\resnet101.h5\n",
      "153/250 [=================>............] - ETA: 33s - loss: 0.4491 - accuracy: 0.8464\n",
      "Epoch 2: accuracy improved from 0.84639 to 0.84658, saving model to output\\resnet101.h5\n",
      "154/250 [=================>............] - ETA: 33s - loss: 0.4482 - accuracy: 0.8466\n",
      "Epoch 2: accuracy did not improve from 0.84658\n",
      "155/250 [=================>............] - ETA: 32s - loss: 0.4482 - accuracy: 0.8462\n",
      "Epoch 2: accuracy did not improve from 0.84658\n",
      "156/250 [=================>............] - ETA: 32s - loss: 0.4482 - accuracy: 0.8461\n",
      "Epoch 2: accuracy improved from 0.84658 to 0.84672, saving model to output\\resnet101.h5\n",
      "157/250 [=================>............] - ETA: 32s - loss: 0.4466 - accuracy: 0.8467\n",
      "Epoch 2: accuracy improved from 0.84672 to 0.84690, saving model to output\\resnet101.h5\n",
      "158/250 [=================>............] - ETA: 32s - loss: 0.4462 - accuracy: 0.8469\n",
      "Epoch 2: accuracy improved from 0.84690 to 0.84728, saving model to output\\resnet101.h5\n",
      "159/250 [==================>...........] - ETA: 32s - loss: 0.4454 - accuracy: 0.8473\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "160/250 [==================>...........] - ETA: 31s - loss: 0.4475 - accuracy: 0.8455\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "161/250 [==================>...........] - ETA: 31s - loss: 0.4469 - accuracy: 0.8457\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "162/250 [==================>...........] - ETA: 30s - loss: 0.4465 - accuracy: 0.8457\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "163/250 [==================>...........] - ETA: 30s - loss: 0.4456 - accuracy: 0.8458\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "164/250 [==================>...........] - ETA: 30s - loss: 0.4456 - accuracy: 0.8456\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "165/250 [==================>...........] - ETA: 29s - loss: 0.4457 - accuracy: 0.8454\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "166/250 [==================>...........] - ETA: 29s - loss: 0.4464 - accuracy: 0.8450\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "167/250 [===================>..........] - ETA: 28s - loss: 0.4456 - accuracy: 0.8450\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "168/250 [===================>..........] - ETA: 28s - loss: 0.4469 - accuracy: 0.8445\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "169/250 [===================>..........] - ETA: 28s - loss: 0.4466 - accuracy: 0.8443\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "170/250 [===================>..........] - ETA: 27s - loss: 0.4457 - accuracy: 0.8446\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "171/250 [===================>..........] - ETA: 27s - loss: 0.4451 - accuracy: 0.8450\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "172/250 [===================>..........] - ETA: 27s - loss: 0.4450 - accuracy: 0.8450\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "173/250 [===================>..........] - ETA: 26s - loss: 0.4436 - accuracy: 0.8457\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "174/250 [===================>..........] - ETA: 26s - loss: 0.4430 - accuracy: 0.8459\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "175/250 [====================>.........] - ETA: 26s - loss: 0.4424 - accuracy: 0.8462\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "176/250 [====================>.........] - ETA: 25s - loss: 0.4424 - accuracy: 0.8462\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "177/250 [====================>.........] - ETA: 25s - loss: 0.4427 - accuracy: 0.8460\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "178/250 [====================>.........] - ETA: 24s - loss: 0.4433 - accuracy: 0.8458\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "179/250 [====================>.........] - ETA: 24s - loss: 0.4438 - accuracy: 0.8455\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "180/250 [====================>.........] - ETA: 24s - loss: 0.4445 - accuracy: 0.8455\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "181/250 [====================>.........] - ETA: 23s - loss: 0.4436 - accuracy: 0.8460\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "182/250 [====================>.........] - ETA: 23s - loss: 0.4437 - accuracy: 0.8461\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "183/250 [====================>.........] - ETA: 22s - loss: 0.4433 - accuracy: 0.8466\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "184/250 [=====================>........] - ETA: 22s - loss: 0.4434 - accuracy: 0.8463\n",
      "Epoch 2: accuracy did not improve from 0.84728\n",
      "185/250 [=====================>........] - ETA: 22s - loss: 0.4425 - accuracy: 0.8468\n",
      "Epoch 2: accuracy improved from 0.84728 to 0.84744, saving model to output\\resnet101.h5\n",
      "186/250 [=====================>........] - ETA: 22s - loss: 0.4412 - accuracy: 0.8474\n",
      "Epoch 2: accuracy did not improve from 0.84744\n",
      "187/250 [=====================>........] - ETA: 21s - loss: 0.4419 - accuracy: 0.8471\n",
      "Epoch 2: accuracy did not improve from 0.84744\n",
      "188/250 [=====================>........] - ETA: 21s - loss: 0.4423 - accuracy: 0.8472\n",
      "Epoch 2: accuracy improved from 0.84744 to 0.84754, saving model to output\\resnet101.h5\n",
      "189/250 [=====================>........] - ETA: 21s - loss: 0.4420 - accuracy: 0.8475\n",
      "Epoch 2: accuracy improved from 0.84754 to 0.84818, saving model to output\\resnet101.h5\n",
      "190/250 [=====================>........] - ETA: 21s - loss: 0.4408 - accuracy: 0.8482\n",
      "Epoch 2: accuracy improved from 0.84818 to 0.84833, saving model to output\\resnet101.h5\n",
      "191/250 [=====================>........] - ETA: 21s - loss: 0.4401 - accuracy: 0.8483\n",
      "Epoch 2: accuracy did not improve from 0.84833\n",
      "192/250 [======================>.......] - ETA: 20s - loss: 0.4395 - accuracy: 0.8481\n",
      "Epoch 2: accuracy improved from 0.84833 to 0.84860, saving model to output\\resnet101.h5\n",
      "193/250 [======================>.......] - ETA: 20s - loss: 0.4390 - accuracy: 0.8486\n",
      "Epoch 2: accuracy did not improve from 0.84860\n",
      "194/250 [======================>.......] - ETA: 20s - loss: 0.4384 - accuracy: 0.8484\n",
      "Epoch 2: accuracy improved from 0.84860 to 0.84887, saving model to output\\resnet101.h5\n",
      "195/250 [======================>.......] - ETA: 20s - loss: 0.4377 - accuracy: 0.8489\n",
      "Epoch 2: accuracy improved from 0.84887 to 0.84949, saving model to output\\resnet101.h5\n",
      "196/250 [======================>.......] - ETA: 19s - loss: 0.4367 - accuracy: 0.8495\n",
      "Epoch 2: accuracy did not improve from 0.84949\n",
      "197/250 [======================>.......] - ETA: 19s - loss: 0.4367 - accuracy: 0.8495\n",
      "Epoch 2: accuracy improved from 0.84949 to 0.85006, saving model to output\\resnet101.h5\n",
      "198/250 [======================>.......] - ETA: 19s - loss: 0.4354 - accuracy: 0.8501\n",
      "Epoch 2: accuracy did not improve from 0.85006\n",
      "199/250 [======================>.......] - ETA: 18s - loss: 0.4354 - accuracy: 0.8499\n",
      "Epoch 2: accuracy did not improve from 0.85006\n",
      "200/250 [=======================>......] - ETA: 18s - loss: 0.4348 - accuracy: 0.8498\n",
      "Epoch 2: accuracy did not improve from 0.85006\n",
      "201/250 [=======================>......] - ETA: 18s - loss: 0.4345 - accuracy: 0.8498\n",
      "Epoch 2: accuracy improved from 0.85006 to 0.85025, saving model to output\\resnet101.h5\n",
      "202/250 [=======================>......] - ETA: 18s - loss: 0.4339 - accuracy: 0.8502\n",
      "Epoch 2: accuracy did not improve from 0.85025\n",
      "203/250 [=======================>......] - ETA: 17s - loss: 0.4348 - accuracy: 0.8499\n",
      "Epoch 2: accuracy did not improve from 0.85025\n",
      "204/250 [=======================>......] - ETA: 17s - loss: 0.4342 - accuracy: 0.8500\n",
      "Epoch 2: accuracy improved from 0.85025 to 0.85031, saving model to output\\resnet101.h5\n",
      "205/250 [=======================>......] - ETA: 16s - loss: 0.4335 - accuracy: 0.8503\n",
      "Epoch 2: accuracy improved from 0.85031 to 0.85073, saving model to output\\resnet101.h5\n",
      "206/250 [=======================>......] - ETA: 16s - loss: 0.4328 - accuracy: 0.8507\n",
      "Epoch 2: accuracy improved from 0.85073 to 0.85130, saving model to output\\resnet101.h5\n",
      "207/250 [=======================>......] - ETA: 16s - loss: 0.4320 - accuracy: 0.8513\n",
      "Epoch 2: accuracy did not improve from 0.85130\n",
      "208/250 [=======================>......] - ETA: 16s - loss: 0.4321 - accuracy: 0.8513\n",
      "Epoch 2: accuracy improved from 0.85130 to 0.85153, saving model to output\\resnet101.h5\n",
      "209/250 [========================>.....] - ETA: 15s - loss: 0.4319 - accuracy: 0.8515\n",
      "Epoch 2: accuracy improved from 0.85153 to 0.85179, saving model to output\\resnet101.h5\n",
      "210/250 [========================>.....] - ETA: 15s - loss: 0.4312 - accuracy: 0.8518\n",
      "Epoch 2: accuracy did not improve from 0.85179\n",
      "211/250 [========================>.....] - ETA: 15s - loss: 0.4312 - accuracy: 0.8518\n",
      "Epoch 2: accuracy improved from 0.85179 to 0.85216, saving model to output\\resnet101.h5\n",
      "212/250 [========================>.....] - ETA: 14s - loss: 0.4308 - accuracy: 0.8522\n",
      "Epoch 2: accuracy did not improve from 0.85216\n",
      "213/250 [========================>.....] - ETA: 14s - loss: 0.4310 - accuracy: 0.8520\n",
      "Epoch 2: accuracy did not improve from 0.85216\n",
      "214/250 [========================>.....] - ETA: 14s - loss: 0.4302 - accuracy: 0.8521\n",
      "Epoch 2: accuracy improved from 0.85216 to 0.85233, saving model to output\\resnet101.h5\n",
      "215/250 [========================>.....] - ETA: 13s - loss: 0.4300 - accuracy: 0.8523\n",
      "Epoch 2: accuracy improved from 0.85233 to 0.85273, saving model to output\\resnet101.h5\n",
      "216/250 [========================>.....] - ETA: 13s - loss: 0.4296 - accuracy: 0.8527\n",
      "Epoch 2: accuracy improved from 0.85273 to 0.85312, saving model to output\\resnet101.h5\n",
      "217/250 [=========================>....] - ETA: 13s - loss: 0.4288 - accuracy: 0.8531\n",
      "Epoch 2: accuracy improved from 0.85312 to 0.85365, saving model to output\\resnet101.h5\n",
      "218/250 [=========================>....] - ETA: 12s - loss: 0.4281 - accuracy: 0.8537\n",
      "Epoch 2: accuracy did not improve from 0.85365\n",
      "219/250 [=========================>....] - ETA: 12s - loss: 0.4284 - accuracy: 0.8536\n",
      "Epoch 2: accuracy did not improve from 0.85365\n",
      "220/250 [=========================>....] - ETA: 11s - loss: 0.4282 - accuracy: 0.8536\n",
      "Epoch 2: accuracy improved from 0.85365 to 0.85380, saving model to output\\resnet101.h5\n",
      "221/250 [=========================>....] - ETA: 11s - loss: 0.4275 - accuracy: 0.8538\n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "222/250 [=========================>....] - ETA: 11s - loss: 0.4284 - accuracy: 0.8535\n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "223/250 [=========================>....] - ETA: 10s - loss: 0.4286 - accuracy: 0.8533\n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "224/250 [=========================>....] - ETA: 10s - loss: 0.4298 - accuracy: 0.8530\n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "225/250 [==========================>...] - ETA: 9s - loss: 0.4293 - accuracy: 0.8533 \n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "226/250 [==========================>...] - ETA: 9s - loss: 0.4295 - accuracy: 0.8533\n",
      "Epoch 2: accuracy did not improve from 0.85380\n",
      "227/250 [==========================>...] - ETA: 9s - loss: 0.4288 - accuracy: 0.8535\n",
      "Epoch 2: accuracy improved from 0.85380 to 0.85390, saving model to output\\resnet101.h5\n",
      "228/250 [==========================>...] - ETA: 8s - loss: 0.4280 - accuracy: 0.8539\n",
      "Epoch 2: accuracy improved from 0.85390 to 0.85400, saving model to output\\resnet101.h5\n",
      "229/250 [==========================>...] - ETA: 8s - loss: 0.4278 - accuracy: 0.8540\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "230/250 [==========================>...] - ETA: 8s - loss: 0.4283 - accuracy: 0.8538\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "231/250 [==========================>...] - ETA: 7s - loss: 0.4279 - accuracy: 0.8539\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "232/250 [==========================>...] - ETA: 7s - loss: 0.4284 - accuracy: 0.8537\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "233/250 [==========================>...] - ETA: 6s - loss: 0.4284 - accuracy: 0.8536\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "234/250 [===========================>..] - ETA: 6s - loss: 0.4288 - accuracy: 0.8535\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "235/250 [===========================>..] - ETA: 6s - loss: 0.4289 - accuracy: 0.8536\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "236/250 [===========================>..] - ETA: 5s - loss: 0.4285 - accuracy: 0.8537\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "237/250 [===========================>..] - ETA: 5s - loss: 0.4287 - accuracy: 0.8536\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "238/250 [===========================>..] - ETA: 4s - loss: 0.4293 - accuracy: 0.8535\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "239/250 [===========================>..] - ETA: 4s - loss: 0.4288 - accuracy: 0.8536\n",
      "Epoch 2: accuracy did not improve from 0.85400\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.4287 - accuracy: 0.8538\n",
      "Epoch 2: accuracy improved from 0.85400 to 0.85413, saving model to output\\resnet101.h5\n",
      "241/250 [===========================>..] - ETA: 3s - loss: 0.4278 - accuracy: 0.8541\n",
      "Epoch 2: accuracy did not improve from 0.85413\n",
      "242/250 [============================>.] - ETA: 3s - loss: 0.4280 - accuracy: 0.8538\n",
      "Epoch 2: accuracy did not improve from 0.85413\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.4274 - accuracy: 0.8539\n",
      "Epoch 2: accuracy improved from 0.85413 to 0.85426, saving model to output\\resnet101.h5\n",
      "244/250 [============================>.] - ETA: 2s - loss: 0.4268 - accuracy: 0.8543\n",
      "Epoch 2: accuracy improved from 0.85426 to 0.85460, saving model to output\\resnet101.h5\n",
      "245/250 [============================>.] - ETA: 2s - loss: 0.4262 - accuracy: 0.8546\n",
      "Epoch 2: accuracy improved from 0.85460 to 0.85469, saving model to output\\resnet101.h5\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4261 - accuracy: 0.8547\n",
      "Epoch 2: accuracy improved from 0.85469 to 0.85490, saving model to output\\resnet101.h5\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.4255 - accuracy: 0.8549\n",
      "Epoch 2: accuracy improved from 0.85490 to 0.85523, saving model to output\\resnet101.h5\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.8552\n",
      "Epoch 2: accuracy did not improve from 0.85523\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4249 - accuracy: 0.8549\n",
      "Epoch 2: accuracy did not improve from 0.85523\n",
      "250/250 [==============================] - 121s 482ms/step - loss: 0.4244 - accuracy: 0.8550 - val_loss: 0.2328 - val_accuracy: 0.9345\n",
      "Epoch 3/15\n",
      "\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  1/250 [..............................] - ETA: 1:53 - loss: 0.4901 - accuracy: 0.7812\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  2/250 [..............................] - ETA: 1:16 - loss: 0.4825 - accuracy: 0.8125\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  3/250 [..............................] - ETA: 1:16 - loss: 0.4563 - accuracy: 0.8229\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  4/250 [..............................] - ETA: 1:14 - loss: 0.4095 - accuracy: 0.8438\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  5/250 [..............................] - ETA: 1:16 - loss: 0.4456 - accuracy: 0.8188\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  6/250 [..............................] - ETA: 1:17 - loss: 0.4612 - accuracy: 0.8229\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  7/250 [..............................] - ETA: 1:16 - loss: 0.4380 - accuracy: 0.8348\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  8/250 [..............................] - ETA: 1:14 - loss: 0.4045 - accuracy: 0.8516\n",
      "Epoch 3: accuracy did not improve from 0.85523\n",
      "  9/250 [>.............................] - ETA: 1:13 - loss: 0.4053 - accuracy: 0.8507\n",
      "Epoch 3: accuracy improved from 0.85523 to 0.85625, saving model to output\\resnet101.h5\n",
      " 10/250 [>.............................] - ETA: 1:30 - loss: 0.4006 - accuracy: 0.8562\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 11/250 [>.............................] - ETA: 1:25 - loss: 0.4210 - accuracy: 0.8409\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 12/250 [>.............................] - ETA: 1:23 - loss: 0.4227 - accuracy: 0.8411\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 13/250 [>.............................] - ETA: 1:21 - loss: 0.4170 - accuracy: 0.8486\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 14/250 [>.............................] - ETA: 1:20 - loss: 0.4140 - accuracy: 0.8504\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 15/250 [>.............................] - ETA: 1:19 - loss: 0.4030 - accuracy: 0.8562\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 16/250 [>.............................] - ETA: 1:18 - loss: 0.4013 - accuracy: 0.8535\n",
      "Epoch 3: accuracy did not improve from 0.85625\n",
      " 17/250 [=>............................] - ETA: 1:17 - loss: 0.4053 - accuracy: 0.8548\n",
      "Epoch 3: accuracy improved from 0.85625 to 0.85938, saving model to output\\resnet101.h5\n",
      " 18/250 [=>............................] - ETA: 1:28 - loss: 0.3920 - accuracy: 0.8594\n",
      "Epoch 3: accuracy improved from 0.85938 to 0.86184, saving model to output\\resnet101.h5\n",
      " 19/250 [=>............................] - ETA: 1:34 - loss: 0.3870 - accuracy: 0.8618\n",
      "Epoch 3: accuracy improved from 0.86184 to 0.86250, saving model to output\\resnet101.h5\n",
      " 20/250 [=>............................] - ETA: 1:38 - loss: 0.3851 - accuracy: 0.8625\n",
      "Epoch 3: accuracy improved from 0.86250 to 0.86458, saving model to output\\resnet101.h5\n",
      " 21/250 [=>............................] - ETA: 1:46 - loss: 0.3776 - accuracy: 0.8646\n",
      "Epoch 3: accuracy improved from 0.86458 to 0.86506, saving model to output\\resnet101.h5\n",
      " 22/250 [=>............................] - ETA: 1:51 - loss: 0.3756 - accuracy: 0.8651\n",
      "Epoch 3: accuracy improved from 0.86506 to 0.86957, saving model to output\\resnet101.h5\n",
      " 23/250 [=>............................] - ETA: 1:58 - loss: 0.3646 - accuracy: 0.8696\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 24/250 [=>............................] - ETA: 1:54 - loss: 0.3736 - accuracy: 0.8659\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 25/250 [==>...........................] - ETA: 1:52 - loss: 0.3769 - accuracy: 0.8625\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 26/250 [==>...........................] - ETA: 1:49 - loss: 0.3808 - accuracy: 0.8642\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 27/250 [==>...........................] - ETA: 1:47 - loss: 0.3791 - accuracy: 0.8623\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 28/250 [==>...........................] - ETA: 1:45 - loss: 0.3754 - accuracy: 0.8638\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 29/250 [==>...........................] - ETA: 1:43 - loss: 0.3770 - accuracy: 0.8631\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 30/250 [==>...........................] - ETA: 1:41 - loss: 0.3746 - accuracy: 0.8646\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 31/250 [==>...........................] - ETA: 1:39 - loss: 0.3727 - accuracy: 0.8669\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 32/250 [==>...........................] - ETA: 1:38 - loss: 0.3709 - accuracy: 0.8672\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 33/250 [==>...........................] - ETA: 1:36 - loss: 0.3676 - accuracy: 0.8684\n",
      "Epoch 3: accuracy did not improve from 0.86957\n",
      " 34/250 [===>..........................] - ETA: 1:35 - loss: 0.3649 - accuracy: 0.8695\n",
      "Epoch 3: accuracy improved from 0.86957 to 0.87143, saving model to output\\resnet101.h5\n",
      " 35/250 [===>..........................] - ETA: 1:38 - loss: 0.3594 - accuracy: 0.8714\n",
      "Epoch 3: accuracy improved from 0.87143 to 0.87326, saving model to output\\resnet101.h5\n",
      " 36/250 [===>..........................] - ETA: 1:43 - loss: 0.3559 - accuracy: 0.8733\n",
      "Epoch 3: accuracy improved from 0.87326 to 0.87331, saving model to output\\resnet101.h5\n",
      " 37/250 [===>..........................] - ETA: 1:47 - loss: 0.3570 - accuracy: 0.8733\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 38/250 [===>..........................] - ETA: 1:44 - loss: 0.3607 - accuracy: 0.8692\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 39/250 [===>..........................] - ETA: 1:43 - loss: 0.3565 - accuracy: 0.8702\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 40/250 [===>..........................] - ETA: 1:41 - loss: 0.3580 - accuracy: 0.8703\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 41/250 [===>..........................] - ETA: 1:40 - loss: 0.3589 - accuracy: 0.8681\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 42/250 [====>.........................] - ETA: 1:38 - loss: 0.3622 - accuracy: 0.8653\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 43/250 [====>.........................] - ETA: 1:37 - loss: 0.3582 - accuracy: 0.8670\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 44/250 [====>.........................] - ETA: 1:35 - loss: 0.3576 - accuracy: 0.8679\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 45/250 [====>.........................] - ETA: 1:34 - loss: 0.3558 - accuracy: 0.8681\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 46/250 [====>.........................] - ETA: 1:33 - loss: 0.3599 - accuracy: 0.8662\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 47/250 [====>.........................] - ETA: 1:31 - loss: 0.3594 - accuracy: 0.8657\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 48/250 [====>.........................] - ETA: 1:30 - loss: 0.3645 - accuracy: 0.8652\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 49/250 [====>.........................] - ETA: 1:29 - loss: 0.3628 - accuracy: 0.8661\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 50/250 [=====>........................] - ETA: 1:28 - loss: 0.3630 - accuracy: 0.8662\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 51/250 [=====>........................] - ETA: 1:27 - loss: 0.3689 - accuracy: 0.8646\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 52/250 [=====>........................] - ETA: 1:26 - loss: 0.3692 - accuracy: 0.8648\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 53/250 [=====>........................] - ETA: 1:25 - loss: 0.3685 - accuracy: 0.8650\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 54/250 [=====>........................] - ETA: 1:24 - loss: 0.3729 - accuracy: 0.8634\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 55/250 [=====>........................] - ETA: 1:23 - loss: 0.3723 - accuracy: 0.8642\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 56/250 [=====>........................] - ETA: 1:22 - loss: 0.3702 - accuracy: 0.8655\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 57/250 [=====>........................] - ETA: 1:22 - loss: 0.3702 - accuracy: 0.8657\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 58/250 [=====>........................] - ETA: 1:21 - loss: 0.3688 - accuracy: 0.8658\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 59/250 [======>.......................] - ETA: 1:20 - loss: 0.3660 - accuracy: 0.8665\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 60/250 [======>.......................] - ETA: 1:19 - loss: 0.3653 - accuracy: 0.8672\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 61/250 [======>.......................] - ETA: 1:18 - loss: 0.3663 - accuracy: 0.8663\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 62/250 [======>.......................] - ETA: 1:17 - loss: 0.3658 - accuracy: 0.8664\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 63/250 [======>.......................] - ETA: 1:16 - loss: 0.3658 - accuracy: 0.8656\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 64/250 [======>.......................] - ETA: 1:16 - loss: 0.3697 - accuracy: 0.8633\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 65/250 [======>.......................] - ETA: 1:15 - loss: 0.3684 - accuracy: 0.8639\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 66/250 [======>.......................] - ETA: 1:14 - loss: 0.3680 - accuracy: 0.8636\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 67/250 [=======>......................] - ETA: 1:13 - loss: 0.3655 - accuracy: 0.8647\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 68/250 [=======>......................] - ETA: 1:13 - loss: 0.3674 - accuracy: 0.8653\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 69/250 [=======>......................] - ETA: 1:12 - loss: 0.3656 - accuracy: 0.8664\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 70/250 [=======>......................] - ETA: 1:11 - loss: 0.3652 - accuracy: 0.8661\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 71/250 [=======>......................] - ETA: 1:11 - loss: 0.3630 - accuracy: 0.8666\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 72/250 [=======>......................] - ETA: 1:10 - loss: 0.3631 - accuracy: 0.8668\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 73/250 [=======>......................] - ETA: 1:09 - loss: 0.3627 - accuracy: 0.8677\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 74/250 [=======>......................] - ETA: 1:09 - loss: 0.3611 - accuracy: 0.8687\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 75/250 [========>.....................] - ETA: 1:08 - loss: 0.3591 - accuracy: 0.8700\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 76/250 [========>.....................] - ETA: 1:07 - loss: 0.3609 - accuracy: 0.8705\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 77/250 [========>.....................] - ETA: 1:07 - loss: 0.3594 - accuracy: 0.8705\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 78/250 [========>.....................] - ETA: 1:06 - loss: 0.3594 - accuracy: 0.8706\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 79/250 [========>.....................] - ETA: 1:05 - loss: 0.3606 - accuracy: 0.8699\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 80/250 [========>.....................] - ETA: 1:05 - loss: 0.3619 - accuracy: 0.8699\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 81/250 [========>.....................] - ETA: 1:04 - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 82/250 [========>.....................] - ETA: 1:04 - loss: 0.3604 - accuracy: 0.8712\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 83/250 [========>.....................] - ETA: 1:03 - loss: 0.3614 - accuracy: 0.8712\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 84/250 [=========>....................] - ETA: 1:03 - loss: 0.3627 - accuracy: 0.8702\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 85/250 [=========>....................] - ETA: 1:02 - loss: 0.3632 - accuracy: 0.8699\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 86/250 [=========>....................] - ETA: 1:01 - loss: 0.3632 - accuracy: 0.8695\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 87/250 [=========>....................] - ETA: 1:01 - loss: 0.3608 - accuracy: 0.8703\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 88/250 [=========>....................] - ETA: 1:00 - loss: 0.3582 - accuracy: 0.8714\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 89/250 [=========>....................] - ETA: 1:00 - loss: 0.3601 - accuracy: 0.8708\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 90/250 [=========>....................] - ETA: 59s - loss: 0.3583 - accuracy: 0.8712 \n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 91/250 [=========>....................] - ETA: 59s - loss: 0.3579 - accuracy: 0.8712\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 92/250 [==========>...................] - ETA: 58s - loss: 0.3576 - accuracy: 0.8709\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 93/250 [==========>...................] - ETA: 58s - loss: 0.3553 - accuracy: 0.8720\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 94/250 [==========>...................] - ETA: 57s - loss: 0.3542 - accuracy: 0.8720\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 95/250 [==========>...................] - ETA: 57s - loss: 0.3535 - accuracy: 0.8720\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 96/250 [==========>...................] - ETA: 56s - loss: 0.3520 - accuracy: 0.8730\n",
      "Epoch 3: accuracy did not improve from 0.87331\n",
      " 97/250 [==========>...................] - ETA: 56s - loss: 0.3527 - accuracy: 0.8727\n",
      "Epoch 3: accuracy improved from 0.87331 to 0.87341, saving model to output\\resnet101.h5\n",
      " 98/250 [==========>...................] - ETA: 56s - loss: 0.3511 - accuracy: 0.8734\n",
      "Epoch 3: accuracy improved from 0.87341 to 0.87437, saving model to output\\resnet101.h5\n",
      " 99/250 [==========>...................] - ETA: 57s - loss: 0.3490 - accuracy: 0.8744\n",
      "Epoch 3: accuracy improved from 0.87437 to 0.87500, saving model to output\\resnet101.h5\n",
      "100/250 [===========>..................] - ETA: 57s - loss: 0.3475 - accuracy: 0.8750\n",
      "Epoch 3: accuracy did not improve from 0.87500\n",
      "101/250 [===========>..................] - ETA: 56s - loss: 0.3476 - accuracy: 0.8747\n",
      "Epoch 3: accuracy improved from 0.87500 to 0.87531, saving model to output\\resnet101.h5\n",
      "102/250 [===========>..................] - ETA: 57s - loss: 0.3473 - accuracy: 0.8753\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "103/250 [===========>..................] - ETA: 56s - loss: 0.3463 - accuracy: 0.8753\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "104/250 [===========>..................] - ETA: 56s - loss: 0.3481 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "105/250 [===========>..................] - ETA: 55s - loss: 0.3499 - accuracy: 0.8735\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "106/250 [===========>..................] - ETA: 55s - loss: 0.3485 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "107/250 [===========>..................] - ETA: 54s - loss: 0.3486 - accuracy: 0.8747\n",
      "Epoch 3: accuracy did not improve from 0.87531\n",
      "108/250 [===========>..................] - ETA: 54s - loss: 0.3477 - accuracy: 0.8753\n",
      "Epoch 3: accuracy improved from 0.87531 to 0.87557, saving model to output\\resnet101.h5\n",
      "109/250 [============>.................] - ETA: 55s - loss: 0.3470 - accuracy: 0.8756\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "110/250 [============>.................] - ETA: 54s - loss: 0.3479 - accuracy: 0.8747\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "111/250 [============>.................] - ETA: 53s - loss: 0.3476 - accuracy: 0.8750\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "112/250 [============>.................] - ETA: 53s - loss: 0.3477 - accuracy: 0.8753\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "113/250 [============>.................] - ETA: 53s - loss: 0.3479 - accuracy: 0.8753\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "114/250 [============>.................] - ETA: 52s - loss: 0.3482 - accuracy: 0.8747\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "115/250 [============>.................] - ETA: 52s - loss: 0.3479 - accuracy: 0.8747\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "116/250 [============>.................] - ETA: 51s - loss: 0.3502 - accuracy: 0.8737\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "117/250 [=============>................] - ETA: 51s - loss: 0.3517 - accuracy: 0.8737\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "118/250 [=============>................] - ETA: 50s - loss: 0.3519 - accuracy: 0.8734\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "119/250 [=============>................] - ETA: 50s - loss: 0.3520 - accuracy: 0.8732\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "120/250 [=============>................] - ETA: 49s - loss: 0.3517 - accuracy: 0.8732\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "121/250 [=============>................] - ETA: 49s - loss: 0.3540 - accuracy: 0.8722\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "122/250 [=============>................] - ETA: 48s - loss: 0.3549 - accuracy: 0.8722\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "123/250 [=============>................] - ETA: 48s - loss: 0.3539 - accuracy: 0.8727\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "124/250 [=============>................] - ETA: 47s - loss: 0.3527 - accuracy: 0.8735\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "125/250 [==============>...............] - ETA: 47s - loss: 0.3534 - accuracy: 0.8733\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "126/250 [==============>...............] - ETA: 46s - loss: 0.3546 - accuracy: 0.8728\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "127/250 [==============>...............] - ETA: 46s - loss: 0.3549 - accuracy: 0.8725\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "128/250 [==============>...............] - ETA: 45s - loss: 0.3546 - accuracy: 0.8726\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "129/250 [==============>...............] - ETA: 45s - loss: 0.3545 - accuracy: 0.8728\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "130/250 [==============>...............] - ETA: 44s - loss: 0.3550 - accuracy: 0.8728\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "131/250 [==============>...............] - ETA: 44s - loss: 0.3550 - accuracy: 0.8731\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "132/250 [==============>...............] - ETA: 43s - loss: 0.3531 - accuracy: 0.8741\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "133/250 [==============>...............] - ETA: 43s - loss: 0.3539 - accuracy: 0.8736\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "134/250 [===============>..............] - ETA: 43s - loss: 0.3549 - accuracy: 0.8731\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "135/250 [===============>..............] - ETA: 42s - loss: 0.3540 - accuracy: 0.8734\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "136/250 [===============>..............] - ETA: 42s - loss: 0.3534 - accuracy: 0.8741\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "137/250 [===============>..............] - ETA: 41s - loss: 0.3532 - accuracy: 0.8743\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "138/250 [===============>..............] - ETA: 41s - loss: 0.3553 - accuracy: 0.8734\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "139/250 [===============>..............] - ETA: 40s - loss: 0.3559 - accuracy: 0.8732\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "140/250 [===============>..............] - ETA: 40s - loss: 0.3549 - accuracy: 0.8737\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "141/250 [===============>..............] - ETA: 39s - loss: 0.3542 - accuracy: 0.8739\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "142/250 [================>.............] - ETA: 39s - loss: 0.3543 - accuracy: 0.8741\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "143/250 [================>.............] - ETA: 39s - loss: 0.3548 - accuracy: 0.8741\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "144/250 [================>.............] - ETA: 38s - loss: 0.3537 - accuracy: 0.8748\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "145/250 [================>.............] - ETA: 38s - loss: 0.3543 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "146/250 [================>.............] - ETA: 37s - loss: 0.3553 - accuracy: 0.8735\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "147/250 [================>.............] - ETA: 37s - loss: 0.3558 - accuracy: 0.8729\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "148/250 [================>.............] - ETA: 36s - loss: 0.3555 - accuracy: 0.8731\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "149/250 [================>.............] - ETA: 36s - loss: 0.3567 - accuracy: 0.8731\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "150/250 [=================>............] - ETA: 36s - loss: 0.3559 - accuracy: 0.8733\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "151/250 [=================>............] - ETA: 35s - loss: 0.3555 - accuracy: 0.8733\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "152/250 [=================>............] - ETA: 35s - loss: 0.3580 - accuracy: 0.8727\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "153/250 [=================>............] - ETA: 34s - loss: 0.3571 - accuracy: 0.8732\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "154/250 [=================>............] - ETA: 34s - loss: 0.3565 - accuracy: 0.8734\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "155/250 [=================>............] - ETA: 34s - loss: 0.3570 - accuracy: 0.8730\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "156/250 [=================>............] - ETA: 33s - loss: 0.3581 - accuracy: 0.8728\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "157/250 [=================>............] - ETA: 33s - loss: 0.3579 - accuracy: 0.8730\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "158/250 [=================>............] - ETA: 32s - loss: 0.3592 - accuracy: 0.8728\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "159/250 [==================>...........] - ETA: 32s - loss: 0.3596 - accuracy: 0.8724\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "160/250 [==================>...........] - ETA: 32s - loss: 0.3606 - accuracy: 0.8721\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "161/250 [==================>...........] - ETA: 31s - loss: 0.3597 - accuracy: 0.8725\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "162/250 [==================>...........] - ETA: 31s - loss: 0.3595 - accuracy: 0.8727\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "163/250 [==================>...........] - ETA: 30s - loss: 0.3593 - accuracy: 0.8727\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "164/250 [==================>...........] - ETA: 30s - loss: 0.3582 - accuracy: 0.8735\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "165/250 [==================>...........] - ETA: 30s - loss: 0.3564 - accuracy: 0.8742\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "166/250 [==================>...........] - ETA: 29s - loss: 0.3564 - accuracy: 0.8741\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "167/250 [===================>..........] - ETA: 29s - loss: 0.3557 - accuracy: 0.8743\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "168/250 [===================>..........] - ETA: 28s - loss: 0.3553 - accuracy: 0.8745\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "169/250 [===================>..........] - ETA: 28s - loss: 0.3551 - accuracy: 0.8747\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "170/250 [===================>..........] - ETA: 28s - loss: 0.3554 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "171/250 [===================>..........] - ETA: 27s - loss: 0.3552 - accuracy: 0.8745\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "172/250 [===================>..........] - ETA: 27s - loss: 0.3541 - accuracy: 0.8749\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "173/250 [===================>..........] - ETA: 26s - loss: 0.3558 - accuracy: 0.8745\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "174/250 [===================>..........] - ETA: 26s - loss: 0.3560 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "175/250 [====================>.........] - ETA: 26s - loss: 0.3568 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "176/250 [====================>.........] - ETA: 25s - loss: 0.3571 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "177/250 [====================>.........] - ETA: 25s - loss: 0.3571 - accuracy: 0.8744\n",
      "Epoch 3: accuracy did not improve from 0.87557\n",
      "178/250 [====================>.........] - ETA: 25s - loss: 0.3558 - accuracy: 0.8751\n",
      "Epoch 3: accuracy improved from 0.87557 to 0.87561, saving model to output\\resnet101.h5\n",
      "179/250 [====================>.........] - ETA: 24s - loss: 0.3548 - accuracy: 0.8756\n",
      "Epoch 3: accuracy improved from 0.87561 to 0.87631, saving model to output\\resnet101.h5\n",
      "180/250 [====================>.........] - ETA: 24s - loss: 0.3532 - accuracy: 0.8763\n",
      "Epoch 3: accuracy improved from 0.87631 to 0.87665, saving model to output\\resnet101.h5\n",
      "181/250 [====================>.........] - ETA: 24s - loss: 0.3529 - accuracy: 0.8766\n",
      "Epoch 3: accuracy improved from 0.87665 to 0.87698, saving model to output\\resnet101.h5\n",
      "182/250 [====================>.........] - ETA: 24s - loss: 0.3531 - accuracy: 0.8770\n",
      "Epoch 3: accuracy improved from 0.87698 to 0.87731, saving model to output\\resnet101.h5\n",
      "183/250 [====================>.........] - ETA: 24s - loss: 0.3524 - accuracy: 0.8773\n",
      "Epoch 3: accuracy did not improve from 0.87731\n",
      "184/250 [=====================>........] - ETA: 23s - loss: 0.3518 - accuracy: 0.8773\n",
      "Epoch 3: accuracy did not improve from 0.87731\n",
      "185/250 [=====================>........] - ETA: 23s - loss: 0.3526 - accuracy: 0.8771\n",
      "Epoch 3: accuracy did not improve from 0.87731\n",
      "186/250 [=====================>........] - ETA: 23s - loss: 0.3525 - accuracy: 0.8769\n",
      "Epoch 3: accuracy improved from 0.87731 to 0.87743, saving model to output\\resnet101.h5\n",
      "187/250 [=====================>........] - ETA: 22s - loss: 0.3512 - accuracy: 0.8774\n",
      "Epoch 3: accuracy did not improve from 0.87743\n",
      "188/250 [=====================>........] - ETA: 22s - loss: 0.3506 - accuracy: 0.8774\n",
      "Epoch 3: accuracy improved from 0.87743 to 0.87757, saving model to output\\resnet101.h5\n",
      "189/250 [=====================>........] - ETA: 22s - loss: 0.3503 - accuracy: 0.8776\n",
      "Epoch 3: accuracy did not improve from 0.87757\n",
      "190/250 [=====================>........] - ETA: 22s - loss: 0.3499 - accuracy: 0.8774\n",
      "Epoch 3: accuracy did not improve from 0.87757\n",
      "191/250 [=====================>........] - ETA: 21s - loss: 0.3494 - accuracy: 0.8775\n",
      "Epoch 3: accuracy improved from 0.87757 to 0.87818, saving model to output\\resnet101.h5\n",
      "192/250 [======================>.......] - ETA: 21s - loss: 0.3490 - accuracy: 0.8782\n",
      "Epoch 3: accuracy improved from 0.87818 to 0.87849, saving model to output\\resnet101.h5\n",
      "193/250 [======================>.......] - ETA: 21s - loss: 0.3486 - accuracy: 0.8785\n",
      "Epoch 3: accuracy did not improve from 0.87849\n",
      "194/250 [======================>.......] - ETA: 20s - loss: 0.3494 - accuracy: 0.8783\n",
      "Epoch 3: accuracy improved from 0.87849 to 0.87862, saving model to output\\resnet101.h5\n",
      "195/250 [======================>.......] - ETA: 20s - loss: 0.3485 - accuracy: 0.8786\n",
      "Epoch 3: accuracy improved from 0.87862 to 0.87876, saving model to output\\resnet101.h5\n",
      "196/250 [======================>.......] - ETA: 20s - loss: 0.3479 - accuracy: 0.8788\n",
      "Epoch 3: accuracy improved from 0.87876 to 0.87906, saving model to output\\resnet101.h5\n",
      "197/250 [======================>.......] - ETA: 20s - loss: 0.3476 - accuracy: 0.8791\n",
      "Epoch 3: accuracy did not improve from 0.87906\n",
      "198/250 [======================>.......] - ETA: 19s - loss: 0.3475 - accuracy: 0.8790\n",
      "Epoch 3: accuracy improved from 0.87906 to 0.87933, saving model to output\\resnet101.h5\n",
      "199/250 [======================>.......] - ETA: 19s - loss: 0.3466 - accuracy: 0.8793\n",
      "Epoch 3: accuracy improved from 0.87933 to 0.87962, saving model to output\\resnet101.h5\n",
      "200/250 [=======================>......] - ETA: 19s - loss: 0.3457 - accuracy: 0.8796\n",
      "Epoch 3: accuracy did not improve from 0.87962\n",
      "201/250 [=======================>......] - ETA: 18s - loss: 0.3460 - accuracy: 0.8794\n",
      "Epoch 3: accuracy did not improve from 0.87962\n",
      "202/250 [=======================>......] - ETA: 18s - loss: 0.3461 - accuracy: 0.8793\n",
      "Epoch 3: accuracy did not improve from 0.87962\n",
      "203/250 [=======================>......] - ETA: 17s - loss: 0.3454 - accuracy: 0.8794\n",
      "Epoch 3: accuracy improved from 0.87962 to 0.87984, saving model to output\\resnet101.h5\n",
      "204/250 [=======================>......] - ETA: 17s - loss: 0.3449 - accuracy: 0.8798\n",
      "Epoch 3: accuracy did not improve from 0.87984\n",
      "205/250 [=======================>......] - ETA: 17s - loss: 0.3455 - accuracy: 0.8797\n",
      "Epoch 3: accuracy improved from 0.87984 to 0.88010, saving model to output\\resnet101.h5\n",
      "206/250 [=======================>......] - ETA: 17s - loss: 0.3451 - accuracy: 0.8801\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "207/250 [=======================>......] - ETA: 16s - loss: 0.3452 - accuracy: 0.8798\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "208/250 [=======================>......] - ETA: 16s - loss: 0.3449 - accuracy: 0.8799\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "209/250 [========================>.....] - ETA: 15s - loss: 0.3468 - accuracy: 0.8790\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "210/250 [========================>.....] - ETA: 15s - loss: 0.3464 - accuracy: 0.8790\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "211/250 [========================>.....] - ETA: 15s - loss: 0.3468 - accuracy: 0.8792\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "212/250 [========================>.....] - ETA: 14s - loss: 0.3471 - accuracy: 0.8789\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "213/250 [========================>.....] - ETA: 14s - loss: 0.3472 - accuracy: 0.8790\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "214/250 [========================>.....] - ETA: 13s - loss: 0.3477 - accuracy: 0.8790\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "215/250 [========================>.....] - ETA: 13s - loss: 0.3466 - accuracy: 0.8796\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "216/250 [========================>.....] - ETA: 13s - loss: 0.3470 - accuracy: 0.8796\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "217/250 [=========================>....] - ETA: 12s - loss: 0.3474 - accuracy: 0.8797\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "218/250 [=========================>....] - ETA: 12s - loss: 0.3493 - accuracy: 0.8791\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "219/250 [=========================>....] - ETA: 11s - loss: 0.3492 - accuracy: 0.8789\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "220/250 [=========================>....] - ETA: 11s - loss: 0.3499 - accuracy: 0.8785\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "221/250 [=========================>....] - ETA: 11s - loss: 0.3504 - accuracy: 0.8779\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "222/250 [=========================>....] - ETA: 10s - loss: 0.3503 - accuracy: 0.8779\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "223/250 [=========================>....] - ETA: 10s - loss: 0.3499 - accuracy: 0.8780\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "224/250 [=========================>....] - ETA: 9s - loss: 0.3493 - accuracy: 0.8781 \n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "225/250 [==========================>...] - ETA: 9s - loss: 0.3497 - accuracy: 0.8779\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "226/250 [==========================>...] - ETA: 9s - loss: 0.3491 - accuracy: 0.8780\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "227/250 [==========================>...] - ETA: 8s - loss: 0.3489 - accuracy: 0.8782\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "228/250 [==========================>...] - ETA: 8s - loss: 0.3488 - accuracy: 0.8782\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "229/250 [==========================>...] - ETA: 7s - loss: 0.3481 - accuracy: 0.8786\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "230/250 [==========================>...] - ETA: 7s - loss: 0.3477 - accuracy: 0.8790\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "231/250 [==========================>...] - ETA: 7s - loss: 0.3470 - accuracy: 0.8795\n",
      "Epoch 3: accuracy did not improve from 0.88010\n",
      "232/250 [==========================>...] - ETA: 6s - loss: 0.3467 - accuracy: 0.8798\n",
      "Epoch 3: accuracy improved from 0.88010 to 0.88018, saving model to output\\resnet101.h5\n",
      "233/250 [==========================>...] - ETA: 6s - loss: 0.3458 - accuracy: 0.8802\n",
      "Epoch 3: accuracy improved from 0.88018 to 0.88029, saving model to output\\resnet101.h5\n",
      "234/250 [===========================>..] - ETA: 6s - loss: 0.3463 - accuracy: 0.8803\n",
      "Epoch 3: accuracy did not improve from 0.88029\n",
      "235/250 [===========================>..] - ETA: 5s - loss: 0.3478 - accuracy: 0.8800\n",
      "Epoch 3: accuracy did not improve from 0.88029\n",
      "236/250 [===========================>..] - ETA: 5s - loss: 0.3478 - accuracy: 0.8801\n",
      "Epoch 3: accuracy did not improve from 0.88029\n",
      "237/250 [===========================>..] - ETA: 4s - loss: 0.3477 - accuracy: 0.8802\n",
      "Epoch 3: accuracy did not improve from 0.88029\n",
      "238/250 [===========================>..] - ETA: 4s - loss: 0.3476 - accuracy: 0.8802\n",
      "Epoch 3: accuracy improved from 0.88029 to 0.88031, saving model to output\\resnet101.h5\n",
      "239/250 [===========================>..] - ETA: 4s - loss: 0.3472 - accuracy: 0.8803\n",
      "Epoch 3: accuracy improved from 0.88031 to 0.88055, saving model to output\\resnet101.h5\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.3464 - accuracy: 0.8805\n",
      "Epoch 3: accuracy did not improve from 0.88055\n",
      "241/250 [===========================>..] - ETA: 3s - loss: 0.3463 - accuracy: 0.8805\n",
      "Epoch 3: accuracy improved from 0.88055 to 0.88063, saving model to output\\resnet101.h5\n",
      "242/250 [============================>.] - ETA: 3s - loss: 0.3461 - accuracy: 0.8806\n",
      "Epoch 3: accuracy improved from 0.88063 to 0.88074, saving model to output\\resnet101.h5\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.3452 - accuracy: 0.8807\n",
      "Epoch 3: accuracy improved from 0.88074 to 0.88084, saving model to output\\resnet101.h5\n",
      "244/250 [============================>.] - ETA: 2s - loss: 0.3448 - accuracy: 0.8808\n",
      "Epoch 3: accuracy did not improve from 0.88084\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.3453 - accuracy: 0.8808\n",
      "Epoch 3: accuracy improved from 0.88084 to 0.88092, saving model to output\\resnet101.h5\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.3449 - accuracy: 0.8809\n",
      "Epoch 3: accuracy did not improve from 0.88092\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.3446 - accuracy: 0.8809\n",
      "Epoch 3: accuracy did not improve from 0.88092\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8809\n",
      "Epoch 3: accuracy improved from 0.88092 to 0.88098, saving model to output\\resnet101.h5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8810\n",
      "Epoch 3: accuracy did not improve from 0.88098\n",
      "250/250 [==============================] - 116s 465ms/step - loss: 0.3447 - accuracy: 0.8810 - val_loss: 0.1952 - val_accuracy: 0.9425\n",
      "Epoch 4/15\n",
      "\n",
      "Epoch 4: accuracy did not improve from 0.88098\n",
      "  1/250 [..............................] - ETA: 1:48 - loss: 0.4178 - accuracy: 0.8438\n",
      "Epoch 4: accuracy did not improve from 0.88098\n",
      "  2/250 [..............................] - ETA: 1:21 - loss: 0.4333 - accuracy: 0.8281\n",
      "Epoch 4: accuracy did not improve from 0.88098\n",
      "  3/250 [..............................] - ETA: 1:20 - loss: 0.3557 - accuracy: 0.8646\n",
      "Epoch 4: accuracy improved from 0.88098 to 0.88281, saving model to output\\resnet101.h5\n",
      "  4/250 [..............................] - ETA: 2:06 - loss: 0.3058 - accuracy: 0.8828\n",
      "Epoch 4: accuracy improved from 0.88281 to 0.88750, saving model to output\\resnet101.h5\n",
      "  5/250 [..............................] - ETA: 2:23 - loss: 0.3163 - accuracy: 0.8875\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      "  6/250 [..............................] - ETA: 2:01 - loss: 0.3462 - accuracy: 0.8802\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      "  7/250 [..............................] - ETA: 1:52 - loss: 0.3639 - accuracy: 0.8661\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      "  8/250 [..............................] - ETA: 1:44 - loss: 0.3764 - accuracy: 0.8672\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      "  9/250 [>.............................] - ETA: 1:39 - loss: 0.3781 - accuracy: 0.8611\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 10/250 [>.............................] - ETA: 1:34 - loss: 0.3692 - accuracy: 0.8625\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 11/250 [>.............................] - ETA: 1:31 - loss: 0.3491 - accuracy: 0.8722\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 12/250 [>.............................] - ETA: 1:29 - loss: 0.3486 - accuracy: 0.8750\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 13/250 [>.............................] - ETA: 1:26 - loss: 0.3317 - accuracy: 0.8822\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 14/250 [>.............................] - ETA: 1:25 - loss: 0.3304 - accuracy: 0.8795\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 15/250 [>.............................] - ETA: 1:23 - loss: 0.3348 - accuracy: 0.8750\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 16/250 [>.............................] - ETA: 1:21 - loss: 0.3375 - accuracy: 0.8750\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 17/250 [=>............................] - ETA: 1:20 - loss: 0.3382 - accuracy: 0.8750\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 18/250 [=>............................] - ETA: 1:18 - loss: 0.3284 - accuracy: 0.8802\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 19/250 [=>............................] - ETA: 1:17 - loss: 0.3401 - accuracy: 0.8783\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 20/250 [=>............................] - ETA: 1:16 - loss: 0.3360 - accuracy: 0.8813\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 21/250 [=>............................] - ETA: 1:15 - loss: 0.3363 - accuracy: 0.8824\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 22/250 [=>............................] - ETA: 1:14 - loss: 0.3413 - accuracy: 0.8793\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 23/250 [=>............................] - ETA: 1:13 - loss: 0.3372 - accuracy: 0.8791\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 24/250 [=>............................] - ETA: 1:12 - loss: 0.3267 - accuracy: 0.8841\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 25/250 [==>...........................] - ETA: 1:11 - loss: 0.3216 - accuracy: 0.8863\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 26/250 [==>...........................] - ETA: 1:10 - loss: 0.3255 - accuracy: 0.8822\n",
      "Epoch 4: accuracy did not improve from 0.88750\n",
      " 27/250 [==>...........................] - ETA: 1:10 - loss: 0.3190 - accuracy: 0.8866\n",
      "Epoch 4: accuracy improved from 0.88750 to 0.88839, saving model to output\\resnet101.h5\n",
      " 28/250 [==>...........................] - ETA: 1:14 - loss: 0.3179 - accuracy: 0.8884\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 29/250 [==>...........................] - ETA: 1:13 - loss: 0.3200 - accuracy: 0.8858\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 30/250 [==>...........................] - ETA: 1:12 - loss: 0.3249 - accuracy: 0.8865\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 31/250 [==>...........................] - ETA: 1:11 - loss: 0.3301 - accuracy: 0.8861\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 32/250 [==>...........................] - ETA: 1:10 - loss: 0.3296 - accuracy: 0.8857\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 33/250 [==>...........................] - ETA: 1:10 - loss: 0.3269 - accuracy: 0.8864\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 34/250 [===>..........................] - ETA: 1:09 - loss: 0.3284 - accuracy: 0.8851\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 35/250 [===>..........................] - ETA: 1:08 - loss: 0.3389 - accuracy: 0.8857\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 36/250 [===>..........................] - ETA: 1:08 - loss: 0.3382 - accuracy: 0.8854\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 37/250 [===>..........................] - ETA: 1:07 - loss: 0.3371 - accuracy: 0.8860\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 38/250 [===>..........................] - ETA: 1:07 - loss: 0.3422 - accuracy: 0.8840\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 39/250 [===>..........................] - ETA: 1:06 - loss: 0.3402 - accuracy: 0.8838\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 40/250 [===>..........................] - ETA: 1:06 - loss: 0.3391 - accuracy: 0.8852\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 41/250 [===>..........................] - ETA: 1:05 - loss: 0.3396 - accuracy: 0.8841\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 42/250 [====>.........................] - ETA: 1:05 - loss: 0.3416 - accuracy: 0.8832\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 43/250 [====>.........................] - ETA: 1:04 - loss: 0.3391 - accuracy: 0.8830\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 44/250 [====>.........................] - ETA: 1:03 - loss: 0.3397 - accuracy: 0.8821\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 45/250 [====>.........................] - ETA: 1:03 - loss: 0.3384 - accuracy: 0.8819\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 46/250 [====>.........................] - ETA: 1:02 - loss: 0.3383 - accuracy: 0.8818\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 47/250 [====>.........................] - ETA: 1:02 - loss: 0.3350 - accuracy: 0.8830\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 48/250 [====>.........................] - ETA: 1:02 - loss: 0.3320 - accuracy: 0.8848\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 49/250 [====>.........................] - ETA: 1:01 - loss: 0.3323 - accuracy: 0.8852\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 50/250 [=====>........................] - ETA: 1:01 - loss: 0.3352 - accuracy: 0.8831\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 51/250 [=====>........................] - ETA: 1:00 - loss: 0.3345 - accuracy: 0.8830\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 52/250 [=====>........................] - ETA: 1:00 - loss: 0.3329 - accuracy: 0.8834\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 53/250 [=====>........................] - ETA: 59s - loss: 0.3329 - accuracy: 0.8838 \n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 54/250 [=====>........................] - ETA: 59s - loss: 0.3317 - accuracy: 0.8843\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.3292 - accuracy: 0.8852\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 56/250 [=====>........................] - ETA: 58s - loss: 0.3270 - accuracy: 0.8862\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 57/250 [=====>........................] - ETA: 58s - loss: 0.3280 - accuracy: 0.8854\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 58/250 [=====>........................] - ETA: 57s - loss: 0.3291 - accuracy: 0.8847\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 59/250 [======>.......................] - ETA: 57s - loss: 0.3269 - accuracy: 0.8856\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 60/250 [======>.......................] - ETA: 56s - loss: 0.3294 - accuracy: 0.8849\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 61/250 [======>.......................] - ETA: 56s - loss: 0.3283 - accuracy: 0.8847\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 62/250 [======>.......................] - ETA: 56s - loss: 0.3258 - accuracy: 0.8856\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 63/250 [======>.......................] - ETA: 55s - loss: 0.3262 - accuracy: 0.8844\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 64/250 [======>.......................] - ETA: 55s - loss: 0.3269 - accuracy: 0.8838\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.3286 - accuracy: 0.8832\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 66/250 [======>.......................] - ETA: 54s - loss: 0.3283 - accuracy: 0.8830\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 67/250 [=======>......................] - ETA: 54s - loss: 0.3261 - accuracy: 0.8839\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 68/250 [=======>......................] - ETA: 53s - loss: 0.3238 - accuracy: 0.8851\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.3236 - accuracy: 0.8859\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 70/250 [=======>......................] - ETA: 53s - loss: 0.3226 - accuracy: 0.8866\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 71/250 [=======>......................] - ETA: 52s - loss: 0.3225 - accuracy: 0.8869\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.3223 - accuracy: 0.8867\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 73/250 [=======>......................] - ETA: 52s - loss: 0.3238 - accuracy: 0.8866\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 74/250 [=======>......................] - ETA: 51s - loss: 0.3224 - accuracy: 0.8868\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.3248 - accuracy: 0.8863\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.3244 - accuracy: 0.8861\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.3238 - accuracy: 0.8864\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 78/250 [========>.....................] - ETA: 50s - loss: 0.3228 - accuracy: 0.8866\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 79/250 [========>.....................] - ETA: 50s - loss: 0.3234 - accuracy: 0.8857\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.3217 - accuracy: 0.8863\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.3218 - accuracy: 0.8858\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.3213 - accuracy: 0.8861\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 83/250 [========>.....................] - ETA: 48s - loss: 0.3211 - accuracy: 0.8855\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.3204 - accuracy: 0.8858\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.3195 - accuracy: 0.8860\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 86/250 [=========>....................] - ETA: 47s - loss: 0.3224 - accuracy: 0.8844\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.3231 - accuracy: 0.8843\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.3230 - accuracy: 0.8842\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.3228 - accuracy: 0.8845\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 90/250 [=========>....................] - ETA: 46s - loss: 0.3219 - accuracy: 0.8847\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.3225 - accuracy: 0.8846\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.3208 - accuracy: 0.8852\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 93/250 [==========>...................] - ETA: 45s - loss: 0.3196 - accuracy: 0.8858\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.3191 - accuracy: 0.8853\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.3175 - accuracy: 0.8859\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.3178 - accuracy: 0.8861\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.3164 - accuracy: 0.8869\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.3159 - accuracy: 0.8871\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.3148 - accuracy: 0.8876\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.3145 - accuracy: 0.8878\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.3151 - accuracy: 0.8874\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.3146 - accuracy: 0.8876\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.3141 - accuracy: 0.8880\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.3149 - accuracy: 0.8879\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.3142 - accuracy: 0.8878\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.3149 - accuracy: 0.8874\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.3177 - accuracy: 0.8876\n",
      "Epoch 4: accuracy did not improve from 0.88839\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.3162 - accuracy: 0.8883\n",
      "Epoch 4: accuracy improved from 0.88839 to 0.88876, saving model to output\\resnet101.h5\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.3152 - accuracy: 0.8888\n",
      "Epoch 4: accuracy did not improve from 0.88876\n",
      "110/250 [============>.................] - ETA: 41s - loss: 0.3160 - accuracy: 0.8886\n",
      "Epoch 4: accuracy improved from 0.88876 to 0.88908, saving model to output\\resnet101.h5\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.3154 - accuracy: 0.8891\n",
      "Epoch 4: accuracy improved from 0.88908 to 0.88979, saving model to output\\resnet101.h5\n",
      "112/250 [============>.................] - ETA: 42s - loss: 0.3143 - accuracy: 0.8898\n",
      "Epoch 4: accuracy improved from 0.88979 to 0.88993, saving model to output\\resnet101.h5\n",
      "113/250 [============>.................] - ETA: 42s - loss: 0.3163 - accuracy: 0.8899\n",
      "Epoch 4: accuracy improved from 0.88993 to 0.89035, saving model to output\\resnet101.h5\n",
      "114/250 [============>.................] - ETA: 42s - loss: 0.3158 - accuracy: 0.8904\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "115/250 [============>.................] - ETA: 42s - loss: 0.3167 - accuracy: 0.8894\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "116/250 [============>.................] - ETA: 42s - loss: 0.3162 - accuracy: 0.8893\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "117/250 [=============>................] - ETA: 41s - loss: 0.3168 - accuracy: 0.8889\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "118/250 [=============>................] - ETA: 41s - loss: 0.3166 - accuracy: 0.8890\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "119/250 [=============>................] - ETA: 41s - loss: 0.3173 - accuracy: 0.8887\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "120/250 [=============>................] - ETA: 40s - loss: 0.3162 - accuracy: 0.8893\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "121/250 [=============>................] - ETA: 40s - loss: 0.3157 - accuracy: 0.8892\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "122/250 [=============>................] - ETA: 40s - loss: 0.3157 - accuracy: 0.8896\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "123/250 [=============>................] - ETA: 39s - loss: 0.3160 - accuracy: 0.8902\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "124/250 [=============>................] - ETA: 39s - loss: 0.3152 - accuracy: 0.8901\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "125/250 [==============>...............] - ETA: 38s - loss: 0.3149 - accuracy: 0.8903\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "126/250 [==============>...............] - ETA: 38s - loss: 0.3155 - accuracy: 0.8899\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "127/250 [==============>...............] - ETA: 38s - loss: 0.3166 - accuracy: 0.8893\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "128/250 [==============>...............] - ETA: 37s - loss: 0.3157 - accuracy: 0.8899\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "129/250 [==============>...............] - ETA: 37s - loss: 0.3147 - accuracy: 0.8903\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "130/250 [==============>...............] - ETA: 37s - loss: 0.3157 - accuracy: 0.8894\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "131/250 [==============>...............] - ETA: 36s - loss: 0.3159 - accuracy: 0.8893\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "132/250 [==============>...............] - ETA: 36s - loss: 0.3160 - accuracy: 0.8890\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "133/250 [==============>...............] - ETA: 36s - loss: 0.3160 - accuracy: 0.8889\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "134/250 [===============>..............] - ETA: 35s - loss: 0.3145 - accuracy: 0.8897\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "135/250 [===============>..............] - ETA: 35s - loss: 0.3144 - accuracy: 0.8896\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "136/250 [===============>..............] - ETA: 35s - loss: 0.3132 - accuracy: 0.8902\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "137/250 [===============>..............] - ETA: 34s - loss: 0.3122 - accuracy: 0.8903\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "138/250 [===============>..............] - ETA: 34s - loss: 0.3117 - accuracy: 0.8902\n",
      "Epoch 4: accuracy did not improve from 0.89035\n",
      "139/250 [===============>..............] - ETA: 34s - loss: 0.3116 - accuracy: 0.8901\n",
      "Epoch 4: accuracy improved from 0.89035 to 0.89062, saving model to output\\resnet101.h5\n",
      "140/250 [===============>..............] - ETA: 34s - loss: 0.3102 - accuracy: 0.8906\n",
      "Epoch 4: accuracy improved from 0.89062 to 0.89096, saving model to output\\resnet101.h5\n",
      "141/250 [===============>..............] - ETA: 34s - loss: 0.3102 - accuracy: 0.8910\n",
      "Epoch 4: accuracy improved from 0.89096 to 0.89107, saving model to output\\resnet101.h5\n",
      "142/250 [================>.............] - ETA: 34s - loss: 0.3100 - accuracy: 0.8911\n",
      "Epoch 4: accuracy improved from 0.89107 to 0.89117, saving model to output\\resnet101.h5\n",
      "143/250 [================>.............] - ETA: 34s - loss: 0.3101 - accuracy: 0.8912\n",
      "Epoch 4: accuracy improved from 0.89117 to 0.89171, saving model to output\\resnet101.h5\n",
      "144/250 [================>.............] - ETA: 34s - loss: 0.3095 - accuracy: 0.8917\n",
      "Epoch 4: accuracy improved from 0.89171 to 0.89181, saving model to output\\resnet101.h5\n",
      "145/250 [================>.............] - ETA: 34s - loss: 0.3092 - accuracy: 0.8918\n",
      "Epoch 4: accuracy improved from 0.89181 to 0.89191, saving model to output\\resnet101.h5\n",
      "146/250 [================>.............] - ETA: 34s - loss: 0.3085 - accuracy: 0.8919\n",
      "Epoch 4: accuracy did not improve from 0.89191\n",
      "147/250 [================>.............] - ETA: 34s - loss: 0.3086 - accuracy: 0.8918\n",
      "Epoch 4: accuracy improved from 0.89191 to 0.89231, saving model to output\\resnet101.h5\n",
      "148/250 [================>.............] - ETA: 34s - loss: 0.3076 - accuracy: 0.8923\n",
      "Epoch 4: accuracy improved from 0.89231 to 0.89262, saving model to output\\resnet101.h5\n",
      "149/250 [================>.............] - ETA: 34s - loss: 0.3069 - accuracy: 0.8926\n",
      "Epoch 4: accuracy improved from 0.89262 to 0.89271, saving model to output\\resnet101.h5\n",
      "150/250 [=================>............] - ETA: 34s - loss: 0.3067 - accuracy: 0.8927\n",
      "Epoch 4: accuracy improved from 0.89271 to 0.89321, saving model to output\\resnet101.h5\n",
      "151/250 [=================>............] - ETA: 34s - loss: 0.3056 - accuracy: 0.8932\n",
      "Epoch 4: accuracy did not improve from 0.89321\n",
      "152/250 [=================>............] - ETA: 33s - loss: 0.3067 - accuracy: 0.8927\n",
      "Epoch 4: accuracy did not improve from 0.89321\n",
      "153/250 [=================>............] - ETA: 33s - loss: 0.3069 - accuracy: 0.8928\n",
      "Epoch 4: accuracy improved from 0.89321 to 0.89326, saving model to output\\resnet101.h5\n",
      "154/250 [=================>............] - ETA: 33s - loss: 0.3056 - accuracy: 0.8933\n",
      "Epoch 4: accuracy improved from 0.89326 to 0.89335, saving model to output\\resnet101.h5\n",
      "155/250 [=================>............] - ETA: 33s - loss: 0.3052 - accuracy: 0.8933\n",
      "Epoch 4: accuracy improved from 0.89335 to 0.89363, saving model to output\\resnet101.h5\n",
      "156/250 [=================>............] - ETA: 33s - loss: 0.3042 - accuracy: 0.8936\n",
      "Epoch 4: accuracy improved from 0.89363 to 0.89371, saving model to output\\resnet101.h5\n",
      "157/250 [=================>............] - ETA: 33s - loss: 0.3037 - accuracy: 0.8937\n",
      "Epoch 4: accuracy improved from 0.89371 to 0.89399, saving model to output\\resnet101.h5\n",
      "158/250 [=================>............] - ETA: 33s - loss: 0.3031 - accuracy: 0.8940\n",
      "Epoch 4: accuracy did not improve from 0.89399\n",
      "159/250 [==================>...........] - ETA: 33s - loss: 0.3029 - accuracy: 0.8937\n",
      "Epoch 4: accuracy did not improve from 0.89399\n",
      "160/250 [==================>...........] - ETA: 32s - loss: 0.3026 - accuracy: 0.8938\n",
      "Epoch 4: accuracy improved from 0.89399 to 0.89441, saving model to output\\resnet101.h5\n",
      "161/250 [==================>...........] - ETA: 32s - loss: 0.3014 - accuracy: 0.8944\n",
      "Epoch 4: accuracy improved from 0.89441 to 0.89448, saving model to output\\resnet101.h5\n",
      "162/250 [==================>...........] - ETA: 32s - loss: 0.3012 - accuracy: 0.8945\n",
      "Epoch 4: accuracy did not improve from 0.89448\n",
      "163/250 [==================>...........] - ETA: 32s - loss: 0.3026 - accuracy: 0.8944\n",
      "Epoch 4: accuracy improved from 0.89448 to 0.89482, saving model to output\\resnet101.h5\n",
      "164/250 [==================>...........] - ETA: 32s - loss: 0.3015 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89482\n",
      "165/250 [==================>...........] - ETA: 31s - loss: 0.3025 - accuracy: 0.8943\n",
      "Epoch 4: accuracy did not improve from 0.89482\n",
      "166/250 [==================>...........] - ETA: 31s - loss: 0.3029 - accuracy: 0.8946\n",
      "Epoch 4: accuracy improved from 0.89482 to 0.89484, saving model to output\\resnet101.h5\n",
      "167/250 [===================>..........] - ETA: 31s - loss: 0.3027 - accuracy: 0.8948\n",
      "Epoch 4: accuracy improved from 0.89484 to 0.89509, saving model to output\\resnet101.h5\n",
      "168/250 [===================>..........] - ETA: 30s - loss: 0.3026 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "169/250 [===================>..........] - ETA: 30s - loss: 0.3031 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "170/250 [===================>..........] - ETA: 30s - loss: 0.3060 - accuracy: 0.8945\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "171/250 [===================>..........] - ETA: 29s - loss: 0.3058 - accuracy: 0.8946\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "172/250 [===================>..........] - ETA: 29s - loss: 0.3054 - accuracy: 0.8944\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "173/250 [===================>..........] - ETA: 28s - loss: 0.3051 - accuracy: 0.8945\n",
      "Epoch 4: accuracy did not improve from 0.89509\n",
      "174/250 [===================>..........] - ETA: 28s - loss: 0.3040 - accuracy: 0.8949\n",
      "Epoch 4: accuracy improved from 0.89509 to 0.89518, saving model to output\\resnet101.h5\n",
      "175/250 [====================>.........] - ETA: 28s - loss: 0.3035 - accuracy: 0.8952\n",
      "Epoch 4: accuracy did not improve from 0.89518\n",
      "176/250 [====================>.........] - ETA: 27s - loss: 0.3035 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89518\n",
      "177/250 [====================>.........] - ETA: 27s - loss: 0.3037 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89518\n",
      "178/250 [====================>.........] - ETA: 27s - loss: 0.3028 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89518\n",
      "179/250 [====================>.........] - ETA: 26s - loss: 0.3022 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89518\n",
      "180/250 [====================>.........] - ETA: 26s - loss: 0.3023 - accuracy: 0.8950\n",
      "Epoch 4: accuracy improved from 0.89518 to 0.89537, saving model to output\\resnet101.h5\n",
      "181/250 [====================>.........] - ETA: 26s - loss: 0.3018 - accuracy: 0.8954\n",
      "Epoch 4: accuracy improved from 0.89537 to 0.89560, saving model to output\\resnet101.h5\n",
      "182/250 [====================>.........] - ETA: 25s - loss: 0.3010 - accuracy: 0.8956\n",
      "Epoch 4: accuracy improved from 0.89560 to 0.89583, saving model to output\\resnet101.h5\n",
      "183/250 [====================>.........] - ETA: 25s - loss: 0.3004 - accuracy: 0.8958\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 25s - loss: 0.3006 - accuracy: 0.8956\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 24s - loss: 0.3006 - accuracy: 0.8958\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 24s - loss: 0.3005 - accuracy: 0.8957\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 23s - loss: 0.3003 - accuracy: 0.8957\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 23s - loss: 0.3009 - accuracy: 0.8954\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 23s - loss: 0.3014 - accuracy: 0.8952\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 22s - loss: 0.3006 - accuracy: 0.8954\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 22s - loss: 0.3003 - accuracy: 0.8953\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 21s - loss: 0.3004 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 21s - loss: 0.3017 - accuracy: 0.8952\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 21s - loss: 0.3013 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 20s - loss: 0.3011 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 20s - loss: 0.3007 - accuracy: 0.8957\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 19s - loss: 0.3008 - accuracy: 0.8958\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 19s - loss: 0.3013 - accuracy: 0.8954\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 19s - loss: 0.3011 - accuracy: 0.8956\n",
      "Epoch 4: accuracy improved from 0.89583 to 0.89594, saving model to output\\resnet101.h5\n",
      "200/250 [=======================>......] - ETA: 18s - loss: 0.3001 - accuracy: 0.8959\n",
      "Epoch 4: accuracy did not improve from 0.89594\n",
      "201/250 [=======================>......] - ETA: 18s - loss: 0.2999 - accuracy: 0.8958\n",
      "Epoch 4: accuracy improved from 0.89594 to 0.89604, saving model to output\\resnet101.h5\n",
      "202/250 [=======================>......] - ETA: 18s - loss: 0.2994 - accuracy: 0.8960\n",
      "Epoch 4: accuracy improved from 0.89604 to 0.89609, saving model to output\\resnet101.h5\n",
      "203/250 [=======================>......] - ETA: 18s - loss: 0.2991 - accuracy: 0.8961\n",
      "Epoch 4: accuracy improved from 0.89609 to 0.89614, saving model to output\\resnet101.h5\n",
      "204/250 [=======================>......] - ETA: 17s - loss: 0.2992 - accuracy: 0.8961\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "205/250 [=======================>......] - ETA: 17s - loss: 0.2991 - accuracy: 0.8959\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "206/250 [=======================>......] - ETA: 16s - loss: 0.2991 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "207/250 [=======================>......] - ETA: 16s - loss: 0.2990 - accuracy: 0.8957\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "208/250 [=======================>......] - ETA: 16s - loss: 0.2988 - accuracy: 0.8956\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "209/250 [========================>.....] - ETA: 15s - loss: 0.2985 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "210/250 [========================>.....] - ETA: 15s - loss: 0.2982 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "211/250 [========================>.....] - ETA: 14s - loss: 0.2978 - accuracy: 0.8957\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "212/250 [========================>.....] - ETA: 14s - loss: 0.2987 - accuracy: 0.8953\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "213/250 [========================>.....] - ETA: 14s - loss: 0.2990 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "214/250 [========================>.....] - ETA: 13s - loss: 0.2993 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "215/250 [========================>.....] - ETA: 13s - loss: 0.2988 - accuracy: 0.8953\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "216/250 [========================>.....] - ETA: 12s - loss: 0.2992 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "217/250 [=========================>....] - ETA: 12s - loss: 0.2990 - accuracy: 0.8947\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "218/250 [=========================>....] - ETA: 12s - loss: 0.2990 - accuracy: 0.8946\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "219/250 [=========================>....] - ETA: 11s - loss: 0.2992 - accuracy: 0.8947\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "220/250 [=========================>....] - ETA: 11s - loss: 0.2995 - accuracy: 0.8947\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "221/250 [=========================>....] - ETA: 10s - loss: 0.2996 - accuracy: 0.8944\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "222/250 [=========================>....] - ETA: 10s - loss: 0.2991 - accuracy: 0.8946\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "223/250 [=========================>....] - ETA: 10s - loss: 0.2987 - accuracy: 0.8946\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "224/250 [=========================>....] - ETA: 9s - loss: 0.2988 - accuracy: 0.8947 \n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "225/250 [==========================>...] - ETA: 9s - loss: 0.2994 - accuracy: 0.8946\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "226/250 [==========================>...] - ETA: 9s - loss: 0.2990 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "227/250 [==========================>...] - ETA: 8s - loss: 0.2983 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "228/250 [==========================>...] - ETA: 8s - loss: 0.2982 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "229/250 [==========================>...] - ETA: 7s - loss: 0.2979 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "230/250 [==========================>...] - ETA: 7s - loss: 0.2977 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "231/250 [==========================>...] - ETA: 7s - loss: 0.2980 - accuracy: 0.8949\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "232/250 [==========================>...] - ETA: 6s - loss: 0.2976 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "233/250 [==========================>...] - ETA: 6s - loss: 0.2977 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "234/250 [===========================>..] - ETA: 5s - loss: 0.2971 - accuracy: 0.8953\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "235/250 [===========================>..] - ETA: 5s - loss: 0.2977 - accuracy: 0.8949\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "236/250 [===========================>..] - ETA: 5s - loss: 0.2979 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "237/250 [===========================>..] - ETA: 4s - loss: 0.2978 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "238/250 [===========================>..] - ETA: 4s - loss: 0.2975 - accuracy: 0.8952\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "239/250 [===========================>..] - ETA: 4s - loss: 0.2981 - accuracy: 0.8949\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.2979 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "241/250 [===========================>..] - ETA: 3s - loss: 0.2982 - accuracy: 0.8948\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2981 - accuracy: 0.8949\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2978 - accuracy: 0.8949\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "244/250 [============================>.] - ETA: 2s - loss: 0.2981 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2984 - accuracy: 0.8950\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2981 - accuracy: 0.8951\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.2973 - accuracy: 0.8955\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.8953\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.8954\n",
      "Epoch 4: accuracy did not improve from 0.89614\n",
      "250/250 [==============================] - 110s 439ms/step - loss: 0.2982 - accuracy: 0.8952 - val_loss: 0.1781 - val_accuracy: 0.9491\n",
      "Epoch 5/15\n",
      "\n",
      "Epoch 5: accuracy improved from 0.89614 to 0.96875, saving model to output\\resnet101.h5\n",
      "  1/250 [..............................] - ETA: 4:22 - loss: 0.2099 - accuracy: 0.9688\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 40s - loss: 0.1696 - accuracy: 0.9688 \n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 54s - loss: 0.2112 - accuracy: 0.9583\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 58s - loss: 0.2254 - accuracy: 0.9297\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:00 - loss: 0.2263 - accuracy: 0.9312\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:01 - loss: 0.2156 - accuracy: 0.9323\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:02 - loss: 0.2186 - accuracy: 0.9286\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:02 - loss: 0.2511 - accuracy: 0.9180\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:02 - loss: 0.2554 - accuracy: 0.9167\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:02 - loss: 0.2581 - accuracy: 0.9187\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:02 - loss: 0.2679 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:02 - loss: 0.2907 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:02 - loss: 0.2797 - accuracy: 0.9111\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:02 - loss: 0.2868 - accuracy: 0.9085\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:01 - loss: 0.2923 - accuracy: 0.9083\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:01 - loss: 0.2992 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:01 - loss: 0.3064 - accuracy: 0.9026\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:01 - loss: 0.3063 - accuracy: 0.9028\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:01 - loss: 0.2998 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:01 - loss: 0.2967 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:01 - loss: 0.2966 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:01 - loss: 0.3047 - accuracy: 0.9034\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:01 - loss: 0.2986 - accuracy: 0.9049\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:01 - loss: 0.3039 - accuracy: 0.9036\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:01 - loss: 0.3026 - accuracy: 0.9038\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:00 - loss: 0.3059 - accuracy: 0.9002\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:00 - loss: 0.3033 - accuracy: 0.9016\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:00 - loss: 0.2999 - accuracy: 0.9029\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:00 - loss: 0.3021 - accuracy: 0.8998\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:00 - loss: 0.3001 - accuracy: 0.9000\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:00 - loss: 0.2961 - accuracy: 0.9012\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.2920 - accuracy: 0.9023\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 59s - loss: 0.2952 - accuracy: 0.8996 \n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 59s - loss: 0.2956 - accuracy: 0.8998\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.2906 - accuracy: 0.9018\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.2901 - accuracy: 0.9019\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.2870 - accuracy: 0.9029\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 0.2881 - accuracy: 0.9030\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.2902 - accuracy: 0.9014\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.2888 - accuracy: 0.9031\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 0.2880 - accuracy: 0.9040\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.2886 - accuracy: 0.9040\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.2890 - accuracy: 0.9026\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.2888 - accuracy: 0.9020\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.2929 - accuracy: 0.9007\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 0.2961 - accuracy: 0.8995\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.3005 - accuracy: 0.8989\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.2983 - accuracy: 0.8997\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 0.2987 - accuracy: 0.8992\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.2963 - accuracy: 0.8994\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.2974 - accuracy: 0.8989\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.2945 - accuracy: 0.9002\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 54s - loss: 0.2915 - accuracy: 0.9015\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.2910 - accuracy: 0.9010\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.2907 - accuracy: 0.9006\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 53s - loss: 0.2899 - accuracy: 0.9007\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 53s - loss: 0.2862 - accuracy: 0.9019\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.2880 - accuracy: 0.9019\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.2867 - accuracy: 0.9025\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 0.2859 - accuracy: 0.9031\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 0.2863 - accuracy: 0.9027\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.2852 - accuracy: 0.9032\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 51s - loss: 0.2843 - accuracy: 0.9043\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 51s - loss: 0.2864 - accuracy: 0.9033\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.2847 - accuracy: 0.9034\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.2818 - accuracy: 0.9048\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.2818 - accuracy: 0.9053\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.2859 - accuracy: 0.9040\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.2854 - accuracy: 0.9035\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.2828 - accuracy: 0.9045\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.2840 - accuracy: 0.9036\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.2824 - accuracy: 0.9041\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.2831 - accuracy: 0.9050\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.2820 - accuracy: 0.9050\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.2808 - accuracy: 0.9054\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.2801 - accuracy: 0.9054\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.2802 - accuracy: 0.9050\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.2806 - accuracy: 0.9046\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.2794 - accuracy: 0.9051\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.2788 - accuracy: 0.9055\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.2791 - accuracy: 0.9055\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.2797 - accuracy: 0.9043\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.2804 - accuracy: 0.9032\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.2798 - accuracy: 0.9040\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.2790 - accuracy: 0.9044\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 0.2792 - accuracy: 0.9048\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.2785 - accuracy: 0.9052\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.2778 - accuracy: 0.9055\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 0.2773 - accuracy: 0.9055\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.2766 - accuracy: 0.9056\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.2796 - accuracy: 0.9042\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.2780 - accuracy: 0.9046\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 0.2779 - accuracy: 0.9046\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.2785 - accuracy: 0.9046\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.2768 - accuracy: 0.9053\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 42s - loss: 0.2766 - accuracy: 0.9049\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.2751 - accuracy: 0.9053\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.2755 - accuracy: 0.9053\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.2767 - accuracy: 0.9056\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 0.2756 - accuracy: 0.9056\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.2753 - accuracy: 0.9053\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.2743 - accuracy: 0.9056\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 40s - loss: 0.2730 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.2730 - accuracy: 0.9056\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.2722 - accuracy: 0.9057\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.2706 - accuracy: 0.9062\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 39s - loss: 0.2696 - accuracy: 0.9065\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.2692 - accuracy: 0.9065\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.2688 - accuracy: 0.9068\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 38s - loss: 0.2681 - accuracy: 0.9071\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.2668 - accuracy: 0.9077\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.2655 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.2650 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 37s - loss: 0.2640 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.2631 - accuracy: 0.9090\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.2633 - accuracy: 0.9089\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.2619 - accuracy: 0.9097\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 36s - loss: 0.2617 - accuracy: 0.9102\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.2616 - accuracy: 0.9105\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.2614 - accuracy: 0.9104\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.2605 - accuracy: 0.9106\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.2601 - accuracy: 0.9106\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.2596 - accuracy: 0.9108\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.2612 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.2610 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.2613 - accuracy: 0.9102\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.2620 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.2622 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.2618 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.2608 - accuracy: 0.9103\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.2622 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.2624 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.2624 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.2616 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.2620 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.2623 - accuracy: 0.9095\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.2641 - accuracy: 0.9081\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.2651 - accuracy: 0.9076\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.2647 - accuracy: 0.9078\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.2655 - accuracy: 0.9078\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.2652 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.2636 - accuracy: 0.9089\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.2635 - accuracy: 0.9093\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.2630 - accuracy: 0.9095\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.2637 - accuracy: 0.9093\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.2630 - accuracy: 0.9097\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.2632 - accuracy: 0.9097\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.2628 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.2633 - accuracy: 0.9101\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.2639 - accuracy: 0.9096\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.2630 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.2638 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.2637 - accuracy: 0.9102\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.2634 - accuracy: 0.9104\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.2662 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.2666 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.2668 - accuracy: 0.9099\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.2670 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.2667 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.2675 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.2686 - accuracy: 0.9096\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.2680 - accuracy: 0.9098\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.2682 - accuracy: 0.9094\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.2685 - accuracy: 0.9093\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.2681 - accuracy: 0.9093\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.2680 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.2683 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.2698 - accuracy: 0.9089\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.2690 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.2685 - accuracy: 0.9090\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.2679 - accuracy: 0.9092\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.2675 - accuracy: 0.9094\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.2674 - accuracy: 0.9094\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.2684 - accuracy: 0.9090\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.2678 - accuracy: 0.9093\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.2681 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.2681 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.2687 - accuracy: 0.9086\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.2690 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.2685 - accuracy: 0.9080\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.2678 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.2686 - accuracy: 0.9080\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.2681 - accuracy: 0.9083\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.2671 - accuracy: 0.9087\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.2662 - accuracy: 0.9090\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.2665 - accuracy: 0.9088\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.2665 - accuracy: 0.9085\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.2658 - accuracy: 0.9088\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.2666 - accuracy: 0.9088\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.2671 - accuracy: 0.9083\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.2678 - accuracy: 0.9077\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.2680 - accuracy: 0.9076\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.2679 - accuracy: 0.9076\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.2674 - accuracy: 0.9079\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.2666 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.2659 - accuracy: 0.9087\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.2658 - accuracy: 0.9087\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.2661 - accuracy: 0.9086\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.2656 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.2648 - accuracy: 0.9096\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.2654 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.2658 - accuracy: 0.9088\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.2674 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.2680 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.2678 - accuracy: 0.9083\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.2671 - accuracy: 0.9087\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.2674 - accuracy: 0.9085\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.2675 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.2681 - accuracy: 0.9081\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.2673 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.2679 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.2676 - accuracy: 0.9085\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.2680 - accuracy: 0.9080\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.2684 - accuracy: 0.9082\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.2682 - accuracy: 0.9083\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.2679 - accuracy: 0.9084 \n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.2676 - accuracy: 0.9086\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.2669 - accuracy: 0.9087\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.2671 - accuracy: 0.9086\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.2674 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.2673 - accuracy: 0.9084\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.2667 - accuracy: 0.9088\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.2660 - accuracy: 0.9091\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.2659 - accuracy: 0.9092\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.2657 - accuracy: 0.9092\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.2651 - accuracy: 0.9096\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.2650 - accuracy: 0.9097\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.2645 - accuracy: 0.9100\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.2640 - accuracy: 0.9101\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.2637 - accuracy: 0.9102\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.2635 - accuracy: 0.9103\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.2634 - accuracy: 0.9103\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.2641 - accuracy: 0.9103\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.2640 - accuracy: 0.9101\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.2635 - accuracy: 0.9104\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.2634 - accuracy: 0.9104\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.2638 - accuracy: 0.9104\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.2631 - accuracy: 0.9106\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.2627 - accuracy: 0.9107\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.2631 - accuracy: 0.9106\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.2627 - accuracy: 0.9107\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2621 - accuracy: 0.9111\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2615 - accuracy: 0.9113\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.2613 - accuracy: 0.9113\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2611 - accuracy: 0.9113\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2614 - accuracy: 0.9111\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.2623 - accuracy: 0.9108\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.9111\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9110\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 90s 357ms/step - loss: 0.2618 - accuracy: 0.9113 - val_loss: 0.1462 - val_accuracy: 0.9607\n",
      "Epoch 6/15\n",
      "\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:47 - loss: 0.1748 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:11 - loss: 0.1477 - accuracy: 0.9531\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 0.2205 - accuracy: 0.9062\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:08 - loss: 0.1767 - accuracy: 0.9297\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:07 - loss: 0.1771 - accuracy: 0.9312\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:07 - loss: 0.1644 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:06 - loss: 0.1583 - accuracy: 0.9420\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:07 - loss: 0.1626 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:06 - loss: 0.1982 - accuracy: 0.9271\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.1912 - accuracy: 0.9344\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.1866 - accuracy: 0.9347\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:05 - loss: 0.1904 - accuracy: 0.9349\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 0.1865 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.1818 - accuracy: 0.9420\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 0.1968 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 0.1936 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.1942 - accuracy: 0.9357\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.1960 - accuracy: 0.9358\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.1943 - accuracy: 0.9342\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.1903 - accuracy: 0.9344\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:03 - loss: 0.2007 - accuracy: 0.9315\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.2148 - accuracy: 0.9261\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.2236 - accuracy: 0.9253\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.2223 - accuracy: 0.9245\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.2326 - accuracy: 0.9212\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.2318 - accuracy: 0.9219\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.2281 - accuracy: 0.9236\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.2267 - accuracy: 0.9241\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.2283 - accuracy: 0.9224\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.2380 - accuracy: 0.9198\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:00 - loss: 0.2367 - accuracy: 0.9204\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.2365 - accuracy: 0.9199\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.2471 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 59s - loss: 0.2468 - accuracy: 0.9182 \n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.2503 - accuracy: 0.9170\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.2544 - accuracy: 0.9141\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.2546 - accuracy: 0.9147\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 0.2511 - accuracy: 0.9161\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.2482 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.2499 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 0.2533 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.2523 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.2497 - accuracy: 0.9193\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.2494 - accuracy: 0.9183\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.2456 - accuracy: 0.9201\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.2463 - accuracy: 0.9205\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.2454 - accuracy: 0.9209\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.2538 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.2529 - accuracy: 0.9184\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.2524 - accuracy: 0.9194\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.2533 - accuracy: 0.9191\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.2520 - accuracy: 0.9201\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.2521 - accuracy: 0.9198\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.2514 - accuracy: 0.9190\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.2543 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.2518 - accuracy: 0.9196\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.2488 - accuracy: 0.9211\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.2460 - accuracy: 0.9224\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.2462 - accuracy: 0.9221\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.2460 - accuracy: 0.9219\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.2448 - accuracy: 0.9221\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.2479 - accuracy: 0.9199\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.2479 - accuracy: 0.9196\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.2475 - accuracy: 0.9189\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.2473 - accuracy: 0.9192\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.2480 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.2493 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.2477 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.2494 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.2481 - accuracy: 0.9183\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.2458 - accuracy: 0.9190\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.2483 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.2467 - accuracy: 0.9187\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.2486 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.2468 - accuracy: 0.9196\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.2470 - accuracy: 0.9190\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.2469 - accuracy: 0.9192\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.2452 - accuracy: 0.9199\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.2463 - accuracy: 0.9193\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.2456 - accuracy: 0.9195\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.2456 - accuracy: 0.9194\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.2452 - accuracy: 0.9192\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.2458 - accuracy: 0.9187\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.2453 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.2462 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.2456 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.2465 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.2473 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.2469 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.2460 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.2468 - accuracy: 0.9166\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.2461 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.2513 - accuracy: 0.9160\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.2508 - accuracy: 0.9166\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.2495 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.2501 - accuracy: 0.9170\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.2496 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.2492 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.2490 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.2490 - accuracy: 0.9167\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.2485 - accuracy: 0.9166\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.2471 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.2460 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.2465 - accuracy: 0.9166\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.2457 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.2469 - accuracy: 0.9164\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.2465 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.2474 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.2481 - accuracy: 0.9164\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.2483 - accuracy: 0.9166\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.2484 - accuracy: 0.9165\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.2473 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.2475 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.2477 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.2483 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.2489 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.2496 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.2488 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.2492 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.2494 - accuracy: 0.9170\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.2503 - accuracy: 0.9167\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.2494 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.2491 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.2492 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.2484 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 36s - loss: 0.2478 - accuracy: 0.9170\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.2479 - accuracy: 0.9167\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.2484 - accuracy: 0.9161\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.2479 - accuracy: 0.9163\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.2468 - accuracy: 0.9167\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.2461 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.2454 - accuracy: 0.9167\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.2455 - accuracy: 0.9164\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.2445 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.2445 - accuracy: 0.9170\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.2446 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.2452 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.2442 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.2438 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.2436 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.2444 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.2445 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.2445 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.2437 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.2449 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.2445 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.2440 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.2433 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.2431 - accuracy: 0.9179\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.2424 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.2434 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.2431 - accuracy: 0.9178\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.2431 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.2422 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.2419 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.2433 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.2427 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.2427 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.2421 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.2417 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.2407 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.2405 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.2404 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.2400 - accuracy: 0.9187\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.2396 - accuracy: 0.9188\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.2395 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.2393 - accuracy: 0.9187\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.2388 - accuracy: 0.9190\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.2386 - accuracy: 0.9191\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.2391 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.2387 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.2382 - accuracy: 0.9189\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.2377 - accuracy: 0.9191\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.2376 - accuracy: 0.9191\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.2395 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.2405 - accuracy: 0.9179\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.2413 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.2420 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.2430 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.2429 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.2429 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.2432 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.2429 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.2429 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.2426 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.2420 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.2427 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.2427 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.2427 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.2451 - accuracy: 0.9168\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.2449 - accuracy: 0.9169\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.2441 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.2440 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.2434 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.2436 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.2438 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.2433 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.2426 - accuracy: 0.9181\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.2435 - accuracy: 0.9181\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.2438 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.2441 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.2442 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.2445 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.2441 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.2444 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.2453 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.2449 - accuracy: 0.9173\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.2450 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.2454 - accuracy: 0.9172\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.2449 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.2445 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.2445 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.2445 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.2444 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.2440 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.2441 - accuracy: 0.9174 \n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.2438 - accuracy: 0.9175\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.2445 - accuracy: 0.9171\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.2439 - accuracy: 0.9174\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.2432 - accuracy: 0.9178\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.2428 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.2423 - accuracy: 0.9183\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.2428 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.2428 - accuracy: 0.9183\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.2424 - accuracy: 0.9184\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.2431 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.2431 - accuracy: 0.9183\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.2430 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.2424 - accuracy: 0.9184\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.2420 - accuracy: 0.9184\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.2432 - accuracy: 0.9179\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.2444 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.2440 - accuracy: 0.9178\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.2446 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.2445 - accuracy: 0.9179\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.2446 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.2443 - accuracy: 0.9176\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.2439 - accuracy: 0.9177\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.2438 - accuracy: 0.9178\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.2435 - accuracy: 0.9179\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.2436 - accuracy: 0.9180\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2433 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2438 - accuracy: 0.9181\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.2440 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2437 - accuracy: 0.9182\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2434 - accuracy: 0.9185\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9187\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2427 - accuracy: 0.9188\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9186\n",
      "Epoch 6: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 91s 364ms/step - loss: 0.2433 - accuracy: 0.9187 - val_loss: 0.1424 - val_accuracy: 0.9612\n",
      "Epoch 7/15\n",
      "\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:47 - loss: 0.5018 - accuracy: 0.8750\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:14 - loss: 0.3393 - accuracy: 0.8906\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:10 - loss: 0.3027 - accuracy: 0.8854\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:16 - loss: 0.2565 - accuracy: 0.9062\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:23 - loss: 0.2560 - accuracy: 0.9062\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:23 - loss: 0.2593 - accuracy: 0.9010\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:21 - loss: 0.2502 - accuracy: 0.9107\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:20 - loss: 0.2299 - accuracy: 0.9219\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:19 - loss: 0.2530 - accuracy: 0.9167\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:19 - loss: 0.2602 - accuracy: 0.9156\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:18 - loss: 0.2569 - accuracy: 0.9205\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:17 - loss: 0.2428 - accuracy: 0.9245\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:16 - loss: 0.2439 - accuracy: 0.9231\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:16 - loss: 0.2593 - accuracy: 0.9196\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:15 - loss: 0.2596 - accuracy: 0.9187\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:15 - loss: 0.2680 - accuracy: 0.9141\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:14 - loss: 0.2757 - accuracy: 0.9136\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:14 - loss: 0.2694 - accuracy: 0.9149\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:14 - loss: 0.2720 - accuracy: 0.9128\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:13 - loss: 0.2643 - accuracy: 0.9156\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:12 - loss: 0.2572 - accuracy: 0.9182\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:11 - loss: 0.2555 - accuracy: 0.9190\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:11 - loss: 0.2610 - accuracy: 0.9171\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:11 - loss: 0.2629 - accuracy: 0.9167\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:11 - loss: 0.2614 - accuracy: 0.9162\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:11 - loss: 0.2603 - accuracy: 0.9147\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:11 - loss: 0.2576 - accuracy: 0.9167\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:10 - loss: 0.2513 - accuracy: 0.9185\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:10 - loss: 0.2500 - accuracy: 0.9192\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:10 - loss: 0.2457 - accuracy: 0.9219\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:10 - loss: 0.2425 - accuracy: 0.9224\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:09 - loss: 0.2480 - accuracy: 0.9199\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:09 - loss: 0.2435 - accuracy: 0.9214\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:09 - loss: 0.2441 - accuracy: 0.9219\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:08 - loss: 0.2400 - accuracy: 0.9232\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:08 - loss: 0.2394 - accuracy: 0.9227\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:08 - loss: 0.2429 - accuracy: 0.9223\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:07 - loss: 0.2436 - accuracy: 0.9235\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:07 - loss: 0.2438 - accuracy: 0.9231\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 1:06 - loss: 0.2419 - accuracy: 0.9242\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 1:06 - loss: 0.2405 - accuracy: 0.9253\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 1:05 - loss: 0.2364 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 1:05 - loss: 0.2335 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 1:04 - loss: 0.2362 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 1:04 - loss: 0.2362 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 1:04 - loss: 0.2357 - accuracy: 0.9266\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 1:03 - loss: 0.2346 - accuracy: 0.9275\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 1:03 - loss: 0.2320 - accuracy: 0.9284\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 1:02 - loss: 0.2300 - accuracy: 0.9292\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 1:02 - loss: 0.2299 - accuracy: 0.9294\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 1:01 - loss: 0.2320 - accuracy: 0.9283\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 1:01 - loss: 0.2301 - accuracy: 0.9291\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 1:01 - loss: 0.2322 - accuracy: 0.9287\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 1:00 - loss: 0.2330 - accuracy: 0.9277\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 1:00 - loss: 0.2368 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 1:00 - loss: 0.2363 - accuracy: 0.9275\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 1:00 - loss: 0.2361 - accuracy: 0.9265\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 1:00 - loss: 0.2359 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 59s - loss: 0.2341 - accuracy: 0.9269 \n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 59s - loss: 0.2358 - accuracy: 0.9266\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 59s - loss: 0.2344 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 59s - loss: 0.2364 - accuracy: 0.9254\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 58s - loss: 0.2346 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 58s - loss: 0.2358 - accuracy: 0.9258\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 57s - loss: 0.2334 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 57s - loss: 0.2313 - accuracy: 0.9280\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 57s - loss: 0.2307 - accuracy: 0.9282\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 56s - loss: 0.2345 - accuracy: 0.9278\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 56s - loss: 0.2334 - accuracy: 0.9280\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 56s - loss: 0.2323 - accuracy: 0.9286\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 55s - loss: 0.2326 - accuracy: 0.9287\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 55s - loss: 0.2309 - accuracy: 0.9293\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 55s - loss: 0.2301 - accuracy: 0.9289\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 54s - loss: 0.2294 - accuracy: 0.9291\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 54s - loss: 0.2278 - accuracy: 0.9300\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 54s - loss: 0.2265 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 53s - loss: 0.2274 - accuracy: 0.9298\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 53s - loss: 0.2288 - accuracy: 0.9291\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 53s - loss: 0.2277 - accuracy: 0.9292\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 52s - loss: 0.2260 - accuracy: 0.9297\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 52s - loss: 0.2246 - accuracy: 0.9302\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 52s - loss: 0.2231 - accuracy: 0.9306\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 51s - loss: 0.2224 - accuracy: 0.9307\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 51s - loss: 0.2225 - accuracy: 0.9304\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 50s - loss: 0.2230 - accuracy: 0.9298\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 50s - loss: 0.2225 - accuracy: 0.9299\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 50s - loss: 0.2207 - accuracy: 0.9303\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 49s - loss: 0.2199 - accuracy: 0.9311\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 49s - loss: 0.2210 - accuracy: 0.9308\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 49s - loss: 0.2226 - accuracy: 0.9302\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 48s - loss: 0.2216 - accuracy: 0.9306\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 48s - loss: 0.2223 - accuracy: 0.9300\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 48s - loss: 0.2211 - accuracy: 0.9308\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 47s - loss: 0.2208 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 47s - loss: 0.2224 - accuracy: 0.9303\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 47s - loss: 0.2209 - accuracy: 0.9307\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 46s - loss: 0.2208 - accuracy: 0.9304\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 46s - loss: 0.2206 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 45s - loss: 0.2217 - accuracy: 0.9302\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 45s - loss: 0.2215 - accuracy: 0.9306\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 45s - loss: 0.2209 - accuracy: 0.9310\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 44s - loss: 0.2195 - accuracy: 0.9317\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 44s - loss: 0.2190 - accuracy: 0.9314\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 44s - loss: 0.2190 - accuracy: 0.9312\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.2181 - accuracy: 0.9315\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.2182 - accuracy: 0.9310\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 43s - loss: 0.2175 - accuracy: 0.9311\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.2171 - accuracy: 0.9311\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.2173 - accuracy: 0.9309\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 42s - loss: 0.2192 - accuracy: 0.9304\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.2189 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 41s - loss: 0.2178 - accuracy: 0.9311\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.2178 - accuracy: 0.9314\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 40s - loss: 0.2189 - accuracy: 0.9306\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 40s - loss: 0.2184 - accuracy: 0.9307\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.2189 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 39s - loss: 0.2177 - accuracy: 0.9308\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 39s - loss: 0.2188 - accuracy: 0.9303\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.2176 - accuracy: 0.9309\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 38s - loss: 0.2190 - accuracy: 0.9307\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 38s - loss: 0.2192 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 38s - loss: 0.2195 - accuracy: 0.9298\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 37s - loss: 0.2193 - accuracy: 0.9301\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 37s - loss: 0.2186 - accuracy: 0.9304\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 37s - loss: 0.2184 - accuracy: 0.9305\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 37s - loss: 0.2186 - accuracy: 0.9308\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 36s - loss: 0.2189 - accuracy: 0.9306\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 36s - loss: 0.2193 - accuracy: 0.9302\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 36s - loss: 0.2210 - accuracy: 0.9293\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 35s - loss: 0.2210 - accuracy: 0.9293\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 35s - loss: 0.2218 - accuracy: 0.9289\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 35s - loss: 0.2211 - accuracy: 0.9292\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 34s - loss: 0.2205 - accuracy: 0.9295\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 34s - loss: 0.2204 - accuracy: 0.9293\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 34s - loss: 0.2207 - accuracy: 0.9292\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.2212 - accuracy: 0.9290\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 33s - loss: 0.2218 - accuracy: 0.9293\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 33s - loss: 0.2218 - accuracy: 0.9291\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.2220 - accuracy: 0.9290\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.2249 - accuracy: 0.9281\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 32s - loss: 0.2252 - accuracy: 0.9280\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 32s - loss: 0.2240 - accuracy: 0.9285\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.2242 - accuracy: 0.9281\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 31s - loss: 0.2240 - accuracy: 0.9284\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.2238 - accuracy: 0.9282\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.2234 - accuracy: 0.9285\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 30s - loss: 0.2228 - accuracy: 0.9286\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.2225 - accuracy: 0.9286\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.2217 - accuracy: 0.9289\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.2224 - accuracy: 0.9287\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.2216 - accuracy: 0.9290\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.2227 - accuracy: 0.9285\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.2248 - accuracy: 0.9279\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.2241 - accuracy: 0.9282\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.2237 - accuracy: 0.9283\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.2236 - accuracy: 0.9286\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.2230 - accuracy: 0.9287\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.2229 - accuracy: 0.9285\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.2246 - accuracy: 0.9284\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.2243 - accuracy: 0.9286\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.2248 - accuracy: 0.9281\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.2249 - accuracy: 0.9280\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.2245 - accuracy: 0.9282\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.2243 - accuracy: 0.9283\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.2250 - accuracy: 0.9279\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.2245 - accuracy: 0.9282\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.2248 - accuracy: 0.9279\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.2253 - accuracy: 0.9274\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.2264 - accuracy: 0.9272\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.2261 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.2260 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.2264 - accuracy: 0.9265\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.2259 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.2259 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.2257 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.2260 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.2258 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.2252 - accuracy: 0.9272\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.2245 - accuracy: 0.9275\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.2245 - accuracy: 0.9275\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.2262 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.2262 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.2261 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.2264 - accuracy: 0.9264\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.2264 - accuracy: 0.9263\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.2261 - accuracy: 0.9263\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.2254 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.2246 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.2238 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.2239 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.2241 - accuracy: 0.9270\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.2245 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.2242 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.2242 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.2242 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.2243 - accuracy: 0.9264\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.2242 - accuracy: 0.9265\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.2240 - accuracy: 0.9265\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.2264 - accuracy: 0.9260\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.2266 - accuracy: 0.9255\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.2270 - accuracy: 0.9256\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.2268 - accuracy: 0.9255\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.2261 - accuracy: 0.9259\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.2254 - accuracy: 0.9262\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.2253 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.2250 - accuracy: 0.9264\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.2249 - accuracy: 0.9266\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.2249 - accuracy: 0.9265\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.2243 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.2245 - accuracy: 0.9267\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.2259 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.2258 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.2253 - accuracy: 0.9272\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.2254 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.2255 - accuracy: 0.9268\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.2255 - accuracy: 0.9269 \n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.2257 - accuracy: 0.9269\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.2249 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.2244 - accuracy: 0.9274\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.2249 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.2249 - accuracy: 0.9271\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.2243 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.2238 - accuracy: 0.9276\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.2244 - accuracy: 0.9274\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.2238 - accuracy: 0.9277\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.2234 - accuracy: 0.9279\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.2235 - accuracy: 0.9278\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.2244 - accuracy: 0.9274\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.2249 - accuracy: 0.9273\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.2248 - accuracy: 0.9274\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.2249 - accuracy: 0.9272\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.2244 - accuracy: 0.9272\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.2253 - accuracy: 0.9266\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.2260 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.2267 - accuracy: 0.9260\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.2261 - accuracy: 0.9262\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.2263 - accuracy: 0.9260\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.2263 - accuracy: 0.9260\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.2268 - accuracy: 0.9257\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.2270 - accuracy: 0.9256\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.2267 - accuracy: 0.9256\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2264 - accuracy: 0.9257\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2265 - accuracy: 0.9256\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.2262 - accuracy: 0.9258\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2263 - accuracy: 0.9257\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2260 - accuracy: 0.9259\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.9261\n",
      "Epoch 7: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.2269 - accuracy: 0.9259 - val_loss: 0.1296 - val_accuracy: 0.9622\n",
      "Epoch 8/15\n",
      "\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:50 - loss: 0.2067 - accuracy: 0.9062\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:11 - loss: 0.1973 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:18 - loss: 0.1789 - accuracy: 0.9375\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:16 - loss: 0.1442 - accuracy: 0.9531\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:16 - loss: 0.1792 - accuracy: 0.9375\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:15 - loss: 0.1748 - accuracy: 0.9375\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:14 - loss: 0.1795 - accuracy: 0.9420\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:12 - loss: 0.1913 - accuracy: 0.9375\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:12 - loss: 0.2097 - accuracy: 0.9236\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:11 - loss: 0.2384 - accuracy: 0.9156\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:11 - loss: 0.2401 - accuracy: 0.9176\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:11 - loss: 0.2383 - accuracy: 0.9167\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:10 - loss: 0.2321 - accuracy: 0.9207\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:10 - loss: 0.2407 - accuracy: 0.9196\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:09 - loss: 0.2352 - accuracy: 0.9208\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:09 - loss: 0.2286 - accuracy: 0.9238\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:08 - loss: 0.2269 - accuracy: 0.9228\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:08 - loss: 0.2294 - accuracy: 0.9201\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:07 - loss: 0.2244 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:06 - loss: 0.2265 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:06 - loss: 0.2361 - accuracy: 0.9196\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:06 - loss: 0.2327 - accuracy: 0.9205\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:06 - loss: 0.2424 - accuracy: 0.9158\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:05 - loss: 0.2370 - accuracy: 0.9180\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:05 - loss: 0.2324 - accuracy: 0.9200\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.2314 - accuracy: 0.9207\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:04 - loss: 0.2313 - accuracy: 0.9213\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:04 - loss: 0.2292 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.2254 - accuracy: 0.9235\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:03 - loss: 0.2215 - accuracy: 0.9250\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.2268 - accuracy: 0.9234\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.2227 - accuracy: 0.9248\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.2214 - accuracy: 0.9242\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.2214 - accuracy: 0.9246\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.2326 - accuracy: 0.9187\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.2345 - accuracy: 0.9184\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.2400 - accuracy: 0.9181\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.2429 - accuracy: 0.9178\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.2415 - accuracy: 0.9191\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.2391 - accuracy: 0.9203 \n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.2399 - accuracy: 0.9200\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.2357 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 0.2334 - accuracy: 0.9230\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.2324 - accuracy: 0.9240\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.2340 - accuracy: 0.9236\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.2323 - accuracy: 0.9246\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.2302 - accuracy: 0.9255\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.2287 - accuracy: 0.9258\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.2311 - accuracy: 0.9235\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.2292 - accuracy: 0.9237\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.2284 - accuracy: 0.9240\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.2296 - accuracy: 0.9237\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.2304 - accuracy: 0.9228\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.2327 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.2321 - accuracy: 0.9216\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.2342 - accuracy: 0.9213\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.2317 - accuracy: 0.9216\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.2325 - accuracy: 0.9208\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.2335 - accuracy: 0.9206\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.2337 - accuracy: 0.9198\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.2329 - accuracy: 0.9206\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.2320 - accuracy: 0.9214\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.2320 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.2344 - accuracy: 0.9204\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.2381 - accuracy: 0.9197\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.2363 - accuracy: 0.9200\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.2370 - accuracy: 0.9198\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.2371 - accuracy: 0.9200\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.2387 - accuracy: 0.9194\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.2378 - accuracy: 0.9196\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.2370 - accuracy: 0.9199\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.2393 - accuracy: 0.9188\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.2379 - accuracy: 0.9199\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.2371 - accuracy: 0.9202\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.2364 - accuracy: 0.9212\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.2344 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.2340 - accuracy: 0.9217\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.2347 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.2348 - accuracy: 0.9205\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.2330 - accuracy: 0.9215\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.2339 - accuracy: 0.9213\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.2328 - accuracy: 0.9215\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.2335 - accuracy: 0.9213\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.2331 - accuracy: 0.9215\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.2328 - accuracy: 0.9217\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.2334 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.2333 - accuracy: 0.9210\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.2323 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.2326 - accuracy: 0.9213\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.2334 - accuracy: 0.9212\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.2339 - accuracy: 0.9210\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.2327 - accuracy: 0.9212\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.2325 - accuracy: 0.9210\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.2311 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.2326 - accuracy: 0.9214\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.2320 - accuracy: 0.9215\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.2322 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.2319 - accuracy: 0.9209\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.2314 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.2318 - accuracy: 0.9206\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.2302 - accuracy: 0.9211\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.2284 - accuracy: 0.9219\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.2270 - accuracy: 0.9226\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.2258 - accuracy: 0.9234\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.2246 - accuracy: 0.9241\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.2232 - accuracy: 0.9245\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.2226 - accuracy: 0.9246\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.2222 - accuracy: 0.9248\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.2214 - accuracy: 0.9252\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.2203 - accuracy: 0.9256\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.2215 - accuracy: 0.9251\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.2218 - accuracy: 0.9249\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.2239 - accuracy: 0.9248\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.2241 - accuracy: 0.9246\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.2242 - accuracy: 0.9250\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.2280 - accuracy: 0.9248\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.2271 - accuracy: 0.9255\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.2266 - accuracy: 0.9258\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.2267 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.2255 - accuracy: 0.9266\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.2255 - accuracy: 0.9267\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.2283 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.2277 - accuracy: 0.9263\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.2274 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.2263 - accuracy: 0.9265\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.2258 - accuracy: 0.9266\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.2256 - accuracy: 0.9267\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.2254 - accuracy: 0.9265\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.2255 - accuracy: 0.9261\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.2246 - accuracy: 0.9264\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.2244 - accuracy: 0.9263\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.2249 - accuracy: 0.9264\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.2243 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.2238 - accuracy: 0.9265\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.2249 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.2254 - accuracy: 0.9258\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.2250 - accuracy: 0.9259\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.2243 - accuracy: 0.9262\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.2241 - accuracy: 0.9263\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.2235 - accuracy: 0.9266\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.2235 - accuracy: 0.9266\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.2227 - accuracy: 0.9272\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.2222 - accuracy: 0.9274\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.2230 - accuracy: 0.9269\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.2237 - accuracy: 0.9267\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.2235 - accuracy: 0.9268\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.2234 - accuracy: 0.9269\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.2239 - accuracy: 0.9269\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.2245 - accuracy: 0.9266\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.2239 - accuracy: 0.9271\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.2231 - accuracy: 0.9276\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.2237 - accuracy: 0.9270\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.2231 - accuracy: 0.9273\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.2229 - accuracy: 0.9274\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.2222 - accuracy: 0.9276\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.2233 - accuracy: 0.9271\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.2237 - accuracy: 0.9271\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.2246 - accuracy: 0.9268\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.2238 - accuracy: 0.9271\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.2239 - accuracy: 0.9270\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.2234 - accuracy: 0.9272\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.2239 - accuracy: 0.9271\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.2248 - accuracy: 0.9270\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.2242 - accuracy: 0.9272\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.2238 - accuracy: 0.9273\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.2240 - accuracy: 0.9270\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.2237 - accuracy: 0.9270\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.2229 - accuracy: 0.9273\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.2225 - accuracy: 0.9275\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.2217 - accuracy: 0.9279\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.2210 - accuracy: 0.9284\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.2214 - accuracy: 0.9282\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.2210 - accuracy: 0.9285\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.2213 - accuracy: 0.9283\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.2213 - accuracy: 0.9282\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.2210 - accuracy: 0.9284\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.2205 - accuracy: 0.9285\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.2202 - accuracy: 0.9285\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.2203 - accuracy: 0.9284\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.2200 - accuracy: 0.9285\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.2199 - accuracy: 0.9283\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.2201 - accuracy: 0.9281\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.2202 - accuracy: 0.9279\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.2202 - accuracy: 0.9282\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.2207 - accuracy: 0.9279\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.2200 - accuracy: 0.9283\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.2202 - accuracy: 0.9281\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.2201 - accuracy: 0.9284\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.2197 - accuracy: 0.9284\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.2190 - accuracy: 0.9286\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.2182 - accuracy: 0.9290\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.2190 - accuracy: 0.9287\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.2186 - accuracy: 0.9288\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.2190 - accuracy: 0.9286\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.2187 - accuracy: 0.9288\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.2182 - accuracy: 0.9290\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.2184 - accuracy: 0.9289\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.2179 - accuracy: 0.9293\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.2172 - accuracy: 0.9295\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.2173 - accuracy: 0.9295\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.2177 - accuracy: 0.9294\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.2173 - accuracy: 0.9296\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.2173 - accuracy: 0.9296\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.2171 - accuracy: 0.9297\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.2164 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.2168 - accuracy: 0.9295\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.2166 - accuracy: 0.9296\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.2165 - accuracy: 0.9298\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.2158 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.2157 - accuracy: 0.9304\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.2155 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.2153 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.2159 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.2162 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.2160 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.2159 - accuracy: 0.9303 \n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.2156 - accuracy: 0.9304\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.2152 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.2153 - accuracy: 0.9307\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.2153 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.2149 - accuracy: 0.9306\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.2153 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.2150 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.2147 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.2150 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.2150 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.2143 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.2144 - accuracy: 0.9304\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.2140 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.2149 - accuracy: 0.9304\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.2147 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.2146 - accuracy: 0.9304\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.2144 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.2141 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.2136 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.2134 - accuracy: 0.9305\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.2129 - accuracy: 0.9306\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.2133 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.2128 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.2124 - accuracy: 0.9303\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.2122 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2123 - accuracy: 0.9302\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2124 - accuracy: 0.9301\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.2125 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2127 - accuracy: 0.9301\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2126 - accuracy: 0.9301\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.9300\n",
      "Epoch 8: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 90s 361ms/step - loss: 0.2126 - accuracy: 0.9297 - val_loss: 0.1150 - val_accuracy: 0.9708\n",
      "Epoch 9/15\n",
      "\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 2:06 - loss: 0.2255 - accuracy: 0.9062\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:18 - loss: 0.2138 - accuracy: 0.9062\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:23 - loss: 0.2051 - accuracy: 0.9167\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:20 - loss: 0.2044 - accuracy: 0.9219\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:18 - loss: 0.2012 - accuracy: 0.9187\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:16 - loss: 0.2080 - accuracy: 0.9115\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:16 - loss: 0.2100 - accuracy: 0.9107\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:15 - loss: 0.2087 - accuracy: 0.9102\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:16 - loss: 0.2116 - accuracy: 0.9097\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:17 - loss: 0.2163 - accuracy: 0.9062\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:16 - loss: 0.2045 - accuracy: 0.9148\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:15 - loss: 0.1939 - accuracy: 0.9219\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:15 - loss: 0.1872 - accuracy: 0.9255\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:14 - loss: 0.1833 - accuracy: 0.9308\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:14 - loss: 0.1874 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:14 - loss: 0.1849 - accuracy: 0.9297\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:13 - loss: 0.1800 - accuracy: 0.9338\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:13 - loss: 0.1763 - accuracy: 0.9340\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:12 - loss: 0.1728 - accuracy: 0.9359\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:12 - loss: 0.1666 - accuracy: 0.9391\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:11 - loss: 0.1645 - accuracy: 0.9405\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:11 - loss: 0.1694 - accuracy: 0.9361\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:10 - loss: 0.1715 - accuracy: 0.9348\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:10 - loss: 0.1712 - accuracy: 0.9336\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:10 - loss: 0.1704 - accuracy: 0.9350\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:09 - loss: 0.1691 - accuracy: 0.9363\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:09 - loss: 0.1741 - accuracy: 0.9340\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:08 - loss: 0.1807 - accuracy: 0.9308\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:08 - loss: 0.1807 - accuracy: 0.9310\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:07 - loss: 0.1818 - accuracy: 0.9323\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:07 - loss: 0.1824 - accuracy: 0.9325\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:07 - loss: 0.1863 - accuracy: 0.9307\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:07 - loss: 0.1872 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:07 - loss: 0.1894 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:07 - loss: 0.1924 - accuracy: 0.9277\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:07 - loss: 0.1904 - accuracy: 0.9280\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:07 - loss: 0.1874 - accuracy: 0.9291\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:06 - loss: 0.1859 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:06 - loss: 0.1861 - accuracy: 0.9295\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 1:05 - loss: 0.1858 - accuracy: 0.9297\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 1:05 - loss: 0.1844 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 1:05 - loss: 0.1833 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 1:04 - loss: 0.1860 - accuracy: 0.9288\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 1:04 - loss: 0.1877 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 1:03 - loss: 0.1850 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 1:03 - loss: 0.1897 - accuracy: 0.9287\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 1:03 - loss: 0.1909 - accuracy: 0.9289\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 1:02 - loss: 0.1930 - accuracy: 0.9277\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 1:02 - loss: 0.1908 - accuracy: 0.9292\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 1:02 - loss: 0.1934 - accuracy: 0.9281\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 1:01 - loss: 0.1909 - accuracy: 0.9295\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 1:01 - loss: 0.1911 - accuracy: 0.9291\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 1:01 - loss: 0.1923 - accuracy: 0.9287\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 1:00 - loss: 0.1959 - accuracy: 0.9277\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 1:00 - loss: 0.1947 - accuracy: 0.9290\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 59s - loss: 0.1970 - accuracy: 0.9286 \n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 59s - loss: 0.1983 - accuracy: 0.9282\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 59s - loss: 0.1970 - accuracy: 0.9289\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 58s - loss: 0.1948 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 58s - loss: 0.1975 - accuracy: 0.9286\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 57s - loss: 0.1961 - accuracy: 0.9288\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 57s - loss: 0.1943 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 57s - loss: 0.1956 - accuracy: 0.9296\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 56s - loss: 0.1956 - accuracy: 0.9297\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 56s - loss: 0.1958 - accuracy: 0.9293\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 56s - loss: 0.1952 - accuracy: 0.9295\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 55s - loss: 0.1938 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 55s - loss: 0.1927 - accuracy: 0.9306\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 55s - loss: 0.1944 - accuracy: 0.9312\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 54s - loss: 0.1963 - accuracy: 0.9308\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 54s - loss: 0.1963 - accuracy: 0.9313\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 54s - loss: 0.1955 - accuracy: 0.9314\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 53s - loss: 0.1954 - accuracy: 0.9315\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 53s - loss: 0.1947 - accuracy: 0.9320\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 52s - loss: 0.1946 - accuracy: 0.9321\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 52s - loss: 0.1944 - accuracy: 0.9317\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 52s - loss: 0.1940 - accuracy: 0.9322\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 51s - loss: 0.1937 - accuracy: 0.9323\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 51s - loss: 0.1966 - accuracy: 0.9316\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 51s - loss: 0.1959 - accuracy: 0.9316\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 50s - loss: 0.1953 - accuracy: 0.9317\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 50s - loss: 0.1952 - accuracy: 0.9318\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 50s - loss: 0.1956 - accuracy: 0.9315\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 49s - loss: 0.1942 - accuracy: 0.9323\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 49s - loss: 0.1947 - accuracy: 0.9324\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 49s - loss: 0.1955 - accuracy: 0.9320\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 48s - loss: 0.1943 - accuracy: 0.9325\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 48s - loss: 0.1966 - accuracy: 0.9322\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 48s - loss: 0.1981 - accuracy: 0.9308\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.1972 - accuracy: 0.9312\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 47s - loss: 0.1966 - accuracy: 0.9317\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 47s - loss: 0.1982 - accuracy: 0.9310\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.1980 - accuracy: 0.9308\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.1996 - accuracy: 0.9305\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 46s - loss: 0.1988 - accuracy: 0.9309\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.2002 - accuracy: 0.9303\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.2006 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 45s - loss: 0.2006 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.2006 - accuracy: 0.9296\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 44s - loss: 0.2001 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.1995 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.2006 - accuracy: 0.9292\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 43s - loss: 0.2026 - accuracy: 0.9287\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.2043 - accuracy: 0.9279\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.2032 - accuracy: 0.9286\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 42s - loss: 0.2053 - accuracy: 0.9281\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 42s - loss: 0.2048 - accuracy: 0.9282\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.2035 - accuracy: 0.9288\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.2043 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 41s - loss: 0.2055 - accuracy: 0.9278\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.2068 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 40s - loss: 0.2067 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 40s - loss: 0.2081 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 40s - loss: 0.2066 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.2069 - accuracy: 0.9264\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 39s - loss: 0.2064 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 39s - loss: 0.2061 - accuracy: 0.9263\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.2064 - accuracy: 0.9261\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 38s - loss: 0.2058 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 38s - loss: 0.2051 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.2046 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.2047 - accuracy: 0.9270\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 37s - loss: 0.2048 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.2050 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.2038 - accuracy: 0.9275\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 36s - loss: 0.2043 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 36s - loss: 0.2045 - accuracy: 0.9267\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.2040 - accuracy: 0.9270\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.2046 - accuracy: 0.9268\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 35s - loss: 0.2053 - accuracy: 0.9264\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.2047 - accuracy: 0.9268\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.2042 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 34s - loss: 0.2031 - accuracy: 0.9276\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.2036 - accuracy: 0.9275\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.2035 - accuracy: 0.9275\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.2043 - accuracy: 0.9267\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 33s - loss: 0.2039 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.2034 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.2040 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.2038 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.2034 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.2040 - accuracy: 0.9263\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.2043 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 31s - loss: 0.2057 - accuracy: 0.9258\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.2053 - accuracy: 0.9261\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.2052 - accuracy: 0.9264\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 30s - loss: 0.2049 - accuracy: 0.9264\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.2055 - accuracy: 0.9263\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.2044 - accuracy: 0.9268\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.2051 - accuracy: 0.9262\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.2044 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.2059 - accuracy: 0.9260\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.2068 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.2071 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.2083 - accuracy: 0.9256\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.2094 - accuracy: 0.9255\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.2100 - accuracy: 0.9254\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.2093 - accuracy: 0.9258\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.2100 - accuracy: 0.9257\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.2093 - accuracy: 0.9258\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.2090 - accuracy: 0.9257\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.2081 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.2084 - accuracy: 0.9260\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.2091 - accuracy: 0.9261\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.2090 - accuracy: 0.9259\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.2092 - accuracy: 0.9262\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.2093 - accuracy: 0.9263\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.2090 - accuracy: 0.9263\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.2083 - accuracy: 0.9266\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.2075 - accuracy: 0.9270\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.2075 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.2074 - accuracy: 0.9270\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.2084 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.2080 - accuracy: 0.9265\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.2082 - accuracy: 0.9268\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.2079 - accuracy: 0.9270\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.2078 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.2084 - accuracy: 0.9268\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.2081 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.2074 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.2071 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.2076 - accuracy: 0.9269\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.2077 - accuracy: 0.9267\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.2067 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.2064 - accuracy: 0.9274\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.2056 - accuracy: 0.9278\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.2052 - accuracy: 0.9276\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.2064 - accuracy: 0.9272\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.2073 - accuracy: 0.9272\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.2074 - accuracy: 0.9273\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.2077 - accuracy: 0.9274\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.2077 - accuracy: 0.9274\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.2080 - accuracy: 0.9271\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.2074 - accuracy: 0.9274\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.2075 - accuracy: 0.9274\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.2068 - accuracy: 0.9278\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.2062 - accuracy: 0.9281\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.2062 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.2060 - accuracy: 0.9285\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.2058 - accuracy: 0.9286\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.2060 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.2054 - accuracy: 0.9285\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.2061 - accuracy: 0.9283\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.2068 - accuracy: 0.9280\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.2063 - accuracy: 0.9282\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.2059 - accuracy: 0.9285\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.2056 - accuracy: 0.9286\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.2053 - accuracy: 0.9286\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.2049 - accuracy: 0.9288\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.2044 - accuracy: 0.9290\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.2040 - accuracy: 0.9294\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.2032 - accuracy: 0.9297\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.2032 - accuracy: 0.9296\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.2031 - accuracy: 0.9295\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.2025 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.2020 - accuracy: 0.9301 \n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.2014 - accuracy: 0.9303\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.2010 - accuracy: 0.9303\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.2004 - accuracy: 0.9305\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.2011 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.2012 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.2012 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.2018 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.2015 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.2009 - accuracy: 0.9302\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.2007 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.2013 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.2016 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.2025 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.2024 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.2019 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.2017 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.2010 - accuracy: 0.9303\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.2012 - accuracy: 0.9304\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.2008 - accuracy: 0.9307\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.2013 - accuracy: 0.9303\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.2010 - accuracy: 0.9305\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.2017 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.2014 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.2013 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.2010 - accuracy: 0.9302\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.2014 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.2020 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.2016 - accuracy: 0.9301\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.2022 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2018 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9300\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2020 - accuracy: 0.9298\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2016 - accuracy: 0.9299\n",
      "Epoch 9: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.2014 - accuracy: 0.9301 - val_loss: 0.1121 - val_accuracy: 0.9677\n",
      "Epoch 10/15\n",
      "\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:46 - loss: 0.1973 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.1660 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:06 - loss: 0.1807 - accuracy: 0.9271\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:06 - loss: 0.1951 - accuracy: 0.9297\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:06 - loss: 0.1701 - accuracy: 0.9438\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:07 - loss: 0.1733 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:07 - loss: 0.1680 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:06 - loss: 0.1549 - accuracy: 0.9414\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:06 - loss: 0.1488 - accuracy: 0.9444\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.1463 - accuracy: 0.9469\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.1712 - accuracy: 0.9432\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.1934 - accuracy: 0.9401\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 0.2099 - accuracy: 0.9327\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.2091 - accuracy: 0.9286\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 0.2057 - accuracy: 0.9312\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 0.2085 - accuracy: 0.9297\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.2041 - accuracy: 0.9320\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.2048 - accuracy: 0.9306\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.2025 - accuracy: 0.9293\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.2018 - accuracy: 0.9312\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:03 - loss: 0.1981 - accuracy: 0.9315\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.1936 - accuracy: 0.9318\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.1916 - accuracy: 0.9321\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:02 - loss: 0.1984 - accuracy: 0.9297\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.1950 - accuracy: 0.9312\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.1973 - accuracy: 0.9303\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:01 - loss: 0.1950 - accuracy: 0.9317\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.1957 - accuracy: 0.9297\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.1982 - accuracy: 0.9300\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:00 - loss: 0.1962 - accuracy: 0.9302\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:00 - loss: 0.1990 - accuracy: 0.9274\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.1989 - accuracy: 0.9268\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.1966 - accuracy: 0.9290\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 59s - loss: 0.1958 - accuracy: 0.9301 \n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.1919 - accuracy: 0.9321\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.1902 - accuracy: 0.9332\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 58s - loss: 0.1967 - accuracy: 0.9316\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 0.1944 - accuracy: 0.9334\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.1978 - accuracy: 0.9327\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.1994 - accuracy: 0.9320\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 0.1969 - accuracy: 0.9329\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.1951 - accuracy: 0.9338\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.1928 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 56s - loss: 0.1903 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 56s - loss: 0.1929 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 0.1960 - accuracy: 0.9348\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.1988 - accuracy: 0.9342\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.1996 - accuracy: 0.9336\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 0.1973 - accuracy: 0.9349\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.1961 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.1939 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.1943 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 54s - loss: 0.1926 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.1950 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.1922 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.1948 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 53s - loss: 0.1966 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.1955 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.1983 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 0.2012 - accuracy: 0.9344\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 0.2026 - accuracy: 0.9344\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.2012 - accuracy: 0.9350\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.1987 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.1975 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.1967 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.1986 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.1990 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.1975 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.1967 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.1976 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.1969 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.1966 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.1957 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.1953 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.1940 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.1958 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.1967 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 47s - loss: 0.1975 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.1958 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.1950 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.1938 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 0.1985 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.1983 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.1977 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.1983 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 0.1983 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.1988 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.1978 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 0.1964 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.1961 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.1967 - accuracy: 0.9361\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.1964 - accuracy: 0.9361\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 0.1967 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.1952 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.1944 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 42s - loss: 0.1947 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.1947 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.1931 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.1929 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 0.1944 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.1944 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.1941 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 40s - loss: 0.1941 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.1941 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.1942 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.1937 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 39s - loss: 0.1928 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.1931 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.1930 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 38s - loss: 0.1931 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.1924 - accuracy: 0.9361\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.1915 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.1911 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 37s - loss: 0.1903 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.1903 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.1890 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 36s - loss: 0.1880 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 36s - loss: 0.1885 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.1902 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.1904 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 35s - loss: 0.1898 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.1905 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.1900 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.1890 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 34s - loss: 0.1889 - accuracy: 0.9375\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.1901 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.1900 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 0.1908 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 0.1911 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.1908 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.1911 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 0.1909 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.1922 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.1921 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 0.1947 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 0.1956 - accuracy: 0.9349\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.1965 - accuracy: 0.9347\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.1965 - accuracy: 0.9345\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 0.1973 - accuracy: 0.9341\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 0.1967 - accuracy: 0.9343\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.1960 - accuracy: 0.9346\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 29s - loss: 0.1958 - accuracy: 0.9344\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.1950 - accuracy: 0.9348\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.1940 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.1939 - accuracy: 0.9351\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 28s - loss: 0.1936 - accuracy: 0.9349\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 28s - loss: 0.1929 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.1931 - accuracy: 0.9355\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 27s - loss: 0.1931 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.1926 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.1921 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.1922 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 26s - loss: 0.1937 - accuracy: 0.9350\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 26s - loss: 0.1932 - accuracy: 0.9352\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.1930 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.1933 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.1934 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.1927 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.1926 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 24s - loss: 0.1929 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.1925 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.1924 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.1923 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 0.1918 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.1922 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.1918 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 22s - loss: 0.1926 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.1925 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.1920 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.1923 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 21s - loss: 0.1918 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.1922 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.1917 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.1916 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.1914 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.1935 - accuracy: 0.9355\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.1933 - accuracy: 0.9353\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 19s - loss: 0.1927 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.1924 - accuracy: 0.9357\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.1925 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.1929 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 18s - loss: 0.1924 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.1916 - accuracy: 0.9359\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.1933 - accuracy: 0.9354\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 17s - loss: 0.1929 - accuracy: 0.9356\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.1926 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.1924 - accuracy: 0.9358\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.1917 - accuracy: 0.9361\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 16s - loss: 0.1917 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.1918 - accuracy: 0.9361\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.1913 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.1915 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.1908 - accuracy: 0.9362\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.1904 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.1902 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 14s - loss: 0.1903 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.1903 - accuracy: 0.9360\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.1897 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.1892 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.1886 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.1882 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.1894 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1893 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.1892 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.1887 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1885 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 0.1882 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.1881 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.1879 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1880 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.1877 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.1875 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1876 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 9s - loss: 0.1873 - accuracy: 0.9369 \n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.1872 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.1873 - accuracy: 0.9364\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1872 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.1870 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.1870 - accuracy: 0.9363\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1868 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1869 - accuracy: 0.9365\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.1864 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1858 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1863 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.1867 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.1867 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1864 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1864 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.1863 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1861 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1859 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1856 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.1854 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1853 - accuracy: 0.9373\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1862 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.1858 - accuracy: 0.9369\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1855 - accuracy: 0.9371\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1864 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1864 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1861 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1858 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1858 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.1857 - accuracy: 0.9366\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1853 - accuracy: 0.9367\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1848 - accuracy: 0.9368\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1845 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9370\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9372\n",
      "Epoch 10: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 87s 350ms/step - loss: 0.1842 - accuracy: 0.9370 - val_loss: 0.1088 - val_accuracy: 0.9662\n",
      "Epoch 11/15\n",
      "\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 2:02 - loss: 0.1568 - accuracy: 0.9062\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:18 - loss: 0.1262 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:16 - loss: 0.1254 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:16 - loss: 0.1242 - accuracy: 0.9453\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:16 - loss: 0.1572 - accuracy: 0.9500\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:15 - loss: 0.1573 - accuracy: 0.9531\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:15 - loss: 0.2112 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:15 - loss: 0.2587 - accuracy: 0.9141\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:14 - loss: 0.2596 - accuracy: 0.9097\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:14 - loss: 0.2510 - accuracy: 0.9094\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:14 - loss: 0.2664 - accuracy: 0.9034\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:14 - loss: 0.2619 - accuracy: 0.9036\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:13 - loss: 0.2460 - accuracy: 0.9111\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:13 - loss: 0.2329 - accuracy: 0.9152\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:12 - loss: 0.2344 - accuracy: 0.9125\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:11 - loss: 0.2248 - accuracy: 0.9180\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:10 - loss: 0.2260 - accuracy: 0.9191\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:09 - loss: 0.2300 - accuracy: 0.9167\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:09 - loss: 0.2281 - accuracy: 0.9194\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:08 - loss: 0.2274 - accuracy: 0.9172\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:08 - loss: 0.2226 - accuracy: 0.9182\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:07 - loss: 0.2189 - accuracy: 0.9190\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:07 - loss: 0.2161 - accuracy: 0.9198\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:07 - loss: 0.2125 - accuracy: 0.9219\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:06 - loss: 0.2154 - accuracy: 0.9225\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:05 - loss: 0.2128 - accuracy: 0.9231\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:05 - loss: 0.2112 - accuracy: 0.9236\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:04 - loss: 0.2080 - accuracy: 0.9252\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:04 - loss: 0.2071 - accuracy: 0.9246\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:03 - loss: 0.2059 - accuracy: 0.9250\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:03 - loss: 0.2070 - accuracy: 0.9264\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:03 - loss: 0.2062 - accuracy: 0.9277\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.2074 - accuracy: 0.9271\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:02 - loss: 0.2095 - accuracy: 0.9265\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:02 - loss: 0.2076 - accuracy: 0.9268\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.2113 - accuracy: 0.9262\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:01 - loss: 0.2090 - accuracy: 0.9274\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.2047 - accuracy: 0.9293\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.2051 - accuracy: 0.9287\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 1:00 - loss: 0.2014 - accuracy: 0.9305\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 1:00 - loss: 0.2028 - accuracy: 0.9299\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.1996 - accuracy: 0.9308 \n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.2001 - accuracy: 0.9302\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.1989 - accuracy: 0.9297\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.1975 - accuracy: 0.9292\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.2005 - accuracy: 0.9293\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.2011 - accuracy: 0.9295\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.1993 - accuracy: 0.9303\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.1981 - accuracy: 0.9305\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.2001 - accuracy: 0.9300\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.1980 - accuracy: 0.9308\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 56s - loss: 0.1962 - accuracy: 0.9315\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 56s - loss: 0.1971 - accuracy: 0.9310\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.1964 - accuracy: 0.9311\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.1973 - accuracy: 0.9318\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 55s - loss: 0.1956 - accuracy: 0.9325\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 55s - loss: 0.1953 - accuracy: 0.9326\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.1959 - accuracy: 0.9327\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.1965 - accuracy: 0.9317\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 54s - loss: 0.1965 - accuracy: 0.9312\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.1958 - accuracy: 0.9319\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.1955 - accuracy: 0.9309\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 53s - loss: 0.1973 - accuracy: 0.9311\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.1966 - accuracy: 0.9316\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.1944 - accuracy: 0.9327\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 52s - loss: 0.1932 - accuracy: 0.9332\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.1936 - accuracy: 0.9328\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.1992 - accuracy: 0.9315\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 51s - loss: 0.1972 - accuracy: 0.9325\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 51s - loss: 0.1960 - accuracy: 0.9335\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.1944 - accuracy: 0.9340\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.1937 - accuracy: 0.9340\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.1962 - accuracy: 0.9336\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.1953 - accuracy: 0.9337\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.1940 - accuracy: 0.9342\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.1923 - accuracy: 0.9346\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.1911 - accuracy: 0.9351\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.1915 - accuracy: 0.9347\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.1944 - accuracy: 0.9339\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.1937 - accuracy: 0.9344\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.1923 - accuracy: 0.9348\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.1910 - accuracy: 0.9356\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.1915 - accuracy: 0.9352\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.1919 - accuracy: 0.9349\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.1913 - accuracy: 0.9353\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.1908 - accuracy: 0.9353\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.1906 - accuracy: 0.9353\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.1900 - accuracy: 0.9354\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.1899 - accuracy: 0.9350\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.1898 - accuracy: 0.9347\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.1890 - accuracy: 0.9351\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.1890 - accuracy: 0.9348\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.1886 - accuracy: 0.9348\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.1883 - accuracy: 0.9348\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.1877 - accuracy: 0.9349\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.1879 - accuracy: 0.9349\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.1871 - accuracy: 0.9352\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.1871 - accuracy: 0.9349\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.1867 - accuracy: 0.9347\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.1858 - accuracy: 0.9350\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.1856 - accuracy: 0.9353\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.1848 - accuracy: 0.9360\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.1851 - accuracy: 0.9363\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.1836 - accuracy: 0.9369\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.1828 - accuracy: 0.9372\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.1831 - accuracy: 0.9369\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.1818 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.1809 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.1812 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.1818 - accuracy: 0.9366\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.1808 - accuracy: 0.9369\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.1800 - accuracy: 0.9372\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.1807 - accuracy: 0.9364\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.1810 - accuracy: 0.9361\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.1821 - accuracy: 0.9356\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.1843 - accuracy: 0.9353\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.1844 - accuracy: 0.9354\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.1839 - accuracy: 0.9356\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.1838 - accuracy: 0.9359\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.1829 - accuracy: 0.9362\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.1830 - accuracy: 0.9360\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.1835 - accuracy: 0.9355\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.1827 - accuracy: 0.9357\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.1819 - accuracy: 0.9362\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.1818 - accuracy: 0.9365\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.1814 - accuracy: 0.9365\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.1810 - accuracy: 0.9365\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.1802 - accuracy: 0.9370\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.1791 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.1792 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.1785 - accuracy: 0.9377\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.1792 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.1783 - accuracy: 0.9380\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.1781 - accuracy: 0.9380\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.1778 - accuracy: 0.9380\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.1767 - accuracy: 0.9384\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.1769 - accuracy: 0.9382\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.1766 - accuracy: 0.9384\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.1758 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.1755 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.1757 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.1754 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.1747 - accuracy: 0.9392\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.1739 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.1732 - accuracy: 0.9399\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.1732 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.1727 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.1722 - accuracy: 0.9402\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.1720 - accuracy: 0.9404\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.1728 - accuracy: 0.9404\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.1724 - accuracy: 0.9406\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.1735 - accuracy: 0.9400\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.1730 - accuracy: 0.9402\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.1729 - accuracy: 0.9399\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.1725 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.1727 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.1731 - accuracy: 0.9399\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.1733 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.1726 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.1723 - accuracy: 0.9402\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.1716 - accuracy: 0.9404\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.1713 - accuracy: 0.9408\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.1719 - accuracy: 0.9410\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.1733 - accuracy: 0.9405\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.1734 - accuracy: 0.9403\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.1730 - accuracy: 0.9405\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.1733 - accuracy: 0.9403\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.1725 - accuracy: 0.9405\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.1727 - accuracy: 0.9403\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.1729 - accuracy: 0.9402\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.1735 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.1734 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.1733 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.1729 - accuracy: 0.9400\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.1729 - accuracy: 0.9400\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.1729 - accuracy: 0.9401\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.1743 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.1741 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.1741 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.1739 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.1753 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.1747 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.1748 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.1761 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.1759 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.1764 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.1759 - accuracy: 0.9385\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.1757 - accuracy: 0.9385\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.1756 - accuracy: 0.9386\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.1753 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.1751 - accuracy: 0.9388\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.1759 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.1757 - accuracy: 0.9384\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.1754 - accuracy: 0.9386\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.1752 - accuracy: 0.9386\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1748 - accuracy: 0.9389\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.1744 - accuracy: 0.9391\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.1757 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.1761 - accuracy: 0.9379\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1761 - accuracy: 0.9379\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.1769 - accuracy: 0.9376\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.1767 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1768 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.1774 - accuracy: 0.9376\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.1785 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1786 - accuracy: 0.9375\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1780 - accuracy: 0.9376\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.1774 - accuracy: 0.9379\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.1778 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1774 - accuracy: 0.9381\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.1781 - accuracy: 0.9379\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.1782 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1782 - accuracy: 0.9378\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1776 - accuracy: 0.9380\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.1776 - accuracy: 0.9382 \n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.1776 - accuracy: 0.9382\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1776 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1783 - accuracy: 0.9379\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.1779 - accuracy: 0.9382\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1776 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1780 - accuracy: 0.9382\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.1779 - accuracy: 0.9383\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1774 - accuracy: 0.9386\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1771 - accuracy: 0.9387\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1767 - accuracy: 0.9389\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.1761 - accuracy: 0.9391\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1760 - accuracy: 0.9393\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1756 - accuracy: 0.9394\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.1756 - accuracy: 0.9394\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1756 - accuracy: 0.9392\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1751 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1756 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.1758 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1760 - accuracy: 0.9393\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1760 - accuracy: 0.9393\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.1757 - accuracy: 0.9395\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1754 - accuracy: 0.9396\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1753 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1752 - accuracy: 0.9397\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1750 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1748 - accuracy: 0.9399\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1750 - accuracy: 0.9398\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.1749 - accuracy: 0.9399\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1746 - accuracy: 0.9400\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1747 - accuracy: 0.9400\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1742 - accuracy: 0.9403\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9405\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9406\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9406\n",
      "Epoch 11: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 0.1749 - accuracy: 0.9401 - val_loss: 0.1024 - val_accuracy: 0.9677\n",
      "Epoch 12/15\n",
      "\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:42 - loss: 0.2228 - accuracy: 0.9062\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.1373 - accuracy: 0.9375\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:06 - loss: 0.1931 - accuracy: 0.9167\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:07 - loss: 0.1593 - accuracy: 0.9297\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:06 - loss: 0.1384 - accuracy: 0.9438\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:05 - loss: 0.1275 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:05 - loss: 0.1221 - accuracy: 0.9554\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:06 - loss: 0.1398 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:05 - loss: 0.1405 - accuracy: 0.9514\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:05 - loss: 0.1530 - accuracy: 0.9500\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:05 - loss: 0.1622 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:05 - loss: 0.1611 - accuracy: 0.9479\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 0.1547 - accuracy: 0.9495\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.1494 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:04 - loss: 0.1451 - accuracy: 0.9542\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 0.1462 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.1407 - accuracy: 0.9559\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.1395 - accuracy: 0.9566\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.1358 - accuracy: 0.9589\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.1459 - accuracy: 0.9563\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.1457 - accuracy: 0.9554\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.1469 - accuracy: 0.9545\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.1425 - accuracy: 0.9565\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:04 - loss: 0.1421 - accuracy: 0.9570\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.1443 - accuracy: 0.9563\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.1408 - accuracy: 0.9579\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:04 - loss: 0.1448 - accuracy: 0.9560\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:04 - loss: 0.1418 - accuracy: 0.9576\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.1406 - accuracy: 0.9580\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:03 - loss: 0.1393 - accuracy: 0.9594\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:03 - loss: 0.1393 - accuracy: 0.9587\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.1410 - accuracy: 0.9580\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.1413 - accuracy: 0.9574\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.1423 - accuracy: 0.9568\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.1472 - accuracy: 0.9554\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.1450 - accuracy: 0.9566\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.1439 - accuracy: 0.9569\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.1415 - accuracy: 0.9581\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.1446 - accuracy: 0.9575\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.1430 - accuracy: 0.9578 \n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.1509 - accuracy: 0.9543\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.1516 - accuracy: 0.9539\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.1530 - accuracy: 0.9528\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 1:00 - loss: 0.1536 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 1:00 - loss: 0.1542 - accuracy: 0.9535\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 1:00 - loss: 0.1534 - accuracy: 0.9538\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 1:00 - loss: 0.1528 - accuracy: 0.9535\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 1:00 - loss: 0.1552 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 59s - loss: 0.1542 - accuracy: 0.9534 \n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 59s - loss: 0.1565 - accuracy: 0.9531\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 59s - loss: 0.1605 - accuracy: 0.9516\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 59s - loss: 0.1674 - accuracy: 0.9495\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 59s - loss: 0.1672 - accuracy: 0.9493\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 59s - loss: 0.1669 - accuracy: 0.9485\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.1670 - accuracy: 0.9477\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 58s - loss: 0.1647 - accuracy: 0.9487\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 58s - loss: 0.1642 - accuracy: 0.9490\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 58s - loss: 0.1660 - accuracy: 0.9488\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 58s - loss: 0.1664 - accuracy: 0.9486\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 57s - loss: 0.1655 - accuracy: 0.9484\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 57s - loss: 0.1640 - accuracy: 0.9493\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 56s - loss: 0.1659 - accuracy: 0.9491\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 56s - loss: 0.1676 - accuracy: 0.9489\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 56s - loss: 0.1666 - accuracy: 0.9492\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.1661 - accuracy: 0.9495\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 55s - loss: 0.1680 - accuracy: 0.9484\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 55s - loss: 0.1680 - accuracy: 0.9473\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 54s - loss: 0.1702 - accuracy: 0.9472\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 54s - loss: 0.1695 - accuracy: 0.9470\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 54s - loss: 0.1683 - accuracy: 0.9473\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 53s - loss: 0.1684 - accuracy: 0.9472\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 53s - loss: 0.1671 - accuracy: 0.9479\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 53s - loss: 0.1659 - accuracy: 0.9486\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 53s - loss: 0.1651 - accuracy: 0.9489\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 52s - loss: 0.1659 - accuracy: 0.9483\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 52s - loss: 0.1648 - accuracy: 0.9486\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 51s - loss: 0.1661 - accuracy: 0.9476\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 51s - loss: 0.1651 - accuracy: 0.9483\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 51s - loss: 0.1648 - accuracy: 0.9482\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 51s - loss: 0.1632 - accuracy: 0.9488\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 50s - loss: 0.1645 - accuracy: 0.9479\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 50s - loss: 0.1642 - accuracy: 0.9482\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 50s - loss: 0.1645 - accuracy: 0.9477\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 49s - loss: 0.1659 - accuracy: 0.9468\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 49s - loss: 0.1664 - accuracy: 0.9463\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.1665 - accuracy: 0.9466\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 48s - loss: 0.1653 - accuracy: 0.9472\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 48s - loss: 0.1648 - accuracy: 0.9471\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.1648 - accuracy: 0.9470\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.1661 - accuracy: 0.9462\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 47s - loss: 0.1692 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.1692 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.1682 - accuracy: 0.9459\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.1698 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.1706 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.1699 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.1708 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 45s - loss: 0.1699 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 45s - loss: 0.1724 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 44s - loss: 0.1722 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.1725 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 44s - loss: 0.1721 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 43s - loss: 0.1746 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.1743 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.1747 - accuracy: 0.9440\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.1757 - accuracy: 0.9440\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 42s - loss: 0.1763 - accuracy: 0.9436\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.1752 - accuracy: 0.9442\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.1741 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 41s - loss: 0.1733 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.1729 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 41s - loss: 0.1725 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.1724 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 40s - loss: 0.1739 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 40s - loss: 0.1732 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.1734 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 39s - loss: 0.1734 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 39s - loss: 0.1739 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.1737 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 38s - loss: 0.1742 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 38s - loss: 0.1738 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 38s - loss: 0.1730 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 38s - loss: 0.1731 - accuracy: 0.9449\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 37s - loss: 0.1738 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 37s - loss: 0.1742 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 37s - loss: 0.1752 - accuracy: 0.9442\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 37s - loss: 0.1750 - accuracy: 0.9444\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 36s - loss: 0.1742 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 36s - loss: 0.1740 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 36s - loss: 0.1735 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 35s - loss: 0.1742 - accuracy: 0.9442\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 35s - loss: 0.1738 - accuracy: 0.9444\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 35s - loss: 0.1738 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 35s - loss: 0.1729 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 34s - loss: 0.1732 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 34s - loss: 0.1737 - accuracy: 0.9446\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 34s - loss: 0.1730 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 33s - loss: 0.1724 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 33s - loss: 0.1727 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 33s - loss: 0.1728 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 33s - loss: 0.1728 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 32s - loss: 0.1722 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 32s - loss: 0.1721 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 32s - loss: 0.1714 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.1714 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 31s - loss: 0.1707 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 31s - loss: 0.1733 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.1728 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 30s - loss: 0.1723 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 30s - loss: 0.1722 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.1718 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 29s - loss: 0.1717 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 29s - loss: 0.1717 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 29s - loss: 0.1721 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.1730 - accuracy: 0.9452\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 28s - loss: 0.1727 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 28s - loss: 0.1725 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.1718 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 27s - loss: 0.1714 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 27s - loss: 0.1716 - accuracy: 0.9461\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.1711 - accuracy: 0.9462\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.1728 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 26s - loss: 0.1729 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.1734 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.1731 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 25s - loss: 0.1727 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.1733 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.1732 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 24s - loss: 0.1733 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.1736 - accuracy: 0.9449\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.1735 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.1734 - accuracy: 0.9449\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 23s - loss: 0.1727 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.1720 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.1720 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 22s - loss: 0.1716 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.1715 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.1719 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 21s - loss: 0.1722 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.1715 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.1718 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.1714 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 20s - loss: 0.1713 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.1735 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.1730 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 19s - loss: 0.1737 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.1734 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.1737 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.1740 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.1746 - accuracy: 0.9451\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.1758 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.1756 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 17s - loss: 0.1755 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.1755 - accuracy: 0.9443\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.1750 - accuracy: 0.9444\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 16s - loss: 0.1748 - accuracy: 0.9444\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.1750 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.1743 - accuracy: 0.9448\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.1752 - accuracy: 0.9443\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1745 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.1746 - accuracy: 0.9445\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.1742 - accuracy: 0.9446\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1739 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.1735 - accuracy: 0.9449\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1742 - accuracy: 0.9447\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 13s - loss: 0.1737 - accuracy: 0.9449\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1732 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1736 - accuracy: 0.9450\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.1729 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1726 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.1723 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.1720 - accuracy: 0.9456\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1716 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1713 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.1709 - accuracy: 0.9458\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.1708 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1705 - accuracy: 0.9459 \n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1700 - accuracy: 0.9461\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1699 - accuracy: 0.9462\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1699 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1713 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1709 - accuracy: 0.9459\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1709 - accuracy: 0.9459\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1704 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1705 - accuracy: 0.9460\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.1704 - accuracy: 0.9461\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1714 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1716 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1715 - accuracy: 0.9453\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1713 - accuracy: 0.9454\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1714 - accuracy: 0.9455\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1710 - accuracy: 0.9457\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.1705 - accuracy: 0.9459\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1699 - accuracy: 0.9462\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1693 - accuracy: 0.9464\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1688 - accuracy: 0.9466\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1684 - accuracy: 0.9467\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1684 - accuracy: 0.9467\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1682 - accuracy: 0.9467\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1679 - accuracy: 0.9466\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1674 - accuracy: 0.9467\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1675 - accuracy: 0.9467\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1674 - accuracy: 0.9468\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1679 - accuracy: 0.9465\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1678 - accuracy: 0.9464\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1679 - accuracy: 0.9463\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 0.9465\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9466\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9463\n",
      "Epoch 12: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 0.1677 - accuracy: 0.9461 - val_loss: 0.1000 - val_accuracy: 0.9708\n",
      "Epoch 13/15\n",
      "\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:54 - loss: 0.1618 - accuracy: 0.9062\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:22 - loss: 0.0915 - accuracy: 0.9531\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:23 - loss: 0.1523 - accuracy: 0.9271\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:20 - loss: 0.1392 - accuracy: 0.9375\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:19 - loss: 0.1386 - accuracy: 0.9438\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:18 - loss: 0.1384 - accuracy: 0.9375\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:16 - loss: 0.1243 - accuracy: 0.9464\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:16 - loss: 0.1270 - accuracy: 0.9453\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:15 - loss: 0.1226 - accuracy: 0.9444\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:14 - loss: 0.1135 - accuracy: 0.9500\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:14 - loss: 0.1124 - accuracy: 0.9517\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:13 - loss: 0.1115 - accuracy: 0.9531\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:12 - loss: 0.1077 - accuracy: 0.9567\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:12 - loss: 0.1054 - accuracy: 0.9598\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:12 - loss: 0.1079 - accuracy: 0.9583\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:12 - loss: 0.1067 - accuracy: 0.9609\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:11 - loss: 0.1027 - accuracy: 0.9632\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:10 - loss: 0.1200 - accuracy: 0.9566\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:10 - loss: 0.1186 - accuracy: 0.9572\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:09 - loss: 0.1178 - accuracy: 0.9578\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:09 - loss: 0.1188 - accuracy: 0.9583\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:08 - loss: 0.1260 - accuracy: 0.9574\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:07 - loss: 0.1268 - accuracy: 0.9565\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:07 - loss: 0.1332 - accuracy: 0.9544\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:06 - loss: 0.1299 - accuracy: 0.9563\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:06 - loss: 0.1309 - accuracy: 0.9567\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:06 - loss: 0.1307 - accuracy: 0.9572\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:05 - loss: 0.1321 - accuracy: 0.9565\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:05 - loss: 0.1320 - accuracy: 0.9569\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:05 - loss: 0.1327 - accuracy: 0.9573\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:05 - loss: 0.1319 - accuracy: 0.9577\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:04 - loss: 0.1308 - accuracy: 0.9580\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:04 - loss: 0.1334 - accuracy: 0.9564\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:04 - loss: 0.1330 - accuracy: 0.9559\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:03 - loss: 0.1346 - accuracy: 0.9554\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:03 - loss: 0.1362 - accuracy: 0.9557\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:03 - loss: 0.1357 - accuracy: 0.9561\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:03 - loss: 0.1370 - accuracy: 0.9556\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:03 - loss: 0.1412 - accuracy: 0.9543\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 1:03 - loss: 0.1415 - accuracy: 0.9547\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 1:02 - loss: 0.1425 - accuracy: 0.9543\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 1:02 - loss: 0.1410 - accuracy: 0.9546\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 1:02 - loss: 0.1425 - accuracy: 0.9535\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 1:02 - loss: 0.1410 - accuracy: 0.9545\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 1:01 - loss: 0.1432 - accuracy: 0.9528\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 1:01 - loss: 0.1473 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 1:01 - loss: 0.1467 - accuracy: 0.9521\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 1:01 - loss: 0.1530 - accuracy: 0.9505\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 1:00 - loss: 0.1521 - accuracy: 0.9509\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 1:00 - loss: 0.1505 - accuracy: 0.9513\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 59s - loss: 0.1499 - accuracy: 0.9510 \n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 59s - loss: 0.1486 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 59s - loss: 0.1477 - accuracy: 0.9522\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 58s - loss: 0.1481 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.1468 - accuracy: 0.9534\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 58s - loss: 0.1471 - accuracy: 0.9537\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 57s - loss: 0.1460 - accuracy: 0.9539\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 57s - loss: 0.1440 - accuracy: 0.9547\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 57s - loss: 0.1447 - accuracy: 0.9539\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 56s - loss: 0.1432 - accuracy: 0.9547\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 56s - loss: 0.1461 - accuracy: 0.9544\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 56s - loss: 0.1456 - accuracy: 0.9546\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 55s - loss: 0.1437 - accuracy: 0.9554\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 55s - loss: 0.1435 - accuracy: 0.9556\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.1417 - accuracy: 0.9563\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 54s - loss: 0.1403 - accuracy: 0.9564\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 54s - loss: 0.1393 - accuracy: 0.9566\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 54s - loss: 0.1392 - accuracy: 0.9563\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.1412 - accuracy: 0.9552\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 53s - loss: 0.1411 - accuracy: 0.9549\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 53s - loss: 0.1407 - accuracy: 0.9551\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.1412 - accuracy: 0.9549\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 52s - loss: 0.1398 - accuracy: 0.9555\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 52s - loss: 0.1401 - accuracy: 0.9544\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.1395 - accuracy: 0.9550\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.1386 - accuracy: 0.9556\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 51s - loss: 0.1395 - accuracy: 0.9554\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 50s - loss: 0.1399 - accuracy: 0.9555\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 50s - loss: 0.1406 - accuracy: 0.9553\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 50s - loss: 0.1394 - accuracy: 0.9559\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.1408 - accuracy: 0.9552\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.1432 - accuracy: 0.9550\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 49s - loss: 0.1430 - accuracy: 0.9552\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.1420 - accuracy: 0.9557\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.1411 - accuracy: 0.9559\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.1419 - accuracy: 0.9560\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 48s - loss: 0.1409 - accuracy: 0.9562\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.1398 - accuracy: 0.9567\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.1402 - accuracy: 0.9561\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.1406 - accuracy: 0.9559\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 47s - loss: 0.1424 - accuracy: 0.9554\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.1438 - accuracy: 0.9548\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.1439 - accuracy: 0.9543\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.1444 - accuracy: 0.9541\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.1473 - accuracy: 0.9526\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.1479 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.1478 - accuracy: 0.9523\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.1472 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.1472 - accuracy: 0.9523\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 44s - loss: 0.1493 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.1487 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.1484 - accuracy: 0.9522\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 43s - loss: 0.1485 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.1481 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.1507 - accuracy: 0.9512\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.1504 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 43s - loss: 0.1511 - accuracy: 0.9506\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.1503 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.1501 - accuracy: 0.9513\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 42s - loss: 0.1496 - accuracy: 0.9514\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 42s - loss: 0.1499 - accuracy: 0.9513\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 42s - loss: 0.1496 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.1489 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 41s - loss: 0.1483 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 41s - loss: 0.1478 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.1470 - accuracy: 0.9523\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 40s - loss: 0.1473 - accuracy: 0.9522\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 40s - loss: 0.1474 - accuracy: 0.9521\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.1498 - accuracy: 0.9517\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 39s - loss: 0.1496 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 39s - loss: 0.1488 - accuracy: 0.9522\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 38s - loss: 0.1483 - accuracy: 0.9524\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 38s - loss: 0.1479 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 38s - loss: 0.1477 - accuracy: 0.9521\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 37s - loss: 0.1476 - accuracy: 0.9523\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 37s - loss: 0.1471 - accuracy: 0.9526\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 37s - loss: 0.1465 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 37s - loss: 0.1457 - accuracy: 0.9529\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 36s - loss: 0.1456 - accuracy: 0.9530\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 36s - loss: 0.1452 - accuracy: 0.9531\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 36s - loss: 0.1451 - accuracy: 0.9528\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 35s - loss: 0.1446 - accuracy: 0.9531\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 35s - loss: 0.1449 - accuracy: 0.9530\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 35s - loss: 0.1460 - accuracy: 0.9524\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 34s - loss: 0.1456 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 34s - loss: 0.1451 - accuracy: 0.9527\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 34s - loss: 0.1448 - accuracy: 0.9528\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 33s - loss: 0.1445 - accuracy: 0.9529\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 33s - loss: 0.1448 - accuracy: 0.9528\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 33s - loss: 0.1445 - accuracy: 0.9529\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 32s - loss: 0.1462 - accuracy: 0.9521\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 32s - loss: 0.1460 - accuracy: 0.9522\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 32s - loss: 0.1459 - accuracy: 0.9521\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 32s - loss: 0.1455 - accuracy: 0.9525\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.1454 - accuracy: 0.9524\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 31s - loss: 0.1451 - accuracy: 0.9523\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 31s - loss: 0.1457 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.1460 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 30s - loss: 0.1473 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 30s - loss: 0.1471 - accuracy: 0.9517\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.1464 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 29s - loss: 0.1474 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 29s - loss: 0.1472 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.1470 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.1464 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 28s - loss: 0.1470 - accuracy: 0.9517\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 28s - loss: 0.1469 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.1472 - accuracy: 0.9512\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 27s - loss: 0.1472 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 27s - loss: 0.1486 - accuracy: 0.9504\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.1485 - accuracy: 0.9505\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.1481 - accuracy: 0.9508\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 26s - loss: 0.1484 - accuracy: 0.9507\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 26s - loss: 0.1492 - accuracy: 0.9505\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.1486 - accuracy: 0.9508\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 25s - loss: 0.1481 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 25s - loss: 0.1485 - accuracy: 0.9510\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.1482 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 24s - loss: 0.1478 - accuracy: 0.9512\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 24s - loss: 0.1473 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 24s - loss: 0.1467 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.1465 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 23s - loss: 0.1465 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 23s - loss: 0.1464 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.1480 - accuracy: 0.9513\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 22s - loss: 0.1476 - accuracy: 0.9514\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 22s - loss: 0.1479 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 22s - loss: 0.1494 - accuracy: 0.9514\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 21s - loss: 0.1489 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 21s - loss: 0.1487 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 21s - loss: 0.1481 - accuracy: 0.9518\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.1484 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 20s - loss: 0.1484 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 20s - loss: 0.1484 - accuracy: 0.9516\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.1477 - accuracy: 0.9519\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 19s - loss: 0.1476 - accuracy: 0.9520\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 19s - loss: 0.1481 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 19s - loss: 0.1480 - accuracy: 0.9515\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.1481 - accuracy: 0.9512\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 18s - loss: 0.1486 - accuracy: 0.9512\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 18s - loss: 0.1489 - accuracy: 0.9511\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.1489 - accuracy: 0.9510\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 17s - loss: 0.1489 - accuracy: 0.9509\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 17s - loss: 0.1496 - accuracy: 0.9507\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.1499 - accuracy: 0.9506\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 16s - loss: 0.1510 - accuracy: 0.9503\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 16s - loss: 0.1507 - accuracy: 0.9505\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 16s - loss: 0.1503 - accuracy: 0.9508\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.1500 - accuracy: 0.9509\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 15s - loss: 0.1513 - accuracy: 0.9503\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 15s - loss: 0.1510 - accuracy: 0.9506\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.1508 - accuracy: 0.9507\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 14s - loss: 0.1504 - accuracy: 0.9509\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 14s - loss: 0.1503 - accuracy: 0.9508\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1516 - accuracy: 0.9505\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 13s - loss: 0.1516 - accuracy: 0.9504\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 13s - loss: 0.1520 - accuracy: 0.9502\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1518 - accuracy: 0.9503\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.1519 - accuracy: 0.9502\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 12s - loss: 0.1517 - accuracy: 0.9501\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.1516 - accuracy: 0.9502\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.1533 - accuracy: 0.9499\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 11s - loss: 0.1541 - accuracy: 0.9497\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 11s - loss: 0.1566 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.1565 - accuracy: 0.9494\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.1563 - accuracy: 0.9495\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 10s - loss: 0.1561 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1568 - accuracy: 0.9493 \n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1565 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 9s - loss: 0.1562 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1559 - accuracy: 0.9497\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1564 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.1568 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1563 - accuracy: 0.9495\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1567 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.1561 - accuracy: 0.9495\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 7s - loss: 0.1558 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1559 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1563 - accuracy: 0.9495\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 6s - loss: 0.1560 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1556 - accuracy: 0.9498\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1560 - accuracy: 0.9496\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.1555 - accuracy: 0.9498\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1555 - accuracy: 0.9497\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1552 - accuracy: 0.9497\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1549 - accuracy: 0.9497\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 4s - loss: 0.1555 - accuracy: 0.9494\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1553 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1556 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.1557 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1560 - accuracy: 0.9492\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1562 - accuracy: 0.9490\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1558 - accuracy: 0.9492\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1564 - accuracy: 0.9489\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1569 - accuracy: 0.9486\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1567 - accuracy: 0.9487\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9489\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9491\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9493\n",
      "Epoch 13: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.1552 - accuracy: 0.9495 - val_loss: 0.0990 - val_accuracy: 0.9703\n",
      "Epoch 14/15\n",
      "\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  1/250 [..............................] - ETA: 1:42 - loss: 0.3128 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.2561 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 0.2169 - accuracy: 0.9271\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 1:09 - loss: 0.1869 - accuracy: 0.9297\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 1:09 - loss: 0.1765 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:08 - loss: 0.1695 - accuracy: 0.9427\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.1687 - accuracy: 0.9420\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.1698 - accuracy: 0.9453\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:07 - loss: 0.1720 - accuracy: 0.9410\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.1666 - accuracy: 0.9438\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.1596 - accuracy: 0.9489\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.1546 - accuracy: 0.9531\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 0.1531 - accuracy: 0.9519\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:07 - loss: 0.1575 - accuracy: 0.9531\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:09 - loss: 0.1680 - accuracy: 0.9500\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:11 - loss: 0.1841 - accuracy: 0.9453\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:11 - loss: 0.1810 - accuracy: 0.9467\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:10 - loss: 0.1787 - accuracy: 0.9462\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:10 - loss: 0.1739 - accuracy: 0.9490\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:11 - loss: 0.1911 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:11 - loss: 0.1925 - accuracy: 0.9464\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:11 - loss: 0.1864 - accuracy: 0.9489\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:10 - loss: 0.1849 - accuracy: 0.9484\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:10 - loss: 0.1881 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:09 - loss: 0.1924 - accuracy: 0.9463\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:09 - loss: 0.1916 - accuracy: 0.9447\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:08 - loss: 0.1874 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:08 - loss: 0.1836 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:07 - loss: 0.1823 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:06 - loss: 0.1808 - accuracy: 0.9490\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:06 - loss: 0.1789 - accuracy: 0.9486\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:06 - loss: 0.1854 - accuracy: 0.9463\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:05 - loss: 0.1867 - accuracy: 0.9460\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:05 - loss: 0.1887 - accuracy: 0.9449\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:04 - loss: 0.1911 - accuracy: 0.9429\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:04 - loss: 0.1878 - accuracy: 0.9436\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:03 - loss: 0.1921 - accuracy: 0.9426\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 1:03 - loss: 0.1960 - accuracy: 0.9408\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 1:02 - loss: 0.1941 - accuracy: 0.9407\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 1:02 - loss: 0.1917 - accuracy: 0.9414\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 1:01 - loss: 0.1911 - accuracy: 0.9421\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 1:01 - loss: 0.1878 - accuracy: 0.9435\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 1:01 - loss: 0.1867 - accuracy: 0.9433\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 1:01 - loss: 0.1841 - accuracy: 0.9439\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 1:00 - loss: 0.1846 - accuracy: 0.9438\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 1:00 - loss: 0.1858 - accuracy: 0.9429\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 59s - loss: 0.1844 - accuracy: 0.9428 \n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 59s - loss: 0.1839 - accuracy: 0.9421\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 59s - loss: 0.1839 - accuracy: 0.9420\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 59s - loss: 0.1859 - accuracy: 0.9406\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 58s - loss: 0.1877 - accuracy: 0.9393\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 58s - loss: 0.1904 - accuracy: 0.9393\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 58s - loss: 0.1892 - accuracy: 0.9399\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 57s - loss: 0.1890 - accuracy: 0.9392\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 57s - loss: 0.1899 - accuracy: 0.9386\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 57s - loss: 0.1904 - accuracy: 0.9381\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 56s - loss: 0.1910 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 56s - loss: 0.1934 - accuracy: 0.9359\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 56s - loss: 0.1916 - accuracy: 0.9359\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 55s - loss: 0.1893 - accuracy: 0.9370\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 55s - loss: 0.1886 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 54s - loss: 0.1873 - accuracy: 0.9380\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 54s - loss: 0.1856 - accuracy: 0.9385\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 54s - loss: 0.1852 - accuracy: 0.9385\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 53s - loss: 0.1837 - accuracy: 0.9385\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 53s - loss: 0.1840 - accuracy: 0.9384\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 53s - loss: 0.1827 - accuracy: 0.9389\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.1838 - accuracy: 0.9389\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 52s - loss: 0.1837 - accuracy: 0.9389\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.1850 - accuracy: 0.9388\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 52s - loss: 0.1832 - accuracy: 0.9397\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 51s - loss: 0.1831 - accuracy: 0.9397\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.1837 - accuracy: 0.9392\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 51s - loss: 0.1834 - accuracy: 0.9392\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.1817 - accuracy: 0.9400\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 50s - loss: 0.1809 - accuracy: 0.9400\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.1805 - accuracy: 0.9399\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.1831 - accuracy: 0.9395\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 49s - loss: 0.1834 - accuracy: 0.9395\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.1821 - accuracy: 0.9402\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.1842 - accuracy: 0.9402\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.1829 - accuracy: 0.9409\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 48s - loss: 0.1823 - accuracy: 0.9409\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.1825 - accuracy: 0.9408\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.1828 - accuracy: 0.9408\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.1815 - accuracy: 0.9415\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.1819 - accuracy: 0.9415\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.1810 - accuracy: 0.9421\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.1801 - accuracy: 0.9421\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.1792 - accuracy: 0.9424\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.1779 - accuracy: 0.9427\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.1786 - accuracy: 0.9423\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.1774 - accuracy: 0.9429\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.1776 - accuracy: 0.9432\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.1770 - accuracy: 0.9434\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.1766 - accuracy: 0.9434\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.1761 - accuracy: 0.9436\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 45s - loss: 0.1754 - accuracy: 0.9442\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.1772 - accuracy: 0.9441\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 44s - loss: 0.1768 - accuracy: 0.9444\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.1761 - accuracy: 0.9446\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 44s - loss: 0.1751 - accuracy: 0.9452\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 43s - loss: 0.1761 - accuracy: 0.9445\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.1755 - accuracy: 0.9444\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.1748 - accuracy: 0.9446\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.1747 - accuracy: 0.9446\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 42s - loss: 0.1749 - accuracy: 0.9442\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.1746 - accuracy: 0.9444\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.1753 - accuracy: 0.9438\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 41s - loss: 0.1753 - accuracy: 0.9440\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.1752 - accuracy: 0.9440\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 41s - loss: 0.1744 - accuracy: 0.9442\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.1739 - accuracy: 0.9441\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 41s - loss: 0.1733 - accuracy: 0.9441\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 41s - loss: 0.1726 - accuracy: 0.9446\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.1718 - accuracy: 0.9448\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 40s - loss: 0.1711 - accuracy: 0.9450\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 40s - loss: 0.1716 - accuracy: 0.9449\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 40s - loss: 0.1707 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 39s - loss: 0.1699 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 39s - loss: 0.1703 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 39s - loss: 0.1698 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 39s - loss: 0.1696 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 39s - loss: 0.1692 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 38s - loss: 0.1685 - accuracy: 0.9463\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 38s - loss: 0.1680 - accuracy: 0.9464\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 38s - loss: 0.1672 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 37s - loss: 0.1664 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 37s - loss: 0.1677 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 37s - loss: 0.1678 - accuracy: 0.9466\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 37s - loss: 0.1679 - accuracy: 0.9461\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 36s - loss: 0.1677 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 36s - loss: 0.1684 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 36s - loss: 0.1693 - accuracy: 0.9452\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 36s - loss: 0.1690 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 35s - loss: 0.1687 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 35s - loss: 0.1683 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 35s - loss: 0.1684 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 35s - loss: 0.1679 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 34s - loss: 0.1674 - accuracy: 0.9462\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 34s - loss: 0.1670 - accuracy: 0.9466\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 34s - loss: 0.1693 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 33s - loss: 0.1689 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 33s - loss: 0.1694 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 33s - loss: 0.1698 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 33s - loss: 0.1695 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 32s - loss: 0.1690 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 32s - loss: 0.1687 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 32s - loss: 0.1692 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 31s - loss: 0.1683 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 31s - loss: 0.1685 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 31s - loss: 0.1682 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 31s - loss: 0.1686 - accuracy: 0.9459\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 30s - loss: 0.1683 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 30s - loss: 0.1680 - accuracy: 0.9456\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 30s - loss: 0.1678 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 29s - loss: 0.1675 - accuracy: 0.9459\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 29s - loss: 0.1684 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 29s - loss: 0.1680 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 28s - loss: 0.1682 - accuracy: 0.9455\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 28s - loss: 0.1678 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 28s - loss: 0.1679 - accuracy: 0.9454\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 28s - loss: 0.1673 - accuracy: 0.9457\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 27s - loss: 0.1668 - accuracy: 0.9459\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 27s - loss: 0.1665 - accuracy: 0.9458\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 27s - loss: 0.1661 - accuracy: 0.9460\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 26s - loss: 0.1658 - accuracy: 0.9461\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 26s - loss: 0.1653 - accuracy: 0.9464\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 26s - loss: 0.1646 - accuracy: 0.9467\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 25s - loss: 0.1642 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 25s - loss: 0.1638 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 25s - loss: 0.1636 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 24s - loss: 0.1632 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 24s - loss: 0.1625 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 24s - loss: 0.1624 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 23s - loss: 0.1623 - accuracy: 0.9478\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 23s - loss: 0.1616 - accuracy: 0.9481\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 23s - loss: 0.1622 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 22s - loss: 0.1628 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 22s - loss: 0.1629 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 22s - loss: 0.1624 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 21s - loss: 0.1619 - accuracy: 0.9480\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 21s - loss: 0.1620 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 21s - loss: 0.1620 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 20s - loss: 0.1614 - accuracy: 0.9481\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 20s - loss: 0.1619 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 20s - loss: 0.1621 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 19s - loss: 0.1621 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 19s - loss: 0.1623 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 19s - loss: 0.1627 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 18s - loss: 0.1625 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 18s - loss: 0.1629 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 18s - loss: 0.1629 - accuracy: 0.9471\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 17s - loss: 0.1634 - accuracy: 0.9467\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 17s - loss: 0.1627 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 17s - loss: 0.1625 - accuracy: 0.9471\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 16s - loss: 0.1639 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 16s - loss: 0.1643 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 16s - loss: 0.1645 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 15s - loss: 0.1645 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 15s - loss: 0.1641 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 15s - loss: 0.1639 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 15s - loss: 0.1637 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 14s - loss: 0.1631 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 14s - loss: 0.1629 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 14s - loss: 0.1626 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 13s - loss: 0.1628 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 13s - loss: 0.1631 - accuracy: 0.9471\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 13s - loss: 0.1635 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 12s - loss: 0.1646 - accuracy: 0.9466\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 12s - loss: 0.1641 - accuracy: 0.9468\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 12s - loss: 0.1635 - accuracy: 0.9471\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 11s - loss: 0.1637 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 11s - loss: 0.1637 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 11s - loss: 0.1636 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.1634 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 10s - loss: 0.1636 - accuracy: 0.9469\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 10s - loss: 0.1637 - accuracy: 0.9468\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1634 - accuracy: 0.9469 \n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 9s - loss: 0.1633 - accuracy: 0.9470\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 9s - loss: 0.1629 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1627 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.1625 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 8s - loss: 0.1621 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1616 - accuracy: 0.9478\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.1621 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 7s - loss: 0.1622 - accuracy: 0.9474\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1629 - accuracy: 0.9471\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1627 - accuracy: 0.9472\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 6s - loss: 0.1625 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 6s - loss: 0.1618 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1616 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.1614 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 5s - loss: 0.1614 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1619 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1621 - accuracy: 0.9473\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 4s - loss: 0.1618 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1617 - accuracy: 0.9475\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1612 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.1612 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1611 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1610 - accuracy: 0.9476\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1608 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1605 - accuracy: 0.9477\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1603 - accuracy: 0.9478\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1598 - accuracy: 0.9480\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9482\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9483\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9483\n",
      "Epoch 14: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 97s 387ms/step - loss: 0.1590 - accuracy: 0.9485 - val_loss: 0.0970 - val_accuracy: 0.9718\n",
      "Epoch 15/15\n",
      "\n",
      "Epoch 15: accuracy improved from 0.96875 to 1.00000, saving model to output\\resnet101.h5\n",
      "  1/250 [..............................] - ETA: 4:39 - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 42s - loss: 0.0722 - accuracy: 0.9844 \n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 56s - loss: 0.0645 - accuracy: 0.9792\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:01 - loss: 0.0593 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:03 - loss: 0.0817 - accuracy: 0.9750\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:05 - loss: 0.0921 - accuracy: 0.9688\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:05 - loss: 0.0897 - accuracy: 0.9688\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:06 - loss: 0.0924 - accuracy: 0.9648\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:06 - loss: 0.0963 - accuracy: 0.9653\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.1004 - accuracy: 0.9656\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.1041 - accuracy: 0.9659\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.1035 - accuracy: 0.9661\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.1058 - accuracy: 0.9639\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 0.1047 - accuracy: 0.9643\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:06 - loss: 0.1064 - accuracy: 0.9646\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:06 - loss: 0.1101 - accuracy: 0.9648\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:06 - loss: 0.1128 - accuracy: 0.9651\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:06 - loss: 0.1092 - accuracy: 0.9670\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:06 - loss: 0.1086 - accuracy: 0.9688\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.1054 - accuracy: 0.9703\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:05 - loss: 0.1045 - accuracy: 0.9717\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:05 - loss: 0.1120 - accuracy: 0.9702\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:05 - loss: 0.1084 - accuracy: 0.9715\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:04 - loss: 0.1110 - accuracy: 0.9714\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.1124 - accuracy: 0.9700\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.1136 - accuracy: 0.9700\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:04 - loss: 0.1230 - accuracy: 0.9653\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.1265 - accuracy: 0.9632\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.1310 - accuracy: 0.9612\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:03 - loss: 0.1321 - accuracy: 0.9615\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:03 - loss: 0.1316 - accuracy: 0.9617\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.1301 - accuracy: 0.9619\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.1285 - accuracy: 0.9621\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:02 - loss: 0.1314 - accuracy: 0.9614\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:02 - loss: 0.1349 - accuracy: 0.9598\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.1354 - accuracy: 0.9601\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:01 - loss: 0.1356 - accuracy: 0.9595\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:01 - loss: 0.1336 - accuracy: 0.9597\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.1310 - accuracy: 0.9607\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.1309 - accuracy: 0.9603 \n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.1406 - accuracy: 0.9582\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.1466 - accuracy: 0.9569\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.1484 - accuracy: 0.9572\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.1579 - accuracy: 0.9568\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.1557 - accuracy: 0.9577\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.1535 - accuracy: 0.9587\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.1515 - accuracy: 0.9596\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 58s - loss: 0.1507 - accuracy: 0.9598\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 58s - loss: 0.1504 - accuracy: 0.9593\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.1489 - accuracy: 0.9601\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 57s - loss: 0.1493 - accuracy: 0.9597\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 57s - loss: 0.1476 - accuracy: 0.9605\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 57s - loss: 0.1479 - accuracy: 0.9606\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.1496 - accuracy: 0.9602\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 56s - loss: 0.1491 - accuracy: 0.9609\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 56s - loss: 0.1512 - accuracy: 0.9611\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 56s - loss: 0.1506 - accuracy: 0.9612\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 55s - loss: 0.1490 - accuracy: 0.9619\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 55s - loss: 0.1482 - accuracy: 0.9615\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 55s - loss: 0.1470 - accuracy: 0.9616\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 55s - loss: 0.1461 - accuracy: 0.9617\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 54s - loss: 0.1470 - accuracy: 0.9608\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 54s - loss: 0.1493 - accuracy: 0.9604\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 54s - loss: 0.1474 - accuracy: 0.9610\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 54s - loss: 0.1470 - accuracy: 0.9617\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 53s - loss: 0.1490 - accuracy: 0.9608\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 53s - loss: 0.1471 - accuracy: 0.9614\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 53s - loss: 0.1474 - accuracy: 0.9606\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.1469 - accuracy: 0.9602\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.1474 - accuracy: 0.9599\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 52s - loss: 0.1467 - accuracy: 0.9600\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.1455 - accuracy: 0.9606\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.1438 - accuracy: 0.9611\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 51s - loss: 0.1420 - accuracy: 0.9617\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.1410 - accuracy: 0.9618\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.1403 - accuracy: 0.9614\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.1400 - accuracy: 0.9619\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 50s - loss: 0.1408 - accuracy: 0.9620\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 50s - loss: 0.1435 - accuracy: 0.9605\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.1428 - accuracy: 0.9606\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.1418 - accuracy: 0.9611\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.1432 - accuracy: 0.9604\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 49s - loss: 0.1440 - accuracy: 0.9602\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.1454 - accuracy: 0.9599\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.1449 - accuracy: 0.9596\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.1452 - accuracy: 0.9594\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.1475 - accuracy: 0.9591\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.1502 - accuracy: 0.9578\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.1492 - accuracy: 0.9583\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 47s - loss: 0.1509 - accuracy: 0.9580\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.1505 - accuracy: 0.9582\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.1511 - accuracy: 0.9579\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.1515 - accuracy: 0.9581\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.1520 - accuracy: 0.9575\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.1525 - accuracy: 0.9570\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.1535 - accuracy: 0.9561\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.1534 - accuracy: 0.9556\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.1535 - accuracy: 0.9554\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.1566 - accuracy: 0.9549\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 44s - loss: 0.1571 - accuracy: 0.9541\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.1567 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.1568 - accuracy: 0.9541\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 43s - loss: 0.1568 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.1562 - accuracy: 0.9541\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.1557 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 42s - loss: 0.1559 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 42s - loss: 0.1565 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.1577 - accuracy: 0.9531\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.1576 - accuracy: 0.9533\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 41s - loss: 0.1568 - accuracy: 0.9534\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.1561 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 40s - loss: 0.1572 - accuracy: 0.9534\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 40s - loss: 0.1576 - accuracy: 0.9536\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 40s - loss: 0.1566 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.1562 - accuracy: 0.9541\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 39s - loss: 0.1560 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 39s - loss: 0.1556 - accuracy: 0.9544\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.1557 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 38s - loss: 0.1559 - accuracy: 0.9543\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 38s - loss: 0.1589 - accuracy: 0.9531\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 38s - loss: 0.1578 - accuracy: 0.9535\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.1573 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 37s - loss: 0.1565 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 37s - loss: 0.1564 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.1561 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 36s - loss: 0.1554 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 36s - loss: 0.1545 - accuracy: 0.9543\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 36s - loss: 0.1552 - accuracy: 0.9544\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.1552 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 35s - loss: 0.1543 - accuracy: 0.9546\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 35s - loss: 0.1552 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.1554 - accuracy: 0.9541\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 34s - loss: 0.1567 - accuracy: 0.9537\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 34s - loss: 0.1559 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.1552 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.1556 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 33s - loss: 0.1558 - accuracy: 0.9537\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 33s - loss: 0.1552 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.1546 - accuracy: 0.9542\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.1546 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 32s - loss: 0.1544 - accuracy: 0.9537\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.1558 - accuracy: 0.9534\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.1560 - accuracy: 0.9532\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 31s - loss: 0.1555 - accuracy: 0.9534\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.1550 - accuracy: 0.9537\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.1545 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 30s - loss: 0.1539 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.1543 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.1548 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.1547 - accuracy: 0.9540\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.1545 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.1542 - accuracy: 0.9538\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.1538 - accuracy: 0.9539\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.1546 - accuracy: 0.9533\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.1554 - accuracy: 0.9530\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.1551 - accuracy: 0.9531\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.1551 - accuracy: 0.9530\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.1558 - accuracy: 0.9529\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.1556 - accuracy: 0.9528\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.1555 - accuracy: 0.9525\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.1550 - accuracy: 0.9527\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.1546 - accuracy: 0.9527\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.1545 - accuracy: 0.9527\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.1542 - accuracy: 0.9526\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.1547 - accuracy: 0.9527\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.1556 - accuracy: 0.9524\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.1561 - accuracy: 0.9519\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.1563 - accuracy: 0.9518\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.1573 - accuracy: 0.9516\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.1582 - accuracy: 0.9513\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.1583 - accuracy: 0.9510\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.1586 - accuracy: 0.9508\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.1589 - accuracy: 0.9503\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.1585 - accuracy: 0.9506\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.1586 - accuracy: 0.9504\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.1584 - accuracy: 0.9505\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.1590 - accuracy: 0.9504\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.1585 - accuracy: 0.9505\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.1585 - accuracy: 0.9504\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.1583 - accuracy: 0.9505\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.1585 - accuracy: 0.9503\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.1582 - accuracy: 0.9502\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.1581 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.1576 - accuracy: 0.9502\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.1573 - accuracy: 0.9502\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.1574 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.1580 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.1578 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.1575 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.1571 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.1576 - accuracy: 0.9494\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.1573 - accuracy: 0.9495\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.1570 - accuracy: 0.9498\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.1570 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.1568 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1568 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.1568 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.1570 - accuracy: 0.9495\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.1565 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1568 - accuracy: 0.9494\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.1563 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.1563 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1560 - accuracy: 0.9498\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.1559 - accuracy: 0.9498\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1564 - accuracy: 0.9494\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 13s - loss: 0.1567 - accuracy: 0.9490\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1563 - accuracy: 0.9493\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1563 - accuracy: 0.9492\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.1559 - accuracy: 0.9493\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1560 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.1558 - accuracy: 0.9492\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.1561 - accuracy: 0.9490\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1561 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1563 - accuracy: 0.9489\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.1560 - accuracy: 0.9490\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.1558 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1556 - accuracy: 0.9493 \n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1556 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1559 - accuracy: 0.9486\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1561 - accuracy: 0.9484\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1558 - accuracy: 0.9487\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1553 - accuracy: 0.9488\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.1549 - accuracy: 0.9490\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1548 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1544 - accuracy: 0.9492\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.1547 - accuracy: 0.9491\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1542 - accuracy: 0.9493\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1538 - accuracy: 0.9496\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1535 - accuracy: 0.9495\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1539 - accuracy: 0.9495\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1536 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1532 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.1530 - accuracy: 0.9500\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1531 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1527 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1526 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1528 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1529 - accuracy: 0.9497\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1525 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1525 - accuracy: 0.9499\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1523 - accuracy: 0.9498\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1519 - accuracy: 0.9500\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1518 - accuracy: 0.9500\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1514 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1512 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1507 - accuracy: 0.9503\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9503\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9501\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 92s 366ms/step - loss: 0.1509 - accuracy: 0.9500 - val_loss: 0.0929 - val_accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    trainGen, steps_per_epoch=trainGen.samples // 32,\n",
    "\tvalidation_data=testGen, validation_steps=testGen.samples // 32,\n",
    "\tepochs=15, callbacks=[checkpoint, early])\n",
    "\n",
    "model.save(os.path.sep.join([config.OUTPUT_PATH, \"resnet101.model\"]), save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = np.arange(0, 15)\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"resnet_losses.png\"]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, hist.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"resnet_accuracy.png\"]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open       0.93      0.96      0.95       388\n",
      "       short       0.72      0.99      0.83       301\n",
      "    mousebit       0.87      0.77      0.82       393\n",
      "        spur       0.95      0.70      0.81       325\n",
      "      copper       0.98      0.98      0.98       294\n",
      "    pin-hole       0.96      0.98      0.97       300\n",
      "\n",
      "    accuracy                           0.89      2001\n",
      "   macro avg       0.90      0.90      0.89      2001\n",
      "weighted avg       0.90      0.89      0.89      2001\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = list()\n",
    "for path in testGen.filepaths:\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    preds = model.predict(image)\n",
    "    predictions.append(preds.argmax(axis=1))\n",
    "\n",
    "#predictions = model.predict(testGen, batch_size=32)\n",
    "print(classification_report(testGen.classes,\n",
    "\tpredictions, target_names=testGen.class_indices))\n",
    "\n",
    "cm = confusion_matrix(testGen.classes, predictions, normalize='all')\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(testGen.class_indices))\n",
    "plt.xticks(tick_marks, testGen.class_indices, rotation=85)\n",
    "plt.yticks(tick_marks, testGen.class_indices)\n",
    "plt.xlabel('Predicted Defect')\n",
    "plt.ylabel('Actual Defect')\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"resnet_confusion_matrix.png\"]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c84cac0d85cf2b51a97d2bd7b0fa6585599b14f00604962e71b8ec1671851d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
