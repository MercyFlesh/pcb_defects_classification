{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools import config\n",
    "\n",
    "if not os.path.exists(config.DEFECTS_PATH):\n",
    "    !python \"tools/extracted_defetcs.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenAug = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "\tzoom_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tvalidation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 6 classes.\n",
      "Found 2001 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"training\")\n",
    "\n",
    "testGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False,  input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "for layer in vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "head = vgg_model.output\n",
    "flatten = Flatten()(head)\n",
    "fc = Dense(512, activation='relu')(flatten)\n",
    "output = Dense(len(trainGen.class_indices), activation=\"softmax\")(fc)\n",
    "\n",
    "model = Model(inputs=vgg_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(os.path.sep.join([config.OUTPUT_PATH, \"vgg.h5\"]), monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.06250, saving model to output\\vgg.h5\n",
      "  1/250 [..............................] - ETA: 57:47 - loss: 15.0392 - accuracy: 0.0625\n",
      "Epoch 1: accuracy improved from 0.06250 to 0.18750, saving model to output\\vgg.h5\n",
      "  2/250 [..............................] - ETA: 8:00 - loss: 13.9344 - accuracy: 0.1875 \n",
      "Epoch 1: accuracy improved from 0.18750 to 0.20833, saving model to output\\vgg.h5\n",
      "  3/250 [..............................] - ETA: 7:15 - loss: 15.2721 - accuracy: 0.2083\n",
      "Epoch 1: accuracy improved from 0.20833 to 0.23438, saving model to output\\vgg.h5\n",
      "  4/250 [..............................] - ETA: 7:20 - loss: 15.9313 - accuracy: 0.2344\n",
      "Epoch 1: accuracy improved from 0.23438 to 0.28125, saving model to output\\vgg.h5\n",
      "  5/250 [..............................] - ETA: 7:18 - loss: 13.9162 - accuracy: 0.2812\n",
      "Epoch 1: accuracy improved from 0.28125 to 0.33333, saving model to output\\vgg.h5\n",
      "  6/250 [..............................] - ETA: 7:11 - loss: 13.7361 - accuracy: 0.3333\n",
      "Epoch 1: accuracy improved from 0.33333 to 0.36161, saving model to output\\vgg.h5\n",
      "  7/250 [..............................] - ETA: 7:03 - loss: 12.4313 - accuracy: 0.3616\n",
      "Epoch 1: accuracy improved from 0.36161 to 0.38559, saving model to output\\vgg.h5\n",
      "  8/250 [..............................] - ETA: 7:57 - loss: 11.8420 - accuracy: 0.3856\n",
      "Epoch 1: accuracy improved from 0.38559 to 0.39925, saving model to output\\vgg.h5\n",
      "  9/250 [>.............................] - ETA: 7:52 - loss: 11.0857 - accuracy: 0.3993\n",
      "Epoch 1: accuracy improved from 0.39925 to 0.42000, saving model to output\\vgg.h5\n",
      " 10/250 [>.............................] - ETA: 7:51 - loss: 10.5471 - accuracy: 0.4200\n",
      "Epoch 1: accuracy improved from 0.42000 to 0.45783, saving model to output\\vgg.h5\n",
      " 11/250 [>.............................] - ETA: 7:47 - loss: 9.7279 - accuracy: 0.4578 \n",
      "Epoch 1: accuracy improved from 0.45783 to 0.48352, saving model to output\\vgg.h5\n",
      " 12/250 [>.............................] - ETA: 7:54 - loss: 9.2169 - accuracy: 0.4835\n",
      "Epoch 1: accuracy improved from 0.48352 to 0.49495, saving model to output\\vgg.h5\n",
      " 13/250 [>.............................] - ETA: 7:52 - loss: 8.8955 - accuracy: 0.4949\n",
      "Epoch 1: accuracy improved from 0.49495 to 0.51402, saving model to output\\vgg.h5\n",
      " 14/250 [>.............................] - ETA: 7:50 - loss: 8.5562 - accuracy: 0.5140\n",
      "Epoch 1: accuracy improved from 0.51402 to 0.51957, saving model to output\\vgg.h5\n",
      " 15/250 [>.............................] - ETA: 7:50 - loss: 8.3246 - accuracy: 0.5196\n",
      "Epoch 1: accuracy improved from 0.51957 to 0.53049, saving model to output\\vgg.h5\n",
      " 16/250 [>.............................] - ETA: 7:47 - loss: 8.0035 - accuracy: 0.5305\n",
      "Epoch 1: accuracy improved from 0.53049 to 0.54962, saving model to output\\vgg.h5\n",
      " 17/250 [=>............................] - ETA: 7:43 - loss: 7.6465 - accuracy: 0.5496\n",
      "Epoch 1: accuracy improved from 0.54962 to 0.55396, saving model to output\\vgg.h5\n",
      " 18/250 [=>............................] - ETA: 7:43 - loss: 7.3872 - accuracy: 0.5540\n",
      "Epoch 1: accuracy improved from 0.55396 to 0.56973, saving model to output\\vgg.h5\n",
      " 19/250 [=>............................] - ETA: 7:43 - loss: 7.0868 - accuracy: 0.5697\n",
      "Epoch 1: accuracy improved from 0.56973 to 0.57419, saving model to output\\vgg.h5\n",
      " 20/250 [=>............................] - ETA: 7:37 - loss: 6.9841 - accuracy: 0.5742\n",
      "Epoch 1: accuracy improved from 0.57419 to 0.57822, saving model to output\\vgg.h5\n",
      " 21/250 [=>............................] - ETA: 7:34 - loss: 6.8245 - accuracy: 0.5782\n",
      "Epoch 1: accuracy improved from 0.57822 to 0.58041, saving model to output\\vgg.h5\n",
      " 22/250 [=>............................] - ETA: 7:31 - loss: 6.7243 - accuracy: 0.5804\n",
      "Epoch 1: accuracy improved from 0.58041 to 0.58240, saving model to output\\vgg.h5\n",
      " 23/250 [=>............................] - ETA: 7:24 - loss: 6.5660 - accuracy: 0.5824\n",
      "Epoch 1: accuracy improved from 0.58240 to 0.59225, saving model to output\\vgg.h5\n",
      " 24/250 [=>............................] - ETA: 7:20 - loss: 6.4042 - accuracy: 0.5922\n",
      "Epoch 1: accuracy improved from 0.59225 to 0.59744, saving model to output\\vgg.h5\n",
      " 25/250 [==>...........................] - ETA: 7:17 - loss: 6.3080 - accuracy: 0.5974\n",
      "Epoch 1: accuracy improved from 0.59744 to 0.60714, saving model to output\\vgg.h5\n",
      " 26/250 [==>...........................] - ETA: 7:13 - loss: 6.1023 - accuracy: 0.6071\n",
      "Epoch 1: accuracy improved from 0.60714 to 0.61019, saving model to output\\vgg.h5\n",
      " 27/250 [==>...........................] - ETA: 7:09 - loss: 6.0223 - accuracy: 0.6102\n",
      "Epoch 1: accuracy improved from 0.61019 to 0.61872, saving model to output\\vgg.h5\n",
      " 28/250 [==>...........................] - ETA: 7:07 - loss: 5.8519 - accuracy: 0.6187\n",
      "Epoch 1: accuracy improved from 0.61872 to 0.62335, saving model to output\\vgg.h5\n",
      " 29/250 [==>...........................] - ETA: 7:03 - loss: 5.7285 - accuracy: 0.6233\n",
      "Epoch 1: accuracy did not improve from 0.62335\n",
      " 30/250 [==>...........................] - ETA: 6:48 - loss: 5.6893 - accuracy: 0.6202\n",
      "Epoch 1: accuracy improved from 0.62335 to 0.62449, saving model to output\\vgg.h5\n",
      " 31/250 [==>...........................] - ETA: 6:45 - loss: 5.5909 - accuracy: 0.6245\n",
      "Epoch 1: accuracy improved from 0.62449 to 0.62749, saving model to output\\vgg.h5\n",
      " 32/250 [==>...........................] - ETA: 6:42 - loss: 5.4702 - accuracy: 0.6275\n",
      "Epoch 1: accuracy improved from 0.62749 to 0.63610, saving model to output\\vgg.h5\n",
      " 33/250 [==>...........................] - ETA: 6:38 - loss: 5.3303 - accuracy: 0.6361\n",
      "Epoch 1: accuracy improved from 0.63610 to 0.64139, saving model to output\\vgg.h5\n",
      " 34/250 [===>..........................] - ETA: 6:35 - loss: 5.2156 - accuracy: 0.6414\n",
      "Epoch 1: accuracy improved from 0.64139 to 0.64727, saving model to output\\vgg.h5\n",
      " 35/250 [===>..........................] - ETA: 6:35 - loss: 5.0870 - accuracy: 0.6473\n",
      "Epoch 1: accuracy improved from 0.64727 to 0.65106, saving model to output\\vgg.h5\n",
      " 36/250 [===>..........................] - ETA: 6:33 - loss: 4.9763 - accuracy: 0.6511\n",
      "Epoch 1: accuracy improved from 0.65106 to 0.65550, saving model to output\\vgg.h5\n",
      " 37/250 [===>..........................] - ETA: 6:32 - loss: 4.8775 - accuracy: 0.6555\n",
      "Epoch 1: accuracy improved from 0.65550 to 0.65719, saving model to output\\vgg.h5\n",
      " 38/250 [===>..........................] - ETA: 6:29 - loss: 4.8051 - accuracy: 0.6572\n",
      "Epoch 1: accuracy improved from 0.65719 to 0.66124, saving model to output\\vgg.h5\n",
      " 39/250 [===>..........................] - ETA: 6:26 - loss: 4.7231 - accuracy: 0.6612\n",
      "Epoch 1: accuracy improved from 0.66124 to 0.66587, saving model to output\\vgg.h5\n",
      " 40/250 [===>..........................] - ETA: 6:25 - loss: 4.6279 - accuracy: 0.6659\n",
      "Epoch 1: accuracy improved from 0.66587 to 0.66950, saving model to output\\vgg.h5\n",
      " 41/250 [===>..........................] - ETA: 6:21 - loss: 4.5896 - accuracy: 0.6695\n",
      "Epoch 1: accuracy improved from 0.66950 to 0.67145, saving model to output\\vgg.h5\n",
      " 42/250 [====>.........................] - ETA: 6:18 - loss: 4.5046 - accuracy: 0.6715\n",
      "Epoch 1: accuracy improved from 0.67145 to 0.67625, saving model to output\\vgg.h5\n",
      " 43/250 [====>.........................] - ETA: 6:17 - loss: 4.4339 - accuracy: 0.6763\n",
      "Epoch 1: accuracy improved from 0.67625 to 0.68084, saving model to output\\vgg.h5\n",
      " 44/250 [====>.........................] - ETA: 6:16 - loss: 4.3536 - accuracy: 0.6808\n",
      "Epoch 1: accuracy improved from 0.68084 to 0.68239, saving model to output\\vgg.h5\n",
      " 45/250 [====>.........................] - ETA: 6:13 - loss: 4.3038 - accuracy: 0.6824\n",
      "Epoch 1: accuracy improved from 0.68239 to 0.68457, saving model to output\\vgg.h5\n",
      " 46/250 [====>.........................] - ETA: 6:13 - loss: 4.2628 - accuracy: 0.6846\n",
      "Epoch 1: accuracy improved from 0.68457 to 0.68666, saving model to output\\vgg.h5\n",
      " 47/250 [====>.........................] - ETA: 6:12 - loss: 4.2098 - accuracy: 0.6867\n",
      "Epoch 1: accuracy improved from 0.68666 to 0.68865, saving model to output\\vgg.h5\n",
      " 48/250 [====>.........................] - ETA: 6:09 - loss: 4.1662 - accuracy: 0.6887\n",
      "Epoch 1: accuracy improved from 0.68865 to 0.69380, saving model to output\\vgg.h5\n",
      " 49/250 [====>.........................] - ETA: 6:07 - loss: 4.0878 - accuracy: 0.6938\n",
      "Epoch 1: accuracy improved from 0.69380 to 0.69747, saving model to output\\vgg.h5\n",
      " 50/250 [=====>........................] - ETA: 6:05 - loss: 4.0196 - accuracy: 0.6975\n",
      "Epoch 1: accuracy improved from 0.69747 to 0.70161, saving model to output\\vgg.h5\n",
      " 51/250 [=====>........................] - ETA: 6:03 - loss: 3.9518 - accuracy: 0.7016\n",
      "Epoch 1: accuracy improved from 0.70161 to 0.70499, saving model to output\\vgg.h5\n",
      " 52/250 [=====>........................] - ETA: 6:02 - loss: 3.9053 - accuracy: 0.7050\n",
      "Epoch 1: accuracy improved from 0.70499 to 0.70764, saving model to output\\vgg.h5\n",
      " 53/250 [=====>........................] - ETA: 6:00 - loss: 3.8710 - accuracy: 0.7076\n",
      "Epoch 1: accuracy improved from 0.70764 to 0.71077, saving model to output\\vgg.h5\n",
      " 54/250 [=====>........................] - ETA: 5:58 - loss: 3.8234 - accuracy: 0.7108\n",
      "Epoch 1: accuracy improved from 0.71077 to 0.71379, saving model to output\\vgg.h5\n",
      " 55/250 [=====>........................] - ETA: 5:55 - loss: 3.7640 - accuracy: 0.7138\n",
      "Epoch 1: accuracy improved from 0.71379 to 0.71783, saving model to output\\vgg.h5\n",
      " 56/250 [=====>........................] - ETA: 5:53 - loss: 3.7220 - accuracy: 0.7178\n",
      "Epoch 1: accuracy improved from 0.71783 to 0.72007, saving model to output\\vgg.h5\n",
      " 57/250 [=====>........................] - ETA: 5:52 - loss: 3.6782 - accuracy: 0.7201\n",
      "Epoch 1: accuracy improved from 0.72007 to 0.72331, saving model to output\\vgg.h5\n",
      " 58/250 [=====>........................] - ETA: 5:50 - loss: 3.6330 - accuracy: 0.7233\n",
      "Epoch 1: accuracy improved from 0.72331 to 0.72698, saving model to output\\vgg.h5\n",
      " 59/250 [======>.......................] - ETA: 5:47 - loss: 3.5788 - accuracy: 0.7270\n",
      "Epoch 1: accuracy improved from 0.72698 to 0.72895, saving model to output\\vgg.h5\n",
      " 60/250 [======>.......................] - ETA: 5:46 - loss: 3.5341 - accuracy: 0.7289\n",
      "Epoch 1: accuracy improved from 0.72895 to 0.73033, saving model to output\\vgg.h5\n",
      " 61/250 [======>.......................] - ETA: 5:43 - loss: 3.5083 - accuracy: 0.7303\n",
      "Epoch 1: accuracy improved from 0.73033 to 0.73167, saving model to output\\vgg.h5\n",
      " 62/250 [======>.......................] - ETA: 5:41 - loss: 3.4846 - accuracy: 0.7317\n",
      "Epoch 1: accuracy improved from 0.73167 to 0.73347, saving model to output\\vgg.h5\n",
      " 63/250 [======>.......................] - ETA: 5:39 - loss: 3.4413 - accuracy: 0.7335\n",
      "Epoch 1: accuracy improved from 0.73347 to 0.73619, saving model to output\\vgg.h5\n",
      " 64/250 [======>.......................] - ETA: 5:37 - loss: 3.3973 - accuracy: 0.7362\n",
      "Epoch 1: accuracy improved from 0.73619 to 0.73835, saving model to output\\vgg.h5\n",
      " 65/250 [======>.......................] - ETA: 5:35 - loss: 3.3606 - accuracy: 0.7383\n",
      "Epoch 1: accuracy improved from 0.73835 to 0.74092, saving model to output\\vgg.h5\n",
      " 66/250 [======>.......................] - ETA: 5:32 - loss: 3.3167 - accuracy: 0.7409\n",
      "Epoch 1: accuracy improved from 0.74092 to 0.74341, saving model to output\\vgg.h5\n",
      " 67/250 [=======>......................] - ETA: 5:30 - loss: 3.2704 - accuracy: 0.7434\n",
      "Epoch 1: accuracy improved from 0.74341 to 0.74583, saving model to output\\vgg.h5\n",
      " 68/250 [=======>......................] - ETA: 5:28 - loss: 3.2498 - accuracy: 0.7458\n",
      "Epoch 1: accuracy improved from 0.74583 to 0.74680, saving model to output\\vgg.h5\n",
      " 69/250 [=======>......................] - ETA: 5:26 - loss: 3.2244 - accuracy: 0.7468\n",
      "Epoch 1: accuracy improved from 0.74680 to 0.74865, saving model to output\\vgg.h5\n",
      " 70/250 [=======>......................] - ETA: 5:24 - loss: 3.1975 - accuracy: 0.7486\n",
      "Epoch 1: accuracy did not improve from 0.74865\n",
      " 71/250 [=======>......................] - ETA: 5:18 - loss: 3.1813 - accuracy: 0.7482\n",
      "Epoch 1: accuracy improved from 0.74865 to 0.75044, saving model to output\\vgg.h5\n",
      " 72/250 [=======>......................] - ETA: 5:16 - loss: 3.1455 - accuracy: 0.7504\n",
      "Epoch 1: accuracy improved from 0.75044 to 0.75173, saving model to output\\vgg.h5\n",
      " 73/250 [=======>......................] - ETA: 5:14 - loss: 3.1258 - accuracy: 0.7517\n",
      "Epoch 1: accuracy improved from 0.75173 to 0.75341, saving model to output\\vgg.h5\n",
      " 74/250 [=======>......................] - ETA: 5:12 - loss: 3.0880 - accuracy: 0.7534\n",
      "Epoch 1: accuracy improved from 0.75341 to 0.75588, saving model to output\\vgg.h5\n",
      " 75/250 [========>.....................] - ETA: 5:10 - loss: 3.0521 - accuracy: 0.7559\n",
      "Epoch 1: accuracy improved from 0.75588 to 0.75788, saving model to output\\vgg.h5\n",
      " 76/250 [========>.....................] - ETA: 5:09 - loss: 3.0159 - accuracy: 0.7579\n",
      "Epoch 1: accuracy improved from 0.75788 to 0.75982, saving model to output\\vgg.h5\n",
      " 77/250 [========>.....................] - ETA: 5:08 - loss: 2.9804 - accuracy: 0.7598\n",
      "Epoch 1: accuracy improved from 0.75982 to 0.76252, saving model to output\\vgg.h5\n",
      " 78/250 [========>.....................] - ETA: 5:06 - loss: 2.9444 - accuracy: 0.7625\n",
      "Epoch 1: accuracy improved from 0.76252 to 0.76435, saving model to output\\vgg.h5\n",
      " 79/250 [========>.....................] - ETA: 5:05 - loss: 2.9089 - accuracy: 0.7644\n",
      "Epoch 1: accuracy improved from 0.76435 to 0.76535, saving model to output\\vgg.h5\n",
      " 80/250 [========>.....................] - ETA: 5:04 - loss: 2.8781 - accuracy: 0.7654\n",
      "Epoch 1: accuracy improved from 0.76535 to 0.76672, saving model to output\\vgg.h5\n",
      " 81/250 [========>.....................] - ETA: 5:03 - loss: 2.8666 - accuracy: 0.7667\n",
      "Epoch 1: accuracy improved from 0.76672 to 0.76767, saving model to output\\vgg.h5\n",
      " 82/250 [========>.....................] - ETA: 5:01 - loss: 2.8431 - accuracy: 0.7677\n",
      "Epoch 1: accuracy improved from 0.76767 to 0.76859, saving model to output\\vgg.h5\n",
      " 83/250 [========>.....................] - ETA: 4:59 - loss: 2.8160 - accuracy: 0.7686\n",
      "Epoch 1: accuracy improved from 0.76859 to 0.76874, saving model to output\\vgg.h5\n",
      " 84/250 [=========>....................] - ETA: 4:57 - loss: 2.8041 - accuracy: 0.7687\n",
      "Epoch 1: accuracy improved from 0.76874 to 0.77000, saving model to output\\vgg.h5\n",
      " 85/250 [=========>....................] - ETA: 4:55 - loss: 2.7874 - accuracy: 0.7700\n",
      "Epoch 1: accuracy improved from 0.77000 to 0.77123, saving model to output\\vgg.h5\n",
      " 86/250 [=========>....................] - ETA: 4:53 - loss: 2.7599 - accuracy: 0.7712\n",
      "Epoch 1: accuracy improved from 0.77123 to 0.77279, saving model to output\\vgg.h5\n",
      " 87/250 [=========>....................] - ETA: 4:52 - loss: 2.7418 - accuracy: 0.7728\n",
      "Epoch 1: accuracy improved from 0.77279 to 0.77396, saving model to output\\vgg.h5\n",
      " 88/250 [=========>....................] - ETA: 4:50 - loss: 2.7240 - accuracy: 0.7740\n",
      "Epoch 1: accuracy improved from 0.77396 to 0.77581, saving model to output\\vgg.h5\n",
      " 89/250 [=========>....................] - ETA: 4:48 - loss: 2.6941 - accuracy: 0.7758\n",
      "Epoch 1: accuracy improved from 0.77581 to 0.77797, saving model to output\\vgg.h5\n",
      " 90/250 [=========>....................] - ETA: 4:47 - loss: 2.6709 - accuracy: 0.7780\n",
      "Epoch 1: accuracy improved from 0.77797 to 0.77974, saving model to output\\vgg.h5\n",
      " 91/250 [=========>....................] - ETA: 4:45 - loss: 2.6484 - accuracy: 0.7797\n",
      "Epoch 1: accuracy improved from 0.77974 to 0.78078, saving model to output\\vgg.h5\n",
      " 92/250 [==========>...................] - ETA: 4:43 - loss: 2.6345 - accuracy: 0.7808\n",
      "Epoch 1: accuracy improved from 0.78078 to 0.78078, saving model to output\\vgg.h5\n",
      " 93/250 [==========>...................] - ETA: 4:42 - loss: 2.6189 - accuracy: 0.7808\n",
      "Epoch 1: accuracy improved from 0.78078 to 0.78313, saving model to output\\vgg.h5\n",
      " 94/250 [==========>...................] - ETA: 4:40 - loss: 2.5909 - accuracy: 0.7831\n",
      "Epoch 1: accuracy improved from 0.78313 to 0.78411, saving model to output\\vgg.h5\n",
      " 95/250 [==========>...................] - ETA: 4:39 - loss: 2.5664 - accuracy: 0.7841\n",
      "Epoch 1: accuracy improved from 0.78411 to 0.78506, saving model to output\\vgg.h5\n",
      " 96/250 [==========>...................] - ETA: 4:37 - loss: 2.5511 - accuracy: 0.7851\n",
      "Epoch 1: accuracy improved from 0.78506 to 0.78599, saving model to output\\vgg.h5\n",
      " 97/250 [==========>...................] - ETA: 4:35 - loss: 2.5311 - accuracy: 0.7860\n",
      "Epoch 1: accuracy improved from 0.78599 to 0.78691, saving model to output\\vgg.h5\n",
      " 98/250 [==========>...................] - ETA: 4:33 - loss: 2.5094 - accuracy: 0.7869\n",
      "Epoch 1: accuracy improved from 0.78691 to 0.78812, saving model to output\\vgg.h5\n",
      " 99/250 [==========>...................] - ETA: 4:32 - loss: 2.4887 - accuracy: 0.7881\n",
      "Epoch 1: accuracy improved from 0.78812 to 0.78931, saving model to output\\vgg.h5\n",
      "100/250 [===========>..................] - ETA: 4:30 - loss: 2.4697 - accuracy: 0.7893\n",
      "Epoch 1: accuracy improved from 0.78931 to 0.79110, saving model to output\\vgg.h5\n",
      "101/250 [===========>..................] - ETA: 4:28 - loss: 2.4493 - accuracy: 0.7911\n",
      "Epoch 1: accuracy improved from 0.79110 to 0.79192, saving model to output\\vgg.h5\n",
      "102/250 [===========>..................] - ETA: 4:26 - loss: 2.4319 - accuracy: 0.7919\n",
      "Epoch 1: accuracy improved from 0.79192 to 0.79335, saving model to output\\vgg.h5\n",
      "103/250 [===========>..................] - ETA: 4:24 - loss: 2.4126 - accuracy: 0.7933\n",
      "Epoch 1: accuracy improved from 0.79335 to 0.79414, saving model to output\\vgg.h5\n",
      "104/250 [===========>..................] - ETA: 4:22 - loss: 2.3968 - accuracy: 0.7941\n",
      "Epoch 1: accuracy improved from 0.79414 to 0.79491, saving model to output\\vgg.h5\n",
      "105/250 [===========>..................] - ETA: 4:20 - loss: 2.3805 - accuracy: 0.7949\n",
      "Epoch 1: accuracy improved from 0.79491 to 0.79656, saving model to output\\vgg.h5\n",
      "106/250 [===========>..................] - ETA: 4:18 - loss: 2.3590 - accuracy: 0.7966\n",
      "Epoch 1: accuracy improved from 0.79656 to 0.79818, saving model to output\\vgg.h5\n",
      "107/250 [===========>..................] - ETA: 4:16 - loss: 2.3399 - accuracy: 0.7982\n",
      "Epoch 1: accuracy improved from 0.79818 to 0.79919, saving model to output\\vgg.h5\n",
      "108/250 [===========>..................] - ETA: 4:15 - loss: 2.3246 - accuracy: 0.7992\n",
      "Epoch 1: accuracy improved from 0.79919 to 0.79960, saving model to output\\vgg.h5\n",
      "109/250 [============>.................] - ETA: 4:14 - loss: 2.3100 - accuracy: 0.7996\n",
      "Epoch 1: accuracy improved from 0.79960 to 0.80057, saving model to output\\vgg.h5\n",
      "110/250 [============>.................] - ETA: 4:12 - loss: 2.2957 - accuracy: 0.8006\n",
      "Epoch 1: accuracy improved from 0.80057 to 0.80068, saving model to output\\vgg.h5\n",
      "111/250 [============>.................] - ETA: 4:10 - loss: 2.2857 - accuracy: 0.8007\n",
      "Epoch 1: accuracy improved from 0.80068 to 0.80163, saving model to output\\vgg.h5\n",
      "112/250 [============>.................] - ETA: 4:08 - loss: 2.2748 - accuracy: 0.8016\n",
      "Epoch 1: accuracy improved from 0.80163 to 0.80284, saving model to output\\vgg.h5\n",
      "113/250 [============>.................] - ETA: 4:07 - loss: 2.2572 - accuracy: 0.8028\n",
      "Epoch 1: accuracy improved from 0.80284 to 0.80430, saving model to output\\vgg.h5\n",
      "114/250 [============>.................] - ETA: 4:05 - loss: 2.2423 - accuracy: 0.8043\n",
      "Epoch 1: accuracy improved from 0.80430 to 0.80546, saving model to output\\vgg.h5\n",
      "115/250 [============>.................] - ETA: 4:03 - loss: 2.2254 - accuracy: 0.8055\n",
      "Epoch 1: accuracy improved from 0.80546 to 0.80580, saving model to output\\vgg.h5\n",
      "116/250 [============>.................] - ETA: 4:01 - loss: 2.2221 - accuracy: 0.8058\n",
      "Epoch 1: accuracy improved from 0.80580 to 0.80720, saving model to output\\vgg.h5\n",
      "117/250 [=============>................] - ETA: 3:59 - loss: 2.2035 - accuracy: 0.8072\n",
      "Epoch 1: accuracy improved from 0.80720 to 0.80804, saving model to output\\vgg.h5\n",
      "118/250 [=============>................] - ETA: 3:57 - loss: 2.1917 - accuracy: 0.8080\n",
      "Epoch 1: accuracy improved from 0.80804 to 0.80861, saving model to output\\vgg.h5\n",
      "119/250 [=============>................] - ETA: 3:55 - loss: 2.1830 - accuracy: 0.8086\n",
      "Epoch 1: accuracy improved from 0.80861 to 0.80890, saving model to output\\vgg.h5\n",
      "120/250 [=============>................] - ETA: 3:53 - loss: 2.1764 - accuracy: 0.8089\n",
      "Epoch 1: accuracy did not improve from 0.80890\n",
      "121/250 [=============>................] - ETA: 3:50 - loss: 2.1704 - accuracy: 0.8084\n",
      "Epoch 1: accuracy improved from 0.80890 to 0.80947, saving model to output\\vgg.h5\n",
      "122/250 [=============>................] - ETA: 3:48 - loss: 2.1596 - accuracy: 0.8095\n",
      "Epoch 1: accuracy improved from 0.80947 to 0.81027, saving model to output\\vgg.h5\n",
      "123/250 [=============>................] - ETA: 3:46 - loss: 2.1478 - accuracy: 0.8103\n",
      "Epoch 1: accuracy improved from 0.81027 to 0.81104, saving model to output\\vgg.h5\n",
      "124/250 [=============>................] - ETA: 3:44 - loss: 2.1372 - accuracy: 0.8110\n",
      "Epoch 1: accuracy improved from 0.81104 to 0.81156, saving model to output\\vgg.h5\n",
      "125/250 [==============>...............] - ETA: 3:42 - loss: 2.1306 - accuracy: 0.8116\n",
      "Epoch 1: accuracy improved from 0.81156 to 0.81157, saving model to output\\vgg.h5\n",
      "126/250 [==============>...............] - ETA: 3:40 - loss: 2.1279 - accuracy: 0.8116\n",
      "Epoch 1: accuracy improved from 0.81157 to 0.81207, saving model to output\\vgg.h5\n",
      "127/250 [==============>...............] - ETA: 3:39 - loss: 2.1123 - accuracy: 0.8121\n",
      "Epoch 1: accuracy improved from 0.81207 to 0.81305, saving model to output\\vgg.h5\n",
      "128/250 [==============>...............] - ETA: 3:37 - loss: 2.1052 - accuracy: 0.8131\n",
      "Epoch 1: accuracy improved from 0.81305 to 0.81353, saving model to output\\vgg.h5\n",
      "129/250 [==============>...............] - ETA: 3:35 - loss: 2.0981 - accuracy: 0.8135\n",
      "Epoch 1: accuracy improved from 0.81353 to 0.81425, saving model to output\\vgg.h5\n",
      "130/250 [==============>...............] - ETA: 3:33 - loss: 2.0889 - accuracy: 0.8143\n",
      "Epoch 1: accuracy improved from 0.81425 to 0.81472, saving model to output\\vgg.h5\n",
      "131/250 [==============>...............] - ETA: 3:31 - loss: 2.0911 - accuracy: 0.8147\n",
      "Epoch 1: accuracy improved from 0.81472 to 0.81565, saving model to output\\vgg.h5\n",
      "132/250 [==============>...............] - ETA: 3:29 - loss: 2.0766 - accuracy: 0.8157\n",
      "Epoch 1: accuracy improved from 0.81565 to 0.81586, saving model to output\\vgg.h5\n",
      "133/250 [==============>...............] - ETA: 3:27 - loss: 2.0729 - accuracy: 0.8159\n",
      "Epoch 1: accuracy improved from 0.81586 to 0.81678, saving model to output\\vgg.h5\n",
      "134/250 [===============>..............] - ETA: 3:26 - loss: 2.0581 - accuracy: 0.8168\n",
      "Epoch 1: accuracy improved from 0.81678 to 0.81767, saving model to output\\vgg.h5\n",
      "135/250 [===============>..............] - ETA: 3:24 - loss: 2.0475 - accuracy: 0.8177\n",
      "Epoch 1: accuracy did not improve from 0.81767\n",
      "136/250 [===============>..............] - ETA: 3:21 - loss: 2.0401 - accuracy: 0.8176\n",
      "Epoch 1: accuracy improved from 0.81767 to 0.81829, saving model to output\\vgg.h5\n",
      "137/250 [===============>..............] - ETA: 3:19 - loss: 2.0280 - accuracy: 0.8183\n",
      "Epoch 1: accuracy improved from 0.81829 to 0.81870, saving model to output\\vgg.h5\n",
      "138/250 [===============>..............] - ETA: 3:17 - loss: 2.0245 - accuracy: 0.8187\n",
      "Epoch 1: accuracy improved from 0.81870 to 0.81956, saving model to output\\vgg.h5\n",
      "139/250 [===============>..............] - ETA: 3:15 - loss: 2.0155 - accuracy: 0.8196\n",
      "Epoch 1: accuracy improved from 0.81956 to 0.81996, saving model to output\\vgg.h5\n",
      "140/250 [===============>..............] - ETA: 3:13 - loss: 2.0122 - accuracy: 0.8200\n",
      "Epoch 1: accuracy improved from 0.81996 to 0.82012, saving model to output\\vgg.h5\n",
      "141/250 [===============>..............] - ETA: 3:12 - loss: 2.0119 - accuracy: 0.8201\n",
      "Epoch 1: accuracy improved from 0.82012 to 0.82118, saving model to output\\vgg.h5\n",
      "142/250 [================>.............] - ETA: 3:10 - loss: 1.9985 - accuracy: 0.8212\n",
      "Epoch 1: accuracy improved from 0.82118 to 0.82243, saving model to output\\vgg.h5\n",
      "143/250 [================>.............] - ETA: 3:08 - loss: 1.9845 - accuracy: 0.8224\n",
      "Epoch 1: accuracy improved from 0.82243 to 0.82345, saving model to output\\vgg.h5\n",
      "144/250 [================>.............] - ETA: 3:07 - loss: 1.9716 - accuracy: 0.8235\n",
      "Epoch 1: accuracy improved from 0.82345 to 0.82424, saving model to output\\vgg.h5\n",
      "145/250 [================>.............] - ETA: 3:05 - loss: 1.9642 - accuracy: 0.8242\n",
      "Epoch 1: accuracy improved from 0.82424 to 0.82438, saving model to output\\vgg.h5\n",
      "146/250 [================>.............] - ETA: 3:03 - loss: 1.9547 - accuracy: 0.8244\n",
      "Epoch 1: accuracy improved from 0.82438 to 0.82472, saving model to output\\vgg.h5\n",
      "147/250 [================>.............] - ETA: 3:01 - loss: 1.9490 - accuracy: 0.8247\n",
      "Epoch 1: accuracy improved from 0.82472 to 0.82506, saving model to output\\vgg.h5\n",
      "148/250 [================>.............] - ETA: 3:00 - loss: 1.9462 - accuracy: 0.8251\n",
      "Epoch 1: accuracy improved from 0.82506 to 0.82540, saving model to output\\vgg.h5\n",
      "149/250 [================>.............] - ETA: 2:58 - loss: 1.9423 - accuracy: 0.8254\n",
      "Epoch 1: accuracy improved from 0.82540 to 0.82636, saving model to output\\vgg.h5\n",
      "150/250 [=================>............] - ETA: 2:57 - loss: 1.9318 - accuracy: 0.8264\n",
      "Epoch 1: accuracy improved from 0.82636 to 0.82710, saving model to output\\vgg.h5\n",
      "151/250 [=================>............] - ETA: 2:55 - loss: 1.9202 - accuracy: 0.8271\n",
      "Epoch 1: accuracy improved from 0.82710 to 0.82762, saving model to output\\vgg.h5\n",
      "152/250 [=================>............] - ETA: 2:53 - loss: 1.9164 - accuracy: 0.8276\n",
      "Epoch 1: accuracy improved from 0.82762 to 0.82814, saving model to output\\vgg.h5\n",
      "153/250 [=================>............] - ETA: 2:52 - loss: 1.9097 - accuracy: 0.8281\n",
      "Epoch 1: accuracy improved from 0.82814 to 0.82865, saving model to output\\vgg.h5\n",
      "154/250 [=================>............] - ETA: 2:50 - loss: 1.8985 - accuracy: 0.8286\n",
      "Epoch 1: accuracy did not improve from 0.82865\n",
      "155/250 [=================>............] - ETA: 2:47 - loss: 1.8931 - accuracy: 0.8283\n",
      "Epoch 1: accuracy did not improve from 0.82865\n",
      "156/250 [=================>............] - ETA: 2:44 - loss: 1.8865 - accuracy: 0.8286\n",
      "Epoch 1: accuracy improved from 0.82865 to 0.82914, saving model to output\\vgg.h5\n",
      "157/250 [=================>............] - ETA: 2:43 - loss: 1.8781 - accuracy: 0.8291\n",
      "Epoch 1: accuracy improved from 0.82914 to 0.82943, saving model to output\\vgg.h5\n",
      "158/250 [=================>............] - ETA: 2:41 - loss: 1.8760 - accuracy: 0.8294\n",
      "Epoch 1: accuracy improved from 0.82943 to 0.82991, saving model to output\\vgg.h5\n",
      "159/250 [==================>...........] - ETA: 2:39 - loss: 1.8708 - accuracy: 0.8299\n",
      "Epoch 1: accuracy improved from 0.82991 to 0.83059, saving model to output\\vgg.h5\n",
      "160/250 [==================>...........] - ETA: 2:37 - loss: 1.8644 - accuracy: 0.8306\n",
      "Epoch 1: accuracy did not improve from 0.83059\n",
      "161/250 [==================>...........] - ETA: 2:35 - loss: 1.8590 - accuracy: 0.8305\n",
      "Epoch 1: accuracy improved from 0.83059 to 0.83133, saving model to output\\vgg.h5\n",
      "162/250 [==================>...........] - ETA: 2:33 - loss: 1.8487 - accuracy: 0.8313\n",
      "Epoch 1: accuracy improved from 0.83133 to 0.83199, saving model to output\\vgg.h5\n",
      "163/250 [==================>...........] - ETA: 2:31 - loss: 1.8385 - accuracy: 0.8320\n",
      "Epoch 1: accuracy did not improve from 0.83199\n",
      "164/250 [==================>...........] - ETA: 2:29 - loss: 1.8400 - accuracy: 0.8319\n",
      "Epoch 1: accuracy did not improve from 0.83199\n",
      "165/250 [==================>...........] - ETA: 2:26 - loss: 1.8342 - accuracy: 0.8319\n",
      "Epoch 1: accuracy improved from 0.83199 to 0.83201, saving model to output\\vgg.h5\n",
      "166/250 [==================>...........] - ETA: 2:24 - loss: 1.8363 - accuracy: 0.8320\n",
      "Epoch 1: accuracy improved from 0.83201 to 0.83208, saving model to output\\vgg.h5\n",
      "167/250 [===================>..........] - ETA: 2:23 - loss: 1.8310 - accuracy: 0.8321\n",
      "Epoch 1: accuracy improved from 0.83208 to 0.83308, saving model to output\\vgg.h5\n",
      "168/250 [===================>..........] - ETA: 2:21 - loss: 1.8201 - accuracy: 0.8331\n",
      "Epoch 1: accuracy improved from 0.83308 to 0.83370, saving model to output\\vgg.h5\n",
      "169/250 [===================>..........] - ETA: 2:19 - loss: 1.8125 - accuracy: 0.8337\n",
      "Epoch 1: accuracy improved from 0.83370 to 0.83395, saving model to output\\vgg.h5\n",
      "170/250 [===================>..........] - ETA: 2:17 - loss: 1.8104 - accuracy: 0.8339\n",
      "Epoch 1: accuracy improved from 0.83395 to 0.83456, saving model to output\\vgg.h5\n",
      "171/250 [===================>..........] - ETA: 2:16 - loss: 1.8102 - accuracy: 0.8346\n",
      "Epoch 1: accuracy improved from 0.83456 to 0.83479, saving model to output\\vgg.h5\n",
      "172/250 [===================>..........] - ETA: 2:14 - loss: 1.8031 - accuracy: 0.8348\n",
      "Epoch 1: accuracy improved from 0.83479 to 0.83539, saving model to output\\vgg.h5\n",
      "173/250 [===================>..........] - ETA: 2:12 - loss: 1.7951 - accuracy: 0.8354\n",
      "Epoch 1: accuracy improved from 0.83539 to 0.83562, saving model to output\\vgg.h5\n",
      "174/250 [===================>..........] - ETA: 2:10 - loss: 1.7903 - accuracy: 0.8356\n",
      "Epoch 1: accuracy improved from 0.83562 to 0.83602, saving model to output\\vgg.h5\n",
      "175/250 [====================>.........] - ETA: 2:09 - loss: 1.7888 - accuracy: 0.8360\n",
      "Epoch 1: accuracy improved from 0.83602 to 0.83642, saving model to output\\vgg.h5\n",
      "176/250 [====================>.........] - ETA: 2:07 - loss: 1.7852 - accuracy: 0.8364\n",
      "Epoch 1: accuracy improved from 0.83642 to 0.83700, saving model to output\\vgg.h5\n",
      "177/250 [====================>.........] - ETA: 2:05 - loss: 1.7763 - accuracy: 0.8370\n",
      "Epoch 1: accuracy improved from 0.83700 to 0.83721, saving model to output\\vgg.h5\n",
      "178/250 [====================>.........] - ETA: 2:04 - loss: 1.7695 - accuracy: 0.8372\n",
      "Epoch 1: accuracy improved from 0.83721 to 0.83725, saving model to output\\vgg.h5\n",
      "179/250 [====================>.........] - ETA: 2:02 - loss: 1.7630 - accuracy: 0.8372\n",
      "Epoch 1: accuracy improved from 0.83725 to 0.83780, saving model to output\\vgg.h5\n",
      "180/250 [====================>.........] - ETA: 2:00 - loss: 1.7556 - accuracy: 0.8378\n",
      "Epoch 1: accuracy improved from 0.83780 to 0.83784, saving model to output\\vgg.h5\n",
      "181/250 [====================>.........] - ETA: 1:58 - loss: 1.7522 - accuracy: 0.8378\n",
      "Epoch 1: accuracy improved from 0.83784 to 0.83839, saving model to output\\vgg.h5\n",
      "182/250 [====================>.........] - ETA: 1:57 - loss: 1.7455 - accuracy: 0.8384\n",
      "Epoch 1: accuracy improved from 0.83839 to 0.83910, saving model to output\\vgg.h5\n",
      "183/250 [====================>.........] - ETA: 1:55 - loss: 1.7365 - accuracy: 0.8391\n",
      "Epoch 1: accuracy improved from 0.83910 to 0.83913, saving model to output\\vgg.h5\n",
      "184/250 [=====================>........] - ETA: 1:54 - loss: 1.7353 - accuracy: 0.8391\n",
      "Epoch 1: accuracy improved from 0.83913 to 0.83966, saving model to output\\vgg.h5\n",
      "185/250 [=====================>........] - ETA: 1:52 - loss: 1.7273 - accuracy: 0.8397\n",
      "Epoch 1: accuracy improved from 0.83966 to 0.84002, saving model to output\\vgg.h5\n",
      "186/250 [=====================>........] - ETA: 1:50 - loss: 1.7190 - accuracy: 0.8400\n",
      "Epoch 1: accuracy improved from 0.84002 to 0.84004, saving model to output\\vgg.h5\n",
      "187/250 [=====================>........] - ETA: 1:48 - loss: 1.7146 - accuracy: 0.8400\n",
      "Epoch 1: accuracy improved from 0.84004 to 0.84073, saving model to output\\vgg.h5\n",
      "188/250 [=====================>........] - ETA: 1:47 - loss: 1.7072 - accuracy: 0.8407\n",
      "Epoch 1: accuracy improved from 0.84073 to 0.84091, saving model to output\\vgg.h5\n",
      "189/250 [=====================>........] - ETA: 1:45 - loss: 1.7014 - accuracy: 0.8409\n",
      "Epoch 1: accuracy improved from 0.84091 to 0.84125, saving model to output\\vgg.h5\n",
      "190/250 [=====================>........] - ETA: 1:43 - loss: 1.6950 - accuracy: 0.8413\n",
      "Epoch 1: accuracy improved from 0.84125 to 0.84143, saving model to output\\vgg.h5\n",
      "191/250 [=====================>........] - ETA: 1:41 - loss: 1.6923 - accuracy: 0.8414\n",
      "Epoch 1: accuracy improved from 0.84143 to 0.84193, saving model to output\\vgg.h5\n",
      "192/250 [======================>.......] - ETA: 1:40 - loss: 1.6850 - accuracy: 0.8419\n",
      "Epoch 1: accuracy improved from 0.84193 to 0.84276, saving model to output\\vgg.h5\n",
      "193/250 [======================>.......] - ETA: 1:38 - loss: 1.6763 - accuracy: 0.8428\n",
      "Epoch 1: accuracy improved from 0.84276 to 0.84324, saving model to output\\vgg.h5\n",
      "194/250 [======================>.......] - ETA: 1:36 - loss: 1.6699 - accuracy: 0.8432\n",
      "Epoch 1: accuracy improved from 0.84324 to 0.84357, saving model to output\\vgg.h5\n",
      "195/250 [======================>.......] - ETA: 1:34 - loss: 1.6632 - accuracy: 0.8436\n",
      "Epoch 1: accuracy improved from 0.84357 to 0.84389, saving model to output\\vgg.h5\n",
      "196/250 [======================>.......] - ETA: 1:33 - loss: 1.6577 - accuracy: 0.8439\n",
      "Epoch 1: accuracy improved from 0.84389 to 0.84421, saving model to output\\vgg.h5\n",
      "197/250 [======================>.......] - ETA: 1:31 - loss: 1.6532 - accuracy: 0.8442\n",
      "Epoch 1: accuracy improved from 0.84421 to 0.84452, saving model to output\\vgg.h5\n",
      "198/250 [======================>.......] - ETA: 1:29 - loss: 1.6465 - accuracy: 0.8445\n",
      "Epoch 1: accuracy improved from 0.84452 to 0.84499, saving model to output\\vgg.h5\n",
      "199/250 [======================>.......] - ETA: 1:27 - loss: 1.6406 - accuracy: 0.8450\n",
      "Epoch 1: accuracy improved from 0.84499 to 0.84545, saving model to output\\vgg.h5\n",
      "200/250 [=======================>......] - ETA: 1:26 - loss: 1.6349 - accuracy: 0.8455\n",
      "Epoch 1: accuracy improved from 0.84545 to 0.84607, saving model to output\\vgg.h5\n",
      "201/250 [=======================>......] - ETA: 1:24 - loss: 1.6274 - accuracy: 0.8461\n",
      "Epoch 1: accuracy improved from 0.84607 to 0.84637, saving model to output\\vgg.h5\n",
      "202/250 [=======================>......] - ETA: 1:22 - loss: 1.6229 - accuracy: 0.8464\n",
      "Epoch 1: accuracy improved from 0.84637 to 0.84666, saving model to output\\vgg.h5\n",
      "203/250 [=======================>......] - ETA: 1:21 - loss: 1.6185 - accuracy: 0.8467\n",
      "Epoch 1: accuracy improved from 0.84666 to 0.84726, saving model to output\\vgg.h5\n",
      "204/250 [=======================>......] - ETA: 1:19 - loss: 1.6115 - accuracy: 0.8473\n",
      "Epoch 1: accuracy improved from 0.84726 to 0.84786, saving model to output\\vgg.h5\n",
      "205/250 [=======================>......] - ETA: 1:17 - loss: 1.6041 - accuracy: 0.8479\n",
      "Epoch 1: accuracy improved from 0.84786 to 0.84799, saving model to output\\vgg.h5\n",
      "206/250 [=======================>......] - ETA: 1:15 - loss: 1.6003 - accuracy: 0.8480\n",
      "Epoch 1: accuracy improved from 0.84799 to 0.84843, saving model to output\\vgg.h5\n",
      "207/250 [=======================>......] - ETA: 1:14 - loss: 1.5941 - accuracy: 0.8484\n",
      "Epoch 1: accuracy improved from 0.84843 to 0.84885, saving model to output\\vgg.h5\n",
      "208/250 [=======================>......] - ETA: 1:12 - loss: 1.5880 - accuracy: 0.8489\n",
      "Epoch 1: accuracy improved from 0.84885 to 0.84928, saving model to output\\vgg.h5\n",
      "209/250 [========================>.....] - ETA: 1:10 - loss: 1.5815 - accuracy: 0.8493\n",
      "Epoch 1: accuracy improved from 0.84928 to 0.84955, saving model to output\\vgg.h5\n",
      "210/250 [========================>.....] - ETA: 1:08 - loss: 1.5792 - accuracy: 0.8496\n",
      "Epoch 1: accuracy improved from 0.84955 to 0.85012, saving model to output\\vgg.h5\n",
      "211/250 [========================>.....] - ETA: 1:07 - loss: 1.5720 - accuracy: 0.8501\n",
      "Epoch 1: accuracy improved from 0.85012 to 0.85053, saving model to output\\vgg.h5\n",
      "212/250 [========================>.....] - ETA: 1:05 - loss: 1.5654 - accuracy: 0.8505\n",
      "Epoch 1: accuracy improved from 0.85053 to 0.85094, saving model to output\\vgg.h5\n",
      "213/250 [========================>.....] - ETA: 1:03 - loss: 1.5603 - accuracy: 0.8509\n",
      "Epoch 1: accuracy improved from 0.85094 to 0.85120, saving model to output\\vgg.h5\n",
      "214/250 [========================>.....] - ETA: 1:02 - loss: 1.5657 - accuracy: 0.8512\n",
      "Epoch 1: accuracy improved from 0.85120 to 0.85175, saving model to output\\vgg.h5\n",
      "215/250 [========================>.....] - ETA: 1:00 - loss: 1.5591 - accuracy: 0.8517\n",
      "Epoch 1: accuracy improved from 0.85175 to 0.85229, saving model to output\\vgg.h5\n",
      "216/250 [========================>.....] - ETA: 58s - loss: 1.5523 - accuracy: 0.8523 \n",
      "Epoch 1: accuracy improved from 0.85229 to 0.85298, saving model to output\\vgg.h5\n",
      "217/250 [=========================>....] - ETA: 56s - loss: 1.5453 - accuracy: 0.8530\n",
      "Epoch 1: accuracy did not improve from 0.85298\n",
      "218/250 [=========================>....] - ETA: 55s - loss: 1.5456 - accuracy: 0.8528\n",
      "Epoch 1: accuracy improved from 0.85298 to 0.85332, saving model to output\\vgg.h5\n",
      "219/250 [=========================>....] - ETA: 53s - loss: 1.5387 - accuracy: 0.8533\n",
      "Epoch 1: accuracy improved from 0.85332 to 0.85370, saving model to output\\vgg.h5\n",
      "220/250 [=========================>....] - ETA: 51s - loss: 1.5330 - accuracy: 0.8537\n",
      "Epoch 1: accuracy improved from 0.85370 to 0.85423, saving model to output\\vgg.h5\n",
      "221/250 [=========================>....] - ETA: 49s - loss: 1.5273 - accuracy: 0.8542\n",
      "Epoch 1: accuracy improved from 0.85423 to 0.85446, saving model to output\\vgg.h5\n",
      "222/250 [=========================>....] - ETA: 48s - loss: 1.5218 - accuracy: 0.8545\n",
      "Epoch 1: accuracy improved from 0.85446 to 0.85497, saving model to output\\vgg.h5\n",
      "223/250 [=========================>....] - ETA: 46s - loss: 1.5151 - accuracy: 0.8550\n",
      "Epoch 1: accuracy improved from 0.85497 to 0.85534, saving model to output\\vgg.h5\n",
      "224/250 [=========================>....] - ETA: 44s - loss: 1.5091 - accuracy: 0.8553\n",
      "Epoch 1: accuracy improved from 0.85534 to 0.85557, saving model to output\\vgg.h5\n",
      "225/250 [==========================>...] - ETA: 43s - loss: 1.5043 - accuracy: 0.8556\n",
      "Epoch 1: accuracy improved from 0.85557 to 0.85580, saving model to output\\vgg.h5\n",
      "226/250 [==========================>...] - ETA: 41s - loss: 1.4993 - accuracy: 0.8558\n",
      "Epoch 1: accuracy did not improve from 0.85580\n",
      "227/250 [==========================>...] - ETA: 39s - loss: 1.4982 - accuracy: 0.8556\n",
      "Epoch 1: accuracy improved from 0.85580 to 0.85610, saving model to output\\vgg.h5\n",
      "228/250 [==========================>...] - ETA: 37s - loss: 1.4920 - accuracy: 0.8561\n",
      "Epoch 1: accuracy improved from 0.85610 to 0.85619, saving model to output\\vgg.h5\n",
      "229/250 [==========================>...] - ETA: 36s - loss: 1.4889 - accuracy: 0.8562\n",
      "Epoch 1: accuracy improved from 0.85619 to 0.85654, saving model to output\\vgg.h5\n",
      "230/250 [==========================>...] - ETA: 34s - loss: 1.4829 - accuracy: 0.8565\n",
      "Epoch 1: accuracy improved from 0.85654 to 0.85716, saving model to output\\vgg.h5\n",
      "231/250 [==========================>...] - ETA: 32s - loss: 1.4765 - accuracy: 0.8572\n",
      "Epoch 1: accuracy improved from 0.85716 to 0.85724, saving model to output\\vgg.h5\n",
      "232/250 [==========================>...] - ETA: 30s - loss: 1.4756 - accuracy: 0.8572\n",
      "Epoch 1: accuracy improved from 0.85724 to 0.85772, saving model to output\\vgg.h5\n",
      "233/250 [==========================>...] - ETA: 29s - loss: 1.4705 - accuracy: 0.8577\n",
      "Epoch 1: accuracy improved from 0.85772 to 0.85793, saving model to output\\vgg.h5\n",
      "234/250 [===========================>..] - ETA: 27s - loss: 1.4674 - accuracy: 0.8579\n",
      "Epoch 1: accuracy did not improve from 0.85793\n",
      "235/250 [===========================>..] - ETA: 25s - loss: 1.4672 - accuracy: 0.8576\n",
      "Epoch 1: accuracy did not improve from 0.85793\n",
      "236/250 [===========================>..] - ETA: 23s - loss: 1.4652 - accuracy: 0.8578\n",
      "Epoch 1: accuracy did not improve from 0.85793\n",
      "237/250 [===========================>..] - ETA: 22s - loss: 1.4638 - accuracy: 0.8577\n",
      "Epoch 1: accuracy improved from 0.85793 to 0.85808, saving model to output\\vgg.h5\n",
      "238/250 [===========================>..] - ETA: 20s - loss: 1.4586 - accuracy: 0.8581\n",
      "Epoch 1: accuracy did not improve from 0.85808\n",
      "239/250 [===========================>..] - ETA: 18s - loss: 1.4559 - accuracy: 0.8580\n",
      "Epoch 1: accuracy improved from 0.85808 to 0.85809, saving model to output\\vgg.h5\n",
      "240/250 [===========================>..] - ETA: 17s - loss: 1.4520 - accuracy: 0.8581\n",
      "Epoch 1: accuracy improved from 0.85809 to 0.85816, saving model to output\\vgg.h5\n",
      "241/250 [===========================>..] - ETA: 15s - loss: 1.4497 - accuracy: 0.8582\n",
      "Epoch 1: accuracy improved from 0.85816 to 0.85823, saving model to output\\vgg.h5\n",
      "242/250 [============================>.] - ETA: 13s - loss: 1.4480 - accuracy: 0.8582\n",
      "Epoch 1: accuracy did not improve from 0.85823\n",
      "243/250 [============================>.] - ETA: 11s - loss: 1.4514 - accuracy: 0.8578\n",
      "Epoch 1: accuracy did not improve from 0.85823\n",
      "244/250 [============================>.] - ETA: 10s - loss: 1.4483 - accuracy: 0.8580\n",
      "Epoch 1: accuracy improved from 0.85823 to 0.85844, saving model to output\\vgg.h5\n",
      "245/250 [============================>.] - ETA: 8s - loss: 1.4427 - accuracy: 0.8584 \n",
      "Epoch 1: accuracy improved from 0.85844 to 0.85863, saving model to output\\vgg.h5\n",
      "246/250 [============================>.] - ETA: 6s - loss: 1.4392 - accuracy: 0.8586\n",
      "Epoch 1: accuracy improved from 0.85863 to 0.85895, saving model to output\\vgg.h5\n",
      "247/250 [============================>.] - ETA: 5s - loss: 1.4345 - accuracy: 0.8590\n",
      "Epoch 1: accuracy improved from 0.85895 to 0.85915, saving model to output\\vgg.h5\n",
      "248/250 [============================>.] - ETA: 3s - loss: 1.4305 - accuracy: 0.8591\n",
      "Epoch 1: accuracy improved from 0.85915 to 0.85921, saving model to output\\vgg.h5\n",
      "249/250 [============================>.] - ETA: 1s - loss: 1.4266 - accuracy: 0.8592\n",
      "Epoch 1: accuracy improved from 0.85921 to 0.85927, saving model to output\\vgg.h5\n",
      "250/250 [==============================] - 455s 2s/step - loss: 1.4235 - accuracy: 0.8593 - val_loss: 0.5868 - val_accuracy: 0.9173\n",
      "Epoch 2/15\n",
      "\n",
      "Epoch 2: accuracy improved from 0.85927 to 0.90625, saving model to output\\vgg.h5\n",
      "  1/250 [..............................] - ETA: 7:29 - loss: 0.2409 - accuracy: 0.9062\n",
      "Epoch 2: accuracy did not improve from 0.90625\n",
      "  2/250 [..............................] - ETA: 43s - loss: 0.3732 - accuracy: 0.9062 \n",
      "Epoch 2: accuracy did not improve from 0.90625\n",
      "  3/250 [..............................] - ETA: 1:02 - loss: 0.6413 - accuracy: 0.8958\n",
      "Epoch 2: accuracy did not improve from 0.90625\n",
      "  4/250 [..............................] - ETA: 1:03 - loss: 0.5768 - accuracy: 0.8906\n",
      "Epoch 2: accuracy did not improve from 0.90625\n",
      "  5/250 [..............................] - ETA: 1:04 - loss: 0.5470 - accuracy: 0.9000\n",
      "Epoch 2: accuracy did not improve from 0.90625\n",
      "  6/250 [..............................] - ETA: 1:04 - loss: 0.5722 - accuracy: 0.9010\n",
      "Epoch 2: accuracy improved from 0.90625 to 0.91518, saving model to output\\vgg.h5\n",
      "  7/250 [..............................] - ETA: 2:02 - loss: 0.4907 - accuracy: 0.9152\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      "  8/250 [..............................] - ETA: 1:50 - loss: 0.5153 - accuracy: 0.9141\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      "  9/250 [>.............................] - ETA: 1:44 - loss: 0.5784 - accuracy: 0.9062\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 10/250 [>.............................] - ETA: 1:39 - loss: 0.7475 - accuracy: 0.9000\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 11/250 [>.............................] - ETA: 1:35 - loss: 0.7007 - accuracy: 0.9006\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 12/250 [>.............................] - ETA: 1:31 - loss: 0.6915 - accuracy: 0.9010\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 13/250 [>.............................] - ETA: 1:29 - loss: 0.6468 - accuracy: 0.9038\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 14/250 [>.............................] - ETA: 1:26 - loss: 0.6422 - accuracy: 0.9062\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 15/250 [>.............................] - ETA: 1:24 - loss: 0.6152 - accuracy: 0.9062\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 16/250 [>.............................] - ETA: 1:23 - loss: 0.6088 - accuracy: 0.9102\n",
      "Epoch 2: accuracy did not improve from 0.91518\n",
      " 17/250 [=>............................] - ETA: 1:21 - loss: 0.5986 - accuracy: 0.9136\n",
      "Epoch 2: accuracy improved from 0.91518 to 0.91667, saving model to output\\vgg.h5\n",
      " 18/250 [=>............................] - ETA: 1:40 - loss: 0.6027 - accuracy: 0.9167\n",
      "Epoch 2: accuracy improved from 0.91667 to 0.91941, saving model to output\\vgg.h5\n",
      " 19/250 [=>............................] - ETA: 1:53 - loss: 0.5893 - accuracy: 0.9194\n",
      "Epoch 2: accuracy did not improve from 0.91941\n",
      " 20/250 [=>............................] - ETA: 1:49 - loss: 0.5762 - accuracy: 0.9187\n",
      "Epoch 2: accuracy did not improve from 0.91941\n",
      " 21/250 [=>............................] - ETA: 1:46 - loss: 0.5657 - accuracy: 0.9182\n",
      "Epoch 2: accuracy improved from 0.91941 to 0.92045, saving model to output\\vgg.h5\n",
      " 22/250 [=>............................] - ETA: 2:01 - loss: 0.5429 - accuracy: 0.9205\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 23/250 [=>............................] - ETA: 1:57 - loss: 0.6211 - accuracy: 0.9185\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 24/250 [=>............................] - ETA: 1:54 - loss: 0.6140 - accuracy: 0.9167\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 25/250 [==>...........................] - ETA: 1:51 - loss: 0.6115 - accuracy: 0.9187\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 26/250 [==>...........................] - ETA: 1:48 - loss: 0.6089 - accuracy: 0.9171\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 27/250 [==>...........................] - ETA: 1:46 - loss: 0.6238 - accuracy: 0.9167\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 28/250 [==>...........................] - ETA: 1:44 - loss: 0.6015 - accuracy: 0.9196\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 29/250 [==>...........................] - ETA: 1:42 - loss: 0.6229 - accuracy: 0.9159\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 30/250 [==>...........................] - ETA: 1:40 - loss: 0.6036 - accuracy: 0.9177\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 31/250 [==>...........................] - ETA: 1:38 - loss: 0.5865 - accuracy: 0.9194\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 32/250 [==>...........................] - ETA: 1:36 - loss: 0.5712 - accuracy: 0.9199\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 33/250 [==>...........................] - ETA: 1:34 - loss: 0.5695 - accuracy: 0.9195\n",
      "Epoch 2: accuracy did not improve from 0.92045\n",
      " 34/250 [===>..........................] - ETA: 1:33 - loss: 0.5837 - accuracy: 0.9200\n",
      "Epoch 2: accuracy improved from 0.92045 to 0.92143, saving model to output\\vgg.h5\n",
      " 35/250 [===>..........................] - ETA: 1:41 - loss: 0.5714 - accuracy: 0.9214\n",
      "Epoch 2: accuracy did not improve from 0.92143\n",
      " 36/250 [===>..........................] - ETA: 1:39 - loss: 0.5856 - accuracy: 0.9201\n",
      "Epoch 2: accuracy did not improve from 0.92143\n",
      " 37/250 [===>..........................] - ETA: 1:37 - loss: 0.5943 - accuracy: 0.9189\n",
      "Epoch 2: accuracy did not improve from 0.92143\n",
      " 38/250 [===>..........................] - ETA: 1:36 - loss: 0.5799 - accuracy: 0.9202\n",
      "Epoch 2: accuracy did not improve from 0.92143\n",
      " 39/250 [===>..........................] - ETA: 1:35 - loss: 0.5773 - accuracy: 0.9207\n",
      "Epoch 2: accuracy did not improve from 0.92143\n",
      " 40/250 [===>..........................] - ETA: 1:33 - loss: 0.5688 - accuracy: 0.9211\n",
      "Epoch 2: accuracy improved from 0.92143 to 0.92226, saving model to output\\vgg.h5\n",
      " 41/250 [===>..........................] - ETA: 1:39 - loss: 0.5580 - accuracy: 0.9223\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 42/250 [====>.........................] - ETA: 1:37 - loss: 0.5651 - accuracy: 0.9204\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 43/250 [====>.........................] - ETA: 1:36 - loss: 0.5604 - accuracy: 0.9201\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 44/250 [====>.........................] - ETA: 1:34 - loss: 0.5505 - accuracy: 0.9197\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 45/250 [====>.........................] - ETA: 1:33 - loss: 0.5438 - accuracy: 0.9201\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 46/250 [====>.........................] - ETA: 1:32 - loss: 0.5366 - accuracy: 0.9205\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 47/250 [====>.........................] - ETA: 1:30 - loss: 0.5559 - accuracy: 0.9189\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 48/250 [====>.........................] - ETA: 1:29 - loss: 0.5458 - accuracy: 0.9199\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 49/250 [====>.........................] - ETA: 1:28 - loss: 0.5491 - accuracy: 0.9196\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 50/250 [=====>........................] - ETA: 1:27 - loss: 0.5453 - accuracy: 0.9194\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 51/250 [=====>........................] - ETA: 1:26 - loss: 0.5467 - accuracy: 0.9191\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 52/250 [=====>........................] - ETA: 1:25 - loss: 0.5396 - accuracy: 0.9195\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 53/250 [=====>........................] - ETA: 1:24 - loss: 0.5476 - accuracy: 0.9198\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 54/250 [=====>........................] - ETA: 1:23 - loss: 0.5525 - accuracy: 0.9190\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 55/250 [=====>........................] - ETA: 1:22 - loss: 0.5504 - accuracy: 0.9193\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 56/250 [=====>........................] - ETA: 1:21 - loss: 0.5538 - accuracy: 0.9185\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 57/250 [=====>........................] - ETA: 1:20 - loss: 0.5508 - accuracy: 0.9183\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 58/250 [=====>........................] - ETA: 1:19 - loss: 0.5418 - accuracy: 0.9192\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 59/250 [======>.......................] - ETA: 1:18 - loss: 0.5338 - accuracy: 0.9200\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 60/250 [======>.......................] - ETA: 1:17 - loss: 0.5271 - accuracy: 0.9203\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 61/250 [======>.......................] - ETA: 1:16 - loss: 0.5208 - accuracy: 0.9211\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 62/250 [======>.......................] - ETA: 1:15 - loss: 0.5185 - accuracy: 0.9214\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 63/250 [======>.......................] - ETA: 1:14 - loss: 0.5122 - accuracy: 0.9221\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 64/250 [======>.......................] - ETA: 1:14 - loss: 0.5136 - accuracy: 0.9214\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 65/250 [======>.......................] - ETA: 1:13 - loss: 0.5213 - accuracy: 0.9202\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 66/250 [======>.......................] - ETA: 1:12 - loss: 0.5174 - accuracy: 0.9205\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 67/250 [=======>......................] - ETA: 1:11 - loss: 0.5144 - accuracy: 0.9207\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 68/250 [=======>......................] - ETA: 1:11 - loss: 0.5127 - accuracy: 0.9210\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 69/250 [=======>......................] - ETA: 1:10 - loss: 0.5091 - accuracy: 0.9207\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 70/250 [=======>......................] - ETA: 1:09 - loss: 0.5028 - accuracy: 0.9214\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 71/250 [=======>......................] - ETA: 1:08 - loss: 0.4989 - accuracy: 0.9217\n",
      "Epoch 2: accuracy did not improve from 0.92226\n",
      " 72/250 [=======>......................] - ETA: 1:08 - loss: 0.4977 - accuracy: 0.9219\n",
      "Epoch 2: accuracy improved from 0.92226 to 0.92252, saving model to output\\vgg.h5\n",
      " 73/250 [=======>......................] - ETA: 1:11 - loss: 0.4945 - accuracy: 0.9225\n",
      "Epoch 2: accuracy improved from 0.92252 to 0.92314, saving model to output\\vgg.h5\n",
      " 74/250 [=======>......................] - ETA: 1:13 - loss: 0.4951 - accuracy: 0.9231\n",
      "Epoch 2: accuracy improved from 0.92314 to 0.92417, saving model to output\\vgg.h5\n",
      " 75/250 [========>.....................] - ETA: 1:15 - loss: 0.4885 - accuracy: 0.9242\n",
      "Epoch 2: accuracy improved from 0.92417 to 0.92434, saving model to output\\vgg.h5\n",
      " 76/250 [========>.....................] - ETA: 1:18 - loss: 0.4867 - accuracy: 0.9243\n",
      "Epoch 2: accuracy improved from 0.92434 to 0.92451, saving model to output\\vgg.h5\n",
      " 77/250 [========>.....................] - ETA: 1:21 - loss: 0.4846 - accuracy: 0.9245\n",
      "Epoch 2: accuracy improved from 0.92451 to 0.92548, saving model to output\\vgg.h5\n",
      " 78/250 [========>.....................] - ETA: 1:25 - loss: 0.4786 - accuracy: 0.9255\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 79/250 [========>.....................] - ETA: 1:24 - loss: 0.4845 - accuracy: 0.9241\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 80/250 [========>.....................] - ETA: 1:23 - loss: 0.4829 - accuracy: 0.9238\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 81/250 [========>.....................] - ETA: 1:22 - loss: 0.4896 - accuracy: 0.9228\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 82/250 [========>.....................] - ETA: 1:21 - loss: 0.4862 - accuracy: 0.9230\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 83/250 [========>.....................] - ETA: 1:20 - loss: 0.4812 - accuracy: 0.9236\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 84/250 [=========>....................] - ETA: 1:19 - loss: 0.4798 - accuracy: 0.9241\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 85/250 [=========>....................] - ETA: 1:18 - loss: 0.4827 - accuracy: 0.9239\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 86/250 [=========>....................] - ETA: 1:17 - loss: 0.4797 - accuracy: 0.9233\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 87/250 [=========>....................] - ETA: 1:17 - loss: 0.4786 - accuracy: 0.9235\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 88/250 [=========>....................] - ETA: 1:16 - loss: 0.4772 - accuracy: 0.9233\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 89/250 [=========>....................] - ETA: 1:15 - loss: 0.4817 - accuracy: 0.9235\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 90/250 [=========>....................] - ETA: 1:14 - loss: 0.4779 - accuracy: 0.9236\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 91/250 [=========>....................] - ETA: 1:13 - loss: 0.4758 - accuracy: 0.9238\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 92/250 [==========>...................] - ETA: 1:12 - loss: 0.4711 - accuracy: 0.9243\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 93/250 [==========>...................] - ETA: 1:12 - loss: 0.4772 - accuracy: 0.9244\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 94/250 [==========>...................] - ETA: 1:11 - loss: 0.4792 - accuracy: 0.9242\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 95/250 [==========>...................] - ETA: 1:10 - loss: 0.4757 - accuracy: 0.9243\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 96/250 [==========>...................] - ETA: 1:09 - loss: 0.4739 - accuracy: 0.9248\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 97/250 [==========>...................] - ETA: 1:09 - loss: 0.4693 - accuracy: 0.9253\n",
      "Epoch 2: accuracy did not improve from 0.92548\n",
      " 98/250 [==========>...................] - ETA: 1:08 - loss: 0.4661 - accuracy: 0.9254\n",
      "Epoch 2: accuracy improved from 0.92548 to 0.92551, saving model to output\\vgg.h5\n",
      " 99/250 [==========>...................] - ETA: 1:10 - loss: 0.4634 - accuracy: 0.9255\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "100/250 [===========>..................] - ETA: 1:09 - loss: 0.4614 - accuracy: 0.9250\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "101/250 [===========>..................] - ETA: 1:08 - loss: 0.4667 - accuracy: 0.9245\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "102/250 [===========>..................] - ETA: 1:07 - loss: 0.4649 - accuracy: 0.9249\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "103/250 [===========>..................] - ETA: 1:07 - loss: 0.4641 - accuracy: 0.9251\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "104/250 [===========>..................] - ETA: 1:06 - loss: 0.4672 - accuracy: 0.9246\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "105/250 [===========>..................] - ETA: 1:05 - loss: 0.4739 - accuracy: 0.9241\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "106/250 [===========>..................] - ETA: 1:04 - loss: 0.4754 - accuracy: 0.9239\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "107/250 [===========>..................] - ETA: 1:04 - loss: 0.4722 - accuracy: 0.9244\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "108/250 [===========>..................] - ETA: 1:03 - loss: 0.4719 - accuracy: 0.9236\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "109/250 [============>.................] - ETA: 1:02 - loss: 0.4730 - accuracy: 0.9237\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "110/250 [============>.................] - ETA: 1:02 - loss: 0.4701 - accuracy: 0.9239\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "111/250 [============>.................] - ETA: 1:01 - loss: 0.4685 - accuracy: 0.9240\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "112/250 [============>.................] - ETA: 1:00 - loss: 0.4689 - accuracy: 0.9235\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "113/250 [============>.................] - ETA: 1:00 - loss: 0.4673 - accuracy: 0.9237\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "114/250 [============>.................] - ETA: 59s - loss: 0.4665 - accuracy: 0.9241 \n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "115/250 [============>.................] - ETA: 59s - loss: 0.4625 - accuracy: 0.9247\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "116/250 [============>.................] - ETA: 58s - loss: 0.4592 - accuracy: 0.9248\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "117/250 [=============>................] - ETA: 57s - loss: 0.4591 - accuracy: 0.9249\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "118/250 [=============>................] - ETA: 57s - loss: 0.4577 - accuracy: 0.9251\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "119/250 [=============>................] - ETA: 56s - loss: 0.4552 - accuracy: 0.9252\n",
      "Epoch 2: accuracy did not improve from 0.92551\n",
      "120/250 [=============>................] - ETA: 55s - loss: 0.4553 - accuracy: 0.9253\n",
      "Epoch 2: accuracy improved from 0.92551 to 0.92588, saving model to output\\vgg.h5\n",
      "121/250 [=============>................] - ETA: 57s - loss: 0.4517 - accuracy: 0.9259\n",
      "Epoch 2: accuracy improved from 0.92588 to 0.92623, saving model to output\\vgg.h5\n",
      "122/250 [=============>................] - ETA: 58s - loss: 0.4510 - accuracy: 0.9262\n",
      "Epoch 2: accuracy improved from 0.92623 to 0.92683, saving model to output\\vgg.h5\n",
      "123/250 [=============>................] - ETA: 58s - loss: 0.4475 - accuracy: 0.9268\n",
      "Epoch 2: accuracy improved from 0.92683 to 0.92717, saving model to output\\vgg.h5\n",
      "124/250 [=============>................] - ETA: 59s - loss: 0.4475 - accuracy: 0.9272\n",
      "Epoch 2: accuracy did not improve from 0.92717\n",
      "125/250 [==============>...............] - ETA: 58s - loss: 0.4464 - accuracy: 0.9270\n",
      "Epoch 2: accuracy did not improve from 0.92717\n",
      "126/250 [==============>...............] - ETA: 58s - loss: 0.4451 - accuracy: 0.9271\n",
      "Epoch 2: accuracy improved from 0.92717 to 0.92741, saving model to output\\vgg.h5\n",
      "127/250 [==============>...............] - ETA: 58s - loss: 0.4420 - accuracy: 0.9274\n",
      "Epoch 2: accuracy did not improve from 0.92741\n",
      "128/250 [==============>...............] - ETA: 58s - loss: 0.4404 - accuracy: 0.9272\n",
      "Epoch 2: accuracy improved from 0.92741 to 0.92757, saving model to output\\vgg.h5\n",
      "129/250 [==============>...............] - ETA: 59s - loss: 0.4384 - accuracy: 0.9276\n",
      "Epoch 2: accuracy improved from 0.92757 to 0.92788, saving model to output\\vgg.h5\n",
      "130/250 [==============>...............] - ETA: 1:00 - loss: 0.4365 - accuracy: 0.9279\n",
      "Epoch 2: accuracy improved from 0.92788 to 0.92796, saving model to output\\vgg.h5\n",
      "131/250 [==============>...............] - ETA: 1:01 - loss: 0.4345 - accuracy: 0.9280\n",
      "Epoch 2: accuracy improved from 0.92796 to 0.92827, saving model to output\\vgg.h5\n",
      "132/250 [==============>...............] - ETA: 1:02 - loss: 0.4339 - accuracy: 0.9283\n",
      "Epoch 2: accuracy did not improve from 0.92827\n",
      "133/250 [==============>...............] - ETA: 1:01 - loss: 0.4373 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92827\n",
      "134/250 [===============>..............] - ETA: 1:00 - loss: 0.4371 - accuracy: 0.9277\n",
      "Epoch 2: accuracy did not improve from 0.92827\n",
      "135/250 [===============>..............] - ETA: 59s - loss: 0.4353 - accuracy: 0.9278 \n",
      "Epoch 2: accuracy did not improve from 0.92827\n",
      "136/250 [===============>..............] - ETA: 59s - loss: 0.4327 - accuracy: 0.9278\n",
      "Epoch 2: accuracy did not improve from 0.92827\n",
      "137/250 [===============>..............] - ETA: 58s - loss: 0.4334 - accuracy: 0.9279\n",
      "Epoch 2: accuracy improved from 0.92827 to 0.92844, saving model to output\\vgg.h5\n",
      "138/250 [===============>..............] - ETA: 59s - loss: 0.4305 - accuracy: 0.9284\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "139/250 [===============>..............] - ETA: 58s - loss: 0.4310 - accuracy: 0.9278\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "140/250 [===============>..............] - ETA: 57s - loss: 0.4296 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "141/250 [===============>..............] - ETA: 57s - loss: 0.4287 - accuracy: 0.9275\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "142/250 [================>.............] - ETA: 56s - loss: 0.4285 - accuracy: 0.9272\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "143/250 [================>.............] - ETA: 55s - loss: 0.4257 - accuracy: 0.9274\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "144/250 [================>.............] - ETA: 54s - loss: 0.4254 - accuracy: 0.9273\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "145/250 [================>.............] - ETA: 54s - loss: 0.4233 - accuracy: 0.9276\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "146/250 [================>.............] - ETA: 53s - loss: 0.4210 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "147/250 [================>.............] - ETA: 52s - loss: 0.4227 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92844\n",
      "148/250 [================>.............] - ETA: 52s - loss: 0.4214 - accuracy: 0.9282\n",
      "Epoch 2: accuracy improved from 0.92844 to 0.92869, saving model to output\\vgg.h5\n",
      "149/250 [================>.............] - ETA: 52s - loss: 0.4185 - accuracy: 0.9287\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "150/250 [=================>............] - ETA: 51s - loss: 0.4234 - accuracy: 0.9283\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "151/250 [=================>............] - ETA: 51s - loss: 0.4300 - accuracy: 0.9282\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "152/250 [=================>............] - ETA: 50s - loss: 0.4284 - accuracy: 0.9285\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "153/250 [=================>............] - ETA: 49s - loss: 0.4324 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "154/250 [=================>............] - ETA: 49s - loss: 0.4303 - accuracy: 0.9282\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "155/250 [=================>............] - ETA: 48s - loss: 0.4278 - accuracy: 0.9284\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "156/250 [=================>............] - ETA: 47s - loss: 0.4269 - accuracy: 0.9285\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "157/250 [=================>............] - ETA: 47s - loss: 0.4270 - accuracy: 0.9279\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "158/250 [=================>............] - ETA: 46s - loss: 0.4272 - accuracy: 0.9282\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "159/250 [==================>...........] - ETA: 45s - loss: 0.4247 - accuracy: 0.9285\n",
      "Epoch 2: accuracy did not improve from 0.92869\n",
      "160/250 [==================>...........] - ETA: 45s - loss: 0.4253 - accuracy: 0.9285\n",
      "Epoch 2: accuracy improved from 0.92869 to 0.92877, saving model to output\\vgg.h5\n",
      "161/250 [==================>...........] - ETA: 45s - loss: 0.4244 - accuracy: 0.9288\n",
      "Epoch 2: accuracy did not improve from 0.92877\n",
      "162/250 [==================>...........] - ETA: 44s - loss: 0.4229 - accuracy: 0.9286\n",
      "Epoch 2: accuracy did not improve from 0.92877\n",
      "163/250 [==================>...........] - ETA: 44s - loss: 0.4261 - accuracy: 0.9285\n",
      "Epoch 2: accuracy did not improve from 0.92877\n",
      "164/250 [==================>...........] - ETA: 43s - loss: 0.4240 - accuracy: 0.9287\n",
      "Epoch 2: accuracy improved from 0.92877 to 0.92879, saving model to output\\vgg.h5\n",
      "165/250 [==================>...........] - ETA: 43s - loss: 0.4229 - accuracy: 0.9288\n",
      "Epoch 2: accuracy did not improve from 0.92879\n",
      "166/250 [==================>...........] - ETA: 42s - loss: 0.4262 - accuracy: 0.9287\n",
      "Epoch 2: accuracy improved from 0.92879 to 0.92889, saving model to output\\vgg.h5\n",
      "167/250 [===================>..........] - ETA: 43s - loss: 0.4239 - accuracy: 0.9289\n",
      "Epoch 2: accuracy improved from 0.92889 to 0.92894, saving model to output\\vgg.h5\n",
      "168/250 [===================>..........] - ETA: 43s - loss: 0.4243 - accuracy: 0.9289\n",
      "Epoch 2: accuracy improved from 0.92894 to 0.92899, saving model to output\\vgg.h5\n",
      "169/250 [===================>..........] - ETA: 43s - loss: 0.4228 - accuracy: 0.9290\n",
      "Epoch 2: accuracy improved from 0.92899 to 0.92941, saving model to output\\vgg.h5\n",
      "170/250 [===================>..........] - ETA: 43s - loss: 0.4204 - accuracy: 0.9294\n",
      "Epoch 2: accuracy improved from 0.92941 to 0.92964, saving model to output\\vgg.h5\n",
      "171/250 [===================>..........] - ETA: 42s - loss: 0.4188 - accuracy: 0.9296\n",
      "Epoch 2: accuracy did not improve from 0.92964\n",
      "172/250 [===================>..........] - ETA: 42s - loss: 0.4206 - accuracy: 0.9293\n",
      "Epoch 2: accuracy did not improve from 0.92964\n",
      "173/250 [===================>..........] - ETA: 41s - loss: 0.4238 - accuracy: 0.9290\n",
      "Epoch 2: accuracy did not improve from 0.92964\n",
      "174/250 [===================>..........] - ETA: 40s - loss: 0.4216 - accuracy: 0.9294\n",
      "Epoch 2: accuracy improved from 0.92964 to 0.92964, saving model to output\\vgg.h5\n",
      "175/250 [====================>.........] - ETA: 40s - loss: 0.4203 - accuracy: 0.9296\n",
      "Epoch 2: accuracy improved from 0.92964 to 0.92969, saving model to output\\vgg.h5\n",
      "176/250 [====================>.........] - ETA: 40s - loss: 0.4205 - accuracy: 0.9297\n",
      "Epoch 2: accuracy improved from 0.92969 to 0.92973, saving model to output\\vgg.h5\n",
      "177/250 [====================>.........] - ETA: 40s - loss: 0.4194 - accuracy: 0.9297\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "178/250 [====================>.........] - ETA: 40s - loss: 0.4186 - accuracy: 0.9296\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "179/250 [====================>.........] - ETA: 39s - loss: 0.4168 - accuracy: 0.9296\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "180/250 [====================>.........] - ETA: 38s - loss: 0.4174 - accuracy: 0.9297\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "181/250 [====================>.........] - ETA: 38s - loss: 0.4172 - accuracy: 0.9297\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "182/250 [====================>.........] - ETA: 37s - loss: 0.4203 - accuracy: 0.9296\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "183/250 [====================>.........] - ETA: 36s - loss: 0.4192 - accuracy: 0.9296\n",
      "Epoch 2: accuracy did not improve from 0.92973\n",
      "184/250 [=====================>........] - ETA: 36s - loss: 0.4188 - accuracy: 0.9297\n",
      "Epoch 2: accuracy improved from 0.92973 to 0.93007, saving model to output\\vgg.h5\n",
      "185/250 [=====================>........] - ETA: 36s - loss: 0.4165 - accuracy: 0.9301\n",
      "Epoch 2: accuracy improved from 0.93007 to 0.93044, saving model to output\\vgg.h5\n",
      "186/250 [=====================>........] - ETA: 36s - loss: 0.4144 - accuracy: 0.9304\n",
      "Epoch 2: accuracy improved from 0.93044 to 0.93065, saving model to output\\vgg.h5\n",
      "187/250 [=====================>........] - ETA: 36s - loss: 0.4134 - accuracy: 0.9306\n",
      "Epoch 2: accuracy improved from 0.93065 to 0.93085, saving model to output\\vgg.h5\n",
      "188/250 [=====================>........] - ETA: 35s - loss: 0.4117 - accuracy: 0.9309\n",
      "Epoch 2: accuracy improved from 0.93085 to 0.93089, saving model to output\\vgg.h5\n",
      "189/250 [=====================>........] - ETA: 35s - loss: 0.4205 - accuracy: 0.9309\n",
      "Epoch 2: accuracy improved from 0.93089 to 0.93092, saving model to output\\vgg.h5\n",
      "190/250 [=====================>........] - ETA: 35s - loss: 0.4209 - accuracy: 0.9309\n",
      "Epoch 2: accuracy improved from 0.93092 to 0.93128, saving model to output\\vgg.h5\n",
      "191/250 [=====================>........] - ETA: 35s - loss: 0.4187 - accuracy: 0.9313\n",
      "Epoch 2: accuracy improved from 0.93128 to 0.93132, saving model to output\\vgg.h5\n",
      "192/250 [======================>.......] - ETA: 34s - loss: 0.4181 - accuracy: 0.9313\n",
      "Epoch 2: accuracy improved from 0.93132 to 0.93151, saving model to output\\vgg.h5\n",
      "193/250 [======================>.......] - ETA: 34s - loss: 0.4163 - accuracy: 0.9315\n",
      "Epoch 2: accuracy improved from 0.93151 to 0.93154, saving model to output\\vgg.h5\n",
      "194/250 [======================>.......] - ETA: 34s - loss: 0.4150 - accuracy: 0.9315\n",
      "Epoch 2: accuracy did not improve from 0.93154\n",
      "195/250 [======================>.......] - ETA: 33s - loss: 0.4141 - accuracy: 0.9314\n",
      "Epoch 2: accuracy did not improve from 0.93154\n",
      "196/250 [======================>.......] - ETA: 32s - loss: 0.4126 - accuracy: 0.9314\n",
      "Epoch 2: accuracy improved from 0.93154 to 0.93179, saving model to output\\vgg.h5\n",
      "197/250 [======================>.......] - ETA: 32s - loss: 0.4105 - accuracy: 0.9318\n",
      "Epoch 2: accuracy improved from 0.93179 to 0.93213, saving model to output\\vgg.h5\n",
      "198/250 [======================>.......] - ETA: 32s - loss: 0.4084 - accuracy: 0.9321\n",
      "Epoch 2: accuracy did not improve from 0.93213\n",
      "199/250 [======================>.......] - ETA: 31s - loss: 0.4076 - accuracy: 0.9320\n",
      "Epoch 2: accuracy did not improve from 0.93213\n",
      "200/250 [=======================>......] - ETA: 30s - loss: 0.4078 - accuracy: 0.9320\n",
      "Epoch 2: accuracy did not improve from 0.93213\n",
      "201/250 [=======================>......] - ETA: 29s - loss: 0.4075 - accuracy: 0.9321\n",
      "Epoch 2: accuracy improved from 0.93213 to 0.93224, saving model to output\\vgg.h5\n",
      "202/250 [=======================>......] - ETA: 29s - loss: 0.4066 - accuracy: 0.9322\n",
      "Epoch 2: accuracy improved from 0.93224 to 0.93227, saving model to output\\vgg.h5\n",
      "203/250 [=======================>......] - ETA: 29s - loss: 0.4064 - accuracy: 0.9323\n",
      "Epoch 2: accuracy did not improve from 0.93227\n",
      "204/250 [=======================>......] - ETA: 28s - loss: 0.4079 - accuracy: 0.9321\n",
      "Epoch 2: accuracy did not improve from 0.93227\n",
      "205/250 [=======================>......] - ETA: 27s - loss: 0.4075 - accuracy: 0.9322\n",
      "Epoch 2: accuracy did not improve from 0.93227\n",
      "206/250 [=======================>......] - ETA: 27s - loss: 0.4066 - accuracy: 0.9322\n",
      "Epoch 2: accuracy did not improve from 0.93227\n",
      "207/250 [=======================>......] - ETA: 26s - loss: 0.4071 - accuracy: 0.9319\n",
      "Epoch 2: accuracy did not improve from 0.93227\n",
      "208/250 [=======================>......] - ETA: 25s - loss: 0.4068 - accuracy: 0.9321\n",
      "Epoch 2: accuracy improved from 0.93227 to 0.93242, saving model to output\\vgg.h5\n",
      "209/250 [========================>.....] - ETA: 25s - loss: 0.4049 - accuracy: 0.9324\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "210/250 [========================>.....] - ETA: 24s - loss: 0.4071 - accuracy: 0.9321\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "211/250 [========================>.....] - ETA: 24s - loss: 0.4060 - accuracy: 0.9322\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "212/250 [========================>.....] - ETA: 23s - loss: 0.4055 - accuracy: 0.9320\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "213/250 [========================>.....] - ETA: 22s - loss: 0.4036 - accuracy: 0.9324\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "214/250 [========================>.....] - ETA: 22s - loss: 0.4048 - accuracy: 0.9321\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "215/250 [========================>.....] - ETA: 21s - loss: 0.4036 - accuracy: 0.9323\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "216/250 [========================>.....] - ETA: 20s - loss: 0.4023 - accuracy: 0.9323\n",
      "Epoch 2: accuracy did not improve from 0.93242\n",
      "217/250 [=========================>....] - ETA: 20s - loss: 0.4011 - accuracy: 0.9323\n",
      "Epoch 2: accuracy improved from 0.93242 to 0.93263, saving model to output\\vgg.h5\n",
      "218/250 [=========================>....] - ETA: 19s - loss: 0.3995 - accuracy: 0.9326\n",
      "Epoch 2: accuracy improved from 0.93263 to 0.93293, saving model to output\\vgg.h5\n",
      "219/250 [=========================>....] - ETA: 19s - loss: 0.3977 - accuracy: 0.9329\n",
      "Epoch 2: accuracy improved from 0.93293 to 0.93295, saving model to output\\vgg.h5\n",
      "220/250 [=========================>....] - ETA: 18s - loss: 0.3963 - accuracy: 0.9330\n",
      "Epoch 2: accuracy improved from 0.93295 to 0.93326, saving model to output\\vgg.h5\n",
      "221/250 [=========================>....] - ETA: 18s - loss: 0.3945 - accuracy: 0.9333\n",
      "Epoch 2: accuracy did not improve from 0.93326\n",
      "222/250 [=========================>....] - ETA: 17s - loss: 0.3949 - accuracy: 0.9330\n",
      "Epoch 2: accuracy did not improve from 0.93326\n",
      "223/250 [=========================>....] - ETA: 16s - loss: 0.3942 - accuracy: 0.9330\n",
      "Epoch 2: accuracy did not improve from 0.93326\n",
      "224/250 [=========================>....] - ETA: 16s - loss: 0.3933 - accuracy: 0.9332\n",
      "Epoch 2: accuracy did not improve from 0.93326\n",
      "225/250 [==========================>...] - ETA: 15s - loss: 0.3930 - accuracy: 0.9332\n",
      "Epoch 2: accuracy improved from 0.93326 to 0.93331, saving model to output\\vgg.h5\n",
      "226/250 [==========================>...] - ETA: 15s - loss: 0.3923 - accuracy: 0.9333\n",
      "Epoch 2: accuracy improved from 0.93331 to 0.93346, saving model to output\\vgg.h5\n",
      "227/250 [==========================>...] - ETA: 14s - loss: 0.3913 - accuracy: 0.9335\n",
      "Epoch 2: accuracy improved from 0.93346 to 0.93375, saving model to output\\vgg.h5\n",
      "228/250 [==========================>...] - ETA: 14s - loss: 0.3897 - accuracy: 0.9338\n",
      "Epoch 2: accuracy improved from 0.93375 to 0.93391, saving model to output\\vgg.h5\n",
      "229/250 [==========================>...] - ETA: 13s - loss: 0.3882 - accuracy: 0.9339\n",
      "Epoch 2: accuracy did not improve from 0.93391\n",
      "230/250 [==========================>...] - ETA: 12s - loss: 0.3881 - accuracy: 0.9338\n",
      "Epoch 2: accuracy did not improve from 0.93391\n",
      "231/250 [==========================>...] - ETA: 12s - loss: 0.3868 - accuracy: 0.9338\n",
      "Epoch 2: accuracy did not improve from 0.93391\n",
      "232/250 [==========================>...] - ETA: 11s - loss: 0.3872 - accuracy: 0.9335\n",
      "Epoch 2: accuracy did not improve from 0.93391\n",
      "233/250 [==========================>...] - ETA: 10s - loss: 0.3863 - accuracy: 0.9337\n",
      "Epoch 2: accuracy did not improve from 0.93391\n",
      "234/250 [===========================>..] - ETA: 10s - loss: 0.3859 - accuracy: 0.9337\n",
      "Epoch 2: accuracy improved from 0.93391 to 0.93400, saving model to output\\vgg.h5\n",
      "235/250 [===========================>..] - ETA: 9s - loss: 0.3843 - accuracy: 0.9340 \n",
      "Epoch 2: accuracy improved from 0.93400 to 0.93428, saving model to output\\vgg.h5\n",
      "236/250 [===========================>..] - ETA: 9s - loss: 0.3827 - accuracy: 0.9343\n",
      "Epoch 2: accuracy did not improve from 0.93428\n",
      "237/250 [===========================>..] - ETA: 8s - loss: 0.3839 - accuracy: 0.9342\n",
      "Epoch 2: accuracy did not improve from 0.93428\n",
      "238/250 [===========================>..] - ETA: 7s - loss: 0.3855 - accuracy: 0.9339\n",
      "Epoch 2: accuracy did not improve from 0.93428\n",
      "239/250 [===========================>..] - ETA: 7s - loss: 0.3843 - accuracy: 0.9341\n",
      "Epoch 2: accuracy did not improve from 0.93428\n",
      "240/250 [===========================>..] - ETA: 6s - loss: 0.3833 - accuracy: 0.9342\n",
      "Epoch 2: accuracy improved from 0.93428 to 0.93448, saving model to output\\vgg.h5\n",
      "241/250 [===========================>..] - ETA: 5s - loss: 0.3817 - accuracy: 0.9345\n",
      "Epoch 2: accuracy did not improve from 0.93448\n",
      "242/250 [============================>.] - ETA: 5s - loss: 0.3821 - accuracy: 0.9342\n",
      "Epoch 2: accuracy improved from 0.93448 to 0.93450, saving model to output\\vgg.h5\n",
      "243/250 [============================>.] - ETA: 4s - loss: 0.3805 - accuracy: 0.9345\n",
      "Epoch 2: accuracy improved from 0.93450 to 0.93464, saving model to output\\vgg.h5\n",
      "244/250 [============================>.] - ETA: 3s - loss: 0.3793 - accuracy: 0.9346\n",
      "Epoch 2: accuracy improved from 0.93464 to 0.93478, saving model to output\\vgg.h5\n",
      "245/250 [============================>.] - ETA: 3s - loss: 0.3786 - accuracy: 0.9348\n",
      "Epoch 2: accuracy improved from 0.93478 to 0.93479, saving model to output\\vgg.h5\n",
      "246/250 [============================>.] - ETA: 2s - loss: 0.3808 - accuracy: 0.9348\n",
      "Epoch 2: accuracy did not improve from 0.93479\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.3814 - accuracy: 0.9347\n",
      "Epoch 2: accuracy improved from 0.93479 to 0.93482, saving model to output\\vgg.h5\n",
      "248/250 [============================>.] - ETA: 1s - loss: 0.3801 - accuracy: 0.9348\n",
      "Epoch 2: accuracy improved from 0.93482 to 0.93508, saving model to output\\vgg.h5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.9351\n",
      "Epoch 2: accuracy improved from 0.93508 to 0.93521, saving model to output\\vgg.h5\n",
      "250/250 [==============================] - 186s 738ms/step - loss: 0.3772 - accuracy: 0.9352 - val_loss: 0.1511 - val_accuracy: 0.9677\n",
      "Epoch 3/15\n",
      "\n",
      "Epoch 3: accuracy did not improve from 0.93521\n",
      "  1/250 [..............................] - ETA: 1:55 - loss: 0.2789 - accuracy: 0.9062\n",
      "Epoch 3: accuracy did not improve from 0.93521\n",
      "  2/250 [..............................] - ETA: 1:07 - loss: 0.3100 - accuracy: 0.9062\n",
      "Epoch 3: accuracy did not improve from 0.93521\n",
      "  3/250 [..............................] - ETA: 1:07 - loss: 0.2921 - accuracy: 0.9167\n",
      "Epoch 3: accuracy did not improve from 0.93521\n",
      "  4/250 [..............................] - ETA: 1:06 - loss: 0.2298 - accuracy: 0.9297\n",
      "Epoch 3: accuracy improved from 0.93521 to 0.93750, saving model to output\\vgg.h5\n",
      "  5/250 [..............................] - ETA: 2:35 - loss: 0.2509 - accuracy: 0.9375\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      "  6/250 [..............................] - ETA: 2:12 - loss: 0.2473 - accuracy: 0.9323\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      "  7/250 [..............................] - ETA: 2:00 - loss: 0.2438 - accuracy: 0.9286\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      "  8/250 [..............................] - ETA: 1:52 - loss: 0.2469 - accuracy: 0.9297\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      "  9/250 [>.............................] - ETA: 1:46 - loss: 0.2405 - accuracy: 0.9306\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      " 10/250 [>.............................] - ETA: 1:41 - loss: 0.2254 - accuracy: 0.9344\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      " 11/250 [>.............................] - ETA: 1:37 - loss: 0.2565 - accuracy: 0.9347\n",
      "Epoch 3: accuracy did not improve from 0.93750\n",
      " 12/250 [>.............................] - ETA: 1:34 - loss: 0.2410 - accuracy: 0.9375\n",
      "Epoch 3: accuracy improved from 0.93750 to 0.93990, saving model to output\\vgg.h5\n",
      " 13/250 [>.............................] - ETA: 2:01 - loss: 0.2401 - accuracy: 0.9399\n",
      "Epoch 3: accuracy improved from 0.93990 to 0.94196, saving model to output\\vgg.h5\n",
      " 14/250 [>.............................] - ETA: 2:18 - loss: 0.2307 - accuracy: 0.9420\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 15/250 [>.............................] - ETA: 2:10 - loss: 0.2286 - accuracy: 0.9417\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 16/250 [>.............................] - ETA: 2:05 - loss: 0.2379 - accuracy: 0.9395\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 17/250 [=>............................] - ETA: 2:00 - loss: 0.2352 - accuracy: 0.9393\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 18/250 [=>............................] - ETA: 1:56 - loss: 0.2502 - accuracy: 0.9375\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 19/250 [=>............................] - ETA: 1:52 - loss: 0.2566 - accuracy: 0.9359\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 20/250 [=>............................] - ETA: 1:49 - loss: 0.2647 - accuracy: 0.9359\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 21/250 [=>............................] - ETA: 1:46 - loss: 0.2632 - accuracy: 0.9360\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 22/250 [=>............................] - ETA: 1:43 - loss: 0.2639 - accuracy: 0.9375\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 23/250 [=>............................] - ETA: 1:39 - loss: 0.2595 - accuracy: 0.9385\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 24/250 [=>............................] - ETA: 1:38 - loss: 0.2534 - accuracy: 0.9398\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 25/250 [==>...........................] - ETA: 1:36 - loss: 0.2482 - accuracy: 0.9397\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 26/250 [==>...........................] - ETA: 1:34 - loss: 0.2787 - accuracy: 0.9372\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 27/250 [==>...........................] - ETA: 1:32 - loss: 0.2751 - accuracy: 0.9372\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 28/250 [==>...........................] - ETA: 1:31 - loss: 0.2651 - accuracy: 0.9395\n",
      "Epoch 3: accuracy did not improve from 0.94196\n",
      " 29/250 [==>...........................] - ETA: 1:29 - loss: 0.2558 - accuracy: 0.9416\n",
      "Epoch 3: accuracy improved from 0.94196 to 0.94362, saving model to output\\vgg.h5\n",
      " 30/250 [==>...........................] - ETA: 1:39 - loss: 0.2471 - accuracy: 0.9436\n",
      "Epoch 3: accuracy did not improve from 0.94362\n",
      " 31/250 [==>...........................] - ETA: 1:36 - loss: 0.2465 - accuracy: 0.9434\n",
      "Epoch 3: accuracy improved from 0.94362 to 0.94522, saving model to output\\vgg.h5\n",
      " 32/250 [==>...........................] - ETA: 1:47 - loss: 0.2388 - accuracy: 0.9452\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 33/250 [==>...........................] - ETA: 1:44 - loss: 0.2351 - accuracy: 0.9450\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 34/250 [===>..........................] - ETA: 1:42 - loss: 0.2380 - accuracy: 0.9429\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 35/250 [===>..........................] - ETA: 1:40 - loss: 0.2311 - accuracy: 0.9445\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 36/250 [===>..........................] - ETA: 1:39 - loss: 0.2318 - accuracy: 0.9443\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 37/250 [===>..........................] - ETA: 1:37 - loss: 0.2416 - accuracy: 0.9416\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 38/250 [===>..........................] - ETA: 1:36 - loss: 0.2463 - accuracy: 0.9406\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 39/250 [===>..........................] - ETA: 1:34 - loss: 0.2422 - accuracy: 0.9414\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 40/250 [===>..........................] - ETA: 1:32 - loss: 0.2379 - accuracy: 0.9421\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 41/250 [===>..........................] - ETA: 1:31 - loss: 0.2460 - accuracy: 0.9404\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 42/250 [====>.........................] - ETA: 1:30 - loss: 0.2485 - accuracy: 0.9403\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 43/250 [====>.........................] - ETA: 1:29 - loss: 0.2532 - accuracy: 0.9395\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 44/250 [====>.........................] - ETA: 1:27 - loss: 0.2474 - accuracy: 0.9409\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 45/250 [====>.........................] - ETA: 1:26 - loss: 0.2442 - accuracy: 0.9415\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 46/250 [====>.........................] - ETA: 1:25 - loss: 0.2395 - accuracy: 0.9428\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 47/250 [====>.........................] - ETA: 1:24 - loss: 0.2462 - accuracy: 0.9414\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 48/250 [====>.........................] - ETA: 1:23 - loss: 0.2432 - accuracy: 0.9420\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 49/250 [====>.........................] - ETA: 1:22 - loss: 0.2430 - accuracy: 0.9425\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 50/250 [=====>........................] - ETA: 1:20 - loss: 0.2401 - accuracy: 0.9430\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 51/250 [=====>........................] - ETA: 1:19 - loss: 0.2405 - accuracy: 0.9429\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 52/250 [=====>........................] - ETA: 1:19 - loss: 0.2359 - accuracy: 0.9440\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 53/250 [=====>........................] - ETA: 1:18 - loss: 0.2479 - accuracy: 0.9439\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 54/250 [=====>........................] - ETA: 1:17 - loss: 0.2440 - accuracy: 0.9444\n",
      "Epoch 3: accuracy did not improve from 0.94522\n",
      " 55/250 [=====>........................] - ETA: 1:16 - loss: 0.2405 - accuracy: 0.9448\n",
      "Epoch 3: accuracy improved from 0.94522 to 0.94582, saving model to output\\vgg.h5\n",
      " 56/250 [=====>........................] - ETA: 1:19 - loss: 0.2369 - accuracy: 0.9458\n",
      "Epoch 3: accuracy did not improve from 0.94582\n",
      " 57/250 [=====>........................] - ETA: 1:18 - loss: 0.2376 - accuracy: 0.9451\n",
      "Epoch 3: accuracy did not improve from 0.94582\n",
      " 58/250 [=====>........................] - ETA: 1:17 - loss: 0.2358 - accuracy: 0.9450\n",
      "Epoch 3: accuracy did not improve from 0.94582\n",
      " 59/250 [======>.......................] - ETA: 1:16 - loss: 0.2466 - accuracy: 0.9443\n",
      "Epoch 3: accuracy did not improve from 0.94582\n",
      " 60/250 [======>.......................] - ETA: 1:16 - loss: 0.2427 - accuracy: 0.9453\n",
      "Epoch 3: accuracy improved from 0.94582 to 0.94617, saving model to output\\vgg.h5\n",
      " 61/250 [======>.......................] - ETA: 1:20 - loss: 0.2389 - accuracy: 0.9462\n",
      "Epoch 3: accuracy improved from 0.94617 to 0.94654, saving model to output\\vgg.h5\n",
      " 62/250 [======>.......................] - ETA: 1:23 - loss: 0.2378 - accuracy: 0.9465\n",
      "Epoch 3: accuracy improved from 0.94654 to 0.94739, saving model to output\\vgg.h5\n",
      " 63/250 [======>.......................] - ETA: 1:26 - loss: 0.2341 - accuracy: 0.9474\n",
      "Epoch 3: accuracy improved from 0.94739 to 0.94773, saving model to output\\vgg.h5\n",
      " 64/250 [======>.......................] - ETA: 1:29 - loss: 0.2336 - accuracy: 0.9477\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 65/250 [======>.......................] - ETA: 1:28 - loss: 0.2489 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 66/250 [======>.......................] - ETA: 1:27 - loss: 0.2457 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 67/250 [=======>......................] - ETA: 1:26 - loss: 0.2485 - accuracy: 0.9473\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 68/250 [=======>......................] - ETA: 1:25 - loss: 0.2587 - accuracy: 0.9462\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 69/250 [=======>......................] - ETA: 1:24 - loss: 0.2583 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 70/250 [=======>......................] - ETA: 1:23 - loss: 0.2547 - accuracy: 0.9473\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 71/250 [=======>......................] - ETA: 1:22 - loss: 0.2630 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 72/250 [=======>......................] - ETA: 1:21 - loss: 0.2594 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 73/250 [=======>......................] - ETA: 1:20 - loss: 0.2565 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 74/250 [=======>......................] - ETA: 1:19 - loss: 0.2570 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 75/250 [========>.....................] - ETA: 1:18 - loss: 0.2556 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 76/250 [========>.....................] - ETA: 1:17 - loss: 0.2561 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 77/250 [========>.....................] - ETA: 1:16 - loss: 0.2537 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 78/250 [========>.....................] - ETA: 1:15 - loss: 0.2555 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 79/250 [========>.....................] - ETA: 1:14 - loss: 0.2536 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 80/250 [========>.....................] - ETA: 1:14 - loss: 0.2573 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 81/250 [========>.....................] - ETA: 1:13 - loss: 0.2556 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 82/250 [========>.....................] - ETA: 1:12 - loss: 0.2631 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 83/250 [========>.....................] - ETA: 1:11 - loss: 0.2617 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 84/250 [=========>....................] - ETA: 1:11 - loss: 0.2597 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 85/250 [=========>....................] - ETA: 1:10 - loss: 0.2568 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 86/250 [=========>....................] - ETA: 1:09 - loss: 0.2553 - accuracy: 0.9473\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 87/250 [=========>....................] - ETA: 1:08 - loss: 0.2611 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 88/250 [=========>....................] - ETA: 1:08 - loss: 0.2622 - accuracy: 0.9460\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 89/250 [=========>....................] - ETA: 1:07 - loss: 0.2593 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 90/250 [=========>....................] - ETA: 1:06 - loss: 0.2595 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 91/250 [=========>....................] - ETA: 1:06 - loss: 0.2591 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 92/250 [==========>...................] - ETA: 1:05 - loss: 0.2596 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 93/250 [==========>...................] - ETA: 1:04 - loss: 0.2583 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 94/250 [==========>...................] - ETA: 1:04 - loss: 0.2572 - accuracy: 0.9465\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 95/250 [==========>...................] - ETA: 1:03 - loss: 0.2560 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 96/250 [==========>...................] - ETA: 1:02 - loss: 0.2545 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 97/250 [==========>...................] - ETA: 1:02 - loss: 0.2519 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 98/250 [==========>...................] - ETA: 1:01 - loss: 0.2515 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      " 99/250 [==========>...................] - ETA: 1:00 - loss: 0.2490 - accuracy: 0.9476\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "100/250 [===========>..................] - ETA: 1:00 - loss: 0.2504 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "101/250 [===========>..................] - ETA: 59s - loss: 0.2494 - accuracy: 0.9474 \n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "102/250 [===========>..................] - ETA: 59s - loss: 0.2546 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "103/250 [===========>..................] - ETA: 58s - loss: 0.2566 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "104/250 [===========>..................] - ETA: 57s - loss: 0.2550 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "105/250 [===========>..................] - ETA: 57s - loss: 0.2529 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "106/250 [===========>..................] - ETA: 56s - loss: 0.2568 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "107/250 [===========>..................] - ETA: 56s - loss: 0.2544 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "108/250 [===========>..................] - ETA: 55s - loss: 0.2554 - accuracy: 0.9476\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "109/250 [============>.................] - ETA: 54s - loss: 0.2562 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "110/250 [============>.................] - ETA: 54s - loss: 0.2552 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "111/250 [============>.................] - ETA: 53s - loss: 0.2535 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "112/250 [============>.................] - ETA: 53s - loss: 0.2517 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "113/250 [============>.................] - ETA: 52s - loss: 0.2497 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "114/250 [============>.................] - ETA: 52s - loss: 0.2487 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "115/250 [============>.................] - ETA: 51s - loss: 0.2479 - accuracy: 0.9475\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "116/250 [============>.................] - ETA: 51s - loss: 0.2478 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "117/250 [=============>................] - ETA: 50s - loss: 0.2481 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "118/250 [=============>................] - ETA: 50s - loss: 0.2468 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "119/250 [=============>................] - ETA: 49s - loss: 0.2457 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "120/250 [=============>................] - ETA: 49s - loss: 0.2448 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "121/250 [=============>................] - ETA: 48s - loss: 0.2428 - accuracy: 0.9473\n",
      "Epoch 3: accuracy improved from 0.94773 to 0.94773, saving model to output\\vgg.h5\n",
      "122/250 [=============>................] - ETA: 49s - loss: 0.2411 - accuracy: 0.9477\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "123/250 [=============>................] - ETA: 49s - loss: 0.2422 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94773\n",
      "124/250 [=============>................] - ETA: 48s - loss: 0.2405 - accuracy: 0.9476\n",
      "Epoch 3: accuracy improved from 0.94773 to 0.94774, saving model to output\\vgg.h5\n",
      "125/250 [==============>...............] - ETA: 49s - loss: 0.2390 - accuracy: 0.9477\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "126/250 [==============>...............] - ETA: 49s - loss: 0.2426 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "127/250 [==============>...............] - ETA: 48s - loss: 0.2485 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "128/250 [==============>...............] - ETA: 48s - loss: 0.2493 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "129/250 [==============>...............] - ETA: 47s - loss: 0.2486 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "130/250 [==============>...............] - ETA: 47s - loss: 0.2520 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "131/250 [==============>...............] - ETA: 46s - loss: 0.2545 - accuracy: 0.9461\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "132/250 [==============>...............] - ETA: 46s - loss: 0.2541 - accuracy: 0.9462\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "133/250 [==============>...............] - ETA: 45s - loss: 0.2576 - accuracy: 0.9459\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "134/250 [===============>..............] - ETA: 45s - loss: 0.2557 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "135/250 [===============>..............] - ETA: 44s - loss: 0.2572 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "136/250 [===============>..............] - ETA: 44s - loss: 0.2553 - accuracy: 0.9467\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "137/250 [===============>..............] - ETA: 43s - loss: 0.2588 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "138/250 [===============>..............] - ETA: 43s - loss: 0.2591 - accuracy: 0.9461\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "139/250 [===============>..............] - ETA: 42s - loss: 0.2579 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "140/250 [===============>..............] - ETA: 42s - loss: 0.2575 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "141/250 [===============>..............] - ETA: 41s - loss: 0.2579 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "142/250 [================>.............] - ETA: 41s - loss: 0.2589 - accuracy: 0.9463\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "143/250 [================>.............] - ETA: 40s - loss: 0.2593 - accuracy: 0.9464\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "144/250 [================>.............] - ETA: 40s - loss: 0.2578 - accuracy: 0.9466\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "145/250 [================>.............] - ETA: 39s - loss: 0.2569 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "146/250 [================>.............] - ETA: 39s - loss: 0.2553 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "147/250 [================>.............] - ETA: 38s - loss: 0.2561 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "148/250 [================>.............] - ETA: 38s - loss: 0.2547 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "149/250 [================>.............] - ETA: 38s - loss: 0.2537 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "150/250 [=================>............] - ETA: 37s - loss: 0.2531 - accuracy: 0.9469\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "151/250 [=================>............] - ETA: 37s - loss: 0.2515 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "152/250 [=================>............] - ETA: 36s - loss: 0.2501 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "153/250 [=================>............] - ETA: 36s - loss: 0.2523 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "154/250 [=================>............] - ETA: 35s - loss: 0.2519 - accuracy: 0.9470\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "155/250 [=================>............] - ETA: 35s - loss: 0.2528 - accuracy: 0.9468\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "156/250 [=================>............] - ETA: 34s - loss: 0.2514 - accuracy: 0.9471\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "157/250 [=================>............] - ETA: 34s - loss: 0.2504 - accuracy: 0.9472\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "158/250 [=================>............] - ETA: 34s - loss: 0.2497 - accuracy: 0.9474\n",
      "Epoch 3: accuracy did not improve from 0.94774\n",
      "159/250 [==================>...........] - ETA: 33s - loss: 0.2481 - accuracy: 0.9477\n",
      "Epoch 3: accuracy improved from 0.94774 to 0.94784, saving model to output\\vgg.h5\n",
      "160/250 [==================>...........] - ETA: 34s - loss: 0.2482 - accuracy: 0.9478\n",
      "Epoch 3: accuracy improved from 0.94784 to 0.94817, saving model to output\\vgg.h5\n",
      "161/250 [==================>...........] - ETA: 34s - loss: 0.2469 - accuracy: 0.9482\n",
      "Epoch 3: accuracy improved from 0.94817 to 0.94830, saving model to output\\vgg.h5\n",
      "162/250 [==================>...........] - ETA: 34s - loss: 0.2458 - accuracy: 0.9483\n",
      "Epoch 3: accuracy improved from 0.94830 to 0.94842, saving model to output\\vgg.h5\n",
      "163/250 [==================>...........] - ETA: 34s - loss: 0.2451 - accuracy: 0.9484\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "164/250 [==================>...........] - ETA: 34s - loss: 0.2447 - accuracy: 0.9484\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "165/250 [==================>...........] - ETA: 33s - loss: 0.2449 - accuracy: 0.9481\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "166/250 [==================>...........] - ETA: 33s - loss: 0.2448 - accuracy: 0.9480\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "167/250 [===================>..........] - ETA: 33s - loss: 0.2449 - accuracy: 0.9480\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "168/250 [===================>..........] - ETA: 32s - loss: 0.2448 - accuracy: 0.9479\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "169/250 [===================>..........] - ETA: 32s - loss: 0.2440 - accuracy: 0.9480\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "170/250 [===================>..........] - ETA: 31s - loss: 0.2429 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "171/250 [===================>..........] - ETA: 31s - loss: 0.2437 - accuracy: 0.9481\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "172/250 [===================>..........] - ETA: 30s - loss: 0.2437 - accuracy: 0.9478\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "173/250 [===================>..........] - ETA: 30s - loss: 0.2425 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "174/250 [===================>..........] - ETA: 29s - loss: 0.2421 - accuracy: 0.9481\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "175/250 [====================>.........] - ETA: 29s - loss: 0.2412 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "176/250 [====================>.........] - ETA: 28s - loss: 0.2411 - accuracy: 0.9480\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "177/250 [====================>.........] - ETA: 28s - loss: 0.2400 - accuracy: 0.9481\n",
      "Epoch 3: accuracy did not improve from 0.94842\n",
      "178/250 [====================>.........] - ETA: 28s - loss: 0.2387 - accuracy: 0.9484\n",
      "Epoch 3: accuracy improved from 0.94842 to 0.94867, saving model to output\\vgg.h5\n",
      "179/250 [====================>.........] - ETA: 28s - loss: 0.2374 - accuracy: 0.9487\n",
      "Epoch 3: accuracy improved from 0.94867 to 0.94878, saving model to output\\vgg.h5\n",
      "180/250 [====================>.........] - ETA: 28s - loss: 0.2367 - accuracy: 0.9488\n",
      "Epoch 3: accuracy improved from 0.94878 to 0.94889, saving model to output\\vgg.h5\n",
      "181/250 [====================>.........] - ETA: 28s - loss: 0.2365 - accuracy: 0.9489\n",
      "Epoch 3: accuracy improved from 0.94889 to 0.94900, saving model to output\\vgg.h5\n",
      "182/250 [====================>.........] - ETA: 28s - loss: 0.2357 - accuracy: 0.9490\n",
      "Epoch 3: accuracy improved from 0.94900 to 0.94911, saving model to output\\vgg.h5\n",
      "183/250 [====================>.........] - ETA: 28s - loss: 0.2346 - accuracy: 0.9491\n",
      "Epoch 3: accuracy improved from 0.94911 to 0.94922, saving model to output\\vgg.h5\n",
      "184/250 [=====================>........] - ETA: 28s - loss: 0.2337 - accuracy: 0.9492\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "185/250 [=====================>........] - ETA: 27s - loss: 0.2363 - accuracy: 0.9490\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "186/250 [=====================>........] - ETA: 27s - loss: 0.2373 - accuracy: 0.9488\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "187/250 [=====================>........] - ETA: 27s - loss: 0.2372 - accuracy: 0.9487\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "188/250 [=====================>........] - ETA: 26s - loss: 0.2373 - accuracy: 0.9486\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "189/250 [=====================>........] - ETA: 26s - loss: 0.2391 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "190/250 [=====================>........] - ETA: 25s - loss: 0.2407 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "191/250 [=====================>........] - ETA: 25s - loss: 0.2409 - accuracy: 0.9483\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "192/250 [======================>.......] - ETA: 24s - loss: 0.2406 - accuracy: 0.9482\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "193/250 [======================>.......] - ETA: 24s - loss: 0.2408 - accuracy: 0.9483\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "194/250 [======================>.......] - ETA: 23s - loss: 0.2396 - accuracy: 0.9486\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "195/250 [======================>.......] - ETA: 23s - loss: 0.2401 - accuracy: 0.9484\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "196/250 [======================>.......] - ETA: 22s - loss: 0.2401 - accuracy: 0.9485\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "197/250 [======================>.......] - ETA: 22s - loss: 0.2394 - accuracy: 0.9486\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "198/250 [======================>.......] - ETA: 21s - loss: 0.2390 - accuracy: 0.9485\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "199/250 [======================>.......] - ETA: 21s - loss: 0.2385 - accuracy: 0.9486\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "200/250 [=======================>......] - ETA: 20s - loss: 0.2374 - accuracy: 0.9489\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "201/250 [=======================>......] - ETA: 20s - loss: 0.2366 - accuracy: 0.9488\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "202/250 [=======================>......] - ETA: 19s - loss: 0.2355 - accuracy: 0.9491\n",
      "Epoch 3: accuracy did not improve from 0.94922\n",
      "203/250 [=======================>......] - ETA: 19s - loss: 0.2350 - accuracy: 0.9490\n",
      "Epoch 3: accuracy improved from 0.94922 to 0.94929, saving model to output\\vgg.h5\n",
      "204/250 [=======================>......] - ETA: 19s - loss: 0.2339 - accuracy: 0.9493\n",
      "Epoch 3: accuracy improved from 0.94929 to 0.94939, saving model to output\\vgg.h5\n",
      "205/250 [=======================>......] - ETA: 19s - loss: 0.2337 - accuracy: 0.9494\n",
      "Epoch 3: accuracy improved from 0.94939 to 0.94948, saving model to output\\vgg.h5\n",
      "206/250 [=======================>......] - ETA: 19s - loss: 0.2333 - accuracy: 0.9495\n",
      "Epoch 3: accuracy improved from 0.94948 to 0.94973, saving model to output\\vgg.h5\n",
      "207/250 [=======================>......] - ETA: 19s - loss: 0.2322 - accuracy: 0.9497\n",
      "Epoch 3: accuracy did not improve from 0.94973\n",
      "208/250 [=======================>......] - ETA: 18s - loss: 0.2322 - accuracy: 0.9495\n",
      "Epoch 3: accuracy did not improve from 0.94973\n",
      "209/250 [========================>.....] - ETA: 18s - loss: 0.2322 - accuracy: 0.9496\n",
      "Epoch 3: accuracy improved from 0.94973 to 0.94985, saving model to output\\vgg.h5\n",
      "210/250 [========================>.....] - ETA: 17s - loss: 0.2312 - accuracy: 0.9499\n",
      "Epoch 3: accuracy improved from 0.94985 to 0.94994, saving model to output\\vgg.h5\n",
      "211/250 [========================>.....] - ETA: 17s - loss: 0.2303 - accuracy: 0.9499\n",
      "Epoch 3: accuracy improved from 0.94994 to 0.95018, saving model to output\\vgg.h5\n",
      "212/250 [========================>.....] - ETA: 17s - loss: 0.2292 - accuracy: 0.9502\n",
      "Epoch 3: accuracy improved from 0.95018 to 0.95026, saving model to output\\vgg.h5\n",
      "213/250 [========================>.....] - ETA: 17s - loss: 0.2292 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95026\n",
      "214/250 [========================>.....] - ETA: 16s - loss: 0.2289 - accuracy: 0.9502\n",
      "Epoch 3: accuracy improved from 0.95026 to 0.95029, saving model to output\\vgg.h5\n",
      "215/250 [========================>.....] - ETA: 16s - loss: 0.2280 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95029\n",
      "216/250 [========================>.....] - ETA: 15s - loss: 0.2278 - accuracy: 0.9502\n",
      "Epoch 3: accuracy did not improve from 0.95029\n",
      "217/250 [=========================>....] - ETA: 15s - loss: 0.2279 - accuracy: 0.9502\n",
      "Epoch 3: accuracy did not improve from 0.95029\n",
      "218/250 [=========================>....] - ETA: 14s - loss: 0.2273 - accuracy: 0.9503\n",
      "Epoch 3: accuracy improved from 0.95029 to 0.95034, saving model to output\\vgg.h5\n",
      "219/250 [=========================>....] - ETA: 14s - loss: 0.2267 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95034\n",
      "220/250 [=========================>....] - ETA: 14s - loss: 0.2273 - accuracy: 0.9503\n",
      "Epoch 3: accuracy improved from 0.95034 to 0.95037, saving model to output\\vgg.h5\n",
      "221/250 [=========================>....] - ETA: 13s - loss: 0.2280 - accuracy: 0.9504\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "222/250 [=========================>....] - ETA: 13s - loss: 0.2276 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "223/250 [=========================>....] - ETA: 12s - loss: 0.2284 - accuracy: 0.9501\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "224/250 [=========================>....] - ETA: 12s - loss: 0.2277 - accuracy: 0.9502\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "225/250 [==========================>...] - ETA: 11s - loss: 0.2279 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "226/250 [==========================>...] - ETA: 11s - loss: 0.2278 - accuracy: 0.9504\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "227/250 [==========================>...] - ETA: 10s - loss: 0.2294 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "228/250 [==========================>...] - ETA: 10s - loss: 0.2291 - accuracy: 0.9502\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "229/250 [==========================>...] - ETA: 9s - loss: 0.2284 - accuracy: 0.9503 \n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "230/250 [==========================>...] - ETA: 9s - loss: 0.2305 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "231/250 [==========================>...] - ETA: 8s - loss: 0.2301 - accuracy: 0.9504\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "232/250 [==========================>...] - ETA: 8s - loss: 0.2295 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "233/250 [==========================>...] - ETA: 7s - loss: 0.2315 - accuracy: 0.9498\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "234/250 [===========================>..] - ETA: 7s - loss: 0.2308 - accuracy: 0.9499\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "235/250 [===========================>..] - ETA: 6s - loss: 0.2308 - accuracy: 0.9497\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "236/250 [===========================>..] - ETA: 6s - loss: 0.2306 - accuracy: 0.9497\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "237/250 [===========================>..] - ETA: 6s - loss: 0.2303 - accuracy: 0.9498\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "238/250 [===========================>..] - ETA: 5s - loss: 0.2295 - accuracy: 0.9498\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "239/250 [===========================>..] - ETA: 5s - loss: 0.2287 - accuracy: 0.9501\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "240/250 [===========================>..] - ETA: 4s - loss: 0.2278 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "241/250 [===========================>..] - ETA: 4s - loss: 0.2275 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "242/250 [============================>.] - ETA: 3s - loss: 0.2272 - accuracy: 0.9503\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "243/250 [============================>.] - ETA: 3s - loss: 0.2271 - accuracy: 0.9502\n",
      "Epoch 3: accuracy did not improve from 0.95037\n",
      "244/250 [============================>.] - ETA: 2s - loss: 0.2266 - accuracy: 0.9502\n",
      "Epoch 3: accuracy improved from 0.95037 to 0.95038, saving model to output\\vgg.h5\n",
      "245/250 [============================>.] - ETA: 2s - loss: 0.2257 - accuracy: 0.9504\n",
      "Epoch 3: accuracy improved from 0.95038 to 0.95046, saving model to output\\vgg.h5\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.2250 - accuracy: 0.9505\n",
      "Epoch 3: accuracy improved from 0.95046 to 0.95066, saving model to output\\vgg.h5\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.2241 - accuracy: 0.9507\n",
      "Epoch 3: accuracy improved from 0.95066 to 0.95073, saving model to output\\vgg.h5\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9507\n",
      "Epoch 3: accuracy improved from 0.95073 to 0.95081, saving model to output\\vgg.h5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9508\n",
      "Epoch 3: accuracy improved from 0.95081 to 0.95088, saving model to output\\vgg.h5\n",
      "250/250 [==============================] - 139s 556ms/step - loss: 0.2227 - accuracy: 0.9509 - val_loss: 0.1402 - val_accuracy: 0.9662\n",
      "Epoch 4/15\n",
      "\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  1/250 [..............................] - ETA: 2:07 - loss: 0.4538 - accuracy: 0.9062\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  2/250 [..............................] - ETA: 1:06 - loss: 0.2946 - accuracy: 0.9219\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  3/250 [..............................] - ETA: 1:05 - loss: 0.2177 - accuracy: 0.9375\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  4/250 [..............................] - ETA: 1:05 - loss: 0.1993 - accuracy: 0.9375\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  5/250 [..............................] - ETA: 1:06 - loss: 0.2284 - accuracy: 0.9312\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  6/250 [..............................] - ETA: 1:06 - loss: 0.2137 - accuracy: 0.9271\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  7/250 [..............................] - ETA: 1:06 - loss: 0.1935 - accuracy: 0.9330\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  8/250 [..............................] - ETA: 1:05 - loss: 0.2059 - accuracy: 0.9336\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      "  9/250 [>.............................] - ETA: 1:05 - loss: 0.2072 - accuracy: 0.9375\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 10/250 [>.............................] - ETA: 1:04 - loss: 0.1972 - accuracy: 0.9375\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 11/250 [>.............................] - ETA: 1:04 - loss: 0.2262 - accuracy: 0.9318\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 12/250 [>.............................] - ETA: 1:04 - loss: 0.2411 - accuracy: 0.9323\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 13/250 [>.............................] - ETA: 1:04 - loss: 0.2374 - accuracy: 0.9351\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 14/250 [>.............................] - ETA: 1:04 - loss: 0.2222 - accuracy: 0.9397\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 15/250 [>.............................] - ETA: 1:03 - loss: 0.2139 - accuracy: 0.9417\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 16/250 [>.............................] - ETA: 1:03 - loss: 0.2231 - accuracy: 0.9434\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 17/250 [=>............................] - ETA: 1:03 - loss: 0.2176 - accuracy: 0.9430\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 18/250 [=>............................] - ETA: 1:02 - loss: 0.2058 - accuracy: 0.9462\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 19/250 [=>............................] - ETA: 1:02 - loss: 0.1972 - accuracy: 0.9474\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 20/250 [=>............................] - ETA: 1:02 - loss: 0.1894 - accuracy: 0.9484\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 21/250 [=>............................] - ETA: 1:02 - loss: 0.1869 - accuracy: 0.9494\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 22/250 [=>............................] - ETA: 1:01 - loss: 0.1923 - accuracy: 0.9489\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 23/250 [=>............................] - ETA: 1:01 - loss: 0.1922 - accuracy: 0.9484\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 24/250 [=>............................] - ETA: 1:01 - loss: 0.1987 - accuracy: 0.9479\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 25/250 [==>...........................] - ETA: 1:01 - loss: 0.1944 - accuracy: 0.9488\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 26/250 [==>...........................] - ETA: 1:01 - loss: 0.1872 - accuracy: 0.9507\n",
      "Epoch 4: accuracy did not improve from 0.95088\n",
      " 27/250 [==>...........................] - ETA: 1:00 - loss: 0.1861 - accuracy: 0.9502\n",
      "Epoch 4: accuracy improved from 0.95088 to 0.95201, saving model to output\\vgg.h5\n",
      " 28/250 [==>...........................] - ETA: 1:10 - loss: 0.1807 - accuracy: 0.9520\n",
      "Epoch 4: accuracy improved from 0.95201 to 0.95259, saving model to output\\vgg.h5\n",
      " 29/250 [==>...........................] - ETA: 1:21 - loss: 0.1783 - accuracy: 0.9526\n",
      "Epoch 4: accuracy improved from 0.95259 to 0.95417, saving model to output\\vgg.h5\n",
      " 30/250 [==>...........................] - ETA: 1:31 - loss: 0.1727 - accuracy: 0.9542\n",
      "Epoch 4: accuracy improved from 0.95417 to 0.95464, saving model to output\\vgg.h5\n",
      " 31/250 [==>...........................] - ETA: 1:39 - loss: 0.1702 - accuracy: 0.9546\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 32/250 [==>...........................] - ETA: 1:36 - loss: 0.1721 - accuracy: 0.9541\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 33/250 [==>...........................] - ETA: 1:35 - loss: 0.1734 - accuracy: 0.9545\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 34/250 [===>..........................] - ETA: 1:33 - loss: 0.1815 - accuracy: 0.9531\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 35/250 [===>..........................] - ETA: 1:32 - loss: 0.1860 - accuracy: 0.9518\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 36/250 [===>..........................] - ETA: 1:30 - loss: 0.1808 - accuracy: 0.9531\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 37/250 [===>..........................] - ETA: 1:29 - loss: 0.1890 - accuracy: 0.9527\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 38/250 [===>..........................] - ETA: 1:27 - loss: 0.1856 - accuracy: 0.9531\n",
      "Epoch 4: accuracy did not improve from 0.95464\n",
      " 39/250 [===>..........................] - ETA: 1:26 - loss: 0.1809 - accuracy: 0.9543\n",
      "Epoch 4: accuracy improved from 0.95464 to 0.95469, saving model to output\\vgg.h5\n",
      " 40/250 [===>..........................] - ETA: 1:32 - loss: 0.1775 - accuracy: 0.9547\n",
      "Epoch 4: accuracy improved from 0.95469 to 0.95503, saving model to output\\vgg.h5\n",
      " 41/250 [===>..........................] - ETA: 1:39 - loss: 0.1783 - accuracy: 0.9550\n",
      "Epoch 4: accuracy improved from 0.95503 to 0.95610, saving model to output\\vgg.h5\n",
      " 42/250 [====>.........................] - ETA: 1:44 - loss: 0.1746 - accuracy: 0.9561\n",
      "Epoch 4: accuracy improved from 0.95610 to 0.95712, saving model to output\\vgg.h5\n",
      " 43/250 [====>.........................] - ETA: 1:49 - loss: 0.1713 - accuracy: 0.9571\n",
      "Epoch 4: accuracy improved from 0.95712 to 0.95810, saving model to output\\vgg.h5\n",
      " 44/250 [====>.........................] - ETA: 1:55 - loss: 0.1675 - accuracy: 0.9581\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 45/250 [====>.........................] - ETA: 1:53 - loss: 0.1665 - accuracy: 0.9576\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 46/250 [====>.........................] - ETA: 1:51 - loss: 0.1649 - accuracy: 0.9579\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 47/250 [====>.........................] - ETA: 1:49 - loss: 0.1651 - accuracy: 0.9574\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 48/250 [====>.........................] - ETA: 1:47 - loss: 0.1691 - accuracy: 0.9564\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 49/250 [====>.........................] - ETA: 1:45 - loss: 0.1672 - accuracy: 0.9566\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 50/250 [=====>........................] - ETA: 1:44 - loss: 0.1649 - accuracy: 0.9569\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 51/250 [=====>........................] - ETA: 1:42 - loss: 0.1656 - accuracy: 0.9571\n",
      "Epoch 4: accuracy did not improve from 0.95810\n",
      " 52/250 [=====>........................] - ETA: 1:41 - loss: 0.1631 - accuracy: 0.9579\n",
      "Epoch 4: accuracy improved from 0.95810 to 0.95873, saving model to output\\vgg.h5\n",
      " 53/250 [=====>........................] - ETA: 1:46 - loss: 0.1602 - accuracy: 0.9587\n",
      "Epoch 4: accuracy improved from 0.95873 to 0.95891, saving model to output\\vgg.h5\n",
      " 54/250 [=====>........................] - ETA: 1:49 - loss: 0.1601 - accuracy: 0.9589\n",
      "Epoch 4: accuracy did not improve from 0.95891\n",
      " 55/250 [=====>........................] - ETA: 1:47 - loss: 0.1620 - accuracy: 0.9585\n",
      "Epoch 4: accuracy improved from 0.95891 to 0.95926, saving model to output\\vgg.h5\n",
      " 56/250 [=====>........................] - ETA: 1:51 - loss: 0.1592 - accuracy: 0.9593\n",
      "Epoch 4: accuracy did not improve from 0.95926\n",
      " 57/250 [=====>........................] - ETA: 1:49 - loss: 0.1607 - accuracy: 0.9589\n",
      "Epoch 4: accuracy did not improve from 0.95926\n",
      " 58/250 [=====>........................] - ETA: 1:47 - loss: 0.1591 - accuracy: 0.9591\n",
      "Epoch 4: accuracy improved from 0.95926 to 0.95975, saving model to output\\vgg.h5\n",
      " 59/250 [======>.......................] - ETA: 1:51 - loss: 0.1565 - accuracy: 0.9597\n",
      "Epoch 4: accuracy improved from 0.95975 to 0.95990, saving model to output\\vgg.h5\n",
      " 60/250 [======>.......................] - ETA: 1:54 - loss: 0.1561 - accuracy: 0.9599\n",
      "Epoch 4: accuracy improved from 0.95990 to 0.96055, saving model to output\\vgg.h5\n",
      " 61/250 [======>.......................] - ETA: 1:58 - loss: 0.1537 - accuracy: 0.9606\n",
      "Epoch 4: accuracy improved from 0.96055 to 0.96069, saving model to output\\vgg.h5\n",
      " 62/250 [======>.......................] - ETA: 2:02 - loss: 0.1518 - accuracy: 0.9607\n",
      "Epoch 4: accuracy did not improve from 0.96069\n",
      " 63/250 [======>.......................] - ETA: 2:00 - loss: 0.1552 - accuracy: 0.9603\n",
      "Epoch 4: accuracy did not improve from 0.96069\n",
      " 64/250 [======>.......................] - ETA: 1:58 - loss: 0.1541 - accuracy: 0.9604\n",
      "Epoch 4: accuracy improved from 0.96069 to 0.96106, saving model to output\\vgg.h5\n",
      " 65/250 [======>.......................] - ETA: 2:01 - loss: 0.1520 - accuracy: 0.9611\n",
      "Epoch 4: accuracy improved from 0.96106 to 0.96165, saving model to output\\vgg.h5\n",
      " 66/250 [======>.......................] - ETA: 2:05 - loss: 0.1497 - accuracy: 0.9616\n",
      "Epoch 4: accuracy improved from 0.96165 to 0.96222, saving model to output\\vgg.h5\n",
      " 67/250 [=======>......................] - ETA: 2:06 - loss: 0.1477 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96222\n",
      " 68/250 [=======>......................] - ETA: 2:04 - loss: 0.1538 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96222\n",
      " 69/250 [=======>......................] - ETA: 2:03 - loss: 0.1529 - accuracy: 0.9620\n",
      "Epoch 4: accuracy improved from 0.96222 to 0.96250, saving model to output\\vgg.h5\n",
      " 70/250 [=======>......................] - ETA: 2:05 - loss: 0.1509 - accuracy: 0.9625\n",
      "Epoch 4: accuracy improved from 0.96250 to 0.96303, saving model to output\\vgg.h5\n",
      " 71/250 [=======>......................] - ETA: 2:06 - loss: 0.1488 - accuracy: 0.9630\n",
      "Epoch 4: accuracy improved from 0.96303 to 0.96354, saving model to output\\vgg.h5\n",
      " 72/250 [=======>......................] - ETA: 2:07 - loss: 0.1468 - accuracy: 0.9635\n",
      "Epoch 4: accuracy improved from 0.96354 to 0.96404, saving model to output\\vgg.h5\n",
      " 73/250 [=======>......................] - ETA: 2:09 - loss: 0.1451 - accuracy: 0.9640\n",
      "Epoch 4: accuracy did not improve from 0.96404\n",
      " 74/250 [=======>......................] - ETA: 2:07 - loss: 0.1475 - accuracy: 0.9637\n",
      "Epoch 4: accuracy did not improve from 0.96404\n",
      " 75/250 [========>.....................] - ETA: 2:05 - loss: 0.1493 - accuracy: 0.9638\n",
      "Epoch 4: accuracy improved from 0.96404 to 0.96423, saving model to output\\vgg.h5\n",
      " 76/250 [========>.....................] - ETA: 2:07 - loss: 0.1473 - accuracy: 0.9642\n",
      "Epoch 4: accuracy improved from 0.96423 to 0.96429, saving model to output\\vgg.h5\n",
      " 77/250 [========>.....................] - ETA: 2:09 - loss: 0.1473 - accuracy: 0.9643\n",
      "Epoch 4: accuracy improved from 0.96429 to 0.96474, saving model to output\\vgg.h5\n",
      " 78/250 [========>.....................] - ETA: 2:11 - loss: 0.1454 - accuracy: 0.9647\n",
      "Epoch 4: accuracy improved from 0.96474 to 0.96479, saving model to output\\vgg.h5\n",
      " 79/250 [========>.....................] - ETA: 2:13 - loss: 0.1460 - accuracy: 0.9648\n",
      "Epoch 4: accuracy improved from 0.96479 to 0.96484, saving model to output\\vgg.h5\n",
      " 80/250 [========>.....................] - ETA: 2:15 - loss: 0.1446 - accuracy: 0.9648\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 81/250 [========>.....................] - ETA: 2:13 - loss: 0.1465 - accuracy: 0.9645\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 82/250 [========>.....................] - ETA: 2:11 - loss: 0.1515 - accuracy: 0.9642\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 83/250 [========>.....................] - ETA: 2:09 - loss: 0.1533 - accuracy: 0.9635\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 84/250 [=========>....................] - ETA: 2:07 - loss: 0.1590 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 85/250 [=========>....................] - ETA: 2:06 - loss: 0.1572 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 86/250 [=========>....................] - ETA: 2:04 - loss: 0.1564 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 87/250 [=========>....................] - ETA: 2:02 - loss: 0.1569 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 88/250 [=========>....................] - ETA: 2:00 - loss: 0.1551 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 89/250 [=========>....................] - ETA: 1:59 - loss: 0.1560 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 90/250 [=========>....................] - ETA: 1:57 - loss: 0.1543 - accuracy: 0.9635\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 91/250 [=========>....................] - ETA: 1:56 - loss: 0.1553 - accuracy: 0.9633\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 92/250 [==========>...................] - ETA: 1:54 - loss: 0.1561 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 93/250 [==========>...................] - ETA: 1:52 - loss: 0.1548 - accuracy: 0.9634\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 94/250 [==========>...................] - ETA: 1:51 - loss: 0.1572 - accuracy: 0.9634\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 95/250 [==========>...................] - ETA: 1:49 - loss: 0.1593 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 96/250 [==========>...................] - ETA: 1:48 - loss: 0.1577 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 97/250 [==========>...................] - ETA: 1:47 - loss: 0.1591 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 98/250 [==========>...................] - ETA: 1:45 - loss: 0.1606 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      " 99/250 [==========>...................] - ETA: 1:44 - loss: 0.1685 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "100/250 [===========>..................] - ETA: 1:43 - loss: 0.1671 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "101/250 [===========>..................] - ETA: 1:41 - loss: 0.1656 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "102/250 [===========>..................] - ETA: 1:40 - loss: 0.1675 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "103/250 [===========>..................] - ETA: 1:39 - loss: 0.1668 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "104/250 [===========>..................] - ETA: 1:37 - loss: 0.1699 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "105/250 [===========>..................] - ETA: 1:36 - loss: 0.1688 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "106/250 [===========>..................] - ETA: 1:35 - loss: 0.1687 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "107/250 [===========>..................] - ETA: 1:34 - loss: 0.1690 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "108/250 [===========>..................] - ETA: 1:32 - loss: 0.1737 - accuracy: 0.9618\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "109/250 [============>.................] - ETA: 1:31 - loss: 0.1739 - accuracy: 0.9610\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "110/250 [============>.................] - ETA: 1:30 - loss: 0.1725 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "111/250 [============>.................] - ETA: 1:29 - loss: 0.1712 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "112/250 [============>.................] - ETA: 1:28 - loss: 0.1702 - accuracy: 0.9618\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "113/250 [============>.................] - ETA: 1:27 - loss: 0.1699 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "114/250 [============>.................] - ETA: 1:26 - loss: 0.1697 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "115/250 [============>.................] - ETA: 1:25 - loss: 0.1694 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "116/250 [============>.................] - ETA: 1:24 - loss: 0.1682 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "117/250 [=============>................] - ETA: 1:23 - loss: 0.1676 - accuracy: 0.9618\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "118/250 [=============>................] - ETA: 1:22 - loss: 0.1684 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "119/250 [=============>................] - ETA: 1:21 - loss: 0.1672 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "120/250 [=============>................] - ETA: 1:20 - loss: 0.1664 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "121/250 [=============>................] - ETA: 1:19 - loss: 0.1679 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "122/250 [=============>................] - ETA: 1:18 - loss: 0.1666 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "123/250 [=============>................] - ETA: 1:17 - loss: 0.1686 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "124/250 [=============>................] - ETA: 1:16 - loss: 0.1679 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "125/250 [==============>...............] - ETA: 1:15 - loss: 0.1681 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "126/250 [==============>...............] - ETA: 1:14 - loss: 0.1695 - accuracy: 0.9611\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "127/250 [==============>...............] - ETA: 1:13 - loss: 0.1683 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "128/250 [==============>...............] - ETA: 1:12 - loss: 0.1697 - accuracy: 0.9609\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "129/250 [==============>...............] - ETA: 1:11 - loss: 0.1691 - accuracy: 0.9610\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "130/250 [==============>...............] - ETA: 1:10 - loss: 0.1678 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "131/250 [==============>...............] - ETA: 1:09 - loss: 0.1684 - accuracy: 0.9611\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "132/250 [==============>...............] - ETA: 1:08 - loss: 0.1673 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "133/250 [==============>...............] - ETA: 1:08 - loss: 0.1664 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "134/250 [===============>..............] - ETA: 1:07 - loss: 0.1655 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "135/250 [===============>..............] - ETA: 1:06 - loss: 0.1656 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "136/250 [===============>..............] - ETA: 1:05 - loss: 0.1644 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "137/250 [===============>..............] - ETA: 1:04 - loss: 0.1654 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "138/250 [===============>..............] - ETA: 1:03 - loss: 0.1674 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "139/250 [===============>..............] - ETA: 1:03 - loss: 0.1664 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "140/250 [===============>..............] - ETA: 1:02 - loss: 0.1653 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "141/250 [===============>..............] - ETA: 1:01 - loss: 0.1647 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "142/250 [================>.............] - ETA: 1:00 - loss: 0.1655 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "143/250 [================>.............] - ETA: 59s - loss: 0.1644 - accuracy: 0.9620 \n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "144/250 [================>.............] - ETA: 59s - loss: 0.1633 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "145/250 [================>.............] - ETA: 58s - loss: 0.1622 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "146/250 [================>.............] - ETA: 57s - loss: 0.1618 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "147/250 [================>.............] - ETA: 56s - loss: 0.1609 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "148/250 [================>.............] - ETA: 55s - loss: 0.1607 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "149/250 [================>.............] - ETA: 55s - loss: 0.1600 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "150/250 [=================>............] - ETA: 54s - loss: 0.1607 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "151/250 [=================>............] - ETA: 53s - loss: 0.1602 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "152/250 [=================>............] - ETA: 53s - loss: 0.1592 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "153/250 [=================>............] - ETA: 52s - loss: 0.1602 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "154/250 [=================>............] - ETA: 51s - loss: 0.1606 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "155/250 [=================>............] - ETA: 50s - loss: 0.1600 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "156/250 [=================>............] - ETA: 50s - loss: 0.1628 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "157/250 [=================>............] - ETA: 49s - loss: 0.1679 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "158/250 [=================>............] - ETA: 48s - loss: 0.1675 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "159/250 [==================>...........] - ETA: 48s - loss: 0.1676 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "160/250 [==================>...........] - ETA: 47s - loss: 0.1689 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "161/250 [==================>...........] - ETA: 46s - loss: 0.1679 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "162/250 [==================>...........] - ETA: 46s - loss: 0.1670 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "163/250 [==================>...........] - ETA: 45s - loss: 0.1669 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "164/250 [==================>...........] - ETA: 44s - loss: 0.1665 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "165/250 [==================>...........] - ETA: 44s - loss: 0.1660 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "166/250 [==================>...........] - ETA: 43s - loss: 0.1651 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "167/250 [===================>..........] - ETA: 42s - loss: 0.1642 - accuracy: 0.9628\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "168/250 [===================>..........] - ETA: 42s - loss: 0.1646 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "169/250 [===================>..........] - ETA: 41s - loss: 0.1648 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "170/250 [===================>..........] - ETA: 40s - loss: 0.1650 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "171/250 [===================>..........] - ETA: 40s - loss: 0.1660 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "172/250 [===================>..........] - ETA: 39s - loss: 0.1656 - accuracy: 0.9624\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "173/250 [===================>..........] - ETA: 39s - loss: 0.1662 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "174/250 [===================>..........] - ETA: 38s - loss: 0.1652 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "175/250 [====================>.........] - ETA: 37s - loss: 0.1656 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "176/250 [====================>.........] - ETA: 37s - loss: 0.1670 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "177/250 [====================>.........] - ETA: 36s - loss: 0.1666 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "178/250 [====================>.........] - ETA: 36s - loss: 0.1657 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "179/250 [====================>.........] - ETA: 35s - loss: 0.1648 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "180/250 [====================>.........] - ETA: 34s - loss: 0.1639 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "181/250 [====================>.........] - ETA: 34s - loss: 0.1648 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "182/250 [====================>.........] - ETA: 33s - loss: 0.1652 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "183/250 [====================>.........] - ETA: 33s - loss: 0.1651 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "184/250 [=====================>........] - ETA: 32s - loss: 0.1658 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "185/250 [=====================>........] - ETA: 31s - loss: 0.1660 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "186/250 [=====================>........] - ETA: 31s - loss: 0.1659 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "187/250 [=====================>........] - ETA: 30s - loss: 0.1654 - accuracy: 0.9614\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "188/250 [=====================>........] - ETA: 30s - loss: 0.1647 - accuracy: 0.9616\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "189/250 [=====================>........] - ETA: 29s - loss: 0.1654 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "190/250 [=====================>........] - ETA: 29s - loss: 0.1659 - accuracy: 0.9609\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "191/250 [=====================>........] - ETA: 28s - loss: 0.1651 - accuracy: 0.9611\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "192/250 [======================>.......] - ETA: 28s - loss: 0.1649 - accuracy: 0.9611\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "193/250 [======================>.......] - ETA: 27s - loss: 0.1649 - accuracy: 0.9610\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "194/250 [======================>.......] - ETA: 26s - loss: 0.1640 - accuracy: 0.9612\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "195/250 [======================>.......] - ETA: 26s - loss: 0.1637 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "196/250 [======================>.......] - ETA: 25s - loss: 0.1636 - accuracy: 0.9613\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "197/250 [======================>.......] - ETA: 25s - loss: 0.1628 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "198/250 [======================>.......] - ETA: 24s - loss: 0.1627 - accuracy: 0.9615\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "199/250 [======================>.......] - ETA: 24s - loss: 0.1619 - accuracy: 0.9617\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "200/250 [=======================>......] - ETA: 23s - loss: 0.1616 - accuracy: 0.9618\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "201/250 [=======================>......] - ETA: 23s - loss: 0.1608 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "202/250 [=======================>......] - ETA: 22s - loss: 0.1602 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "203/250 [=======================>......] - ETA: 22s - loss: 0.1604 - accuracy: 0.9620\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "204/250 [=======================>......] - ETA: 21s - loss: 0.1601 - accuracy: 0.9619\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "205/250 [=======================>......] - ETA: 21s - loss: 0.1593 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "206/250 [=======================>......] - ETA: 20s - loss: 0.1587 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "207/250 [=======================>......] - ETA: 20s - loss: 0.1583 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "208/250 [=======================>......] - ETA: 19s - loss: 0.1582 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "209/250 [========================>.....] - ETA: 19s - loss: 0.1581 - accuracy: 0.9621\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "210/250 [========================>.....] - ETA: 18s - loss: 0.1574 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "211/250 [========================>.....] - ETA: 18s - loss: 0.1576 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "212/250 [========================>.....] - ETA: 17s - loss: 0.1576 - accuracy: 0.9622\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "213/250 [========================>.....] - ETA: 17s - loss: 0.1569 - accuracy: 0.9623\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "214/250 [========================>.....] - ETA: 16s - loss: 0.1562 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "215/250 [========================>.....] - ETA: 16s - loss: 0.1557 - accuracy: 0.9625\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "216/250 [========================>.....] - ETA: 15s - loss: 0.1553 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "217/250 [=========================>....] - ETA: 15s - loss: 0.1547 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "218/250 [=========================>....] - ETA: 14s - loss: 0.1545 - accuracy: 0.9626\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "219/250 [=========================>....] - ETA: 14s - loss: 0.1539 - accuracy: 0.9628\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "220/250 [=========================>....] - ETA: 13s - loss: 0.1544 - accuracy: 0.9628\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "221/250 [=========================>....] - ETA: 13s - loss: 0.1539 - accuracy: 0.9628\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "222/250 [=========================>....] - ETA: 12s - loss: 0.1538 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "223/250 [=========================>....] - ETA: 12s - loss: 0.1533 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "224/250 [=========================>....] - ETA: 11s - loss: 0.1535 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "225/250 [==========================>...] - ETA: 11s - loss: 0.1531 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "226/250 [==========================>...] - ETA: 10s - loss: 0.1527 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "227/250 [==========================>...] - ETA: 10s - loss: 0.1522 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "228/250 [==========================>...] - ETA: 9s - loss: 0.1516 - accuracy: 0.9632 \n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "229/250 [==========================>...] - ETA: 9s - loss: 0.1522 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "230/250 [==========================>...] - ETA: 8s - loss: 0.1516 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "231/250 [==========================>...] - ETA: 8s - loss: 0.1522 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "232/250 [==========================>...] - ETA: 8s - loss: 0.1516 - accuracy: 0.9633\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "233/250 [==========================>...] - ETA: 7s - loss: 0.1535 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "234/250 [===========================>..] - ETA: 7s - loss: 0.1532 - accuracy: 0.9630\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "235/250 [===========================>..] - ETA: 6s - loss: 0.1551 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "236/250 [===========================>..] - ETA: 6s - loss: 0.1550 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "237/250 [===========================>..] - ETA: 5s - loss: 0.1548 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "238/250 [===========================>..] - ETA: 5s - loss: 0.1545 - accuracy: 0.9627\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "239/250 [===========================>..] - ETA: 4s - loss: 0.1540 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "240/250 [===========================>..] - ETA: 4s - loss: 0.1541 - accuracy: 0.9628\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "241/250 [===========================>..] - ETA: 3s - loss: 0.1536 - accuracy: 0.9629\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "242/250 [============================>.] - ETA: 3s - loss: 0.1530 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "243/250 [============================>.] - ETA: 3s - loss: 0.1525 - accuracy: 0.9633\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "244/250 [============================>.] - ETA: 2s - loss: 0.1527 - accuracy: 0.9631\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "245/250 [============================>.] - ETA: 2s - loss: 0.1526 - accuracy: 0.9632\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1519 - accuracy: 0.9633\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "247/250 [============================>.] - ETA: 1s - loss: 0.1523 - accuracy: 0.9632\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9634\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9634\n",
      "Epoch 4: accuracy did not improve from 0.96484\n",
      "250/250 [==============================] - 125s 500ms/step - loss: 0.1508 - accuracy: 0.9634 - val_loss: 0.0773 - val_accuracy: 0.9798\n",
      "Epoch 5/15\n",
      "\n",
      "Epoch 5: accuracy did not improve from 0.96484\n",
      "  1/250 [..............................] - ETA: 1:46 - loss: 0.0894 - accuracy: 0.9375\n",
      "Epoch 5: accuracy improved from 0.96484 to 0.96875, saving model to output\\vgg.h5\n",
      "  2/250 [..............................] - ETA: 7:43 - loss: 0.0473 - accuracy: 0.9688\n",
      "Epoch 5: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 4:14 - loss: 0.0685 - accuracy: 0.9688\n",
      "Epoch 5: accuracy improved from 0.96875 to 0.97656, saving model to output\\vgg.h5\n",
      "  4/250 [..............................] - ETA: 5:08 - loss: 0.0517 - accuracy: 0.9766\n",
      "Epoch 5: accuracy did not improve from 0.97656\n",
      "  5/250 [..............................] - ETA: 4:01 - loss: 0.2004 - accuracy: 0.9750\n",
      "Epoch 5: accuracy improved from 0.97656 to 0.97917, saving model to output\\vgg.h5\n",
      "  6/250 [..............................] - ETA: 4:34 - loss: 0.1682 - accuracy: 0.9792\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "  7/250 [..............................] - ETA: 3:54 - loss: 0.2009 - accuracy: 0.9777\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "  8/250 [..............................] - ETA: 3:30 - loss: 0.1913 - accuracy: 0.9766\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "  9/250 [>.............................] - ETA: 3:14 - loss: 0.1844 - accuracy: 0.9722\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 10/250 [>.............................] - ETA: 3:00 - loss: 0.1661 - accuracy: 0.9750\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 11/250 [>.............................] - ETA: 2:48 - loss: 0.2031 - accuracy: 0.9716\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 12/250 [>.............................] - ETA: 2:38 - loss: 0.1927 - accuracy: 0.9688\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 13/250 [>.............................] - ETA: 2:30 - loss: 0.1813 - accuracy: 0.9688\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 14/250 [>.............................] - ETA: 2:23 - loss: 0.1685 - accuracy: 0.9710\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 15/250 [>.............................] - ETA: 2:18 - loss: 0.1605 - accuracy: 0.9708\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 16/250 [>.............................] - ETA: 2:13 - loss: 0.1577 - accuracy: 0.9707\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 17/250 [=>............................] - ETA: 2:09 - loss: 0.1485 - accuracy: 0.9724\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 18/250 [=>............................] - ETA: 2:05 - loss: 0.1414 - accuracy: 0.9740\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 19/250 [=>............................] - ETA: 2:02 - loss: 0.1439 - accuracy: 0.9720\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 20/250 [=>............................] - ETA: 1:58 - loss: 0.1507 - accuracy: 0.9703\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 21/250 [=>............................] - ETA: 1:56 - loss: 0.1440 - accuracy: 0.9717\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 22/250 [=>............................] - ETA: 1:53 - loss: 0.2083 - accuracy: 0.9702\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 23/250 [=>............................] - ETA: 1:50 - loss: 0.1994 - accuracy: 0.9715\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 24/250 [=>............................] - ETA: 1:48 - loss: 0.1930 - accuracy: 0.9714\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 25/250 [==>...........................] - ETA: 1:47 - loss: 0.1890 - accuracy: 0.9700\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 26/250 [==>...........................] - ETA: 1:45 - loss: 0.2126 - accuracy: 0.9675\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 27/250 [==>...........................] - ETA: 1:43 - loss: 0.2048 - accuracy: 0.9688\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 28/250 [==>...........................] - ETA: 1:40 - loss: 0.1975 - accuracy: 0.9699\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 29/250 [==>...........................] - ETA: 1:38 - loss: 0.1909 - accuracy: 0.9709\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 30/250 [==>...........................] - ETA: 1:37 - loss: 0.1850 - accuracy: 0.9719\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 31/250 [==>...........................] - ETA: 1:35 - loss: 0.1800 - accuracy: 0.9728\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 32/250 [==>...........................] - ETA: 1:34 - loss: 0.1770 - accuracy: 0.9727\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 33/250 [==>...........................] - ETA: 1:32 - loss: 0.1756 - accuracy: 0.9725\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 34/250 [===>..........................] - ETA: 1:31 - loss: 0.1705 - accuracy: 0.9733\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 35/250 [===>..........................] - ETA: 1:30 - loss: 0.1657 - accuracy: 0.9741\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 36/250 [===>..........................] - ETA: 1:28 - loss: 0.1815 - accuracy: 0.9714\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 37/250 [===>..........................] - ETA: 1:27 - loss: 0.1778 - accuracy: 0.9713\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 38/250 [===>..........................] - ETA: 1:26 - loss: 0.1749 - accuracy: 0.9712\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 39/250 [===>..........................] - ETA: 1:25 - loss: 0.1713 - accuracy: 0.9720\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 40/250 [===>..........................] - ETA: 1:24 - loss: 0.1671 - accuracy: 0.9727\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 41/250 [===>..........................] - ETA: 1:23 - loss: 0.1631 - accuracy: 0.9733\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 42/250 [====>.........................] - ETA: 1:23 - loss: 0.1607 - accuracy: 0.9732\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 43/250 [====>.........................] - ETA: 1:22 - loss: 0.1570 - accuracy: 0.9738\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 44/250 [====>.........................] - ETA: 1:21 - loss: 0.1539 - accuracy: 0.9744\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 45/250 [====>.........................] - ETA: 1:20 - loss: 0.1515 - accuracy: 0.9743\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 46/250 [====>.........................] - ETA: 1:19 - loss: 0.1487 - accuracy: 0.9749\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 47/250 [====>.........................] - ETA: 1:18 - loss: 0.1514 - accuracy: 0.9741\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 48/250 [====>.........................] - ETA: 1:17 - loss: 0.1534 - accuracy: 0.9740\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 49/250 [====>.........................] - ETA: 1:16 - loss: 0.1513 - accuracy: 0.9739\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 50/250 [=====>........................] - ETA: 1:16 - loss: 0.1546 - accuracy: 0.9731\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 51/250 [=====>........................] - ETA: 1:15 - loss: 0.1570 - accuracy: 0.9730\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 52/250 [=====>........................] - ETA: 1:14 - loss: 0.1544 - accuracy: 0.9736\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 53/250 [=====>........................] - ETA: 1:14 - loss: 0.1521 - accuracy: 0.9735\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 54/250 [=====>........................] - ETA: 1:13 - loss: 0.1496 - accuracy: 0.9740\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 55/250 [=====>........................] - ETA: 1:12 - loss: 0.1498 - accuracy: 0.9733\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 56/250 [=====>........................] - ETA: 1:12 - loss: 0.1475 - accuracy: 0.9738\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 57/250 [=====>........................] - ETA: 1:11 - loss: 0.1450 - accuracy: 0.9742\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 58/250 [=====>........................] - ETA: 1:11 - loss: 0.1467 - accuracy: 0.9741\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 59/250 [======>.......................] - ETA: 1:10 - loss: 0.1475 - accuracy: 0.9740\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 60/250 [======>.......................] - ETA: 1:09 - loss: 0.1496 - accuracy: 0.9734\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 61/250 [======>.......................] - ETA: 1:09 - loss: 0.1492 - accuracy: 0.9734\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 62/250 [======>.......................] - ETA: 1:08 - loss: 0.1518 - accuracy: 0.9723\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 63/250 [======>.......................] - ETA: 1:07 - loss: 0.1514 - accuracy: 0.9717\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 64/250 [======>.......................] - ETA: 1:07 - loss: 0.1498 - accuracy: 0.9717\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 65/250 [======>.......................] - ETA: 1:06 - loss: 0.1478 - accuracy: 0.9721\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 66/250 [======>.......................] - ETA: 1:05 - loss: 0.1488 - accuracy: 0.9721\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 67/250 [=======>......................] - ETA: 1:05 - loss: 0.1474 - accuracy: 0.9715\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 68/250 [=======>......................] - ETA: 1:04 - loss: 0.1454 - accuracy: 0.9720\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 69/250 [=======>......................] - ETA: 1:03 - loss: 0.1452 - accuracy: 0.9717\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 70/250 [=======>......................] - ETA: 1:03 - loss: 0.1474 - accuracy: 0.9712\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 71/250 [=======>......................] - ETA: 1:02 - loss: 0.1494 - accuracy: 0.9711\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 72/250 [=======>......................] - ETA: 1:01 - loss: 0.1519 - accuracy: 0.9707\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 73/250 [=======>......................] - ETA: 1:01 - loss: 0.1528 - accuracy: 0.9698\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 74/250 [=======>......................] - ETA: 1:00 - loss: 0.1526 - accuracy: 0.9698\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 75/250 [========>.....................] - ETA: 1:00 - loss: 0.1547 - accuracy: 0.9697\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 76/250 [========>.....................] - ETA: 59s - loss: 0.1545 - accuracy: 0.9693 \n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 77/250 [========>.....................] - ETA: 59s - loss: 0.1528 - accuracy: 0.9697\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 78/250 [========>.....................] - ETA: 58s - loss: 0.1516 - accuracy: 0.9693\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 79/250 [========>.....................] - ETA: 58s - loss: 0.1497 - accuracy: 0.9697\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 80/250 [========>.....................] - ETA: 57s - loss: 0.1480 - accuracy: 0.9701\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 81/250 [========>.....................] - ETA: 57s - loss: 0.1463 - accuracy: 0.9705\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 82/250 [========>.....................] - ETA: 56s - loss: 0.1451 - accuracy: 0.9708\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 83/250 [========>.....................] - ETA: 56s - loss: 0.1519 - accuracy: 0.9697\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 84/250 [=========>....................] - ETA: 55s - loss: 0.1525 - accuracy: 0.9693\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 85/250 [=========>....................] - ETA: 55s - loss: 0.1510 - accuracy: 0.9696\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 86/250 [=========>....................] - ETA: 54s - loss: 0.1502 - accuracy: 0.9693\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 87/250 [=========>....................] - ETA: 54s - loss: 0.1485 - accuracy: 0.9696\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 88/250 [=========>....................] - ETA: 53s - loss: 0.1468 - accuracy: 0.9700\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 89/250 [=========>....................] - ETA: 53s - loss: 0.1461 - accuracy: 0.9696\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 90/250 [=========>....................] - ETA: 52s - loss: 0.1486 - accuracy: 0.9696\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 91/250 [=========>....................] - ETA: 52s - loss: 0.1483 - accuracy: 0.9696\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 92/250 [==========>...................] - ETA: 52s - loss: 0.1467 - accuracy: 0.9699\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 93/250 [==========>...................] - ETA: 51s - loss: 0.1463 - accuracy: 0.9699\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 94/250 [==========>...................] - ETA: 51s - loss: 0.1500 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 95/250 [==========>...................] - ETA: 50s - loss: 0.1487 - accuracy: 0.9699\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 96/250 [==========>...................] - ETA: 50s - loss: 0.1489 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 97/250 [==========>...................] - ETA: 49s - loss: 0.1520 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 98/250 [==========>...................] - ETA: 49s - loss: 0.1524 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      " 99/250 [==========>...................] - ETA: 49s - loss: 0.1542 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "100/250 [===========>..................] - ETA: 48s - loss: 0.1528 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "101/250 [===========>..................] - ETA: 48s - loss: 0.1536 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "102/250 [===========>..................] - ETA: 47s - loss: 0.1521 - accuracy: 0.9698\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "103/250 [===========>..................] - ETA: 47s - loss: 0.1542 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "104/250 [===========>..................] - ETA: 47s - loss: 0.1533 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "105/250 [===========>..................] - ETA: 46s - loss: 0.1531 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "106/250 [===========>..................] - ETA: 46s - loss: 0.1518 - accuracy: 0.9695\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "107/250 [===========>..................] - ETA: 45s - loss: 0.1521 - accuracy: 0.9694\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "108/250 [===========>..................] - ETA: 45s - loss: 0.1519 - accuracy: 0.9692\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "109/250 [============>.................] - ETA: 45s - loss: 0.1523 - accuracy: 0.9689\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "110/250 [============>.................] - ETA: 44s - loss: 0.1524 - accuracy: 0.9689\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "111/250 [============>.................] - ETA: 44s - loss: 0.1533 - accuracy: 0.9686\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "112/250 [============>.................] - ETA: 44s - loss: 0.1571 - accuracy: 0.9672\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "113/250 [============>.................] - ETA: 43s - loss: 0.1574 - accuracy: 0.9672\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "114/250 [============>.................] - ETA: 43s - loss: 0.1572 - accuracy: 0.9672\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "115/250 [============>.................] - ETA: 42s - loss: 0.1583 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "116/250 [============>.................] - ETA: 42s - loss: 0.1589 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "117/250 [=============>................] - ETA: 42s - loss: 0.1589 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "118/250 [=============>................] - ETA: 41s - loss: 0.1589 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "119/250 [=============>................] - ETA: 41s - loss: 0.1579 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "120/250 [=============>................] - ETA: 41s - loss: 0.1568 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "121/250 [=============>................] - ETA: 40s - loss: 0.1557 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "122/250 [=============>................] - ETA: 40s - loss: 0.1564 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "123/250 [=============>................] - ETA: 39s - loss: 0.1554 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "124/250 [=============>................] - ETA: 39s - loss: 0.1587 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "125/250 [==============>...............] - ETA: 39s - loss: 0.1598 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "126/250 [==============>...............] - ETA: 38s - loss: 0.1585 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "127/250 [==============>...............] - ETA: 38s - loss: 0.1572 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "128/250 [==============>...............] - ETA: 38s - loss: 0.1582 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "129/250 [==============>...............] - ETA: 37s - loss: 0.1576 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "130/250 [==============>...............] - ETA: 37s - loss: 0.1614 - accuracy: 0.9655\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "131/250 [==============>...............] - ETA: 37s - loss: 0.1606 - accuracy: 0.9655\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "132/250 [==============>...............] - ETA: 36s - loss: 0.1618 - accuracy: 0.9650\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "133/250 [==============>...............] - ETA: 36s - loss: 0.1607 - accuracy: 0.9653\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "134/250 [===============>..............] - ETA: 35s - loss: 0.1613 - accuracy: 0.9651\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "135/250 [===============>..............] - ETA: 35s - loss: 0.1604 - accuracy: 0.9651\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "136/250 [===============>..............] - ETA: 35s - loss: 0.1598 - accuracy: 0.9651\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "137/250 [===============>..............] - ETA: 34s - loss: 0.1587 - accuracy: 0.9654\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "138/250 [===============>..............] - ETA: 34s - loss: 0.1575 - accuracy: 0.9657\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "139/250 [===============>..............] - ETA: 34s - loss: 0.1565 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "140/250 [===============>..............] - ETA: 33s - loss: 0.1557 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "141/250 [===============>..............] - ETA: 33s - loss: 0.1553 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "142/250 [================>.............] - ETA: 33s - loss: 0.1553 - accuracy: 0.9657\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "143/250 [================>.............] - ETA: 32s - loss: 0.1547 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "144/250 [================>.............] - ETA: 32s - loss: 0.1537 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "145/250 [================>.............] - ETA: 32s - loss: 0.1533 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "146/250 [================>.............] - ETA: 31s - loss: 0.1523 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "147/250 [================>.............] - ETA: 31s - loss: 0.1531 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "148/250 [================>.............] - ETA: 31s - loss: 0.1523 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "149/250 [================>.............] - ETA: 30s - loss: 0.1524 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "150/250 [=================>............] - ETA: 30s - loss: 0.1514 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "151/250 [=================>............] - ETA: 30s - loss: 0.1526 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "152/250 [=================>............] - ETA: 29s - loss: 0.1516 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "153/250 [=================>............] - ETA: 29s - loss: 0.1506 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "154/250 [=================>............] - ETA: 29s - loss: 0.1497 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.1500 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "156/250 [=================>............] - ETA: 28s - loss: 0.1494 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "157/250 [=================>............] - ETA: 28s - loss: 0.1489 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.1481 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "159/250 [==================>...........] - ETA: 27s - loss: 0.1489 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "160/250 [==================>...........] - ETA: 27s - loss: 0.1480 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.1475 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.1479 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "163/250 [==================>...........] - ETA: 26s - loss: 0.1473 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.1464 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.1461 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "166/250 [==================>...........] - ETA: 25s - loss: 0.1477 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.1477 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.1468 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "169/250 [===================>..........] - ETA: 24s - loss: 0.1471 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.1465 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.1465 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.1459 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "173/250 [===================>..........] - ETA: 23s - loss: 0.1450 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.1450 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.1446 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "176/250 [====================>.........] - ETA: 22s - loss: 0.1445 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.1446 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.1438 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "179/250 [====================>.........] - ETA: 21s - loss: 0.1430 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.1448 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.1446 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.1443 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.1440 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.1432 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.1446 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.1441 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.1437 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.1435 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.1427 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.1423 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.1426 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.1422 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.1523 - accuracy: 0.9657\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.1536 - accuracy: 0.9657\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.1529 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1532 - accuracy: 0.9656\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.1527 - accuracy: 0.9656\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.1520 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.1517 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1520 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.1517 - accuracy: 0.9658\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.1518 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1546 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.1538 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1531 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1525 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1525 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1525 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.1518 - accuracy: 0.9663\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1511 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.1504 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.1497 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1490 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1488 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.1481 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.1479 - accuracy: 0.9669 \n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1476 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1471 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1473 - accuracy: 0.9669\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1473 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1475 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1470 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1479 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1473 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1469 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.1462 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1461 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1461 - accuracy: 0.9667\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1459 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1457 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1451 - accuracy: 0.9668\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1453 - accuracy: 0.9666\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.1467 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1467 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1480 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1488 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1489 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1484 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1486 - accuracy: 0.9660\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1492 - accuracy: 0.9659\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1487 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1484 - accuracy: 0.9661\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1479 - accuracy: 0.9662\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1473 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1473 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1469 - accuracy: 0.9664\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9665\n",
      "Epoch 5: accuracy did not improve from 0.97917\n",
      "250/250 [==============================] - 90s 358ms/step - loss: 0.1462 - accuracy: 0.9664 - val_loss: 0.0990 - val_accuracy: 0.9703\n",
      "Epoch 6/15\n",
      "\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  1/250 [..............................] - ETA: 1:43 - loss: 0.5920 - accuracy: 0.8438\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  2/250 [..............................] - ETA: 1:04 - loss: 0.5901 - accuracy: 0.8906\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  3/250 [..............................] - ETA: 1:03 - loss: 0.3964 - accuracy: 0.9271\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  4/250 [..............................] - ETA: 1:02 - loss: 0.3043 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  5/250 [..............................] - ETA: 1:02 - loss: 0.2689 - accuracy: 0.9375\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  6/250 [..............................] - ETA: 1:02 - loss: 0.2455 - accuracy: 0.9427\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  7/250 [..............................] - ETA: 1:02 - loss: 0.2333 - accuracy: 0.9464\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  8/250 [..............................] - ETA: 1:02 - loss: 0.2112 - accuracy: 0.9492\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "  9/250 [>.............................] - ETA: 1:02 - loss: 0.1878 - accuracy: 0.9549\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 10/250 [>.............................] - ETA: 1:02 - loss: 0.1906 - accuracy: 0.9531\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 11/250 [>.............................] - ETA: 1:02 - loss: 0.1796 - accuracy: 0.9545\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 12/250 [>.............................] - ETA: 1:01 - loss: 0.2236 - accuracy: 0.9531\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 13/250 [>.............................] - ETA: 1:01 - loss: 0.2070 - accuracy: 0.9567\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 14/250 [>.............................] - ETA: 1:03 - loss: 0.1949 - accuracy: 0.9598\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 15/250 [>.............................] - ETA: 1:03 - loss: 0.1824 - accuracy: 0.9625\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 16/250 [>.............................] - ETA: 1:03 - loss: 0.1858 - accuracy: 0.9609\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 17/250 [=>............................] - ETA: 1:03 - loss: 0.1760 - accuracy: 0.9632\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 18/250 [=>............................] - ETA: 1:03 - loss: 0.1839 - accuracy: 0.9618\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 19/250 [=>............................] - ETA: 1:03 - loss: 0.1814 - accuracy: 0.9605\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.1756 - accuracy: 0.9609\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.1695 - accuracy: 0.9613\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.2071 - accuracy: 0.9602\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.1982 - accuracy: 0.9620\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 24/250 [=>............................] - ETA: 1:05 - loss: 0.1908 - accuracy: 0.9635\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.1841 - accuracy: 0.9650\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.1772 - accuracy: 0.9663\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 27/250 [==>...........................] - ETA: 1:04 - loss: 0.1750 - accuracy: 0.9653\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 28/250 [==>...........................] - ETA: 1:04 - loss: 0.1843 - accuracy: 0.9621\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 29/250 [==>...........................] - ETA: 1:04 - loss: 0.1804 - accuracy: 0.9623\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 30/250 [==>...........................] - ETA: 1:04 - loss: 0.1745 - accuracy: 0.9635\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 31/250 [==>...........................] - ETA: 1:04 - loss: 0.1699 - accuracy: 0.9637\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 32/250 [==>...........................] - ETA: 1:03 - loss: 0.1748 - accuracy: 0.9619\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 33/250 [==>...........................] - ETA: 1:03 - loss: 0.1798 - accuracy: 0.9602\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 34/250 [===>..........................] - ETA: 1:03 - loss: 0.1748 - accuracy: 0.9614\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 35/250 [===>..........................] - ETA: 1:03 - loss: 0.1756 - accuracy: 0.9616\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 36/250 [===>..........................] - ETA: 1:03 - loss: 0.1712 - accuracy: 0.9627\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 37/250 [===>..........................] - ETA: 1:02 - loss: 0.1666 - accuracy: 0.9637\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 38/250 [===>..........................] - ETA: 1:02 - loss: 0.1661 - accuracy: 0.9638\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 39/250 [===>..........................] - ETA: 1:02 - loss: 0.1640 - accuracy: 0.9639\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 40/250 [===>..........................] - ETA: 1:02 - loss: 0.1600 - accuracy: 0.9648\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 41/250 [===>..........................] - ETA: 1:01 - loss: 0.1623 - accuracy: 0.9634\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 42/250 [====>.........................] - ETA: 1:01 - loss: 0.1615 - accuracy: 0.9621\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 43/250 [====>.........................] - ETA: 1:01 - loss: 0.1608 - accuracy: 0.9622\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 44/250 [====>.........................] - ETA: 1:01 - loss: 0.1611 - accuracy: 0.9616\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 45/250 [====>.........................] - ETA: 1:01 - loss: 0.1587 - accuracy: 0.9618\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 46/250 [====>.........................] - ETA: 1:00 - loss: 0.1592 - accuracy: 0.9613\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 47/250 [====>.........................] - ETA: 1:00 - loss: 0.1599 - accuracy: 0.9614\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 48/250 [====>.........................] - ETA: 1:00 - loss: 0.1585 - accuracy: 0.9609\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 49/250 [====>.........................] - ETA: 1:00 - loss: 0.1593 - accuracy: 0.9598\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 50/250 [=====>........................] - ETA: 59s - loss: 0.1562 - accuracy: 0.9606 \n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 51/250 [=====>........................] - ETA: 59s - loss: 0.1534 - accuracy: 0.9614\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 52/250 [=====>........................] - ETA: 59s - loss: 0.1527 - accuracy: 0.9609\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 53/250 [=====>........................] - ETA: 58s - loss: 0.1633 - accuracy: 0.9605\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 54/250 [=====>........................] - ETA: 58s - loss: 0.1604 - accuracy: 0.9612\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.1677 - accuracy: 0.9585\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 56/250 [=====>........................] - ETA: 57s - loss: 0.1648 - accuracy: 0.9593\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 57/250 [=====>........................] - ETA: 57s - loss: 0.1636 - accuracy: 0.9594\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 58/250 [=====>........................] - ETA: 57s - loss: 0.1629 - accuracy: 0.9596\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 59/250 [======>.......................] - ETA: 56s - loss: 0.1607 - accuracy: 0.9597\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 60/250 [======>.......................] - ETA: 56s - loss: 0.1581 - accuracy: 0.9604\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 61/250 [======>.......................] - ETA: 56s - loss: 0.1629 - accuracy: 0.9600\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 62/250 [======>.......................] - ETA: 55s - loss: 0.1605 - accuracy: 0.9607\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 63/250 [======>.......................] - ETA: 55s - loss: 0.1586 - accuracy: 0.9608\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 64/250 [======>.......................] - ETA: 54s - loss: 0.1573 - accuracy: 0.9609\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 65/250 [======>.......................] - ETA: 54s - loss: 0.1549 - accuracy: 0.9615\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 66/250 [======>.......................] - ETA: 54s - loss: 0.1534 - accuracy: 0.9616\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 67/250 [=======>......................] - ETA: 53s - loss: 0.1513 - accuracy: 0.9622\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 68/250 [=======>......................] - ETA: 53s - loss: 0.1509 - accuracy: 0.9619\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.1503 - accuracy: 0.9620\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.1486 - accuracy: 0.9625\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 71/250 [=======>......................] - ETA: 52s - loss: 0.1500 - accuracy: 0.9621\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.1480 - accuracy: 0.9627\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.1461 - accuracy: 0.9632\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 74/250 [=======>......................] - ETA: 51s - loss: 0.1510 - accuracy: 0.9633\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.1511 - accuracy: 0.9629\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 76/250 [========>.....................] - ETA: 50s - loss: 0.1498 - accuracy: 0.9630\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.1482 - accuracy: 0.9635\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 78/250 [========>.....................] - ETA: 50s - loss: 0.1488 - accuracy: 0.9631\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 79/250 [========>.....................] - ETA: 49s - loss: 0.1496 - accuracy: 0.9628\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.1478 - accuracy: 0.9633\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.1479 - accuracy: 0.9633\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 82/250 [========>.....................] - ETA: 48s - loss: 0.1462 - accuracy: 0.9638\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 83/250 [========>.....................] - ETA: 48s - loss: 0.1460 - accuracy: 0.9639\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.1453 - accuracy: 0.9639\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 85/250 [=========>....................] - ETA: 47s - loss: 0.1437 - accuracy: 0.9643\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 86/250 [=========>....................] - ETA: 47s - loss: 0.1421 - accuracy: 0.9648\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.1406 - accuracy: 0.9652\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.1390 - accuracy: 0.9656\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.1374 - accuracy: 0.9659\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 90/250 [=========>....................] - ETA: 46s - loss: 0.1391 - accuracy: 0.9656\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.1376 - accuracy: 0.9660\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.1363 - accuracy: 0.9664\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 93/250 [==========>...................] - ETA: 45s - loss: 0.1355 - accuracy: 0.9664\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.1341 - accuracy: 0.9668\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.1337 - accuracy: 0.9668\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.1328 - accuracy: 0.9668\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.1322 - accuracy: 0.9668\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.1330 - accuracy: 0.9665\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.1341 - accuracy: 0.9662\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.1328 - accuracy: 0.9666\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.1329 - accuracy: 0.9663\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.1319 - accuracy: 0.9666\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.1342 - accuracy: 0.9660\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.1329 - accuracy: 0.9663\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.1319 - accuracy: 0.9667\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.1318 - accuracy: 0.9664\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.1305 - accuracy: 0.9667\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.1295 - accuracy: 0.9670\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.1285 - accuracy: 0.9673\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.1378 - accuracy: 0.9670\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.1365 - accuracy: 0.9673\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.1356 - accuracy: 0.9674\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.1344 - accuracy: 0.9676\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.1333 - accuracy: 0.9679\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.1322 - accuracy: 0.9682\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.1327 - accuracy: 0.9682\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.1316 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.1308 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.1299 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.1288 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.1295 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.1299 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.1307 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.1354 - accuracy: 0.9677\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.1344 - accuracy: 0.9680\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.1334 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.1327 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.1319 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.1309 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.1317 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.1320 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.1318 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.1309 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.1300 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.1291 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.1287 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.1284 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.1277 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.1285 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.1295 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.1291 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.1300 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.1298 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.1290 - accuracy: 0.9694\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.1281 - accuracy: 0.9696\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.1274 - accuracy: 0.9698\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.1278 - accuracy: 0.9698\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.1279 - accuracy: 0.9698\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.1301 - accuracy: 0.9694\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.1300 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.1311 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.1310 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.1314 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.1305 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.1300 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.1292 - accuracy: 0.9692\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.1291 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.1285 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.1283 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.1278 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.1278 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.1275 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.1281 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.1287 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.1283 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.1277 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.1269 - accuracy: 0.9697\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.1264 - accuracy: 0.9699\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.1259 - accuracy: 0.9699\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.1257 - accuracy: 0.9699\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.1281 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.1274 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.1272 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.1272 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.1264 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.1260 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.1253 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.1248 - accuracy: 0.9695\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.1262 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.1263 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.1262 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.1256 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.1273 - accuracy: 0.9689\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.1287 - accuracy: 0.9689\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.1280 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.1276 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.1285 - accuracy: 0.9689\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.1283 - accuracy: 0.9689\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.1277 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.1273 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.1281 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.1280 - accuracy: 0.9686\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.1276 - accuracy: 0.9686\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.1270 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.1276 - accuracy: 0.9686\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1274 - accuracy: 0.9687\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.1268 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.1262 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.1257 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1257 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.1264 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.1258 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1257 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.1254 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1248 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1242 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1237 - accuracy: 0.9694\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1236 - accuracy: 0.9693\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.1231 - accuracy: 0.9694\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1260 - accuracy: 0.9691\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.1271 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.1275 - accuracy: 0.9690\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1288 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1326 - accuracy: 0.9687\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.1329 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.1323 - accuracy: 0.9687 \n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1320 - accuracy: 0.9687\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.1314 - accuracy: 0.9688\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1323 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1317 - accuracy: 0.9687\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1322 - accuracy: 0.9682\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1317 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1311 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1316 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1313 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.1309 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1317 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1311 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1330 - accuracy: 0.9681\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1326 - accuracy: 0.9681\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1321 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1320 - accuracy: 0.9681\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.1315 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1309 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1328 - accuracy: 0.9681\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1322 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1317 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1316 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1315 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1330 - accuracy: 0.9680\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1324 - accuracy: 0.9681\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1320 - accuracy: 0.9682\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1320 - accuracy: 0.9680\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1316 - accuracy: 0.9682\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1311 - accuracy: 0.9683\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1306 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9684\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9685\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9687\n",
      "Epoch 6: accuracy did not improve from 0.97917\n",
      "250/250 [==============================] - 92s 367ms/step - loss: 0.1297 - accuracy: 0.9685 - val_loss: 0.0481 - val_accuracy: 0.9844\n",
      "Epoch 7/15\n",
      "\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  1/250 [..............................] - ETA: 1:46 - loss: 0.2266 - accuracy: 0.9688\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  2/250 [..............................] - ETA: 1:06 - loss: 0.1691 - accuracy: 0.9688\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 0.1318 - accuracy: 0.9688\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  4/250 [..............................] - ETA: 1:08 - loss: 0.1419 - accuracy: 0.9609\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  5/250 [..............................] - ETA: 1:07 - loss: 0.1977 - accuracy: 0.9563\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  6/250 [..............................] - ETA: 1:07 - loss: 0.2060 - accuracy: 0.9583\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.1879 - accuracy: 0.9598\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.1646 - accuracy: 0.9648\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      "  9/250 [>.............................] - ETA: 1:09 - loss: 0.1490 - accuracy: 0.9653\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 10/250 [>.............................] - ETA: 1:09 - loss: 0.1362 - accuracy: 0.9688\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 11/250 [>.............................] - ETA: 1:09 - loss: 0.1354 - accuracy: 0.9688\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 12/250 [>.............................] - ETA: 1:09 - loss: 0.1242 - accuracy: 0.9714\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 13/250 [>.............................] - ETA: 1:08 - loss: 0.1147 - accuracy: 0.9736\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 14/250 [>.............................] - ETA: 1:08 - loss: 0.1065 - accuracy: 0.9754\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 15/250 [>.............................] - ETA: 1:07 - loss: 0.1040 - accuracy: 0.9750\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 16/250 [>.............................] - ETA: 1:07 - loss: 0.1059 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 17/250 [=>............................] - ETA: 1:06 - loss: 0.1112 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 0.1149 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 19/250 [=>............................] - ETA: 1:05 - loss: 0.1088 - accuracy: 0.9753\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.1036 - accuracy: 0.9766\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.0986 - accuracy: 0.9777\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.0976 - accuracy: 0.9773\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.0934 - accuracy: 0.9783\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.0954 - accuracy: 0.9779\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.0923 - accuracy: 0.9787\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 26/250 [==>...........................] - ETA: 1:03 - loss: 0.0903 - accuracy: 0.9784\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.0869 - accuracy: 0.9792\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.0915 - accuracy: 0.9788\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 29/250 [==>...........................] - ETA: 1:02 - loss: 0.0905 - accuracy: 0.9784\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.0951 - accuracy: 0.9771\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.0920 - accuracy: 0.9778\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.0897 - accuracy: 0.9785\n",
      "Epoch 7: accuracy did not improve from 0.97917\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.0878 - accuracy: 0.9792\n",
      "Epoch 7: accuracy improved from 0.97917 to 0.97978, saving model to output\\vgg.h5\n",
      " 34/250 [===>..........................] - ETA: 1:10 - loss: 0.0858 - accuracy: 0.9798\n",
      "Epoch 7: accuracy improved from 0.97978 to 0.98036, saving model to output\\vgg.h5\n",
      " 35/250 [===>..........................] - ETA: 1:17 - loss: 0.0834 - accuracy: 0.9804\n",
      "Epoch 7: accuracy improved from 0.98036 to 0.98090, saving model to output\\vgg.h5\n",
      " 36/250 [===>..........................] - ETA: 1:25 - loss: 0.0814 - accuracy: 0.9809\n",
      "Epoch 7: accuracy did not improve from 0.98090\n",
      " 37/250 [===>..........................] - ETA: 1:23 - loss: 0.0883 - accuracy: 0.9806\n",
      "Epoch 7: accuracy improved from 0.98090 to 0.98109, saving model to output\\vgg.h5\n",
      " 38/250 [===>..........................] - ETA: 1:31 - loss: 0.0861 - accuracy: 0.9811\n",
      "Epoch 7: accuracy did not improve from 0.98109\n",
      " 39/250 [===>..........................] - ETA: 1:29 - loss: 0.0859 - accuracy: 0.9808\n",
      "Epoch 7: accuracy improved from 0.98109 to 0.98125, saving model to output\\vgg.h5\n",
      " 40/250 [===>..........................] - ETA: 1:36 - loss: 0.0839 - accuracy: 0.9812\n",
      "Epoch 7: accuracy improved from 0.98125 to 0.98171, saving model to output\\vgg.h5\n",
      " 41/250 [===>..........................] - ETA: 1:41 - loss: 0.0820 - accuracy: 0.9817\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 42/250 [====>.........................] - ETA: 1:39 - loss: 0.0950 - accuracy: 0.9807\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 43/250 [====>.........................] - ETA: 1:38 - loss: 0.0928 - accuracy: 0.9811\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 44/250 [====>.........................] - ETA: 1:36 - loss: 0.0910 - accuracy: 0.9815\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 45/250 [====>.........................] - ETA: 1:35 - loss: 0.0917 - accuracy: 0.9812\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 46/250 [====>.........................] - ETA: 1:34 - loss: 0.0898 - accuracy: 0.9817\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 47/250 [====>.........................] - ETA: 1:32 - loss: 0.0892 - accuracy: 0.9807\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 48/250 [====>.........................] - ETA: 1:31 - loss: 0.0878 - accuracy: 0.9811\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 49/250 [====>.........................] - ETA: 1:30 - loss: 0.0904 - accuracy: 0.9802\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 50/250 [=====>........................] - ETA: 1:29 - loss: 0.0910 - accuracy: 0.9794\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 51/250 [=====>........................] - ETA: 1:28 - loss: 0.0902 - accuracy: 0.9792\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 52/250 [=====>........................] - ETA: 1:27 - loss: 0.0886 - accuracy: 0.9796\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 53/250 [=====>........................] - ETA: 1:26 - loss: 0.0923 - accuracy: 0.9788\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 54/250 [=====>........................] - ETA: 1:24 - loss: 0.0909 - accuracy: 0.9792\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 55/250 [=====>........................] - ETA: 1:23 - loss: 0.0925 - accuracy: 0.9778\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 56/250 [=====>........................] - ETA: 1:23 - loss: 0.0909 - accuracy: 0.9782\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 57/250 [=====>........................] - ETA: 1:22 - loss: 0.0893 - accuracy: 0.9786\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 58/250 [=====>........................] - ETA: 1:21 - loss: 0.0901 - accuracy: 0.9784\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 59/250 [======>.......................] - ETA: 1:20 - loss: 0.0887 - accuracy: 0.9788\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 60/250 [======>.......................] - ETA: 1:20 - loss: 0.0939 - accuracy: 0.9786\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 61/250 [======>.......................] - ETA: 1:19 - loss: 0.0937 - accuracy: 0.9780\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 62/250 [======>.......................] - ETA: 1:18 - loss: 0.0961 - accuracy: 0.9773\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 63/250 [======>.......................] - ETA: 1:17 - loss: 0.0964 - accuracy: 0.9772\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 64/250 [======>.......................] - ETA: 1:17 - loss: 0.1032 - accuracy: 0.9766\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 65/250 [======>.......................] - ETA: 1:16 - loss: 0.1047 - accuracy: 0.9760\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 66/250 [======>.......................] - ETA: 1:15 - loss: 0.1032 - accuracy: 0.9763\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 67/250 [=======>......................] - ETA: 1:14 - loss: 0.1074 - accuracy: 0.9757\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 68/250 [=======>......................] - ETA: 1:14 - loss: 0.1119 - accuracy: 0.9756\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 69/250 [=======>......................] - ETA: 1:13 - loss: 0.1134 - accuracy: 0.9755\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 70/250 [=======>......................] - ETA: 1:12 - loss: 0.1126 - accuracy: 0.9754\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 71/250 [=======>......................] - ETA: 1:12 - loss: 0.1110 - accuracy: 0.9758\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 72/250 [=======>......................] - ETA: 1:11 - loss: 0.1123 - accuracy: 0.9753\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 73/250 [=======>......................] - ETA: 1:10 - loss: 0.1113 - accuracy: 0.9756\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 74/250 [=======>......................] - ETA: 1:10 - loss: 0.1098 - accuracy: 0.9759\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 75/250 [========>.....................] - ETA: 1:09 - loss: 0.1090 - accuracy: 0.9758\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 76/250 [========>.....................] - ETA: 1:08 - loss: 0.1076 - accuracy: 0.9762\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 77/250 [========>.....................] - ETA: 1:08 - loss: 0.1067 - accuracy: 0.9761\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 78/250 [========>.....................] - ETA: 1:07 - loss: 0.1065 - accuracy: 0.9760\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 79/250 [========>.....................] - ETA: 1:07 - loss: 0.1070 - accuracy: 0.9759\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 80/250 [========>.....................] - ETA: 1:06 - loss: 0.1066 - accuracy: 0.9758\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 81/250 [========>.....................] - ETA: 1:05 - loss: 0.1053 - accuracy: 0.9761\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 82/250 [========>.....................] - ETA: 1:05 - loss: 0.1044 - accuracy: 0.9760\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 83/250 [========>.....................] - ETA: 1:04 - loss: 0.1040 - accuracy: 0.9759\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 84/250 [=========>....................] - ETA: 1:04 - loss: 0.1029 - accuracy: 0.9762\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 85/250 [=========>....................] - ETA: 1:03 - loss: 0.1017 - accuracy: 0.9765\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 86/250 [=========>....................] - ETA: 1:03 - loss: 0.1049 - accuracy: 0.9757\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 87/250 [=========>....................] - ETA: 1:02 - loss: 0.1037 - accuracy: 0.9759\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 88/250 [=========>....................] - ETA: 1:01 - loss: 0.1040 - accuracy: 0.9755\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 89/250 [=========>....................] - ETA: 1:01 - loss: 0.1032 - accuracy: 0.9758\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 90/250 [=========>....................] - ETA: 1:00 - loss: 0.1021 - accuracy: 0.9760\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 91/250 [=========>....................] - ETA: 1:00 - loss: 0.1014 - accuracy: 0.9760\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 92/250 [==========>...................] - ETA: 59s - loss: 0.1032 - accuracy: 0.9755 \n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 93/250 [==========>...................] - ETA: 59s - loss: 0.1033 - accuracy: 0.9751\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 94/250 [==========>...................] - ETA: 58s - loss: 0.1072 - accuracy: 0.9751\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 95/250 [==========>...................] - ETA: 58s - loss: 0.1062 - accuracy: 0.9753\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 96/250 [==========>...................] - ETA: 57s - loss: 0.1056 - accuracy: 0.9753\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 97/250 [==========>...................] - ETA: 57s - loss: 0.1073 - accuracy: 0.9752\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 98/250 [==========>...................] - ETA: 56s - loss: 0.1065 - accuracy: 0.9751\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      " 99/250 [==========>...................] - ETA: 56s - loss: 0.1060 - accuracy: 0.9751\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "100/250 [===========>..................] - ETA: 55s - loss: 0.1051 - accuracy: 0.9753\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "101/250 [===========>..................] - ETA: 55s - loss: 0.1065 - accuracy: 0.9752\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "102/250 [===========>..................] - ETA: 54s - loss: 0.1055 - accuracy: 0.9755\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "103/250 [===========>..................] - ETA: 54s - loss: 0.1062 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "104/250 [===========>..................] - ETA: 53s - loss: 0.1063 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "105/250 [===========>..................] - ETA: 53s - loss: 0.1073 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "106/250 [===========>..................] - ETA: 52s - loss: 0.1065 - accuracy: 0.9749\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "107/250 [===========>..................] - ETA: 52s - loss: 0.1056 - accuracy: 0.9752\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "108/250 [===========>..................] - ETA: 51s - loss: 0.1055 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "109/250 [============>.................] - ETA: 51s - loss: 0.1070 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "110/250 [============>.................] - ETA: 50s - loss: 0.1065 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "111/250 [============>.................] - ETA: 50s - loss: 0.1072 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "112/250 [============>.................] - ETA: 49s - loss: 0.1092 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "113/250 [============>.................] - ETA: 49s - loss: 0.1083 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "114/250 [============>.................] - ETA: 48s - loss: 0.1087 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "115/250 [============>.................] - ETA: 48s - loss: 0.1086 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "116/250 [============>.................] - ETA: 48s - loss: 0.1077 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "117/250 [=============>................] - ETA: 47s - loss: 0.1068 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "118/250 [=============>................] - ETA: 47s - loss: 0.1067 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "119/250 [=============>................] - ETA: 47s - loss: 0.1058 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "120/250 [=============>................] - ETA: 46s - loss: 0.1082 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "121/250 [=============>................] - ETA: 46s - loss: 0.1074 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "122/250 [=============>................] - ETA: 45s - loss: 0.1065 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "123/250 [=============>................] - ETA: 45s - loss: 0.1060 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "124/250 [=============>................] - ETA: 44s - loss: 0.1052 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "125/250 [==============>...............] - ETA: 44s - loss: 0.1045 - accuracy: 0.9750\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "126/250 [==============>...............] - ETA: 43s - loss: 0.1045 - accuracy: 0.9750\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "127/250 [==============>...............] - ETA: 43s - loss: 0.1063 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "128/250 [==============>...............] - ETA: 43s - loss: 0.1055 - accuracy: 0.9749\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "129/250 [==============>...............] - ETA: 42s - loss: 0.1047 - accuracy: 0.9750\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "130/250 [==============>...............] - ETA: 42s - loss: 0.1052 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "131/250 [==============>...............] - ETA: 41s - loss: 0.1057 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "132/250 [==============>...............] - ETA: 41s - loss: 0.1076 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "133/250 [==============>...............] - ETA: 41s - loss: 0.1068 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "134/250 [===============>..............] - ETA: 40s - loss: 0.1130 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "135/250 [===============>..............] - ETA: 40s - loss: 0.1125 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "136/250 [===============>..............] - ETA: 39s - loss: 0.1117 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "137/250 [===============>..............] - ETA: 39s - loss: 0.1123 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "138/250 [===============>..............] - ETA: 39s - loss: 0.1135 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "139/250 [===============>..............] - ETA: 38s - loss: 0.1127 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "140/250 [===============>..............] - ETA: 38s - loss: 0.1130 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "141/250 [===============>..............] - ETA: 37s - loss: 0.1124 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "142/250 [================>.............] - ETA: 37s - loss: 0.1128 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "143/250 [================>.............] - ETA: 37s - loss: 0.1153 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "144/250 [================>.............] - ETA: 36s - loss: 0.1145 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "145/250 [================>.............] - ETA: 36s - loss: 0.1143 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "146/250 [================>.............] - ETA: 35s - loss: 0.1152 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "147/250 [================>.............] - ETA: 35s - loss: 0.1177 - accuracy: 0.9733\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "148/250 [================>.............] - ETA: 35s - loss: 0.1169 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "149/250 [================>.............] - ETA: 34s - loss: 0.1161 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "150/250 [=================>............] - ETA: 34s - loss: 0.1156 - accuracy: 0.9736\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "151/250 [=================>............] - ETA: 33s - loss: 0.1149 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "152/250 [=================>............] - ETA: 33s - loss: 0.1143 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "153/250 [=================>............] - ETA: 33s - loss: 0.1146 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "154/250 [=================>............] - ETA: 32s - loss: 0.1139 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "155/250 [=================>............] - ETA: 32s - loss: 0.1148 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "156/250 [=================>............] - ETA: 31s - loss: 0.1150 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "157/250 [=================>............] - ETA: 31s - loss: 0.1174 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "158/250 [=================>............] - ETA: 31s - loss: 0.1173 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "159/250 [==================>...........] - ETA: 30s - loss: 0.1180 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "160/250 [==================>...........] - ETA: 30s - loss: 0.1175 - accuracy: 0.9731\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "161/250 [==================>...........] - ETA: 30s - loss: 0.1168 - accuracy: 0.9733\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "162/250 [==================>...........] - ETA: 29s - loss: 0.1180 - accuracy: 0.9733\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "163/250 [==================>...........] - ETA: 29s - loss: 0.1173 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "164/250 [==================>...........] - ETA: 28s - loss: 0.1167 - accuracy: 0.9736\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "165/250 [==================>...........] - ETA: 28s - loss: 0.1160 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "166/250 [==================>...........] - ETA: 28s - loss: 0.1163 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "167/250 [===================>..........] - ETA: 27s - loss: 0.1157 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "168/250 [===================>..........] - ETA: 27s - loss: 0.1171 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "169/250 [===================>..........] - ETA: 27s - loss: 0.1164 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "170/250 [===================>..........] - ETA: 26s - loss: 0.1157 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "171/250 [===================>..........] - ETA: 26s - loss: 0.1158 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "172/250 [===================>..........] - ETA: 26s - loss: 0.1155 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "173/250 [===================>..........] - ETA: 25s - loss: 0.1179 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "174/250 [===================>..........] - ETA: 25s - loss: 0.1172 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "175/250 [====================>.........] - ETA: 24s - loss: 0.1166 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "176/250 [====================>.........] - ETA: 24s - loss: 0.1160 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "177/250 [====================>.........] - ETA: 24s - loss: 0.1154 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "178/250 [====================>.........] - ETA: 23s - loss: 0.1149 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "179/250 [====================>.........] - ETA: 23s - loss: 0.1149 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "180/250 [====================>.........] - ETA: 23s - loss: 0.1144 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "181/250 [====================>.........] - ETA: 22s - loss: 0.1147 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "182/250 [====================>.........] - ETA: 22s - loss: 0.1141 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "183/250 [====================>.........] - ETA: 22s - loss: 0.1141 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "184/250 [=====================>........] - ETA: 21s - loss: 0.1136 - accuracy: 0.9748\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "185/250 [=====================>........] - ETA: 21s - loss: 0.1156 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "186/250 [=====================>........] - ETA: 21s - loss: 0.1184 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "187/250 [=====================>........] - ETA: 20s - loss: 0.1178 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "188/250 [=====================>........] - ETA: 20s - loss: 0.1179 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "189/250 [=====================>........] - ETA: 20s - loss: 0.1186 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "190/250 [=====================>........] - ETA: 19s - loss: 0.1182 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "191/250 [=====================>........] - ETA: 19s - loss: 0.1194 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "192/250 [======================>.......] - ETA: 18s - loss: 0.1188 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "193/250 [======================>.......] - ETA: 18s - loss: 0.1190 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "194/250 [======================>.......] - ETA: 18s - loss: 0.1185 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "195/250 [======================>.......] - ETA: 17s - loss: 0.1179 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "196/250 [======================>.......] - ETA: 17s - loss: 0.1174 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "197/250 [======================>.......] - ETA: 17s - loss: 0.1171 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "198/250 [======================>.......] - ETA: 16s - loss: 0.1182 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "199/250 [======================>.......] - ETA: 16s - loss: 0.1180 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "200/250 [=======================>......] - ETA: 16s - loss: 0.1178 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "201/250 [=======================>......] - ETA: 15s - loss: 0.1178 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "202/250 [=======================>......] - ETA: 15s - loss: 0.1175 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "203/250 [=======================>......] - ETA: 15s - loss: 0.1194 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "204/250 [=======================>......] - ETA: 14s - loss: 0.1197 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "205/250 [=======================>......] - ETA: 14s - loss: 0.1192 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "206/250 [=======================>......] - ETA: 14s - loss: 0.1186 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "207/250 [=======================>......] - ETA: 13s - loss: 0.1180 - accuracy: 0.9743\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "208/250 [=======================>......] - ETA: 13s - loss: 0.1175 - accuracy: 0.9744\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "209/250 [========================>.....] - ETA: 13s - loss: 0.1169 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "210/250 [========================>.....] - ETA: 12s - loss: 0.1164 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "211/250 [========================>.....] - ETA: 12s - loss: 0.1160 - accuracy: 0.9746\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "212/250 [========================>.....] - ETA: 12s - loss: 0.1155 - accuracy: 0.9747\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "213/250 [========================>.....] - ETA: 11s - loss: 0.1160 - accuracy: 0.9745\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "214/250 [========================>.....] - ETA: 11s - loss: 0.1165 - accuracy: 0.9742\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "215/250 [========================>.....] - ETA: 11s - loss: 0.1167 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.1178 - accuracy: 0.9739\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "217/250 [=========================>....] - ETA: 10s - loss: 0.1173 - accuracy: 0.9740\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "218/250 [=========================>....] - ETA: 10s - loss: 0.1169 - accuracy: 0.9741\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.1176 - accuracy: 0.9738 \n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "220/250 [=========================>....] - ETA: 9s - loss: 0.1172 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "221/250 [=========================>....] - ETA: 9s - loss: 0.1171 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.1170 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.1173 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "224/250 [=========================>....] - ETA: 8s - loss: 0.1168 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1169 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.1169 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "227/250 [==========================>...] - ETA: 7s - loss: 0.1166 - accuracy: 0.9738\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1174 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.1175 - accuracy: 0.9733\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "230/250 [==========================>...] - ETA: 6s - loss: 0.1171 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "231/250 [==========================>...] - ETA: 6s - loss: 0.1166 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1162 - accuracy: 0.9737\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.1180 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "234/250 [===========================>..] - ETA: 5s - loss: 0.1175 - accuracy: 0.9736\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1177 - accuracy: 0.9736\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.1182 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "237/250 [===========================>..] - ETA: 4s - loss: 0.1180 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1180 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1196 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "240/250 [===========================>..] - ETA: 3s - loss: 0.1211 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1210 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1210 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.1207 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1205 - accuracy: 0.9732\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1200 - accuracy: 0.9733\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1195 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9734\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9735\n",
      "Epoch 7: accuracy did not improve from 0.98171\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 0.1184 - accuracy: 0.9734 - val_loss: 0.0525 - val_accuracy: 0.9884\n",
      "Epoch 8/15\n",
      "\n",
      "Epoch 8: accuracy improved from 0.98171 to 1.00000, saving model to output\\vgg.h5\n",
      "  1/250 [..............................] - ETA: 7:07 - loss: 6.9647e-04 - accuracy: 1.0000\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 43s - loss: 0.0131 - accuracy: 1.0000     \n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 56s - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:00 - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:01 - loss: 0.0446 - accuracy: 0.9937\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:00 - loss: 0.0510 - accuracy: 0.9896\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:02 - loss: 0.0477 - accuracy: 0.9866\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:02 - loss: 0.0794 - accuracy: 0.9805\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:02 - loss: 0.0713 - accuracy: 0.9826\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:02 - loss: 0.0645 - accuracy: 0.9844\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:03 - loss: 0.0630 - accuracy: 0.9830\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:03 - loss: 0.0601 - accuracy: 0.9844\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:02 - loss: 0.0555 - accuracy: 0.9856\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:02 - loss: 0.1136 - accuracy: 0.9799\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:01 - loss: 0.1157 - accuracy: 0.9771\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:01 - loss: 0.1098 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:01 - loss: 0.1034 - accuracy: 0.9798\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:01 - loss: 0.0988 - accuracy: 0.9809\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:00 - loss: 0.0936 - accuracy: 0.9819\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:00 - loss: 0.0892 - accuracy: 0.9828\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:00 - loss: 0.0855 - accuracy: 0.9836\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:00 - loss: 0.0938 - accuracy: 0.9815\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:00 - loss: 0.0897 - accuracy: 0.9823\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:00 - loss: 0.0860 - accuracy: 0.9831\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:00 - loss: 0.0847 - accuracy: 0.9825\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 59s - loss: 0.0826 - accuracy: 0.9820 \n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 59s - loss: 0.0812 - accuracy: 0.9815\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 59s - loss: 0.1307 - accuracy: 0.9810\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 58s - loss: 0.1298 - accuracy: 0.9806\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 58s - loss: 0.1257 - accuracy: 0.9812\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 58s - loss: 0.1235 - accuracy: 0.9808\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 57s - loss: 0.1344 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 57s - loss: 0.1316 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 57s - loss: 0.1280 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 56s - loss: 0.1245 - accuracy: 0.9795\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 56s - loss: 0.1213 - accuracy: 0.9800\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 56s - loss: 0.1190 - accuracy: 0.9797\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 56s - loss: 0.1159 - accuracy: 0.9803\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 55s - loss: 0.1132 - accuracy: 0.9808\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 55s - loss: 0.1104 - accuracy: 0.9812\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 55s - loss: 0.1077 - accuracy: 0.9817\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 55s - loss: 0.1072 - accuracy: 0.9814\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 54s - loss: 0.1080 - accuracy: 0.9804\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 54s - loss: 0.1081 - accuracy: 0.9801\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 54s - loss: 0.1151 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 54s - loss: 0.1168 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 53s - loss: 0.1149 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 53s - loss: 0.1125 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 53s - loss: 0.1212 - accuracy: 0.9777\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 52s - loss: 0.1197 - accuracy: 0.9775\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 52s - loss: 0.1173 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 52s - loss: 0.1157 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 52s - loss: 0.1136 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 51s - loss: 0.1164 - accuracy: 0.9774\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 51s - loss: 0.1145 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 51s - loss: 0.1130 - accuracy: 0.9777\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 50s - loss: 0.1118 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 50s - loss: 0.1134 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 50s - loss: 0.1118 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 50s - loss: 0.1120 - accuracy: 0.9776\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 49s - loss: 0.1102 - accuracy: 0.9780\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 49s - loss: 0.1084 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 49s - loss: 0.1081 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 49s - loss: 0.1067 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 48s - loss: 0.1051 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 48s - loss: 0.1075 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 48s - loss: 0.1084 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 48s - loss: 0.1078 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 47s - loss: 0.1063 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 47s - loss: 0.1050 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 47s - loss: 0.1036 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 46s - loss: 0.1043 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 46s - loss: 0.1045 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 46s - loss: 0.1032 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 46s - loss: 0.1019 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 45s - loss: 0.1006 - accuracy: 0.9794\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 45s - loss: 0.0996 - accuracy: 0.9797\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 45s - loss: 0.0994 - accuracy: 0.9796\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 45s - loss: 0.0994 - accuracy: 0.9794\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 44s - loss: 0.0992 - accuracy: 0.9793\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 44s - loss: 0.1052 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 44s - loss: 0.1132 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 43s - loss: 0.1125 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 43s - loss: 0.1128 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 43s - loss: 0.1142 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 43s - loss: 0.1133 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 42s - loss: 0.1120 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 42s - loss: 0.1108 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 42s - loss: 0.1119 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 42s - loss: 0.1117 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 41s - loss: 0.1130 - accuracy: 0.9777\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 41s - loss: 0.1118 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 41s - loss: 0.1111 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 41s - loss: 0.1107 - accuracy: 0.9777\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 40s - loss: 0.1096 - accuracy: 0.9780\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 40s - loss: 0.1085 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 40s - loss: 0.1078 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 40s - loss: 0.1068 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 39s - loss: 0.1058 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 39s - loss: 0.1057 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 39s - loss: 0.1048 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 38s - loss: 0.1046 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 38s - loss: 0.1071 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 38s - loss: 0.1063 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 38s - loss: 0.1056 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 37s - loss: 0.1047 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 37s - loss: 0.1045 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 37s - loss: 0.1037 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 37s - loss: 0.1041 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 36s - loss: 0.1032 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 36s - loss: 0.1023 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 36s - loss: 0.1015 - accuracy: 0.9791\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 35s - loss: 0.1017 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 35s - loss: 0.1009 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 35s - loss: 0.1005 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 35s - loss: 0.1003 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 34s - loss: 0.0994 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 34s - loss: 0.0987 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 34s - loss: 0.0980 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 34s - loss: 0.0975 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 33s - loss: 0.0968 - accuracy: 0.9791\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 33s - loss: 0.0960 - accuracy: 0.9793\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 33s - loss: 0.0966 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 33s - loss: 0.0962 - accuracy: 0.9791\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 32s - loss: 0.0959 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 32s - loss: 0.0984 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 32s - loss: 0.0989 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 32s - loss: 0.0983 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 31s - loss: 0.0985 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 31s - loss: 0.0981 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 31s - loss: 0.0977 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 30s - loss: 0.0970 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 30s - loss: 0.0962 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 30s - loss: 0.0956 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 30s - loss: 0.0950 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 29s - loss: 0.0943 - accuracy: 0.9793\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 29s - loss: 0.0942 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 29s - loss: 0.0940 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 29s - loss: 0.0934 - accuracy: 0.9793\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 28s - loss: 0.0929 - accuracy: 0.9795\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 28s - loss: 0.0928 - accuracy: 0.9792\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 28s - loss: 0.0930 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 28s - loss: 0.0927 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 27s - loss: 0.0938 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 27s - loss: 0.0932 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 27s - loss: 0.0928 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 26s - loss: 0.0923 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 26s - loss: 0.0925 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 26s - loss: 0.0919 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 26s - loss: 0.0916 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 25s - loss: 0.0925 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 25s - loss: 0.0922 - accuracy: 0.9780\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 25s - loss: 0.0917 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 25s - loss: 0.0911 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 24s - loss: 0.0905 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 24s - loss: 0.0903 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 24s - loss: 0.0899 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 24s - loss: 0.0898 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 23s - loss: 0.0892 - accuracy: 0.9780\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 23s - loss: 0.0888 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 23s - loss: 0.0884 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 23s - loss: 0.0879 - accuracy: 0.9782\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 22s - loss: 0.0875 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 22s - loss: 0.0877 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 22s - loss: 0.0882 - accuracy: 0.9777\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 22s - loss: 0.0887 - accuracy: 0.9774\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 21s - loss: 0.0881 - accuracy: 0.9775\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 21s - loss: 0.0884 - accuracy: 0.9775\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 21s - loss: 0.0880 - accuracy: 0.9776\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 20s - loss: 0.0875 - accuracy: 0.9778\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 20s - loss: 0.0870 - accuracy: 0.9779\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 20s - loss: 0.0865 - accuracy: 0.9780\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 20s - loss: 0.0861 - accuracy: 0.9781\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 19s - loss: 0.0857 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 19s - loss: 0.0853 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 19s - loss: 0.0851 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 19s - loss: 0.0846 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 18s - loss: 0.0844 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 18s - loss: 0.0844 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 18s - loss: 0.0839 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 18s - loss: 0.0852 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 17s - loss: 0.0851 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 17s - loss: 0.0847 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 17s - loss: 0.0843 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 16s - loss: 0.0841 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 16s - loss: 0.0839 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 16s - loss: 0.0838 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 16s - loss: 0.0834 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 15s - loss: 0.0831 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 15s - loss: 0.0835 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 15s - loss: 0.0838 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 15s - loss: 0.0842 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 14s - loss: 0.0841 - accuracy: 0.9783\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 14s - loss: 0.0836 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 14s - loss: 0.0832 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 14s - loss: 0.0828 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 13s - loss: 0.0824 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 13s - loss: 0.0820 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 13s - loss: 0.0816 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.0815 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 12s - loss: 0.0811 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 12s - loss: 0.0807 - accuracy: 0.9791\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 12s - loss: 0.0817 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.0847 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 11s - loss: 0.0857 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 11s - loss: 0.0853 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 0.0850 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 10s - loss: 0.0850 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 10s - loss: 0.0849 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 10s - loss: 0.0845 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.0848 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 9s - loss: 0.0846 - accuracy: 0.9786 \n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 9s - loss: 0.0846 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 9s - loss: 0.0842 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.0854 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 8s - loss: 0.0853 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 8s - loss: 0.0849 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.0846 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.0842 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 7s - loss: 0.0849 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 7s - loss: 0.0845 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.0841 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.0837 - accuracy: 0.9791\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 6s - loss: 0.0838 - accuracy: 0.9790\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.0837 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.0840 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0840 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 5s - loss: 0.0836 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.0834 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0840 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 4s - loss: 0.0836 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 4s - loss: 0.0841 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.0848 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0845 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 3s - loss: 0.0841 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.0857 - accuracy: 0.9785\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0853 - accuracy: 0.9786\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0851 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 2s - loss: 0.0847 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0845 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0855 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0851 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.0849 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0848 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0853 - accuracy: 0.9788\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0850 - accuracy: 0.9789\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9784\n",
      "Epoch 8: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 83s 327ms/step - loss: 0.0897 - accuracy: 0.9783 - val_loss: 0.0657 - val_accuracy: 0.9824\n",
      "Epoch 9/15\n",
      "\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:46 - loss: 0.0864 - accuracy: 0.9375\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:05 - loss: 0.0472 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:04 - loss: 0.0724 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:03 - loss: 0.1728 - accuracy: 0.9609\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:03 - loss: 0.1387 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:02 - loss: 0.1567 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:02 - loss: 0.1390 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:02 - loss: 0.1224 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:02 - loss: 0.1299 - accuracy: 0.9653\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:02 - loss: 0.1247 - accuracy: 0.9656\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:02 - loss: 0.1134 - accuracy: 0.9688\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:02 - loss: 0.1040 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:02 - loss: 0.0976 - accuracy: 0.9736\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:02 - loss: 0.0944 - accuracy: 0.9732\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:01 - loss: 0.0970 - accuracy: 0.9729\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:01 - loss: 0.0985 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:01 - loss: 0.1398 - accuracy: 0.9724\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:00 - loss: 0.1338 - accuracy: 0.9722\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:00 - loss: 0.1438 - accuracy: 0.9720\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:00 - loss: 0.1397 - accuracy: 0.9719\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:00 - loss: 0.1334 - accuracy: 0.9732\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 59s - loss: 0.1350 - accuracy: 0.9730 \n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 59s - loss: 0.1306 - accuracy: 0.9742\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 58s - loss: 0.1253 - accuracy: 0.9753\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 58s - loss: 0.1205 - accuracy: 0.9762\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 58s - loss: 0.1169 - accuracy: 0.9760\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 58s - loss: 0.1247 - accuracy: 0.9745\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 57s - loss: 0.1271 - accuracy: 0.9721\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 57s - loss: 0.1227 - accuracy: 0.9731\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 57s - loss: 0.1247 - accuracy: 0.9729\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 56s - loss: 0.1270 - accuracy: 0.9728\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 56s - loss: 0.1232 - accuracy: 0.9736\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 56s - loss: 0.1195 - accuracy: 0.9744\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 56s - loss: 0.1160 - accuracy: 0.9752\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 56s - loss: 0.1132 - accuracy: 0.9759\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 55s - loss: 0.1110 - accuracy: 0.9757\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 55s - loss: 0.1080 - accuracy: 0.9764\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 55s - loss: 0.1060 - accuracy: 0.9770\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 55s - loss: 0.1095 - accuracy: 0.9752\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 55s - loss: 0.1156 - accuracy: 0.9734\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 54s - loss: 0.1304 - accuracy: 0.9733\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 54s - loss: 0.1276 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 54s - loss: 0.1255 - accuracy: 0.9738\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 54s - loss: 0.1279 - accuracy: 0.9737\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 53s - loss: 0.1257 - accuracy: 0.9743\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 53s - loss: 0.1300 - accuracy: 0.9735\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 53s - loss: 0.1274 - accuracy: 0.9741\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 53s - loss: 0.1249 - accuracy: 0.9746\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 52s - loss: 0.1224 - accuracy: 0.9751\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 52s - loss: 0.1204 - accuracy: 0.9756\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 52s - loss: 0.1201 - accuracy: 0.9755\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 52s - loss: 0.1178 - accuracy: 0.9760\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 51s - loss: 0.1247 - accuracy: 0.9752\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 51s - loss: 0.1243 - accuracy: 0.9751\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 50s - loss: 0.1236 - accuracy: 0.9753\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 50s - loss: 0.1214 - accuracy: 0.9757\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 50s - loss: 0.1198 - accuracy: 0.9756\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 50s - loss: 0.1180 - accuracy: 0.9760\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 50s - loss: 0.1161 - accuracy: 0.9764\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 50s - loss: 0.1163 - accuracy: 0.9763\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 49s - loss: 0.1160 - accuracy: 0.9762\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 49s - loss: 0.1143 - accuracy: 0.9766\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 49s - loss: 0.1260 - accuracy: 0.9755\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 48s - loss: 0.1261 - accuracy: 0.9749\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 48s - loss: 0.1260 - accuracy: 0.9748\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 48s - loss: 0.1241 - accuracy: 0.9751\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 48s - loss: 0.1222 - accuracy: 0.9755\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 47s - loss: 0.1224 - accuracy: 0.9750\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 47s - loss: 0.1206 - accuracy: 0.9753\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 47s - loss: 0.1189 - accuracy: 0.9757\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 47s - loss: 0.1176 - accuracy: 0.9760\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 46s - loss: 0.1162 - accuracy: 0.9764\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 46s - loss: 0.1149 - accuracy: 0.9767\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 46s - loss: 0.1151 - accuracy: 0.9766\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 46s - loss: 0.1137 - accuracy: 0.9769\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 45s - loss: 0.1125 - accuracy: 0.9768\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 45s - loss: 0.1178 - accuracy: 0.9759\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 45s - loss: 0.1233 - accuracy: 0.9754\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 45s - loss: 0.1219 - accuracy: 0.9757\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 45s - loss: 0.1210 - accuracy: 0.9756\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 44s - loss: 0.1224 - accuracy: 0.9755\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 44s - loss: 0.1214 - accuracy: 0.9758\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 44s - loss: 0.1223 - accuracy: 0.9753\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 44s - loss: 0.1208 - accuracy: 0.9756\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 43s - loss: 0.1196 - accuracy: 0.9759\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 43s - loss: 0.1189 - accuracy: 0.9758\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 43s - loss: 0.1210 - accuracy: 0.9754\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 43s - loss: 0.1201 - accuracy: 0.9753\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 42s - loss: 0.1201 - accuracy: 0.9749\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 42s - loss: 0.1213 - accuracy: 0.9745\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 42s - loss: 0.1215 - accuracy: 0.9741\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 41s - loss: 0.1221 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 41s - loss: 0.1209 - accuracy: 0.9743\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 41s - loss: 0.1196 - accuracy: 0.9746\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 41s - loss: 0.1206 - accuracy: 0.9742\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 40s - loss: 0.1193 - accuracy: 0.9744\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 40s - loss: 0.1181 - accuracy: 0.9747\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 40s - loss: 0.1171 - accuracy: 0.9750\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 40s - loss: 0.1169 - accuracy: 0.9749\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 39s - loss: 0.1191 - accuracy: 0.9745\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 39s - loss: 0.1182 - accuracy: 0.9748\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 39s - loss: 0.1171 - accuracy: 0.9750\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 39s - loss: 0.1172 - accuracy: 0.9750\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 39s - loss: 0.1162 - accuracy: 0.9752\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 38s - loss: 0.1183 - accuracy: 0.9749\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 38s - loss: 0.1219 - accuracy: 0.9748\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 38s - loss: 0.1230 - accuracy: 0.9744\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 38s - loss: 0.1222 - accuracy: 0.9744\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 37s - loss: 0.1210 - accuracy: 0.9746\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 37s - loss: 0.1200 - accuracy: 0.9749\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 37s - loss: 0.1202 - accuracy: 0.9748\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 37s - loss: 0.1193 - accuracy: 0.9750\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 37s - loss: 0.1208 - accuracy: 0.9747\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 36s - loss: 0.1237 - accuracy: 0.9744\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 36s - loss: 0.1252 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 36s - loss: 0.1241 - accuracy: 0.9743\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 36s - loss: 0.1295 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 35s - loss: 0.1285 - accuracy: 0.9742\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 35s - loss: 0.1279 - accuracy: 0.9741\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 35s - loss: 0.1275 - accuracy: 0.9741\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 35s - loss: 0.1274 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 34s - loss: 0.1264 - accuracy: 0.9743\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 34s - loss: 0.1259 - accuracy: 0.9740\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 34s - loss: 0.1270 - accuracy: 0.9739\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 33s - loss: 0.1270 - accuracy: 0.9734\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 33s - loss: 0.1268 - accuracy: 0.9733\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 33s - loss: 0.1266 - accuracy: 0.9730\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 0.1262 - accuracy: 0.9730\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 32s - loss: 0.1252 - accuracy: 0.9732\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 32s - loss: 0.1250 - accuracy: 0.9732\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 32s - loss: 0.1244 - accuracy: 0.9732\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 0.1236 - accuracy: 0.9731\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 31s - loss: 0.1228 - accuracy: 0.9733\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 31s - loss: 0.1237 - accuracy: 0.9731\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 0.1262 - accuracy: 0.9726\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 30s - loss: 0.1253 - accuracy: 0.9728\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 30s - loss: 0.1247 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 30s - loss: 0.1257 - accuracy: 0.9720\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 0.1248 - accuracy: 0.9722\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 29s - loss: 0.1253 - accuracy: 0.9720\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 29s - loss: 0.1244 - accuracy: 0.9722\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 29s - loss: 0.1254 - accuracy: 0.9719\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.1250 - accuracy: 0.9719\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 28s - loss: 0.1243 - accuracy: 0.9721\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 28s - loss: 0.1235 - accuracy: 0.9723\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 28s - loss: 0.1243 - accuracy: 0.9723\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 27s - loss: 0.1234 - accuracy: 0.9725\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 27s - loss: 0.1228 - accuracy: 0.9726\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 27s - loss: 0.1220 - accuracy: 0.9728\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.1229 - accuracy: 0.9726\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 26s - loss: 0.1221 - accuracy: 0.9728\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 26s - loss: 0.1217 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 26s - loss: 0.1210 - accuracy: 0.9729\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 26s - loss: 0.1216 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 25s - loss: 0.1217 - accuracy: 0.9727\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 25s - loss: 0.1221 - accuracy: 0.9724\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.1214 - accuracy: 0.9726\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.1210 - accuracy: 0.9726\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 24s - loss: 0.1202 - accuracy: 0.9728\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 24s - loss: 0.1217 - accuracy: 0.9725\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.1219 - accuracy: 0.9725\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.1223 - accuracy: 0.9721\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 23s - loss: 0.1216 - accuracy: 0.9723\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 0.1211 - accuracy: 0.9723\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.1230 - accuracy: 0.9721\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 22s - loss: 0.1233 - accuracy: 0.9720\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 22s - loss: 0.1225 - accuracy: 0.9722\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.1219 - accuracy: 0.9724\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.1219 - accuracy: 0.9722\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.1289 - accuracy: 0.9718\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 21s - loss: 0.1292 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.1287 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.1295 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.1300 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.1293 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.1293 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.1289 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.1284 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.1277 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.1273 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.1270 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.1264 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.1257 - accuracy: 0.9712\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.1280 - accuracy: 0.9705\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.1300 - accuracy: 0.9702\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.1319 - accuracy: 0.9700\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.1312 - accuracy: 0.9702\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.1307 - accuracy: 0.9701\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.1302 - accuracy: 0.9701\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.1295 - accuracy: 0.9703\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.1318 - accuracy: 0.9701\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.1319 - accuracy: 0.9701\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.1313 - accuracy: 0.9703\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.1306 - accuracy: 0.9704\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.1300 - accuracy: 0.9706\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1294 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.1290 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.1284 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.1280 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.1275 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.1283 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.1280 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1288 - accuracy: 0.9705\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.1282 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.1276 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1272 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1298 - accuracy: 0.9705\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.1292 - accuracy: 0.9706\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.1286 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1280 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.1280 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.1286 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.1281 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.1276 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.1272 - accuracy: 0.9708 \n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.1295 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.1294 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.1299 - accuracy: 0.9704\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.1293 - accuracy: 0.9705\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.1288 - accuracy: 0.9707\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.1284 - accuracy: 0.9706\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.1278 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.1288 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.1283 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.1277 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.1281 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.1276 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.1271 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.1319 - accuracy: 0.9709\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.1318 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.1313 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.1318 - accuracy: 0.9708\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.1312 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.1307 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.1301 - accuracy: 0.9712\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.1296 - accuracy: 0.9713\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.1293 - accuracy: 0.9713\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.1287 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.1289 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.1290 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.1289 - accuracy: 0.9714\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.1290 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.1289 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.1285 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.1286 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.1293 - accuracy: 0.9710\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9712\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9711\n",
      "Epoch 9: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 89s 354ms/step - loss: 0.1294 - accuracy: 0.9709 - val_loss: 0.0581 - val_accuracy: 0.9834\n",
      "Epoch 10/15\n",
      "\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:50 - loss: 0.0557 - accuracy: 0.9688\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:09 - loss: 0.0449 - accuracy: 0.9844\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:13 - loss: 0.0301 - accuracy: 0.9896\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:10 - loss: 0.0232 - accuracy: 0.9922\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:10 - loss: 0.0187 - accuracy: 0.9937\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 0.0364 - accuracy: 0.9896\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.0798 - accuracy: 0.9821\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.0750 - accuracy: 0.9805\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:09 - loss: 0.0825 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:10 - loss: 0.0765 - accuracy: 0.9781\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:11 - loss: 0.0942 - accuracy: 0.9773\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:10 - loss: 0.0897 - accuracy: 0.9766\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:09 - loss: 0.1009 - accuracy: 0.9760\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:09 - loss: 0.0951 - accuracy: 0.9777\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:08 - loss: 0.0894 - accuracy: 0.9792\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:07 - loss: 0.0859 - accuracy: 0.9785\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:07 - loss: 0.0811 - accuracy: 0.9798\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:06 - loss: 0.0769 - accuracy: 0.9809\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:05 - loss: 0.0729 - accuracy: 0.9819\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.0693 - accuracy: 0.9828\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.0661 - accuracy: 0.9836\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.0631 - accuracy: 0.9844\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.0622 - accuracy: 0.9837\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.0608 - accuracy: 0.9831\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.0603 - accuracy: 0.9825\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:03 - loss: 0.0581 - accuracy: 0.9832\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.0567 - accuracy: 0.9838\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.0626 - accuracy: 0.9821\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:02 - loss: 0.0747 - accuracy: 0.9817\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.0822 - accuracy: 0.9802\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.0796 - accuracy: 0.9808\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:01 - loss: 0.0780 - accuracy: 0.9814\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.0779 - accuracy: 0.9811\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.0789 - accuracy: 0.9807\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.0767 - accuracy: 0.9812\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.0756 - accuracy: 0.9818\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.0736 - accuracy: 0.9823\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.0719 - accuracy: 0.9827 \n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.0711 - accuracy: 0.9824\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.0727 - accuracy: 0.9820\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.0709 - accuracy: 0.9825\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.0698 - accuracy: 0.9829\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 0.0682 - accuracy: 0.9833\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.0672 - accuracy: 0.9830\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.0672 - accuracy: 0.9826\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.0660 - accuracy: 0.9830\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.0684 - accuracy: 0.9820\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.0670 - accuracy: 0.9824\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.0657 - accuracy: 0.9828\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.0649 - accuracy: 0.9825\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.0640 - accuracy: 0.9828\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 56s - loss: 0.0667 - accuracy: 0.9826\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 56s - loss: 0.0674 - accuracy: 0.9823\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.0673 - accuracy: 0.9821\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.0661 - accuracy: 0.9824\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 55s - loss: 0.0654 - accuracy: 0.9821\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.0652 - accuracy: 0.9819\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.0642 - accuracy: 0.9822\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.0640 - accuracy: 0.9820\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 54s - loss: 0.0631 - accuracy: 0.9823\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 54s - loss: 0.0630 - accuracy: 0.9821\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.0636 - accuracy: 0.9819\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 53s - loss: 0.0632 - accuracy: 0.9816\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.0628 - accuracy: 0.9814\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 53s - loss: 0.0618 - accuracy: 0.9817\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 52s - loss: 0.0609 - accuracy: 0.9820\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 52s - loss: 0.0604 - accuracy: 0.9823\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.0597 - accuracy: 0.9825\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 51s - loss: 0.0589 - accuracy: 0.9828\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 51s - loss: 0.0585 - accuracy: 0.9830\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.0577 - accuracy: 0.9833\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 51s - loss: 0.0573 - accuracy: 0.9831\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.0567 - accuracy: 0.9833\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.0583 - accuracy: 0.9831\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.0602 - accuracy: 0.9829\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.0613 - accuracy: 0.9827\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 49s - loss: 0.0606 - accuracy: 0.9830\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.0600 - accuracy: 0.9832\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.0614 - accuracy: 0.9822\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.0615 - accuracy: 0.9820\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 48s - loss: 0.0611 - accuracy: 0.9823\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.0651 - accuracy: 0.9809\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.0643 - accuracy: 0.9812\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.0660 - accuracy: 0.9810\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.0696 - accuracy: 0.9801\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.0708 - accuracy: 0.9797\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.0707 - accuracy: 0.9792\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.0701 - accuracy: 0.9794\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.0694 - accuracy: 0.9796\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.0719 - accuracy: 0.9788\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.0717 - accuracy: 0.9787\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.0710 - accuracy: 0.9789\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 45s - loss: 0.0703 - accuracy: 0.9792\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.0698 - accuracy: 0.9794\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.0691 - accuracy: 0.9796\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.0716 - accuracy: 0.9788\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.0715 - accuracy: 0.9787\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.0708 - accuracy: 0.9790\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.0711 - accuracy: 0.9785\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.0722 - accuracy: 0.9778\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.0728 - accuracy: 0.9777\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.0726 - accuracy: 0.9776\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.0720 - accuracy: 0.9779\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.0785 - accuracy: 0.9775\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.0809 - accuracy: 0.9771\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.0808 - accuracy: 0.9770\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.0802 - accuracy: 0.9772\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.0797 - accuracy: 0.9771\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.0789 - accuracy: 0.9774\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.0782 - accuracy: 0.9776\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.0783 - accuracy: 0.9775\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.0794 - accuracy: 0.9774\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.0805 - accuracy: 0.9768\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.0798 - accuracy: 0.9770\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.0805 - accuracy: 0.9769\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.0863 - accuracy: 0.9768\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.0857 - accuracy: 0.9770\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.0850 - accuracy: 0.9772\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.0861 - accuracy: 0.9772\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.0870 - accuracy: 0.9771\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.0871 - accuracy: 0.9770\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.0883 - accuracy: 0.9767\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.0884 - accuracy: 0.9766\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.0886 - accuracy: 0.9763\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.0879 - accuracy: 0.9765\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.0875 - accuracy: 0.9764\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.0937 - accuracy: 0.9764\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.0943 - accuracy: 0.9761\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.0961 - accuracy: 0.9760\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.0977 - accuracy: 0.9760\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.0973 - accuracy: 0.9759\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.0971 - accuracy: 0.9759\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.0987 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.0984 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.0978 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.1009 - accuracy: 0.9752\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.1002 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.0995 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.0988 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.0981 - accuracy: 0.9759\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.0977 - accuracy: 0.9758\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.0978 - accuracy: 0.9758\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.1057 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.1058 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.1055 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.1053 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.1055 - accuracy: 0.9747\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.1052 - accuracy: 0.9747\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.1061 - accuracy: 0.9746\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.1054 - accuracy: 0.9748\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.1048 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.1041 - accuracy: 0.9751\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.1049 - accuracy: 0.9751\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.1043 - accuracy: 0.9752\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.1047 - accuracy: 0.9752\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.1044 - accuracy: 0.9752\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.1041 - accuracy: 0.9751\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.1044 - accuracy: 0.9749\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.1043 - accuracy: 0.9748\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.1055 - accuracy: 0.9748\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.1049 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.1043 - accuracy: 0.9751\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.1037 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.1031 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.1026 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.1032 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.1029 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.1023 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.1018 - accuracy: 0.9758\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.1017 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.1024 - accuracy: 0.9751\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.1019 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.1020 - accuracy: 0.9749\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.1026 - accuracy: 0.9745\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.1031 - accuracy: 0.9743\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.1034 - accuracy: 0.9743\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.1044 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.1039 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.1037 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.1031 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.1029 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.1025 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.1019 - accuracy: 0.9742\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.1038 - accuracy: 0.9738\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.1032 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.1037 - accuracy: 0.9738\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.1032 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.1028 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.1024 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.1019 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.1017 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.1012 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.1009 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.1031 - accuracy: 0.9737\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.1025 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.1021 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.1017 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.1016 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.1021 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.1030 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.1031 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.1030 - accuracy: 0.9739\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.1033 - accuracy: 0.9738\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.1028 - accuracy: 0.9740\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.1023 - accuracy: 0.9741\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.1020 - accuracy: 0.9742\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.1016 - accuracy: 0.9743\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.1011 - accuracy: 0.9745\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.1007 - accuracy: 0.9746\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.1002 - accuracy: 0.9747\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.0998 - accuracy: 0.9748\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.0993 - accuracy: 0.9749\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.0991 - accuracy: 0.9749\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0986 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.0986 - accuracy: 0.9750\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.0983 - accuracy: 0.9751 \n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0978 - accuracy: 0.9752\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.0974 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.0970 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0966 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0970 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.0969 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.0967 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0963 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.0960 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.0974 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0970 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0965 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.0969 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0965 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0961 - accuracy: 0.9758\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.0957 - accuracy: 0.9759\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.0962 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0962 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0967 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.0969 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0968 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0964 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0962 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0967 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0964 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0963 - accuracy: 0.9753\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.0959 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0956 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0958 - accuracy: 0.9754\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0954 - accuracy: 0.9755\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9756\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9757\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9758\n",
      "Epoch 10: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 90s 359ms/step - loss: 0.0942 - accuracy: 0.9758 - val_loss: 0.0684 - val_accuracy: 0.9834\n",
      "Epoch 11/15\n",
      "\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:45 - loss: 0.1714 - accuracy: 0.9688\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:04 - loss: 0.0997 - accuracy: 0.9688\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:09 - loss: 0.0714 - accuracy: 0.9792\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:12 - loss: 0.0637 - accuracy: 0.9766\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 0.0510 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:12 - loss: 0.0447 - accuracy: 0.9844\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:12 - loss: 0.0487 - accuracy: 0.9821\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:13 - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:15 - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:14 - loss: 0.0345 - accuracy: 0.9875\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:15 - loss: 0.0319 - accuracy: 0.9886\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:14 - loss: 0.0320 - accuracy: 0.9870\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:13 - loss: 0.0310 - accuracy: 0.9880\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:13 - loss: 0.0289 - accuracy: 0.9888\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:13 - loss: 0.0273 - accuracy: 0.9896\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:12 - loss: 0.0260 - accuracy: 0.9902\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:13 - loss: 0.0248 - accuracy: 0.9908\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:12 - loss: 0.0238 - accuracy: 0.9913\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:11 - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:11 - loss: 0.0267 - accuracy: 0.9906\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:10 - loss: 0.0330 - accuracy: 0.9881\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:10 - loss: 0.0328 - accuracy: 0.9872\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:09 - loss: 0.0364 - accuracy: 0.9851\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:09 - loss: 0.0807 - accuracy: 0.9805\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:08 - loss: 0.0790 - accuracy: 0.9800\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:08 - loss: 0.0761 - accuracy: 0.9808\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:08 - loss: 0.0733 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:07 - loss: 0.0710 - accuracy: 0.9821\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:07 - loss: 0.0690 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:07 - loss: 0.0789 - accuracy: 0.9802\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:06 - loss: 0.0896 - accuracy: 0.9788\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:06 - loss: 0.0879 - accuracy: 0.9785\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:06 - loss: 0.0890 - accuracy: 0.9782\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:06 - loss: 0.0864 - accuracy: 0.9789\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:05 - loss: 0.0875 - accuracy: 0.9786\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:05 - loss: 0.0852 - accuracy: 0.9792\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:04 - loss: 0.0829 - accuracy: 0.9797\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:04 - loss: 0.0893 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:04 - loss: 0.0986 - accuracy: 0.9768\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 1:03 - loss: 0.1009 - accuracy: 0.9766\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 1:03 - loss: 0.0999 - accuracy: 0.9764\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 1:03 - loss: 0.0977 - accuracy: 0.9769\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 1:02 - loss: 0.0969 - accuracy: 0.9767\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 1:03 - loss: 0.0947 - accuracy: 0.9773\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 1:02 - loss: 0.0927 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 1:02 - loss: 0.0941 - accuracy: 0.9776\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 1:02 - loss: 0.0939 - accuracy: 0.9774\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 1:01 - loss: 0.0947 - accuracy: 0.9772\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 1:01 - loss: 0.0928 - accuracy: 0.9777\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 1:01 - loss: 0.0939 - accuracy: 0.9775\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 1:00 - loss: 0.0923 - accuracy: 0.9779\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 1:00 - loss: 0.0933 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 59s - loss: 0.0918 - accuracy: 0.9782 \n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 59s - loss: 0.0902 - accuracy: 0.9786\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 59s - loss: 0.0936 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 58s - loss: 0.0987 - accuracy: 0.9777\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 58s - loss: 0.0970 - accuracy: 0.9781\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 58s - loss: 0.0978 - accuracy: 0.9779\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 57s - loss: 0.0973 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 57s - loss: 0.0996 - accuracy: 0.9771\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 57s - loss: 0.0981 - accuracy: 0.9775\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 56s - loss: 0.0967 - accuracy: 0.9778\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 56s - loss: 0.0952 - accuracy: 0.9782\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 55s - loss: 0.0940 - accuracy: 0.9785\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.0927 - accuracy: 0.9788\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 55s - loss: 0.0930 - accuracy: 0.9787\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 54s - loss: 0.0916 - accuracy: 0.9790\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 54s - loss: 0.0903 - accuracy: 0.9793\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 54s - loss: 0.0894 - accuracy: 0.9792\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 53s - loss: 0.0881 - accuracy: 0.9795\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 53s - loss: 0.0886 - accuracy: 0.9793\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.0885 - accuracy: 0.9792\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 52s - loss: 0.0877 - accuracy: 0.9795\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 52s - loss: 0.0879 - accuracy: 0.9793\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.0869 - accuracy: 0.9796\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.0878 - accuracy: 0.9790\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.0871 - accuracy: 0.9793\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 50s - loss: 0.0873 - accuracy: 0.9792\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 50s - loss: 0.0863 - accuracy: 0.9794\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.0854 - accuracy: 0.9797\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.0844 - accuracy: 0.9799\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.0840 - accuracy: 0.9798\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 48s - loss: 0.0830 - accuracy: 0.9800\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.0820 - accuracy: 0.9803\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.0812 - accuracy: 0.9805\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.0803 - accuracy: 0.9807\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.0801 - accuracy: 0.9806\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.0792 - accuracy: 0.9808\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.0793 - accuracy: 0.9803\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 46s - loss: 0.0805 - accuracy: 0.9802\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.0797 - accuracy: 0.9804\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.0788 - accuracy: 0.9806\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 45s - loss: 0.0781 - accuracy: 0.9808\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.0773 - accuracy: 0.9811\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.0766 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.0772 - accuracy: 0.9808\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.0769 - accuracy: 0.9803\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.0763 - accuracy: 0.9805\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.0756 - accuracy: 0.9807\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.0765 - accuracy: 0.9806\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.0757 - accuracy: 0.9808\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.0753 - accuracy: 0.9807\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.0746 - accuracy: 0.9809\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.0739 - accuracy: 0.9811\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.0733 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 42s - loss: 0.0727 - accuracy: 0.9814\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.0739 - accuracy: 0.9813\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.0733 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.0735 - accuracy: 0.9814\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.0729 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.0723 - accuracy: 0.9817\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 40s - loss: 0.0727 - accuracy: 0.9816\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.0741 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.0736 - accuracy: 0.9814\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.0745 - accuracy: 0.9810\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.0775 - accuracy: 0.9809\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.0770 - accuracy: 0.9810\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.0763 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 38s - loss: 0.0758 - accuracy: 0.9814\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.0752 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.0746 - accuracy: 0.9817\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.0749 - accuracy: 0.9816\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.0753 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.0748 - accuracy: 0.9816\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.0786 - accuracy: 0.9810\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.0780 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.0778 - accuracy: 0.9811\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.0773 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.0768 - accuracy: 0.9813\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.0763 - accuracy: 0.9815\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.0762 - accuracy: 0.9812\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.0757 - accuracy: 0.9813\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.0752 - accuracy: 0.9814\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.0747 - accuracy: 0.9816\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.0741 - accuracy: 0.9817\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.0741 - accuracy: 0.9816\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.0737 - accuracy: 0.9818\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.0732 - accuracy: 0.9819\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.0732 - accuracy: 0.9818\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.0727 - accuracy: 0.9819\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.0722 - accuracy: 0.9820\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.0717 - accuracy: 0.9822\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.0712 - accuracy: 0.9823\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.0707 - accuracy: 0.9824\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.0703 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.0704 - accuracy: 0.9824\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.0704 - accuracy: 0.9824\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.0699 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.0695 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.0693 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.0689 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.0684 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.0680 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.0688 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.0684 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.0684 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.0680 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.0675 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.0675 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.0670 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.0680 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.0678 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.0676 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.0678 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.0679 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.0679 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.0675 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.0675 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.0672 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.0670 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.0673 - accuracy: 0.9823\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.0674 - accuracy: 0.9822\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.0673 - accuracy: 0.9823\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.0669 - accuracy: 0.9824\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.0665 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.0662 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.0658 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.0663 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.0665 - accuracy: 0.9824\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.0662 - accuracy: 0.9825\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.0659 - accuracy: 0.9826\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.0655 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.0652 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.0648 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.0661 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.0658 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.0662 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.0658 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.0655 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.0652 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.0653 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.0653 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.0650 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.0646 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.0645 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.0643 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.0640 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.0643 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.0640 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.0637 - accuracy: 0.9834\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.0634 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.0633 - accuracy: 0.9834\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.0630 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.0627 - accuracy: 0.9836\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.0647 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.0644 - accuracy: 0.9836\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.0652 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.0650 - accuracy: 0.9834\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.0648 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.0645 - accuracy: 0.9836\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.0644 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.0642 - accuracy: 0.9836\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.0639 - accuracy: 0.9837\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0637 - accuracy: 0.9836\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.0649 - accuracy: 0.9835\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.0648 - accuracy: 0.9835 \n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0677 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.0683 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.0680 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0677 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0681 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.0685 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.0684 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0681 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.0678 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.0677 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0676 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0673 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.0670 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0667 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0666 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.0671 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.0668 - accuracy: 0.9832\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0667 - accuracy: 0.9833\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0668 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.0673 - accuracy: 0.9827\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0670 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0669 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0666 - accuracy: 0.9828\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0663 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0661 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0658 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.0655 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0655 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0653 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0650 - accuracy: 0.9831\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9830\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9829\n",
      "Epoch 11: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 89s 354ms/step - loss: 0.0669 - accuracy: 0.9830 - val_loss: 0.1041 - val_accuracy: 0.9758\n",
      "Epoch 12/15\n",
      "\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:54 - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:05 - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:09 - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:10 - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:12 - loss: 0.0348 - accuracy: 0.9937\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:12 - loss: 0.0502 - accuracy: 0.9844\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:12 - loss: 0.0833 - accuracy: 0.9821\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:13 - loss: 0.0729 - accuracy: 0.9844\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:13 - loss: 0.0657 - accuracy: 0.9861\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:12 - loss: 0.0596 - accuracy: 0.9875\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:11 - loss: 0.0686 - accuracy: 0.9858\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:10 - loss: 0.0754 - accuracy: 0.9844\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:10 - loss: 0.0700 - accuracy: 0.9856\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:10 - loss: 0.0678 - accuracy: 0.9844\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:09 - loss: 0.0862 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:08 - loss: 0.0964 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:08 - loss: 0.1022 - accuracy: 0.9743\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:07 - loss: 0.0967 - accuracy: 0.9757\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:06 - loss: 0.1161 - accuracy: 0.9753\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.1103 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:05 - loss: 0.1059 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:05 - loss: 0.1012 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.0997 - accuracy: 0.9783\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:04 - loss: 0.0956 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.0931 - accuracy: 0.9800\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:03 - loss: 0.1085 - accuracy: 0.9772\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.1045 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.1009 - accuracy: 0.9788\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:02 - loss: 0.0975 - accuracy: 0.9795\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.0952 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.0966 - accuracy: 0.9788\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.0981 - accuracy: 0.9775\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.0951 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.0925 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.1155 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.1123 - accuracy: 0.9774\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.1095 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.1068 - accuracy: 0.9786\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.1091 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.1103 - accuracy: 0.9773 \n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.1077 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.1055 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.1049 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.1025 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.1062 - accuracy: 0.9771\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.1086 - accuracy: 0.9769\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.1063 - accuracy: 0.9774\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.1105 - accuracy: 0.9759\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.1113 - accuracy: 0.9758\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.1174 - accuracy: 0.9744\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.1173 - accuracy: 0.9743\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 56s - loss: 0.1183 - accuracy: 0.9742\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 56s - loss: 0.1166 - accuracy: 0.9746\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.1159 - accuracy: 0.9745\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.1138 - accuracy: 0.9750\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.1123 - accuracy: 0.9749\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.1122 - accuracy: 0.9748\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.1110 - accuracy: 0.9747\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.1112 - accuracy: 0.9746\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.1095 - accuracy: 0.9750\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.1080 - accuracy: 0.9754\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.1065 - accuracy: 0.9758\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.1058 - accuracy: 0.9757\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.1127 - accuracy: 0.9746\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.1115 - accuracy: 0.9745\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.1099 - accuracy: 0.9749\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.1090 - accuracy: 0.9748\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.1084 - accuracy: 0.9747\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.1069 - accuracy: 0.9751\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.1084 - accuracy: 0.9746\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.1086 - accuracy: 0.9745\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.1084 - accuracy: 0.9744\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.1072 - accuracy: 0.9747\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.1058 - accuracy: 0.9751\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.1045 - accuracy: 0.9754\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.1031 - accuracy: 0.9757\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.1018 - accuracy: 0.9761\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.1005 - accuracy: 0.9764\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.0993 - accuracy: 0.9767\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.0981 - accuracy: 0.9770\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.0998 - accuracy: 0.9765\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 0.0990 - accuracy: 0.9764\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.0987 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.1000 - accuracy: 0.9762\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.0989 - accuracy: 0.9765\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 0.1008 - accuracy: 0.9764\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.0996 - accuracy: 0.9767\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.0990 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 0.0987 - accuracy: 0.9761\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.0986 - accuracy: 0.9757\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.0976 - accuracy: 0.9760\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 43s - loss: 0.0966 - accuracy: 0.9762\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 0.0991 - accuracy: 0.9758\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.0983 - accuracy: 0.9761\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.0974 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 42s - loss: 0.0964 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.0954 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.0974 - accuracy: 0.9767\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.0964 - accuracy: 0.9770\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 0.0986 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.1029 - accuracy: 0.9765\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.1020 - accuracy: 0.9767\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.1020 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.1021 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.1041 - accuracy: 0.9762\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.1039 - accuracy: 0.9761\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.1032 - accuracy: 0.9761\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.1023 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.1014 - accuracy: 0.9765\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.1017 - accuracy: 0.9764\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.1014 - accuracy: 0.9764\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.1006 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.0999 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.0991 - accuracy: 0.9770\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.1010 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.1002 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.1005 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 36s - loss: 0.0997 - accuracy: 0.9770\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.1001 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.1020 - accuracy: 0.9763\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.1012 - accuracy: 0.9765\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.1004 - accuracy: 0.9767\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.1006 - accuracy: 0.9766\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.0998 - accuracy: 0.9768\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.0990 - accuracy: 0.9770\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.0983 - accuracy: 0.9772\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.0992 - accuracy: 0.9771\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.0987 - accuracy: 0.9771\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.0980 - accuracy: 0.9772\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.0973 - accuracy: 0.9774\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.0965 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.0960 - accuracy: 0.9775\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.0953 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.0954 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.0949 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.0943 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.0939 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.0934 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.0927 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.0932 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.0944 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.0941 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.0934 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.0928 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.0964 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.0958 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.0961 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.0959 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.0953 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.0947 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.0951 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.0945 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.0950 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.0944 - accuracy: 0.9783\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.0940 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.0936 - accuracy: 0.9786\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.0930 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.0925 - accuracy: 0.9788\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.0920 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.0925 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.0920 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.0917 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.0951 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.0958 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.0956 - accuracy: 0.9786\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.0969 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.0969 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.0963 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.0958 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.0953 - accuracy: 0.9785\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.0948 - accuracy: 0.9786\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.0942 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.0937 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.0932 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.0929 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.0924 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.0920 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.0918 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.0939 - accuracy: 0.9785\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.0938 - accuracy: 0.9785\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.0950 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.0951 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.0952 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.0951 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.0946 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.0941 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.0941 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.0952 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.0950 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.0952 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.0953 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.0948 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.0975 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.0972 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.0971 - accuracy: 0.9775\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.0970 - accuracy: 0.9774\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.0965 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.0961 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.0956 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.0952 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.0950 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.0948 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.0945 - accuracy: 0.9776\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.0941 - accuracy: 0.9777\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.0937 - accuracy: 0.9778\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.0932 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 0.0928 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.0926 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.0927 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.0927 - accuracy: 0.9779\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.0923 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.0919 - accuracy: 0.9781\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.0916 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0918 - accuracy: 0.9780\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.0914 - accuracy: 0.9781 \n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.0910 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0909 - accuracy: 0.9782\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.0906 - accuracy: 0.9783\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.0902 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0899 - accuracy: 0.9785\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0899 - accuracy: 0.9784\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.0895 - accuracy: 0.9785\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.0891 - accuracy: 0.9786\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0887 - accuracy: 0.9787\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.0883 - accuracy: 0.9788\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.0879 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0876 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0874 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.0871 - accuracy: 0.9791\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0876 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0872 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 4s - loss: 0.0877 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.0874 - accuracy: 0.9790\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0870 - accuracy: 0.9791\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0867 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.0866 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0871 - accuracy: 0.9791\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0868 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0866 - accuracy: 0.9793\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0867 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0864 - accuracy: 0.9793\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0863 - accuracy: 0.9793\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.0862 - accuracy: 0.9792\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0860 - accuracy: 0.9793\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0859 - accuracy: 0.9793\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0856 - accuracy: 0.9794\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9791\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9789\n",
      "Epoch 12: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.0897 - accuracy: 0.9789 - val_loss: 0.0346 - val_accuracy: 0.9914\n",
      "Epoch 13/15\n",
      "\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:48 - loss: 1.9841e-04 - accuracy: 1.0000\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:09 - loss: 0.0040 - accuracy: 1.0000    \n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 0.0597 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:10 - loss: 0.0532 - accuracy: 0.9766\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 0.0940 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:11 - loss: 0.0879 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:09 - loss: 0.1253 - accuracy: 0.9643\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:11 - loss: 0.1118 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:11 - loss: 0.1142 - accuracy: 0.9618\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:10 - loss: 0.1029 - accuracy: 0.9656\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:09 - loss: 0.1113 - accuracy: 0.9659\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:09 - loss: 0.1026 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:08 - loss: 0.0948 - accuracy: 0.9712\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:08 - loss: 0.1240 - accuracy: 0.9665\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:09 - loss: 0.1165 - accuracy: 0.9688\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:10 - loss: 0.1105 - accuracy: 0.9707\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:10 - loss: 0.1042 - accuracy: 0.9724\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:10 - loss: 0.0985 - accuracy: 0.9740\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:09 - loss: 0.1044 - accuracy: 0.9737\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:09 - loss: 0.0992 - accuracy: 0.9750\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:08 - loss: 0.0945 - accuracy: 0.9762\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:08 - loss: 0.1038 - accuracy: 0.9744\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:07 - loss: 0.0995 - accuracy: 0.9755\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:07 - loss: 0.0953 - accuracy: 0.9766\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:06 - loss: 0.0916 - accuracy: 0.9775\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:05 - loss: 0.0904 - accuracy: 0.9772\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:05 - loss: 0.0917 - accuracy: 0.9757\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:05 - loss: 0.0884 - accuracy: 0.9766\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:04 - loss: 0.0896 - accuracy: 0.9763\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:04 - loss: 0.0892 - accuracy: 0.9760\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:03 - loss: 0.0865 - accuracy: 0.9768\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:03 - loss: 0.0849 - accuracy: 0.9766\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:03 - loss: 0.0823 - accuracy: 0.9773\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:03 - loss: 0.0842 - accuracy: 0.9770\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:03 - loss: 0.0840 - accuracy: 0.9768\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:03 - loss: 0.0816 - accuracy: 0.9774\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:03 - loss: 0.0798 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:03 - loss: 0.0777 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:03 - loss: 0.0766 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 1:03 - loss: 0.0747 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 1:03 - loss: 0.0778 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 1:03 - loss: 0.0830 - accuracy: 0.9777\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 1:03 - loss: 0.0849 - accuracy: 0.9767\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 1:03 - loss: 0.0830 - accuracy: 0.9773\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 1:03 - loss: 0.0947 - accuracy: 0.9757\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 1:02 - loss: 0.0950 - accuracy: 0.9755\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 1:02 - loss: 0.0942 - accuracy: 0.9754\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 1:02 - loss: 0.0937 - accuracy: 0.9753\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 1:02 - loss: 0.0941 - accuracy: 0.9751\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 1:01 - loss: 0.0923 - accuracy: 0.9756\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 1:01 - loss: 0.0906 - accuracy: 0.9761\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 1:01 - loss: 0.0909 - accuracy: 0.9760\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 1:00 - loss: 0.0921 - accuracy: 0.9758\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 1:01 - loss: 0.0922 - accuracy: 0.9757\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 1:01 - loss: 0.0908 - accuracy: 0.9761\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 1:00 - loss: 0.0943 - accuracy: 0.9754\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 1:00 - loss: 0.0926 - accuracy: 0.9759\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 1:00 - loss: 0.0913 - accuracy: 0.9763\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 59s - loss: 0.0897 - accuracy: 0.9767 \n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 59s - loss: 0.0883 - accuracy: 0.9771\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 58s - loss: 0.0869 - accuracy: 0.9775\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 58s - loss: 0.0859 - accuracy: 0.9773\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 58s - loss: 0.0849 - accuracy: 0.9777\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 58s - loss: 0.0836 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 57s - loss: 0.0828 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 57s - loss: 0.0833 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 56s - loss: 0.0822 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 56s - loss: 0.0843 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 56s - loss: 0.0835 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 55s - loss: 0.0867 - accuracy: 0.9777\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 55s - loss: 0.0855 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 55s - loss: 0.0850 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 54s - loss: 0.0838 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 54s - loss: 0.0827 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 54s - loss: 0.0821 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 53s - loss: 0.0835 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 53s - loss: 0.0826 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 53s - loss: 0.0815 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 52s - loss: 0.0821 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 52s - loss: 0.0839 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 52s - loss: 0.0848 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 52s - loss: 0.0838 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 51s - loss: 0.0880 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 51s - loss: 0.0869 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 50s - loss: 0.0918 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 50s - loss: 0.0926 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 50s - loss: 0.0916 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 49s - loss: 0.0907 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 49s - loss: 0.0897 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 49s - loss: 0.0888 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 48s - loss: 0.0879 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 48s - loss: 0.0896 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 48s - loss: 0.0912 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 47s - loss: 0.0905 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 47s - loss: 0.0912 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 47s - loss: 0.0902 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 46s - loss: 0.0893 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 46s - loss: 0.0939 - accuracy: 0.9777\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 46s - loss: 0.0936 - accuracy: 0.9776\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 45s - loss: 0.0930 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 45s - loss: 0.0956 - accuracy: 0.9774\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 45s - loss: 0.0948 - accuracy: 0.9776\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 44s - loss: 0.0939 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 44s - loss: 0.0931 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 44s - loss: 0.0924 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.0915 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 43s - loss: 0.0907 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 43s - loss: 0.0899 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 43s - loss: 0.0894 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 42s - loss: 0.0896 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 42s - loss: 0.0888 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 42s - loss: 0.0880 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.0873 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 41s - loss: 0.0866 - accuracy: 0.9794\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 41s - loss: 0.0860 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.0852 - accuracy: 0.9798\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 40s - loss: 0.0847 - accuracy: 0.9800\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 40s - loss: 0.0846 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.0847 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 39s - loss: 0.0865 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 39s - loss: 0.0859 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 38s - loss: 0.0861 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 38s - loss: 0.0869 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 38s - loss: 0.0866 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 37s - loss: 0.0880 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 37s - loss: 0.0877 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 37s - loss: 0.0881 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 36s - loss: 0.0878 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 36s - loss: 0.0918 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 36s - loss: 0.0927 - accuracy: 0.9776\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 35s - loss: 0.0920 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 35s - loss: 0.0914 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 35s - loss: 0.0907 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 35s - loss: 0.0906 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 34s - loss: 0.0899 - accuracy: 0.9782\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 34s - loss: 0.0894 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 34s - loss: 0.0901 - accuracy: 0.9779\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 34s - loss: 0.0903 - accuracy: 0.9778\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 33s - loss: 0.0897 - accuracy: 0.9780\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 33s - loss: 0.0891 - accuracy: 0.9781\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 33s - loss: 0.0884 - accuracy: 0.9783\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 32s - loss: 0.0878 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 32s - loss: 0.0876 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 32s - loss: 0.0871 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.0871 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 31s - loss: 0.0871 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 31s - loss: 0.0865 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.0861 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 30s - loss: 0.0886 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 30s - loss: 0.0880 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 30s - loss: 0.0877 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 29s - loss: 0.0872 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 29s - loss: 0.0866 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 29s - loss: 0.0877 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.0872 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 28s - loss: 0.0866 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 28s - loss: 0.0876 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.0874 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 27s - loss: 0.0869 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 27s - loss: 0.0874 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.0872 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.0867 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 26s - loss: 0.0864 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.0862 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.0857 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 25s - loss: 0.0856 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 25s - loss: 0.0856 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.0861 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 24s - loss: 0.0857 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 24s - loss: 0.0852 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.0848 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.0861 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 23s - loss: 0.0863 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.0858 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.0854 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 22s - loss: 0.0850 - accuracy: 0.9794\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 22s - loss: 0.0845 - accuracy: 0.9795\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.0841 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 21s - loss: 0.0841 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 21s - loss: 0.0837 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.0834 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.0839 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 20s - loss: 0.0834 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.0844 - accuracy: 0.9794\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.0839 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 19s - loss: 0.0851 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.0849 - accuracy: 0.9794\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.0847 - accuracy: 0.9795\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.0843 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 18s - loss: 0.0851 - accuracy: 0.9795\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.0854 - accuracy: 0.9795\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.0850 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 17s - loss: 0.0846 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.0845 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.0842 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 16s - loss: 0.0858 - accuracy: 0.9795\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.0854 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.0850 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.0846 - accuracy: 0.9798\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 15s - loss: 0.0841 - accuracy: 0.9799\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.0852 - accuracy: 0.9799\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.0849 - accuracy: 0.9800\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 14s - loss: 0.0846 - accuracy: 0.9799\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.0843 - accuracy: 0.9799\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.0849 - accuracy: 0.9798\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 13s - loss: 0.0845 - accuracy: 0.9799\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.0854 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.0850 - accuracy: 0.9797\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.0852 - accuracy: 0.9796\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 12s - loss: 0.0859 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.0857 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.0866 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 11s - loss: 0.0861 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0858 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.0867 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.0867 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0864 - accuracy: 0.9792 \n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.0861 - accuracy: 0.9793\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.0862 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0859 - accuracy: 0.9791\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0855 - accuracy: 0.9792\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.0874 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.0875 - accuracy: 0.9789\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0871 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.0876 - accuracy: 0.9790\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.0882 - accuracy: 0.9788\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0881 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0881 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.0878 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0874 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0900 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.0897 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.0893 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0889 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0899 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.0899 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0896 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0893 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0890 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0887 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0892 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0889 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.0886 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0885 - accuracy: 0.9784\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0882 - accuracy: 0.9785\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0879 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0876 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9787\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9786\n",
      "Epoch 13: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.0871 - accuracy: 0.9787 - val_loss: 0.0349 - val_accuracy: 0.9869\n",
      "Epoch 14/15\n",
      "\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:53 - loss: 0.1177 - accuracy: 0.9688\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:23 - loss: 0.1180 - accuracy: 0.9688\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:23 - loss: 0.1153 - accuracy: 0.9688\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:19 - loss: 0.0912 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:18 - loss: 0.0733 - accuracy: 0.9812\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:18 - loss: 0.0693 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:18 - loss: 0.0636 - accuracy: 0.9777\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:17 - loss: 0.0565 - accuracy: 0.9805\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:16 - loss: 0.0545 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:16 - loss: 0.0587 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:16 - loss: 0.0553 - accuracy: 0.9801\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:15 - loss: 0.0523 - accuracy: 0.9818\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:14 - loss: 0.0505 - accuracy: 0.9808\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:14 - loss: 0.0479 - accuracy: 0.9821\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:12 - loss: 0.0485 - accuracy: 0.9812\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:11 - loss: 0.0455 - accuracy: 0.9824\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:11 - loss: 0.0685 - accuracy: 0.9816\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:10 - loss: 0.0761 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:09 - loss: 0.0753 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:09 - loss: 0.0749 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:09 - loss: 0.0718 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:09 - loss: 0.0729 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:08 - loss: 0.0733 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:08 - loss: 0.0754 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:08 - loss: 0.0726 - accuracy: 0.9775\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:07 - loss: 0.0790 - accuracy: 0.9760\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:06 - loss: 0.0770 - accuracy: 0.9757\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:06 - loss: 0.0786 - accuracy: 0.9754\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:06 - loss: 0.0829 - accuracy: 0.9752\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:06 - loss: 0.0861 - accuracy: 0.9750\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:05 - loss: 0.0833 - accuracy: 0.9758\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:05 - loss: 0.0808 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:05 - loss: 0.0783 - accuracy: 0.9773\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:05 - loss: 0.0761 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:04 - loss: 0.0932 - accuracy: 0.9750\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:04 - loss: 0.0931 - accuracy: 0.9748\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:03 - loss: 0.0906 - accuracy: 0.9755\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:03 - loss: 0.0909 - accuracy: 0.9737\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:03 - loss: 0.0888 - accuracy: 0.9744\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 1:02 - loss: 0.0869 - accuracy: 0.9750\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 1:02 - loss: 0.0848 - accuracy: 0.9756\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 1:02 - loss: 0.0829 - accuracy: 0.9762\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 1:01 - loss: 0.0892 - accuracy: 0.9753\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 1:01 - loss: 0.0979 - accuracy: 0.9744\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 1:01 - loss: 0.0958 - accuracy: 0.9750\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 1:01 - loss: 0.0959 - accuracy: 0.9742\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 1:00 - loss: 0.0938 - accuracy: 0.9747\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 1:00 - loss: 0.0925 - accuracy: 0.9753\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 1:00 - loss: 0.0910 - accuracy: 0.9758\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 59s - loss: 0.0892 - accuracy: 0.9762 \n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 59s - loss: 0.0881 - accuracy: 0.9761\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 58s - loss: 0.0871 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 58s - loss: 0.0911 - accuracy: 0.9764\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 58s - loss: 0.0897 - accuracy: 0.9769\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.0887 - accuracy: 0.9767\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 58s - loss: 0.0891 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 57s - loss: 0.0878 - accuracy: 0.9770\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 57s - loss: 0.0863 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 57s - loss: 0.0857 - accuracy: 0.9772\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 56s - loss: 0.0843 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 56s - loss: 0.0829 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 56s - loss: 0.0818 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 55s - loss: 0.0811 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 55s - loss: 0.0800 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.0793 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 54s - loss: 0.0787 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 54s - loss: 0.0775 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 54s - loss: 0.0796 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.0786 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 53s - loss: 0.0777 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 53s - loss: 0.0767 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 52s - loss: 0.0768 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 52s - loss: 0.0758 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 52s - loss: 0.0755 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.0754 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.0755 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 51s - loss: 0.0748 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 51s - loss: 0.0752 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 51s - loss: 0.0747 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 50s - loss: 0.0757 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 50s - loss: 0.0748 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 50s - loss: 0.0740 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 49s - loss: 0.0731 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 49s - loss: 0.0724 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 49s - loss: 0.0720 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 49s - loss: 0.0712 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 48s - loss: 0.0718 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 48s - loss: 0.0715 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 48s - loss: 0.0722 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 48s - loss: 0.0715 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 47s - loss: 0.0713 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 47s - loss: 0.0707 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 47s - loss: 0.0711 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 46s - loss: 0.0704 - accuracy: 0.9791\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 46s - loss: 0.0733 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 46s - loss: 0.0727 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 45s - loss: 0.0744 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 45s - loss: 0.0741 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 45s - loss: 0.0746 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 45s - loss: 0.0742 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 44s - loss: 0.0753 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 44s - loss: 0.0774 - accuracy: 0.9770\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 44s - loss: 0.0778 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 43s - loss: 0.0771 - accuracy: 0.9769\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 43s - loss: 0.0766 - accuracy: 0.9771\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 43s - loss: 0.0761 - accuracy: 0.9770\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 43s - loss: 0.0812 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 42s - loss: 0.0810 - accuracy: 0.9766\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 42s - loss: 0.0803 - accuracy: 0.9768\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 42s - loss: 0.0797 - accuracy: 0.9770\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 41s - loss: 0.0791 - accuracy: 0.9772\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 41s - loss: 0.0789 - accuracy: 0.9771\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 41s - loss: 0.0791 - accuracy: 0.9770\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 41s - loss: 0.0784 - accuracy: 0.9772\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 40s - loss: 0.0778 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 40s - loss: 0.0771 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 40s - loss: 0.0767 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 39s - loss: 0.0760 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 39s - loss: 0.0774 - accuracy: 0.9777\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 39s - loss: 0.0803 - accuracy: 0.9773\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 38s - loss: 0.0799 - accuracy: 0.9773\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 38s - loss: 0.0806 - accuracy: 0.9772\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 38s - loss: 0.0804 - accuracy: 0.9771\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 38s - loss: 0.0798 - accuracy: 0.9773\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 37s - loss: 0.0791 - accuracy: 0.9775\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 37s - loss: 0.0789 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 37s - loss: 0.0784 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 36s - loss: 0.0793 - accuracy: 0.9775\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 36s - loss: 0.0800 - accuracy: 0.9775\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 36s - loss: 0.0796 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 35s - loss: 0.0790 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 35s - loss: 0.0785 - accuracy: 0.9777\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 35s - loss: 0.0779 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 34s - loss: 0.0807 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 34s - loss: 0.0802 - accuracy: 0.9775\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 34s - loss: 0.0796 - accuracy: 0.9777\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 33s - loss: 0.0795 - accuracy: 0.9774\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 33s - loss: 0.0790 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 33s - loss: 0.0784 - accuracy: 0.9777\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.0779 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 32s - loss: 0.0774 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 32s - loss: 0.0771 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.0766 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 31s - loss: 0.0761 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 31s - loss: 0.0770 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 31s - loss: 0.0765 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 30s - loss: 0.0760 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 30s - loss: 0.0756 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 30s - loss: 0.0756 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.0799 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 29s - loss: 0.0802 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 29s - loss: 0.0800 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.0795 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.0797 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 28s - loss: 0.0797 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.0805 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.0809 - accuracy: 0.9776\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 27s - loss: 0.0805 - accuracy: 0.9778\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 27s - loss: 0.0800 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.0796 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.0809 - accuracy: 0.9780\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 26s - loss: 0.0805 - accuracy: 0.9779\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.0801 - accuracy: 0.9781\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.0796 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 25s - loss: 0.0792 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.0788 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.0784 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 24s - loss: 0.0780 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 24s - loss: 0.0785 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.0780 - accuracy: 0.9786\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.0776 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 23s - loss: 0.0771 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.0770 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.0766 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 22s - loss: 0.0762 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.0760 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.0766 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.0768 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 21s - loss: 0.0764 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.0762 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.0780 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 20s - loss: 0.0780 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 20s - loss: 0.0781 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.0778 - accuracy: 0.9782\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 19s - loss: 0.0775 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 19s - loss: 0.0772 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.0770 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.0768 - accuracy: 0.9783\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 18s - loss: 0.0764 - accuracy: 0.9784\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.0760 - accuracy: 0.9785\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.0756 - accuracy: 0.9787\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 17s - loss: 0.0753 - accuracy: 0.9788\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 17s - loss: 0.0749 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.0745 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.0748 - accuracy: 0.9789\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 16s - loss: 0.0745 - accuracy: 0.9790\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.0741 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.0744 - accuracy: 0.9791\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 15s - loss: 0.0741 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.0737 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.0734 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 14s - loss: 0.0730 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 14s - loss: 0.0727 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.0724 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.0730 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 13s - loss: 0.0732 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.0728 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.0725 - accuracy: 0.9798\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 12s - loss: 0.0723 - accuracy: 0.9799\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.0721 - accuracy: 0.9799\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.0718 - accuracy: 0.9799\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.0725 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 11s - loss: 0.0721 - accuracy: 0.9798\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0727 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.0724 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 10s - loss: 0.0723 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0721 - accuracy: 0.9796 \n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.0718 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.0718 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0722 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0721 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.0722 - accuracy: 0.9792\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 8s - loss: 0.0719 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0721 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.0717 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 7s - loss: 0.0715 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0725 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0722 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.0723 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0720 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0717 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.0714 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 5s - loss: 0.0713 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0713 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0712 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.0715 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0712 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0717 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0720 - accuracy: 0.9793\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0717 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0715 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0715 - accuracy: 0.9794\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.0713 - accuracy: 0.9795\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0711 - accuracy: 0.9796\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0708 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0706 - accuracy: 0.9798\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9797\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9798\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9799\n",
      "Epoch 14: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.0698 - accuracy: 0.9799 - val_loss: 0.0484 - val_accuracy: 0.9884\n",
      "Epoch 15/15\n",
      "\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  1/250 [..............................] - ETA: 1:44 - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  2/250 [..............................] - ETA: 1:03 - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  3/250 [..............................] - ETA: 1:03 - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  4/250 [..............................] - ETA: 1:04 - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  5/250 [..............................] - ETA: 1:03 - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  6/250 [..............................] - ETA: 1:05 - loss: 0.0166 - accuracy: 0.9948\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  7/250 [..............................] - ETA: 1:05 - loss: 0.0302 - accuracy: 0.9911\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  8/250 [..............................] - ETA: 1:07 - loss: 0.0536 - accuracy: 0.9883\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "  9/250 [>.............................] - ETA: 1:11 - loss: 0.0610 - accuracy: 0.9861\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 10/250 [>.............................] - ETA: 1:12 - loss: 0.0566 - accuracy: 0.9875\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 11/250 [>.............................] - ETA: 1:13 - loss: 0.0515 - accuracy: 0.9886\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 12/250 [>.............................] - ETA: 1:15 - loss: 0.0488 - accuracy: 0.9896\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 13/250 [>.............................] - ETA: 1:15 - loss: 0.0453 - accuracy: 0.9904\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 14/250 [>.............................] - ETA: 1:15 - loss: 0.0421 - accuracy: 0.9911\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 15/250 [>.............................] - ETA: 1:14 - loss: 0.0872 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 16/250 [>.............................] - ETA: 1:13 - loss: 0.0828 - accuracy: 0.9863\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 17/250 [=>............................] - ETA: 1:13 - loss: 0.0861 - accuracy: 0.9853\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 18/250 [=>............................] - ETA: 1:13 - loss: 0.0825 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 19/250 [=>............................] - ETA: 1:13 - loss: 0.0791 - accuracy: 0.9852\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 20/250 [=>............................] - ETA: 1:10 - loss: 0.0776 - accuracy: 0.9855\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 21/250 [=>............................] - ETA: 1:11 - loss: 0.0742 - accuracy: 0.9862\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 22/250 [=>............................] - ETA: 1:10 - loss: 0.0785 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 23/250 [=>............................] - ETA: 1:10 - loss: 0.0769 - accuracy: 0.9860\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 24/250 [=>............................] - ETA: 1:10 - loss: 0.0739 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 25/250 [==>...........................] - ETA: 1:09 - loss: 0.0826 - accuracy: 0.9859\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 26/250 [==>...........................] - ETA: 1:09 - loss: 0.0794 - accuracy: 0.9865\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 27/250 [==>...........................] - ETA: 1:09 - loss: 0.0766 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 28/250 [==>...........................] - ETA: 1:08 - loss: 0.0781 - accuracy: 0.9863\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 29/250 [==>...........................] - ETA: 1:08 - loss: 0.0771 - accuracy: 0.9857\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 30/250 [==>...........................] - ETA: 1:07 - loss: 0.0778 - accuracy: 0.9840\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 31/250 [==>...........................] - ETA: 1:07 - loss: 0.0753 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 32/250 [==>...........................] - ETA: 1:06 - loss: 0.0730 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 33/250 [==>...........................] - ETA: 1:06 - loss: 0.0757 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 34/250 [===>..........................] - ETA: 1:05 - loss: 0.0777 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 35/250 [===>..........................] - ETA: 1:05 - loss: 0.0765 - accuracy: 0.9836\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 36/250 [===>..........................] - ETA: 1:05 - loss: 0.0763 - accuracy: 0.9832\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 37/250 [===>..........................] - ETA: 1:04 - loss: 0.0743 - accuracy: 0.9837\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 38/250 [===>..........................] - ETA: 1:04 - loss: 0.0754 - accuracy: 0.9833\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 39/250 [===>..........................] - ETA: 1:03 - loss: 0.0740 - accuracy: 0.9837\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 40/250 [===>..........................] - ETA: 1:03 - loss: 0.0728 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 41/250 [===>..........................] - ETA: 1:02 - loss: 0.0710 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 42/250 [====>.........................] - ETA: 1:02 - loss: 0.0695 - accuracy: 0.9849\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 43/250 [====>.........................] - ETA: 1:02 - loss: 0.0679 - accuracy: 0.9853\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 44/250 [====>.........................] - ETA: 1:01 - loss: 0.0666 - accuracy: 0.9856\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 45/250 [====>.........................] - ETA: 1:01 - loss: 0.0651 - accuracy: 0.9859\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 46/250 [====>.........................] - ETA: 1:00 - loss: 0.0646 - accuracy: 0.9862\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 47/250 [====>.........................] - ETA: 1:00 - loss: 0.0633 - accuracy: 0.9865\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 48/250 [====>.........................] - ETA: 1:00 - loss: 0.0622 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 49/250 [====>.........................] - ETA: 59s - loss: 0.0610 - accuracy: 0.9871 \n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 50/250 [=====>........................] - ETA: 59s - loss: 0.0622 - accuracy: 0.9861\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 51/250 [=====>........................] - ETA: 59s - loss: 0.0617 - accuracy: 0.9857\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 52/250 [=====>........................] - ETA: 59s - loss: 0.0611 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 53/250 [=====>........................] - ETA: 58s - loss: 0.0606 - accuracy: 0.9857\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 54/250 [=====>........................] - ETA: 58s - loss: 0.0662 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 55/250 [=====>........................] - ETA: 58s - loss: 0.0651 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 56/250 [=====>........................] - ETA: 57s - loss: 0.0645 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 57/250 [=====>........................] - ETA: 57s - loss: 0.0634 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 58/250 [=====>........................] - ETA: 57s - loss: 0.0624 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 59/250 [======>.......................] - ETA: 56s - loss: 0.0613 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 60/250 [======>.......................] - ETA: 56s - loss: 0.0603 - accuracy: 0.9853\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 61/250 [======>.......................] - ETA: 56s - loss: 0.0593 - accuracy: 0.9855\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 62/250 [======>.......................] - ETA: 55s - loss: 0.0619 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 63/250 [======>.......................] - ETA: 55s - loss: 0.0610 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 64/250 [======>.......................] - ETA: 55s - loss: 0.0615 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 65/250 [======>.......................] - ETA: 55s - loss: 0.0606 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 66/250 [======>.......................] - ETA: 54s - loss: 0.0598 - accuracy: 0.9852\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 67/250 [=======>......................] - ETA: 54s - loss: 0.0589 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 68/250 [=======>......................] - ETA: 54s - loss: 0.0582 - accuracy: 0.9856\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 69/250 [=======>......................] - ETA: 53s - loss: 0.0573 - accuracy: 0.9858\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 70/250 [=======>......................] - ETA: 53s - loss: 0.0565 - accuracy: 0.9860\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 71/250 [=======>......................] - ETA: 53s - loss: 0.0565 - accuracy: 0.9858\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 72/250 [=======>......................] - ETA: 53s - loss: 0.0559 - accuracy: 0.9860\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 73/250 [=======>......................] - ETA: 52s - loss: 0.0553 - accuracy: 0.9862\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 74/250 [=======>......................] - ETA: 52s - loss: 0.0546 - accuracy: 0.9864\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 75/250 [========>.....................] - ETA: 51s - loss: 0.0539 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 76/250 [========>.....................] - ETA: 51s - loss: 0.0542 - accuracy: 0.9863\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 77/250 [========>.....................] - ETA: 51s - loss: 0.0538 - accuracy: 0.9865\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 78/250 [========>.....................] - ETA: 51s - loss: 0.0535 - accuracy: 0.9863\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 79/250 [========>.....................] - ETA: 50s - loss: 0.0530 - accuracy: 0.9864\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 80/250 [========>.....................] - ETA: 50s - loss: 0.0524 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.0517 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 82/250 [========>.....................] - ETA: 49s - loss: 0.0511 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 83/250 [========>.....................] - ETA: 49s - loss: 0.0505 - accuracy: 0.9871\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.0500 - accuracy: 0.9873\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.0509 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 86/250 [=========>....................] - ETA: 48s - loss: 0.0503 - accuracy: 0.9872\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.0498 - accuracy: 0.9873\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.0492 - accuracy: 0.9875\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 89/250 [=========>....................] - ETA: 47s - loss: 0.0487 - accuracy: 0.9876\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 90/250 [=========>....................] - ETA: 46s - loss: 0.0484 - accuracy: 0.9874\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.0479 - accuracy: 0.9876\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.0488 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 93/250 [==========>...................] - ETA: 46s - loss: 0.0504 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.0516 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.0510 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 96/250 [==========>...................] - ETA: 45s - loss: 0.0506 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.0501 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.0497 - accuracy: 0.9872\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.0493 - accuracy: 0.9873\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.0488 - accuracy: 0.9874\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.0484 - accuracy: 0.9875\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.0482 - accuracy: 0.9877\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.0477 - accuracy: 0.9878\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.0475 - accuracy: 0.9876\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.0471 - accuracy: 0.9877\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "106/250 [===========>..................] - ETA: 42s - loss: 0.0484 - accuracy: 0.9872\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.0480 - accuracy: 0.9874\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.0477 - accuracy: 0.9875\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.0489 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.0485 - accuracy: 0.9871\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.0485 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "112/250 [============>.................] - ETA: 40s - loss: 0.0482 - accuracy: 0.9871\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "113/250 [============>.................] - ETA: 40s - loss: 0.0500 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.0500 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.0496 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "116/250 [============>.................] - ETA: 39s - loss: 0.0493 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.0490 - accuracy: 0.9871\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.0512 - accuracy: 0.9867\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "119/250 [=============>................] - ETA: 38s - loss: 0.0514 - accuracy: 0.9865\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.0509 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.0505 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.0502 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "123/250 [=============>................] - ETA: 37s - loss: 0.0500 - accuracy: 0.9870\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.0503 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.0499 - accuracy: 0.9869\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "126/250 [==============>...............] - ETA: 36s - loss: 0.0499 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.0500 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.0497 - accuracy: 0.9868\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.0500 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "130/250 [==============>...............] - ETA: 35s - loss: 0.0500 - accuracy: 0.9865\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.0496 - accuracy: 0.9866\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.0505 - accuracy: 0.9862\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "133/250 [==============>...............] - ETA: 34s - loss: 0.0503 - accuracy: 0.9863\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.0503 - accuracy: 0.9862\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.0518 - accuracy: 0.9860\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.0524 - accuracy: 0.9857\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.0531 - accuracy: 0.9856\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.0534 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.0538 - accuracy: 0.9853\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.0535 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.0540 - accuracy: 0.9853\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.0536 - accuracy: 0.9854\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.0548 - accuracy: 0.9849\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.0575 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.0591 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.0587 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.0585 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.0598 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.0603 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.0601 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.0597 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.0598 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.0595 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.0592 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.0598 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.0595 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.0592 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.0588 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.0593 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.0594 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.0599 - accuracy: 0.9840\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.0598 - accuracy: 0.9839\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.0595 - accuracy: 0.9840\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.0592 - accuracy: 0.9841\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.0590 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.0587 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.0592 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.0589 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.0596 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.0592 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.0589 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.0596 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.0605 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.0602 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.0601 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.0597 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.0591 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.0588 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.0586 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.0586 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.0583 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.0586 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.0590 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.0587 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.0583 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.0581 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.0581 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.0587 - accuracy: 0.9842\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.0584 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.0581 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.0578 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.0575 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.0573 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.0570 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.0568 - accuracy: 0.9848\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.0571 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.0569 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.0568 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.0565 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.0562 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.0561 - accuracy: 0.9848\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.0573 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.0570 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.0570 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.0568 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.0569 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.0578 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.0575 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.0572 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.0580 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.0582 - accuracy: 0.9843\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.0579 - accuracy: 0.9844\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.0578 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.0576 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.0581 - accuracy: 0.9845 \n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.0579 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.0583 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.0580 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.0587 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.0584 - accuracy: 0.9845\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.0582 - accuracy: 0.9846\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.0580 - accuracy: 0.9847\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.0577 - accuracy: 0.9848\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.0575 - accuracy: 0.9848\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.0572 - accuracy: 0.9849\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.0570 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.0568 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.0567 - accuracy: 0.9849\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.0565 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.0562 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.0567 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.0565 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.0563 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.0567 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.0566 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.0563 - accuracy: 0.9852\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.0569 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.0567 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.0568 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.0570 - accuracy: 0.9849\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.0568 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.0566 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.0564 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.0563 - accuracy: 0.9852\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.0575 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9850\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9851\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9852\n",
      "Epoch 15: accuracy did not improve from 1.00000\n",
      "250/250 [==============================] - 89s 357ms/step - loss: 0.0569 - accuracy: 0.9852 - val_loss: 0.0553 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    trainGen, steps_per_epoch=trainGen.samples // 32,\n",
    "\tvalidation_data=testGen, validation_steps=testGen.samples // 32,\n",
    "\tepochs=15, callbacks=[checkpoint, early])\n",
    "\n",
    "model.save(os.path.sep.join([config.OUTPUT_PATH, \"vgg.model\"]), save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = np.arange(0, 15)\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and validation loss VGG16\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"vgg_losses.png\"]))\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, hist.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training and validation accuracy VGG16\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"vgg_accuracy.png\"]))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open      0.977     0.979     0.978       388\n",
      "       short      0.963     0.963     0.963       301\n",
      "    mousebit      0.982     0.969     0.976       393\n",
      "        spur      0.987     0.966     0.977       325\n",
      "      copper      0.990     0.997     0.993       294\n",
      "    pin-hole      0.961     0.990     0.975       300\n",
      "\n",
      "    accuracy                          0.977      2001\n",
      "   macro avg      0.977     0.978     0.977      2001\n",
      "weighted avg      0.977     0.977     0.977      2001\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAGoCAYAAAAHJ+8hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAB2xUlEQVR4nO3dd1xV9f/A8de9wOUyRBmiMoRUSNx7p5ZU5h45ypnmtmmmZTkqc2duzZ17lWluTJy5xYmCoqgoKKICMi/3/P7w5/1KLmTd4fvZ4z7invn+3Hu97/P+nM85V6UoioIQQggh8o3a2AEIIYQQrxpJvkIIIUQ+k+QrhBBC5DNJvkIIIUQ+k+QrhBBC5DNJvkIIIUQ+k+QrzMLSpUsJCAhAo9GgUqnyZB8NGzakYcOGebJtSxEcHIxKpSI4ONjYoQhh1iT5ihe6d+8eo0aNonLlyjg5OaHVailVqhS9evXixIkTeb7/8+fP061bN4oVK8acOXNYsmRJnu/T0kVERDBy5EhCQkKMFsOdO3ewtbWlSZMmz12uXbt2WFlZERUVlWn6hg0baNmyJR4eHmg0GpycnKhatSpDhgzh4sWLT91WREQEn3zyCQEBATg4OKDVannttdf44IMP+Pvvv/nvbQ9+/vlnWrVqhaenJyqVis6dOz831nv37vHVV19RokQJbG1tKVq0KE2bNuXKlSsvfkHEK0UlN9kQz3P27Fnee+89bt68Sbt27ahTpw5arZbw8HDWrFnDlStXuHr1Kl5eXnkWw+zZs+nXrx9HjhyhWrVqebaftLQ0ADQaTZ7tw1QEBQXx9ttvs3DhQrp3757l9fR6PWlpaWg0GtTqnB+7t27dmo0bNxIVFUWRIkWemH/v3j2KFi1K/fr12b59OwDp6el07tyZ1atXU6lSJVq1aoW3tzfJycmcOHGC9evXc+/ePe7evUuBAgUM21q1ahXdu3dHq9XywQcfUKFCBaytrbly5QqbN2/mxIkTzJw5k379+hnWUalUuLu7U6NGDf7++286derE0qVLn9qWmJgY6tevz/379/n4448pUaIEcXFxHD58mKFDh1KlSpUcv17CclgbOwBhuhITE2nRogUPHjzg0KFDT3x5jB49mgkTJjxRLeS2W7duAVCoUKE83c+rkHSz68GDBzg4OKBWq9Fqtbm23W7durF+/XpWrFjB559//sT81atXk5qaSrdu3QzThg4dyurVq/nhhx/4/vvvn1hn2rRpjBs3LtO0Y8eO0aVLFypVqsTmzZtxc3PLNP+nn35i+/btPHjwINP0iIgIXnvtNYAXnu7o168fycnJnDx58qkHEkJkogjxDJMmTVIAZcGCBVle5/r160q3bt0Ud3d3RaPRKAEBAcovv/yi6PX6TMs1aNBA8fT0VC5fvqw0a9ZMcXR0VJydnZU+ffooycnJhuWAJx7dunVTFEVRfHx8DH8/bsSIEcp/P9onTpxQmjVrpri7uyu2traKh4eH0rp1ayUyMjJTTA0aNMi0nl6vV3755RclICBA0Wg0iru7u9KtWzclKioq03ILFy5UAGXr1q3KiBEjFE9PT8XW1lapU6eOEhISkqXXzsfHR6lbt65y7NgxpX79+oqdnZ3i5eWlTJs2TVEURbl8+bLSokULpUCBAoqLi4vy1VdfKRkZGU/E8c477yjFihVTbGxsFG9vb2XgwIHK/fv3n4j1v48RI0Zkev2OHTum9OnTRylcuLDh9dy1a5cCKLt27VIURVHi4uIUT09PpWzZspnet9TUVKVSpUpKkSJFlFu3bj2zzWlpaYqrq6tSuXLlp86vW7euUqBAAeXBgweKoihKVFSUotFolDfffDNLr+kjTZs2VaysrJRLly691HqPA5ROnTo9dV54eLgCGN6r1NTUTK+HEP8l53zFM/3555/Y2try4YcfZmn5O3fuUKdOHVasWEGnTp2YNGkSxYsX58svv+STTz55Yvnk5GQCAwMpUqQIEyZMoEWLFsyZM4fRo0cbllmyZAmtW7cGYOLEiSxZsoQ+ffq8VDtu375NYGAgoaGhfPnll8yYMYO+ffty+/Ztrl279tx1P/nkE7788ku8vLyYNGkSXbp0YeXKldSuXZs7d+48sfywYcPYvHkzgwYNYsSIEZw/f55WrVqh0+myFOuNGzdo2rQpNWrUYMKECRQrVoxPPvmEBQsW0LBhQzw9PRk3bhzVqlVj4sSJ/Pbbb5nWnz59Oq6urnzxxRdMnz6dJk2a8Ntvv9G8eXPDMvXr12fo0KEA9O7dmyVLlrBkyRLatGmTaVtdu3bl4sWLDB8+nFGjRj01XmdnZxYtWsS5c+cYMmSIYfp3331HSEgI8+fPp3Dhws9sr42NDR988AEnTpzg7NmzmeZFRESwf/9+3n//fezt7QHYvHkzaWlpL9VVnpyczPbt26lfvz4lSpTI8nov41GXuJeXF02aNMHOzg47OzuqVavGnj178mSfwswZO/sL0+Xi4qJUqFAhy8sPHjxYAZS1a9capun1eqV169YKoJw6dcowvUGDBgqgTJ48OdM2WrZsqRQuXDjTtEeVWHh4eKbpWa18169frwDK4cOHnxv/fyvfM2fOKIDSokWLTJX7o+0NGjTIMO1RNVmtWjUlPT3dMP3PP/9UAGXTpk3P3fej9gDK+vXrDdNiY2MVrVarqFQqZerUqYbpaWlpSrFixZ6oGB9ViI9btGiRAigHDhwwTNuxY4cCKAsXLnxi+Uev37vvvvtEj8V/K99HPv/8c0WlUinbt29XgoODFbVarfTt2/eFbVYURTl8+LACKEOGDMk0feTIkU/s64svvlAA5cSJE5mW1ev1yu3btzM9UlJSFEVRlJMnTyqA8tlnnz2x7/v372da5969e8+Mk+dUvp999pkCKG5ubkqDBg2U5cuXK3PmzFF8fHwUjUajHD9+PEuvhXh1SOUrnik+Ph4nJ6csL79hwwZKlSpF27ZtDdNUKhWDBw8GYOPGjZmWV6vVT1SxDRo04Pbt2yQkJOQg8swenSvesGEDqampWV7vUbyDBw/OdL6vZcuWvP7662zYsOGJdXr16oW19f+GUjRo0ACAS5cuZWmfxYoVo2XLlobnrq6uvP7666hUKnr16mWYbmNjQ40aNZ7Y7qMKUa/Xc//+fWJjY6lfvz4AR44cyVIMj/Tt2zfLl3WNGTOGsmXL0r17d7p27UqpUqWYNGlSltatXr06AQEBLFu2DL1eb5i+ZMkSfHx8DK8hPPxMApkGUsHDXpfChQtneqxYseK56wB8+OGHmdZ5/LV/GYmJicDD9ysoKIgPPviA3r17888//6AoCj/88EO2tisslyRf8UxOTk4vlQSvXLlC6dKln5hepkwZAC5fvpxpuru7O3Z2dpmmOTs7AxAXF/ey4T5T/fr16dixIz/99BMuLi40btyYqVOnEhsb+9z1Hl0eEhAQ8MS8gICAp14+4uPjk+n5y7bnv+vDw4MHd3f3JwY6FSpUiPj4eDIyMgzTDh8+zNtvv42DgwOFChWicOHChq7We/fuZSmGR0qWLJnlZbVaLYsXL+bGjRtcu3aNpUuXGg4EsqJr165cv36dXbt2AXDgwAEuXbpEly5dMh0APDoY/O/nsmDBguzYsYMdO3Ywfvz4TPOetQ48HDT4aL3/DsJ6GY8+xx988EGmg68SJUpQp04d6XoWT5DkK56pTJkynD9//qWqxZdhZWX1zHlKFkZQP6sqezwZPVpuxYoVHDt2jKFDh5KcnMyXX35J6dKlc/0612e1KSvted76WXmtrly5wptvvsmNGzcYP348GzZsYMeOHWzduhUgU1WZFf89MHqRLVu2GOI5ffr0S63buXNn1Gq14Rru33//HXiYlB/36EDu5MmTmabb2NgQGBhIYGAglStXzjSvVKlS2NjYPLEOQMWKFQ3r2dravlTMj/Pw8AB46ijnokWLcvfu3WxvW1gmSb7imVq1akVqaqqh++5FXnvtNc6fP//E9NDQUMP83OTs7PzUL7WIiIinLl+lShW+//57du/ezfHjx7l///4TVdLjHsX7KP7HhYaG4uvrm73A88hff/1FUlISmzZt4pNPPqF58+YEBgY+Nc7cvkvYsWPHGDVqFB06dKBhw4Z8/vnnT/R0PI+XlxdvvfUW69at4+7du6xevZratWvj5+eXabkmTZpgY2PD4sWLs7xte3t73n77bfbu3fvMz0ZOVa9eHYDr168/Me/69evPHXQmXk2SfMUz9e7dG19fXwYPHvzUqkGn0zFu3DjDF07z5s25ePEif/75p2EZRVGYOHEiAC1atMjV+Pz8/Pj3339JTk42TLty5Qrr16/PtNzdu3efqDwDAgKws7N7bkXSrFkzACZNmpRp/Y0bN3LhwoVcb09OPaqO/9vWsWPHPrGso6MjQK5UZMnJyXTu3JkiRYowa9YsFi9ejFqtpmvXri9VbXfr1o3ExEQ+/vhj7t69m+na3kc8PDzo378/u3bt4scff3zqdp7WyzBy5EjUajUdO3Z86ij1Z62XVQ0aNKBYsWIsWbKEpKQkw/RTp07x77//8u6772Z728IyyU02xDMVKFCADRs28N5771G9enXat29P7dq10Wq1XLx4kbVr1xIREWG45d6QIUNYtWoVH3zwAQMGDKBEiRJs2rSJLVu2MGDAAMqVK5er8fXr14/Vq1cTGBhIp06duH37NjNnziQgIIBjx44Zllu8eDHTpk2jdevWlCpVCp1Ox8qVK0lISHjuZVRly5ZlwIABzJgxg8aNG9O8eXMiIyOZPn06xYsX55tvvsnV9uRU48aN0Wq1NGnShD59+qBWq9m4ceNTzzeXLVsWe3t7Zs2ahaOjIwUKFKBcuXLZeo8GDx7MhQsXCAoKwtnZGWdnZ6ZPn06XLl0YP3684bKmF2nTpg39+vXjjz/+wNbWlg4dOjx1ufHjx3P9+nWGDx/OH3/8YbjDVWJiImFhYaxYsQIbGxtDVzA8rEwXLVpEjx49KFWqVKY7XF2/fp2//vqLGzdu8Pbbb2fa15IlS4iMjDQ8P3PmDD/99BPwcCzBo8FsNjY2TJkyhQ4dOlC7dm0++ugjEhISmDJlCoUKFXrmpVriFWakUdbCjMTFxSnDhw9XKlasqDg4OCgajUYpWbKk0rt3b+XkyZOZlr1+/brStWtXxc3NTdFoNErp0qWVSZMmPfMmG//16JKdy5cvG6Y961IjRVGUmTNnKr6+vopGo1HKli2rrF69+olLjY4fP6506tRJ8fX1VbRareLi4qLUq1dPWbdu3RMx/fcmGxkZGcqkSZOU0qVLKxqNRilcuLDStWtX5fr160+Ne8eOHU/EyGM3sHieRzfZ+K9nvVbdunVTgEyXNgUFBSk1atRQ7O3tFTc3N6Vbt27KrVu3nhrD2rVrlbJlyyo2NjZPvcnG017v/15qtHXrVgVQvvzyyyeWbd++vaLRaJ64LOh5unfvrgDK+++//9zl9Hq98scffyjNmzdXihQpolhbWysFChRQKleurAwePPipsSuKooSFhSn9+/dX/P39FTs7O8XW1lbx9fVVOnTooGzYsOGJ5R9dEve0x9Pe040bNyo1a9ZU7OzslIIFCyqtW7dWLly4kOX2i1eH3NtZCCGEyGdyzlcIIYTIZ5J8hRBCiHwmyVcIIYTIZ5J8hRBCiHwmyVcIIYTIZ5J8hRBCmLTIG0+/MYo5k0uNcsCu8kBjh5Dr7hyaZuwQ8kwu31HRZOT2rSKFyC5tHt62ya7Kp9leN/n41FyMJHfIHa6EEEKYPgs7yJRuZyGEECKfSeUrhBDC9Kksq1aU5CuEEML0WVi3syRfIYQQpk8qXyGEECKfWVjla1mHEkIIIYQZkMpXCCGE6ZNuZyGEECKfWVi3syRfIYQQps/CKl/Lao0QQghhBqTyFUIIYfqk21kIIYTIZxbW7SzJVwghhOmTylcIIYTIZxZW+VpWa4QQQggzIMnXiBb81JWI7aOJ2TuBU+uH0711bcO8tm9X5sS677i1byLH1w2jecMKmdb9pNObXN7xMzF7JzB7RCc0NubXiXExPBwXJzt6dO9i7FByRWpqKn179+T1Ur64uzhRs1pltm3dYuywcmzWjOnUrVmNgg629OrR3djh5CpLbltcXBzt32+Na0EH/Ev6sHLFcmOHlDMqdfYfJsj8vrEtyIQF2+k7ajlp6Tr8fYuwbe5nnDx/nZjYeBaM7ka7L35j+/5zNK5XlmXje1K66XBu300ksHYAgz56m/d6T+Xm7fus+qU33/drwvdTNxi7SS/li88GUrVadWOHkWt0Oh1eXt5sDwrGu3hxtm7ZTJcPO3Dk+Cl8fH2NHV62FfPwYMi33xG0fRvJycnGDidXWXLbPv90ABqNhsioGE6GhNCmZVMqVKhImbJljR1a9qgt65yvaR4SvCJCI6JJS9cBoCgKiqJQwssNzyKFuJeQzPb95wDYuu8sD1JSKeFdGIDOzWuyeP2/hEZEcy8hmTFzt9C5eS2jtSM71qxeSaFChWj45lvGDiXXODg48N3wkfj4+qJWq2nStBm+vq9x4vgxY4eWI61at6FFy1a4uLoaO5RcZ6lte/DgAev/WMeIkT/i6OhI3Xr1aNqsBcuXLTF2aNlnYZWvaUb1Cvn1m/bcOfALp9YPJzo2nq37znLs3FUuXI6maYPyqNUqmjesQFqajtNhUQAElCxq+BvgdFgURd2ccCnoYKxmvJT4+Hh+GjWCseMnGTuUPBUTE0N4eBgBZcy00hBmKzwsDGtra/z8/Q3TylesSOi5s0aMKodUquw/TJB0OxvZ52NW8+W4NdSq8BpvVPMjNV2HXq+w7O/DLPq5O1qNNWnpGXT6ej5JKWkAONrZcj/xf11kj/52tLcl7v4Do7TjZfww8nu6ftQDTy8vY4eSZ9LT0+nRrTOdunTl9dKljR2OeMUkPkjEyckp07SCTgVJSEgwUkTivyT5mgC9XuFASAQdm9agd7s3CI2IZvRnrXi31xROhF6jSoA3a37tQ6uBMzkVFkVicipODlrD+k4OdgAkJqUaqwlZdvJkCMH/7OTA4ePGDiXP6PV6enbvio1Gw+Qp040djngFOTo4Eh8fn2lafEI8BQoUMFJEuSCPu4+nTp3KmTNnSE1NpVChQrRo0YJGjRpx69YtBg4ciK2trWHZli1b8v777wMPD7Tnzp3LoUOH0Gg0tGzZkmbNmr1wf5J8TYi1lZoSXm5orK3Zf/wix89dBeDYuascPXOFt2qW5lRYFKGXoinv78W6HScAKO/vSXRsvFlUvXt3BxMZeYXXS/kA8CAxkYyMDOqEnuPAIfM+NwoPz9337f0xt27F8OeGTdjY2Bg7JPEK8vP3R6fTcTE8nFJ+fgCcPnnSvE+B5HH3cevWrenXrx82NjZERUUxcuRIXnvtNRwdHQFYtGgRVlZWT6y3Zs0aoqOjmTFjBvfu3WPUqFF4eXlRqVKl5+7PrJPv33//za5duwB46623qF69Oj///DMlSpTg8uXLeHl5GY5YIiIiWLx4MSkpKTg5OdG/f3+cnZ0ZOXIkpUqV4uzZsyQlJdG3b18CAgLyPPbCzo40rPE6m/ecJjk1nbdqlqZ946p0+2YR9xOTGfTR21Tw9+RUWBQVX/eiTuVSzFm9F4Blfx/it1FdWLnlCDdv3Wfox++ydOPBPI85N/T4uDfvt+9oeD5l8kSuRkby67SZRowq93w6sB8XzoeyaesO7OzsjB1OrtDpdOh0OjIyMsjIyCAlJQVra2usrc366wOw3LY5ODjQsnUbfhg1nFlz5nEyJIS/N/7Frj0HjB1a9uVx5evt7f2/XalUqFQqoqOjKVWq1HPX2717N/3798fR0RFHR0caNWpEcHCw5SbfiIgIdu3axejRowH49ttvKVOmDDdu3KBv376ULl2amTNnsm3bNpo0acKCBQv4+uuvcXJy4sCBA6xYsYL+/fsDD7sJx4wZw/Hjx1m7di3ff/99nsevAL3a1WPqsA6oVSqu3rzL4Anr2LT7NACj52xm+YSPcXctQOzdRCYs2MbOg+cB2HEglMmLg9j626fY2dqwfudJfpy1Oc9jzg329vbY29sbnjs6OmKr1VK4cGEjRpU7rkZGMn/ub9ja2vKadzHD9GkzZtPxw05GjCxnxv78E6N/HGV4vmL5UoZ9P4Lvho80XlC5xJLbNmXaTPr06kFxD3dcXF2ZMn2W+V5mlAuGDh1q+DswMJDAwMAnlpk3bx7BwcGkpaXx2muvUaVKFUP3ff/+/VGpVFSoUIHOnTvj5OREYmIid+/excfHx7ANX19fjhw58sJ4VIqiKLnQrny3efNmEhIS6NChAwArV67EycmJjRs3MmvWLADOnDnD5s2b6dixI99//z3u7u7Aw2Tr7OzMd999x8iRI+nYsSOlS5fm3r17fP/990ybNu2p+wwKCiIoKAiAsWPHYld5YD60NH/dOfT0tlsCEx30mGMqS22YMDvaPCzn7N6dmO11k7d9leVl9Xo9YWFhnD17lpYtW6LT6YiKisLX15eEhATmz59PSkoKw4YNIzY2lv79+7N06VI0Gg0Ap06dYs6cOcyYMeO5+zHbyvdZ/vtF9Oi5l5eXoUr+r0fn5dRqNXq9/pnbftbRkhBCiDyWT9frqtVqSpcuzZ49e9i+fTtNmjShZMmSABQqVIiePXvSu3dvkpOT0WofDnxNTk42JN+kpCTD9OfuJ++akLdKly7NkSNHSE1NJSUlhSNHjhAQEEBsbCxhYWEA7Nu3j9KlS+Ph4UF8fLxhuk6n49q1a8YMXwghxMvI5+t89Xo9MTExz5yvKAqOjo44OzsTGRlpmB4ZGZnp/PGzmG3lW6JECRo2bMi3334LPBxw5eDggIeHB1u3bmXWrFl4enryzjvvYG1tzaBBg1i4cCFJSUlkZGTQpEmTLL1AQgghTEAeVr7379/nzJkzVK1aFY1Gw6lTp9i/fz+fffYZ4eHhODg4ULRoUR48eMDChQspW7asYexK/fr1WbduHSVKlOD+/fvs3LnTMJ7ouc0x13O+T3Pr1i3GjRvHpEn5c+ckOedrXiz11Kic8xWmIk/P+TaZku11kzd/9tz58fHxTJo0icjISBRFwc3Njffee4/AwED27dvHihUriI+Px87OzjDgqlChQoBc5yuEEMKS5eFBppOTE6NGjXrqvHr16lGvXr1nrmtjY0P//v2zVO0+zqKSr7u7e75VvUIIIfKRif5AQnZZVPIVQghhoST5CiGEEPnMwsY2WNahhBBCCGEGpPIVQghh+qTbWQghhMhnFtbtLMlXCCGE6bOwyteyWiOEEEKYAal8hRBCmD7pdhZCCCHyl6XdRlWSrxBCCJMnyVcIIYTIb5aVe2XAlRBCCJHfpPIVQghh8qTbWQghhMhnknyFEEKIfCbJVwghhMhnlpZ8ZcCVEEIIkc+k8hVCCGH6LKvwleQrhBDC9Flat7Mk3xy4fXCqsUPIdQGD/zZ2CHnmwqTmxg4hTyiKYuwQ8oylfeE+YrnvWd69X5b2WZBzvkIIIUQ+k8pXCCGEybO0yleSrxBCCJMnyVcIIYTIb5aVeyX5CiGEMH2WVvnKgCshhBAin0nlK4QQwuRZWuUryVcIIYTJk+QrhBBC5DfLyr2SfIUQQpg+S6t8ZcCVEEIIkc+k8hVCCGHyLK3yleQrhBDC5OV18p06dSpnzpwhNTWVQoUK0aJFCxo1agTA6dOnmT9/PrGxsfj5+dG/f38KFy4MQHp6OnPnzuXQoUNoNBpatmxJs2bNXrg/Sb5CCCFMXl4n39atW9OvXz9sbGyIiopi5MiRvPbaa7i5uTFx4kT69u1L1apVWbVqFb/++iujR48GYM2aNURHRzNjxgzu3bvHqFGj8PLyolKlSs/dn5zzFUII8crz9vbGxsYGeJjoVSoV0dHRHD58GG9vb2rXro1Go6Fdu3ZcuXKFqKgoAHbv3k3btm1xdHTEy8uLRo0aERwc/ML9SeUrhBDC9OWw8B06dKjh78DAQAIDA59YZt68eQQHB5OWlsZrr71GlSpVWLFiBT4+PoZltFotRYsW5dq1axQsWJC7d+9mmu/r68uRI0deGI8kXyGEECYvp93OY8eOfeEyH3/8MT169CAsLIyzZ89ibW1NSkoKTk5OmZazt7cnJSWFlJQUw/P/znsR6XYWQghh8h51BWfn8TLUajWlS5fmzp07bN++Ha1WS3JycqZlkpKS0Gq1aLVagEzzH8174X5eKiohhBDCCPIr+T6i1+uJiYnB29ubyMhIw/SUlBTDdEdHR5ydnTPNj4yMxNvb+4Xbl+Rr4tauXknVimUp4lKACgF+7N+319ghvZDGSs34Dyqyf0Qjzo57j82D69MwwN0wv2Ot4uz+7i3OjX+PxX1r4u5km2n9oc0DCPn5XUJ+fpehzQPyO/xsmzVjOnVrVqOggy29enQ3dji5JjU1lb69e/J6KV/cXZyoWa0y27ZuMXZYuSIuLo7277fGtaAD/iV9WLliubFDyhWW/J7lhfv377N//35SUlLQ6/WEhISwf/9+ypcvT40aNbh69SoHDx4kLS2NtWvX4uPjg6enJwD169dn3bp1JCYmEhUVxc6dO2nYsOEL9ynnfE3YP0E7GD7sGxYtXUG16jWIvnnT2CFliZWViht3k+kw7QBRd5N5s4w7M7pX5d1xwXi52DO4WWk6Tj/AldsPGNGmHNO6VaXDtAMAfFjHh3fKF6XxuN0owLL+tbgWl8Sy/ZHP36kJKObhwZBvvyNo+7YnuqnMmU6nw8vLm+1BwXgXL87WLZvp8mEHjhw/hY+vr7HDy5HPPx2ARqMhMiqGkyEhtGnZlAoVKlKmbFljh5YjFvme5eGVRiqViu3btzN37lwURcHNzY1u3bpRrVo1AAYNGsSCBQuYNm0afn5+fPbZZ4Z127dvz9y5cxkwYIDhOt8XXWYEoFIURcmrBlm6xFR9nm6/UcN6dO32Ed0+6pmn+3lc2a835cl2tw5pwJStYVTxdUZro+b7tWcAcHey5ciP7/DGDzu5eieJPz6vy5pD11jx71UAOtTypmNtH1pP3pfjGC5Map7jbWTFyOHfEXX9OnMXLMqX/Rnjn3CNKhX59rvhtGrTNk/3k5fXdj548IBihZ05FnIGP39/AHp064KHpyc//fziwTk5YanvmZ1N3r1fxT/ZkO11r05rkYuR5A7pdjZRGRkZnDh2lNjYWCqW8ef1ksUZ9PknZllRuRXQ8FphB8JuJgCZv1Af/f16sQIA+BUtQOiNeMP8c1Hx+BctkI/RiheJiYkhPDyMgDLmXR2Gh4VhbW1tSLwA5StWJPTcWSNGlTcs4T3L73O+eU2Sr4m6FRNDeno6f/25jm07d7P/0HFOhoQwfsxoY4f2UqzVKqZ0qcK6w9e5dCuR4NBbNK3kQWmPAtjaqPnsXX/0egU7jRUADrbWJCTrDOsnpOhw1MrZEVORnp5Oj26d6dSlK6+XLm3scHIk8UHiE5eQFHQqSEJCgpEiyhuW8p5J8jVhAwYMID4+/sULPsOVK1c4fvx4LkaUfVo7OwD69BtA0WLFcHNz45PPPmf7NvMZNKFSweQulUnP0DN87WkA9ofFMnnLBWb3qMb+EYFcj0siMVXHzXsPr4t7kJo52TraWpOYonvq9kX+0uv19OzeFRuNhslTphs7nBxzdHB84vsiPiGeAgUsp6fF0t4zS2JRyTcnMjIyuHLlCidOnDB2KAA4Ozvj6emV+ajNRI/gnmX8BxUpXMCWPguOotP/7xzX7/uu0PCnXVT7bjtbTt7EWq3iwv93SYdHJxDg+b9qpIynE2HRllWJmCNFUejb+2Nu3Yphxaq1htvwmTM/f390Oh0Xw8MN006fPGnWXbOPs7T3zNIqX7Ptz0tJSWHy5MnExcWh1+tp2/bhIIKtW7dy7NgxdDodX375JZ6eniQmJjJz5kxu3bqFra0tvXv3xsfHh9WrVxMTE8OtW7dwdXXlwoULpKWlcf78eVq3bk2dOnWM2sbOXbszZ9YM3n6nMdY2NsyYOoXG7zU1akxZNbp9eUoVKUCnGf+Smv6/gWm21mp8/v/8r4ezHWM6VGDBnsvEJ6cDsO7IdXo1LMGuc7dQFIVeb5Zk0d7LxmrGS9HpdOh0OjIyMsjIyCAlJQVra2usrc32n5nBpwP7ceF8KJu27sDu/3tlzJ2DgwMtW7fhh1HDmTVnHidDQvh741/s2nPA2KHlCot7z0wzh2ab2X4rhISE4OzszDfffAM8vKvIsmXLKFCgAOPGjWPbtm1s3LiRvn37snr1al577TW+/vprzpw5w/Tp05kwYQIA169f58cff0Sj0RAcHMylS5fo2fPpo4uDgoIICgoCsnarspwa8u133LkTS+XypbHVamnTth2Dh36b5/vNKU9nOzrX9SUlPYOjP71jmP7tqlP8cy6GqV2r4ONqT2KqjjWHrjFp03nDMsv2R1Lc1Z7tQxoAsPLgVbO4zAhg7M8/MfrHUYbnK5YvZdj3I/hu+EjjBZULrkZGMn/ub9ja2vKadzHD9GkzZtPxw05GjCznpkybSZ9ePSju4Y6LqytTps8y+8uMwDLfM1OtYLPLbJNv8eLFWbJkCUuXLqVq1aoEBDy8GUPNmjUBKFGiBIcPHwbg/PnzDBo0CIBy5cqRmJhIUlISANWqVUOj0WRpn8+6GXdesbGxYfLUGUyeOiPf9pkbou4m4/PZxmfObzxu93PXH7MhlDEbQnM7rDz33fCRZp9on6a4jw9JaXl7WZ2xuLi4sGbdemOHkess+T2zFGabfD08PBg3bhzHjx9n5cqVlC9fHsDQxadWq8nIyHjhdmxtbV+4jBBCCOOytMrXbAdcxcXFodFoqF+/Pi1atCAiIuKZy5YuXZq9ex/elvHs2bMUKFAg069QPPK0G2gLIYQwPpUq+w9TZLbJ9+rVq3z77bcMHjyYtWvXGgZcPU379u2JiIjgq6++Yvny5QwYMOCpy5UrV46oqCgGDx7MgQOWMehCCCEsgaWNdpbbS+ZAXt9e0hjy6vaSpiC/bi+Z3yz5n7CpfnHmlKW+Z3l5e0n/r7dme92w8Y1zMZLcYbaVrxBCCGGuzHbAlRBCiFeHpfWCSPIVQghh8iws90ryFUIIYfrUasvKvnLOVwghhMhnUvkKIYQwedLtLIQQQuQzGXAlhBBC5DMLy72SfIUQQpg+S6t8ZcCVEEIIkc+k8hVCCGHyLK3yleQrhBDC5FlY7pXkK4QQwvRJ5SuEEELkMwvLvTLgSgghhMhvUvkKIYQwedLtLIQQQuQzC8u9knyFEEKYPkurfOWcrxBCCJHPpPIVQghh8iys8JXkK4QQwvRZWrezJN8cUFvYhwHgwqTmxg4hzzhXH2jsEPLE3SPTjR2CeEm6DMXYIeQNm7z7TszLr9v09HTmzZvH6dOnSUxMpEiRInz44YdUrlyZW7duMXDgQGxtbQ3Lt2zZkvfff9+w7ty5czl06BAajYaWLVvSrFmzF+5Tkq8QQgiTl5eVb0ZGBq6urowcORI3NzdOnDjB5MmTmThxomGZRYsWYWVl9cS6a9asITo6mhkzZnDv3j1GjRqFl5cXlSpVeu4+ZcCVEEKIV5pWq6V9+/a4u7ujVqupWrUq7u7uREREvHDd3bt307ZtWxwdHfHy8qJRo0YEBwe/cD2pfIUQQpi8/DzLd+/ePW7evIm3t7dhWv/+/VGpVFSoUIHOnTvj5OREYmIid+/excfHx7Ccr68vR44ceeE+JPkKIYQweTntdh46dKjh78DAQAIDA5+6nE6nY9q0aTRo0ABPT09SUlIYM2YMvr6+JCQkMH/+fKZNm8awYcNISUkBwN7e3rC+vb29YfrzSPIVQghh8nJa+Y4dO/aFy+j1eqZPn461tTU9evQAHnZJlyxZEoBChQrRs2dPevfuTXJyMlqtFoDk5GQ0Gg0ASUlJhunPI+d8hRBCmDyVSpXtR1YoisLs2bO5f/8+gwYNwtr6+bWpoig4Ojri7OxMZGSkYXpkZGSm7upnkeQrhBDilTd37lyioqIYMmSIoYoFCA8P58aNG+j1ehISEli4cCFly5Y1dDXXr1+fdevWkZiYSFRUFDt37qRhw4Yv3J90OwshhDB5eXmp0e3btwkKCsLGxoZevXoZpvfu3RuVSsWKFSuIj4/Hzs6OChUq8NlnnxmWad++PXPnzmXAgAGG63xfdJkRgEpRFAu92jvvJaVZ3kunVlvejUMekZtsCFORrtMbO4Q8UUCbd52pDSbvz/a6u7+om4uR5A6pfIUQQpg8S7u9pJzzFUIIIfKZVL5CCCFMnoUVvpJ8hRBCmD5L63aW5CuEEMLkWVjuleQrhBDC9FnaT7jKgCshhBAin0nlK4QQwuRZWOEryVcIIYTps7QBV9LtbMJ6dO9CCR8PiroVpGLZ11m0YJ6xQ8oVcXFxtH+/Na4FHfAv6cPKFcuNHVKWLfipKxHbRxOzdwKn1g+ne+vahnlt367MiXXfcWvfRI6vG0bzhhUM88qULMaGGQO49s9Ykk+Y3x2pzPk9ex5LbdeF86E0axyIVxFnKpb1Z+Nffxo7pBxTq7L/MEVS+Zqwr74eyqw587C1teXC+fM0fudNKlaqTOUqVY0dWo58/unDe6BGRsVwMiSENi2bUqFCRcqULWvs0F5owoLt9B21nLR0Hf6+Rdg29zNOnr9OTGw8C0Z3o90Xv7F9/zka1yvLsvE9Kd10OLfvJpKuy2DdjuP8tmYPayb3MXYzXpo5v2fPY4nt0ul0dGzXmp4f9+GvTdvYt3c3Hdq2ZO/BY/j5+Rs7vGyTylfkmzJlymJrawv87+e0IiIuGTmqnHnw4AHr/1jHiJE/4ujoSN169WjarAXLly0xdmhZEhoRTVq6Dnj4k2KKolDCyw3PIoW4l5DM9v3nANi67ywPUlIp4V0YgPDIWyxe/y/nLt00WuzZZe7v2bNYarvCLpwn+uYNBnz6OVZWVjRo+BY1a9dh5fKlxg5NPCZLyXf8+PFPnT5x4sRcDUY86fNP+uNWyIHKFQIoWrQY7zZuYuyQciQ8LAxra2v8/P93BF6+YkVCz501YlQv59dv2nPnwC+cWj+c6Nh4tu47y7FzV7lwOZqmDcqjVqto3rACaWk6TodFGTvcHLOE9+xpLLVdT6UohJ49Y+wockSlyv7DFGUp+Z49+/QP47Omi9zz67SZxNyJZ8c/e2jZqrWhEjZXiQ8ScXJyyjStoFNBEhISjBTRy/t8zGoK1xtEo49+4a9/QkhN16HXKyz7+zCLfu7O/UO/sujn7gz8aSVJKWnGDjfHLOE9expLbZef/+sULuzOlF8mkp6ezs6g7ezbu4ek5CRjh5Yjqhz8Z4qee8531apVwMNzCI/+fiQmJobChQvnXWS5bOTIkXTp0oWSJUtmmn706FGuX79Oq1atOHz4MB4eHnh5eRkpyqezsrKiTt16rFy+lLlzZtF/4KfGDinbHB0ciY+PzzQtPiGeAgUKGCmi7NHrFQ6ERNCxaQ16t3uD0IhoRn/Wind7TeFE6DWqBHiz5tc+tBo4k1NmXv1aynv2X5baLhsbG5av/oPBX37G5F/GU7lKVVq3bWf2B+6mOnAqu55b+d65c4c7d+6g1+sNfz96uLm58eWXX+ZXnHmmWrVqtGrVCoAjR45w/fp14wb0HLoMndmf8/Xz90en03ExPNww7fTJkwSUMc8BLtZWakp4uVHR34v9xy9y/NxVFEXh2LmrHD1zhbdqljZ2iDlmae/ZI5baLoBy5SuwZccuIqNus37jVq5cvkzVatWNHZZ4zHMr3/79+wPg7+9PYGBgtndy69Ytfv75Z/z8/AgLC6NkyZI0bNiQNWvWcP/+fT799FOKFi3KzJkzuXXrFra2tvTu3RsfHx9Wr16NVqulRYsWAAwaNIghQ4bg5OTE5MmTiYuLQ6/X07ZtW+rUqUNERASLFy8mJSUFJycn+vfvj7OzMwB79uxh9uzZ6PV6+vXrR6lSpQgODubSpUvUq1ePo0ePcu7cOdatW8egQYMoWrRottucU7du3WJ38D+816QZdnZ2/LMziDWrVrLod/O+FMLBwYGWrdvww6jhzJozj5MhIfy98S927Tlg7NBeqLCzIw1rvM7mPadJTk3nrZqlad+4Kt2+WcT9xGQGffQ2Ffw9ORUWRcXXvahTuRRzVu81rG+rsUZjY234W1EwDN4yZeb8nj2PpbYL4MzpU5Ty80ev1zNvzixiom/SqUt3Y4eVI5Y22jlLlxrZ2NgQGRmJj4+PYdqVK1e4evUq9evXz9KOoqOj+fLLL/Hy8uKbb75h3759/PDDDxw9epQ//vgDNzc3XnvtNb7++mvOnDnD9OnTmTBhwjO3FxISgrOzM9988w0ASUlJ6HQ6FixYwNdff42TkxMHDhxgxYoVhoOI1NRUJkyYwLlz55g1axaTJk0ybO/111+nWrVqVK1alVq1amWpTXlJpVIx77fZfDawH3q9Hu/iPoyfOJmmzVsYO7QcmzJtJn169aC4hzsurq5MmT7LLC7tUIBe7eoxdVgH1CoVV2/eZfCEdWzafRqA0XM2s3zCx7i7FiD2biITFmxj58HzABQv5sKFzT8YtnXv0K9E3rhD6aYjjNGUl2au79mLWGq7Vi5fyu+L5pOenk7tuvVYv2mb2Xc7W1juzVryXbVq1RMjnt3c3Bg/fnyWk6+7uzvFixcHwNvbm/Lly6NSqShevDi3b98mNjaWQYMGAVCuXDkSExNJSnr2AIHixYuzZMkSli5dStWqVQkICODq1atcu3aNH3/8EQC9Xm+oegHq1asHQJkyZUhKSuLBgwdZiv2RoKAggoKCABg7duxLrfuyChcuzLag4Dzdh7G4uLiwZt16Y4fx0mLvJvLOx1OeOX/2qj3MXrXnqfOu3ozDrvLAvAotz5nre/Yiltqun8aM56cxT79KxVxZ2g8rZCn5JicnY29vn2mavb39SyUvGxsbw98qlcrwXKVSodfrsbKyeup6VlZWKIpieJ6W9nD0qIeHB+PGjeP48eOsXLmS8uXLU6NGDby8vBg9enSWYnrZbozAwMAcdb8LIYTIHgvLvVm71MjLy4uDBw9mmnb48OFcHRVcunRp9u59eH7s7NmzFChQAHt7ewoXLszly5cBiIiI4NatW8DD28JpNBrq169PixYtiIiIwMPDg/j4eMLCwoCHo7SvXbtm2MeBAw/P5Zw/fx57e/snDijs7OxITk7OtTYJIYQQT5OlyrdTp06MGTOGAwcOULRoUaKjozl9+rThfGtuaN++PTNnzuSrr77C1taWAQMGAFCrVi327NnDl19+SalSpfDw8ADg6tWrLF26FJVKhbW1NR9//DHW1tYMGjSIhQsXkpSUREZGBk2aNMHb2xsAjUbD119/TUZGBv369Xsihjp16jBnzhy2bNnCl19+adQBV0IIIf7H0gZcqZTH+3Sf4/bt2+zfv5/Y2Fjc3NyoV68ebm5ueR2fSUtKy9JLZ1bUlnYx3WOcq5vvOdfnuXvE/H6o4VWXrtMbO4Q8UUCbd3csbrfoeLbXXdO9Si5Gkjuy/MMKhQsXpkWLFty/fz/TICYhhBAir72SA64ePHjAvHnzOHjwINbW1ixZsoSjR49y8eJFOnbsmNcxCiGEeMVZVurN4oCruXPnYm9vz8yZM7G2fpiv/f39DQOYhBBCCJF1Wap8T58+zZw5cwyJF8DJyYn79+/nWWBCCCHEI5Y24CpLla+9vf0Tv/QRGxsr536FEELkC7Uq+w9TlKXk26hRIyZNmsSZM2dQFIWwsDBmzJjB22+/ndfxCSGEEKhUqmw/TFGWup1btmyJRqNh/vz5ZGRkMGvWLAIDA2nSxLx/2F0IIYQwhmcm3yVLltClSxfg4R2nmjRpIslWCCGEUZhoAZttz+x2fvQDAsBzf11ICCGEyGuvTLezr68vkyZNwsvLi/T0dFatWvXU5Tp06JBnwQkhhBBgugOnsuuZyffLL78kKCiI27dvoygKd+7cyc+4hBBCCIO8rGDT09OZN28ep0+fJjExkSJFivDhhx9SuXJl4OHltvPnzyc2NhY/Pz/69+9P4cKFDevOnTuXQ4cOodFoaNmyJc2aNXvhPp+ZfAsWLEjbtm2Bh7+L++gH6YUQQghLkpGRgaurKyNHjsTNzY0TJ04wefJkJk6ciFarZeLEifTt25eqVauyatUqfv31V8NP165Zs4bo6GhmzJjBvXv3GDVqFF5eXlSqVOm5+8zSpUb9+/cnISGBPXv2sGHDBuDhT/pJNSyEECI/qHLweBGtVkv79u1xd3dHrVZTtWpV3N3diYiI4PDhw3h7e1O7dm00Gg3t2rXjypUrREVFAbB7927atm2Lo6MjXl5eNGrUiODg4BfuM0vJ99y5c3z++efs3buXtWvXAhAdHc3cuXOzsroQQgiRI2qVKtuPl3Xv3j1u3ryJt7c3165dw8fHxzBPq9VStGhRrl27RmJiInfv3s0039fXN9PvyD9Llq7zXbRoEZ9//jnly5fno48+AqBUqVJcunTpZdskhBBCvLScnvIdOnSo4e/AwEACAwOfupxOp2PatGk0aNAAT09PUlJScHJyyrSMvb09KSkppKSkGJ7/d96LZCn53r59m/Lly2de0dqajIyMrKwuhBBC5EhOB1yNHTv2hcvo9XqmT5+OtbU1PXr0AB5WusnJyZmWS0pKQqvVotVqAUhOTkaj0WSa9yJZ6nb28vIiJCQk07TTp09TvHjxrKwuhBBCmDRFUZg9ezb3799n0KBBhh8S8vb2JjIy0rBcSkoKMTExeHt74+joiLOzc6b5kZGReHt7v3B/WUq+Xbp0Ydq0aUyfPp20tDR+++03Zs6cSefOnV+2fUIIIcRLU6my/8iKuXPnEhUVxZAhQwxVLECNGjW4evUqBw8eJC0tjbVr1+Lj44OnpycA9evXZ926dSQmJhIVFcXOnTtp2LDhi9ujKIqSlcDi4uLYu3cvt2/fxs3NjTfeeANXV9estcpCJaVl6aUzK2pLu5L9Mc7VBxo7hDxx98h0Y4cgXlK6Tm/sEPJEAW2W6rls6bfuXLbXndW2zHPn3759mwEDBmBjY4Na/b829O7dmzfeeINTp06xYMECbt++bbjO193dHcj+db5ZTr7iSZJ8zYskX2EqJPm+vP5/ZD/5zmzz/ORrDC8ccHX9+nVWr17N+fPnSUxMxNHRkYCAANq1a4eXl1d+xCiEEEJYlOdWvjdv3mTo0KEEBARQs2ZNnJ2diYuL4/Dhw4SGhjJmzBg8PDzyM16TkqIzdgS5T5dhmUfkANZWeXdUbkyePVcYO4Q8c31eR2OHkCdM9Wb/OaXN0vUz2TPgz9BsrzujdUAuRpI7nvtS/fnnn7zxxht8/PHHmaa/9dZbLFiwgPXr18ttJ4UQQuQ5Szt0fm57QkNDadGixVPnNWvWjLNnz+ZJUEIIIcTjXpmfFASIj483/HLDf7m5uZGQkJAnQQkhhBCPs7SxoC+s5J911KBWq032iEIIIYQwZc+tfFNTUxkxYsRT5ymKQlpaWp4EJYQQQjzO0irf5ybfvn37Pnflt956K1eDEUIIIZ7G0npan5t8s3KLLCGEECKvWVrla2mjt4UQQgiTl4eXRAshhBC5w8J6nSX5CiGEMH1qC8u+knyFEEKYPEs7R5ql5Juens7atWvZv38/CQkJLF68mJMnT3Lz5k0aN26c1zEKIYR4xVlY4Zu1g4nFixdz7do1Pv30U8Nwb29vb7Zv356nwQkhhBCWKEuV7+HDh5k6dSpardaQfF1cXIiLi8vT4IQQQgh4Rc/5Wltbo9dn/qm5+Ph4ChQokCdBCSGEEI+zsNybtW7nWrVqMX36dG7dugXA3bt3mT9/PnXq1MnT4IQQQgh4eJON7D5MUZaS74cffoi7uzuDBg0iKSmJTz/9FGdnZ9q1a5fX8QkhhBCoVapsP0xRlrudu3fvTvfu3Q3dzZZ2n00hhBAiv2Sp8o2JiTE8kpOTuXXrluG5yDtxcXG0f781rgUd8C/pw8oVy40dUo4VdXXK9Chob8NXX3xq7LByxawZ06lbsxoFHWzp1aO7scN5KbP71ObslFZcmf0+h8Y1pXODEgDYWKlZOLAuJyY2587iD6hb2v2p69tYqfl3TBNOT26Zn2HnSGpqKn179+T1Ur64uzhRs1pltm3dYuywcoU5fxafRaXK/sMUZany/fTTZ385rlq1KteCEZl9/ukANBoNkVExnAwJoU3LplSoUJEyZcsaO7Rsi74Tb/g7MTGRUj4etGrzvhEjyj3FPDwY8u13BG3fRnJysrHDeSmT/z7Lp/MPkabT41esAH8NbcTpyLucu3afg2GxzN52gQUD6z1z/U+alCY2IRVHrU0+Rp0zOp0OLy9vtgcF4128OFu3bKbLhx04cvwUPr6+xg4vR8z5s/gspnruNruylHz/m2Dv3bvHmjVrCAgIyJOgBDx48ID1f6zjWMgZHB0dqVuvHk2btWD5siX89PNYY4eXK/76cx2FC7tTt94bxg4lV7Rq3QaA48eOEnX9upGjeTkXov53UKQooAC+7o6cvHKXOdsvAKDXK09dt7ibA+3q+PLdihP8+lGN/Ag3Vzg4OPDd8JGG502aNsPX9zVOHD9m9snXnD+Lz6LCsrJvtu7YVahQIbp3787y5ebfDWqqwsPCsLa2xs/f3zCtfMWKhJ47a8SoctfypUv4oFMXGT9gIiZ0rca139pxaFwzYu4lE3TyZpbWG9ulKj+tPUVKWkYeR5i3YmJiCA8PI6CM+fYsCfOR7Xs737hxg9TU1NyMRTwm8UEiTk5OmaYVdCpIQkKCkSLKXVcjI9m3dzczZs81diji/w3+/ShDlhyjeilX6gUUIVX34mTatKoXVmoVm45df+b5YHOQnp5Oj26d6dSlK6+XLm3scMRTvJLdzsOHD89UnaSmpnLt2jXef98yztWZIkcHR+Lj4zNNi0+wnBubrFy+lNp16uH72mvGDkU8Rq8oHAqPpV0dX3q85cdvO8Keuay9xooR7SvR8Zfg/AswD+j1enp274qNRsPkKdONHY54hlcy+b711luZnmu1Wnx8fChWrFieBGVsGRkZWFlZGTUGP39/dDodF8PDKeXnB8Dpkyctpkts+bIlfPnV18YOQzyDtZUaX3fH5y5TomgBirs58Pe3gQBorNU42dtwbkor3v1xB9diH+RHqDmiKAp9e3/MrVsx/LlhEzY25jNg7FVjaaenXph89Xo9Z86coU+fPib7wUxJSWHy5MnExcWh1+tp27Yty5Yto3bt2pw4cQKNRsNnn31G0aJFmTFjBlWrVqVWrVoAdOnShSVLlnD27FlWrVqFg4MDN27cYMqUKUZtk4ODAy1bt+GHUcOZNWceJ0NC+HvjX+zac8CoceWGg/8e4OaNKFq3taybtOh0OnQ6HRkZGWRkZJCSkoK1tTXW1qb9y51uBWx5o0wRtofcIDktgwZli9Cmlg+9Zz38rGms1YbLNWys1djaqElN1xN6/T4VvvzLsJ0apdwY16Uqb47YRmy8eZyS+nRgPy6cD2XT1h3Y2dkZO5xcY66fxeextMr3hQOu1Go1p06dMumjjpCQEJydnZkwYQKTJk2iUqVKANjb2zNp0iQaN27MokWLXridy5cv89FHHxk98T4yZdpMkpOTKe7hTrcuHzBl+iyzvszokeVLf6dFy9YW04X+yNiff8K5gB0Tx49lxfKlOBewY+zPPxk7rBdSgI/e8uP05JZEzGrLDx0rM2zZcbaeiALg0Nim3JjXAQ8Xe9YNfpMb8zrg7eZAhl7h1v0Uw+PugzT0Cty6n4JeefrIaFNyNTKS+XN/49TJEF7zLkZh5wIUdi7AyuXLjB1ajpnrZ/FVkqXDoKZNm7J69Wrat29vkkdOxYsXZ8mSJSxdupSqVasaLoGqW7eu4f+LFy9+4XZKlSqFu/uzB40EBQURFBQEwNixeX+5j4uLC2vWrc/z/eS3qTNmGzuEPPHd8JGZLl0xF3cSUmkxZucz51f+amOWtrP//C3Kf/HXixc0EcV9fEhK0794QTNkrp/F5zHh+i9bnptJ9+3bR7169di6dSv37t1j06ZNT4zAnTVrVp4GmBUeHh6MGzeO48ePs3LlSsqXLw9kPkfw6G8rKyvDLzTp9Xp0Op1hGVtb2+fuJzAwkMDAwNwOXwghxAuY6j2as+u5yXfu3LnUq1ePTz75JL/iyZa4uDgcHR2pX78+Dg4O7Nz58Cj+wIEDtGrVigMHDuD3/4OWChcuTEREBHXq1OHo0aNkZJj3tYlCCPEqsLRzvs9Nvsr/n7cpU6ZMvgSTXVevXmXp0qWoVCqsra35+OOP+eWXX0hMTOSrr77CxsaGzz77DIBGjRoxYcIEBg8eTMWKFV9Y7QohhDA+Cyt8n598H410fp5y5crlakDZUalSJcMgq8e1aNGCzp07Z5pWqFAhRo8ebXj+aH7ZsmUpawGDmYQQQry8rVu3EhwczNWrV6lbty4DBgwA4NatWwwcODBTodayZUvDfS7S09OZO3cuhw4dQqPR0LJlS5o1a/bC/T03+aanpzN79mxDBfxfKpWK6dPlonQhhBB5S53H93Z2dnamTZs2nDx5krS0tCfmL1q06Kn3f1izZg3R0dHMmDGDe/fuMWrUKLy8vJ5aED7uuclXq9WabXKdMWOGsUMQQgiRS/K627lmzZoAREREcOfOnSyvt3v3bvr374+joyOOjo40atSI4ODgnCVfIYQQwhQYe8BV//79UalUVKhQgc6dO+Pk5ERiYiJ3797Fx8fHsJyvry9Hjhx54fayNOBKCCGEMGdDhw41/P0yl406OTkxZswYfH19SUhIYP78+UybNo1hw4aRkpICPLyh0yP29vaG6c/z3OT7+++/Zyk4IYQQIi/l9Drf7N4YSavVUrJkSeDhgN2ePXvSu3dvkpOT0Wq1ACQnJ6PRaABISkoyTH+ebP2erxBCCJGfVKrsP/KCoig4Ojri7OxMZGSkYXpkZCTe3t4vXF+SrxBCCJOnVqmy/ciKjIwM0tLS0Ov16PV60tLSyMjIIDw8nBs3bqDX60lISGDhwoWULVvW0NVcv3591q1bR2JiIlFRUezcuZOGDRu+cH8y4EoIIYTJy+vRzuvWrWPt2rWG53v37uX999/Hw8ODFStWEB8fj52dHRUqVDDctAmgffv2zJ07lwEDBhiu833RSGcAlSKjqrItRffiZcyNLsMybzQPD3+j1hJ59lxh7BDyzPV5HY0dQp4w5V+JywltHpZzC45czfa6PaoXz8VIcodUvkIIIUyepR06S/IVQghh8iytt0CSrxBCCJNnWalXkq8QQggzYGm/52tp3ehCCCGEyZPKVwghhMmzrLpXkq8QQggzYGG9zpJ8hRBCmD5LG+0s53yFEEKIfCaVrxBCCJNnaZWiJF8hhBAmz9K6nSX5CiGEMHmWlXol+QohhDADUvkKi2apv/xjyaLmf2DsEPKM/xcbjB1Cngib3MLYIQgjk+QrhBDC5FlaWSDJVwghhMmTbmchhBAin1lW6pXkK4QQwgxYWOFrcd3oQgghhMmTylcIIYTJU1tYx7MkXyGEECbP0rqdJfkKIYQweSoLq3zlnK8QQgiRz6TyFUIIYfKk21kIIYTIZzLgSgghhMhnUvkKIYQQ+czSkq8MuBJCCCHymVS+QgghTJ6lXWokyVcIIYTJU1tW7pXkK4QQwvRJ5SuEEELkMxlwJfJNXFwc7d9vjWtBB/xL+rByxXJjh5QrpF3mZdaM6dStWY2CDrb06tHd2OG8FI21mvEfVuTAqEDOTWjCliENaFjG3TC/Y+3i7BneiNCJTfi9Xy2KONka5vV8swT7RjTi7Pj3OPLTOwxvUxYrM+r7tNTPo6WQyteEff7pADQaDZFRMZwMCaFNy6ZUqFCRMmXLGju0HJF2mZdiHh4M+fY7grZvIzk52djhvBQrtYqbd1NoP2U/UXeTeatMEWZ+VI13xuzCy8Wer5sH0HHqAS7fTmRk2/JM616V9lMPABB0Opo1B68Sn6yjoL0Ns3tW46MGrzFvV4SRW5U1lvZ5zOtu561btxIcHMzVq1epW7cuAwYMMMw7ffo08+fPJzY2Fj8/P/r370/hwoUBSE9PZ+7cuRw6dAiNRkPLli1p1qzZC/cnla+JevDgAev/WMeIkT/i6OhI3Xr1aNqsBcuXLTF2aDki7TI/rVq3oUXLVri4uho7lJeWnJbB5C0XuB6XjKLAzrMxXLuTRHnvQjQqV4RNJ24QFp1AeobC1K0XqOXnho+bPQCRsUnEJ+sAUAGKAr6FHYzYmqyzxM+jWpX9R1Y4OzvTpk0b3nzzzUzT4+PjmThxIh06dGDBggWUKFGCX3/91TB/zZo1REdHM2PGDEaMGMFff/1FSEjIi9vzEm0X+Sg8LAxra2v8/P0N08pXrEjoubNGjCrnpF3CmNwK2PKauwNh0QnAf84j/v8T/2JOhkktq3pydvx7nBr3HgEeTizbH5mf4WabJX4eVTn4Lytq1qxJjRo1KFCgQKbphw8fxtvbm9q1a6PRaGjXrh1XrlwhKioKgN27d9O2bVscHR3x8vKiUaNGBAcHv3B/0u1sohIfJOLk5JRpWkGngiQkJBgpotwh7RLGYq1WMbVbFdYdusalmER2h95ieveqLN0XyeXbiXze2B+9XsFOY2VY569jUfx1LArfwg60reFFbHyqEVuQdfJ5fNLQoUMNfwcGBhIYGJil9a5du4aPj4/huVarpWjRoly7do2CBQty9+7dTPN9fX05cuTIC7cryddEOTo4Eh8fn2lafEL8E0dl5kbaJYxBpYJfu1YhTafn+zWnAdh3IZZfNl9gTs9qOGptWBB8icRUHdH3njyvfeX2A8JuJvBThwr0mffiL1Zjs8TPY05HO48dOzZb66WkpDxxIGNvb09KSgopKSmG5/+d9yLS7fwMer3eqPv38/dHp9NxMTzcMO30yZMElDHPwRKPSLuEMUz4sBJuBWzpM/8IOr1imP773is0+PEfqg7bxuaQm1irVVy48fTq0FqtNpwPNnWW+HlU5eCRE1qt9omBhklJSWi1WrRaLUCm+Y/mvYjJVr67d+9m48aNqFQqihcvTocOHZg1axYJCQk4OTnRv39/3NzcmDFjBjY2NkRERJCcnEzXrl2pWrUqwcHBHD58mKSkJOLi4njjjTdo164dAHv27GHLli3odDr8/Pz4+OOPUavVdOnShbfffpvTp0/Ts2dPSpcubbT2Ozg40LJ1G34YNZxZc+ZxMiSEvzf+xa49B4wWU26QdpkfnU6HTqcjIyODjIwMUlJSsLa2xtraZL8+Mvm5QwVKFXHkw+n/kpr+v4NqW2s1PoUdCLuZgIezHWM/qMiC3RHcT04HHl6GtON0NHcS0/Ar6siAd0qxO/S2sZrxUizx86g20oW+3t7e7N692/A8JSWFmJgYvL29cXR0xNnZmcjISCpUqABAZGQk3t7eL9yuSf7ruXbtGn/88Qc//vgjTk5OJCYmMn36dBo0aEDDhg35559/WLBgAV9//TUAt2/f5ueffyYmJoZRo0ZRvnx5AC5evMikSZOwtbXlm2++oUqVKtja2nLgwAF+/PFHrK2tmTdvHnv37qVBgwakpqZSqlQpunbt+tS4goKCCAoKArLfhfEypkybSZ9ePSju4Y6LqytTps8y28sEHiftMi9jf/6J0T+OMjxfsXwpw74fwXfDRxovqCzydLajcz1fUtIzOPbzu4bp36w8yT9nY5jWrSo+bvYkpupYc/AaE/8+b1imWgkXBjcLwMHWijuJaWw6cYNJm84/bTcmydI+j3mdeh8dXOr1evR6PWlpaVhZWVGjRg2WLFnCwYMHqVKlCmvXrsXHxwdPT08A6tevz7p16yhRogT3799n586d9O/f/8XtURRFeeFS+WzLli3cu3ePDz74wDCtZ8+ezJkzB2tra3Q6HX369GH+/PnMmDGDgIAA3nrrLQBGjBjBRx99xJUrVzhz5gwDBw4EYNWqVTg6OmJlZcWff/5p6MNPS0ujbt26tG/fno4dO7J8+XLU6qz1xqfocrnhQohM/L/YYOwQ8kTY5BbGDiFPaPOwnDt48V62161VqtALl1m9ejVr167NNO3999+nffv2nDp1igULFnD79m3Ddb7u7g9v1pLd63xNsvJ9WaosdkeoVCoURaFBgwZ8+OGHT8y3sbHJcuIVQgiRj/K49G3fvj3t27d/6rwKFSpkurb3cTY2NvTv3z9L1e7jTDLTlCtXjoMHDxqGxScmJuLv78+BAw/PV+zbty/T+diDBw+i1+uJjo4mJiYGDw8P4OFdSRITE0lLS+PIkSO8/vrrlC9fnoMHD3L//n3Dtm/fNo/zOEII8arK6+t885tJVr7e3t60bt2akSNHolar8fX1pUePHsycOZMNGzYYBlw94urqyrfffktycjK9evVCo9EAULJkSSZNmsSdO3d44403KFmyJAAdO3bkp59+QlEUrKys6Nmzp+FWYUIIIUyPpf2wgkme830ZM2bMoGrVqtSqVSvT9ODgYC5dukTPnj3zbN9yzleIvCXnfM1LXp7zPRJxP9vrVi9RMBcjyR0m2e0shBBCWDKzr3yNSSpfIfKWVL7mJU8r38s5qHxfM73K1yTP+QohhBCPM9WBU9klyVcIIYTJs7QBV3LOVwghhMhnUvkKIYQweRZW+EryFUIIYQYsLPtK8hVCCGHyZMCVEEIIkc9kwJUQQgghckQqXyGEECbPwgpfSb5CCCHMgIVlX0m+QgghTJ6lDbiSc75CCCFEPpPKVwghhMmztNHOknyFEEKYPAvLvZJ8hRBCmAELy76SfIUQQpg8GXAlhBBCiByRylcIIYTJkwFXQgghRD6zsNyLSlEUxdhBmKsUnbEjEC9Dr7fMj7pabWlfS5av5Kd/GjuEPBE1s3WebTv05oNsrxtQzCEXI8kdUvkKIYQweTLgSgghhBA5IpWvEEIIkycDroQQQoh8ZmG5V5KvEEIIM2Bh2VfO+QohhBD5TCpfIYQQJs/SRjtL8hVCCGHyZMCVEEIIkc/yOveOHDmS8PBw1OqHZ2NdXFyYMmUKAPv27WP58uUkJCRQvnx5+vfvj6OjY472J8lXCCGE6cuHyrdHjx40atQo07Rr167x22+/MXToUEqUKMGcOXOYN28en3/+eY72JQOuhBBCiGfYu3cvVatWpUyZMmi1Wjp06MChQ4dITk7O0Xal8hVCCGHycjrgaujQoYa/AwMDCQwMfGKZ5cuXs3z5cjw8POjYsSNly5bl+vXr+Pv7G5YpWrQo1tbW3Lx5kxIlSmQ7Hkm+QgghTF5OB1yNHTv2ufM7deqEl5cX1tbW7N+/n3HjxjF+/HhSUlKwt7fPtKy9vX2OK1/pdhZCCGHyVDl4ZIWfnx92dnbY2NjQsGFDXn/9dU6cOIFWq30i0SYnJ2NnZ5ej9kjlK4QQwvTl86VGKpUKRVHw8vIiMjLSMD0mJob09HSKFSuWo+1L5SuEEOKV9uDBA0JCQkhLSyMjI4O9e/cSGhpKpUqVeOONNzh27BihoaGkpKSwatUqatasKZWvEEIIy5eXd7jKyMhg1apVREVFoVar8fT0ZPDgwXh4eADQq1cvpk6dSmJiouE635xSKYqi5Hgrr6gUnbEjEC9Dr7fMj7pabWG3/nkFlPz0T2OHkCeiZrbOs21fjUvN9rrFXWxzMZLcId3OJiwuLo7277fGtaAD/iV9WLliubFDyhWW2i6AHt27UMLHg6JuBalY9nUWLZhn7JByhaW+Z+baLo21momdK3Pox3e58Esztn/zJm+WKWKY/0EdH/aNfJuwX5qzdEAdihTUGuYtGVCbsF+aGx6Xp7YkaNhbxmjGS8nrAVf5TbqdTdjnnw5Ao9EQGRXDyZAQ2rRsSoUKFSlTtqyxQ8sRS20XwFdfD2XWnHnY2tpy4fx5Gr/zJhUrVaZylarGDi1HLPU9M9d2WalV3LibTNvJe4m6m0SjskWZ/XF1Gv30D96u9gxtWZZ2v+7l8q1EfmhXgRk9qvP+5L0AdJnxb6Ztrfm8Hvsv3DZGM15pUvmaqAcPHrD+j3WMGPkjjo6O1K1Xj6bNWrB82RJjh5YjltquR8qUKYut7cMuLpVKhUqlIiLikpGjyhlLfc/MuV3JaRn8suk81+OSUBQIOhPN1TtJVCheiMDyRfn7eBRhNxNIz1D4dcsFavu54ePm8MR2vFzsqVnKjbWHrhmhFS9Hpcr+wxRJ8jVR4WFhWFtb4/fYnVXKV6xI6LmzRowq5yy1XY/7/JP+uBVyoHKFAIoWLca7jZsYO6QcsdT3zJLa5VbAlhLujly4GQ9kTjiP/nzdw+mJ9d6v6c2hi7Fcj0vKhyhzyrI6niX5mqjEB4k4OWX+x1LQqSAJCQlGiih3WGq7HvfrtJnE3Ilnxz97aNmqtaESNleW+p5ZSrus1Sqmf1SNtQevcikmkeCzMTSv4kmApxNaGzVfNCmNXq9gp7F6Yt33axZnzcGrRoj65Unlmw9mz57N9evXX2qdLl26vNTyq1evZsOGDS+1Tn5ydHAkPj4+07T4hHgKFChgpIhyh6W267+srKyoU7ceUdevM3fOLGOHkyOW+p5ZQrtUKpjavRppOj3DVp0EYO+F20z8O5S5vWpy8Md3uRaXRGKqjpt3M9+lqXpJV9ydtPx9IsoYob80y6p7TTT59u3bFy8vL2OHYVR+/v7odDouhocbpp0+eZKAMqY9EORFLLVdz6LL0Jn9OV9Lfc8soV2TOlehsJMtveceQvfYpXSL91ym3sgdVBq6hc0nbmCtVnHhRuYDjXY1i7Pl5A2SUjPyO2yBkUc737p1i59//pkSJUpw+fJlvLy8GDhwIGPGjKFLly6ULFmSLl260KRJE44fP45Go2Hw4MEUKlToqdtbsWLFE8vdunWLWbNmkZCQgJOTE/3798fNzS3TetHR0cyfP5/4+HhsbW3p06cPnp6e+fAKPJuDgwMtW7fhh1HDmTVnHidDQvh741/s2nPAqHHllKW2Cx5+nncH/8N7TZphZ2fHPzuDWLNqJYt+N4/LV57FUt8zc2/X2A8q4Ve0AB2m7iMlXW+YbmutxrewAxduJuDhbMe4Dysxf9cl7ienG5bR2qhpXtWTj+ccNEbo2WKq3cfZZfTK98aNG7zzzjtMnjwZOzs7tm3blml+amoqfn5+TJgwgYCAAHbu3PnU7TxruQULFtCgQQMmTpxIvXr1WLBgwRPr/vbbb/To0YNx48bRpUsX5s0zjWszp0ybSXJyMsU93OnW5QOmTJ9l8pdAZIWltkulUjHvt9n4l/DGs4gL3w4dzPiJk2navIWxQ8sxS33PzLVdni52dHnjNcp4FSRkTBPDNbutq3tha2PF9B7VCZ/cnE1fN+TY5TjGbzyXaf13K3oQn5TO/rBYI7Xg5aly8J8pMvp1vq6urpQuXRqA+vXrs3nz5kzzra2tqVr14TWSJUqU4NSpU0/dzrOWCw8P56uvvjJsf9myZZnWS0lJ4cKFC/zyyy+GaTrd029dFRQURFBQEPDin6fKDS4uLqxZtz7P95PfLLVdhQsXZltQsLHDyBOW+p6Za7ui4pLx7P/su2S9Pfqf567/19Hr/HX05cbVGJ1p5tBsM3ryVf2nL+G/z62srAzT1Go1GRkZ6PV6hgwZAkC1atXo0KHDU5fLCr1ej4ODAxMmTHjhss/6AWYhhBB5y8Jyr/G7nWNjYwkLCwNg3759hir4edRqNRMmTGDChAl06NDhucv6+/tz4MCBZ27f3t4ed3d3/v334V1fFEXhypUr2WiJEEIIkTVGr3w9PDzYunUrs2bNwtPTk3feeYdjx47l2vZ79OjBzJkz2bBhg2HA1X99+umnzJ07lz/++AOdTkfdunXx9fXNtRiEEELkjKUNuDLqrxrdunWLcePGMWnSJGOFkCPyq0bmRX7VSJgK+VWjl3c7IftfuIULGL3OfILpRSSEEEL8l4UdYxr1nK+7u7vZVr1CCCFEdknlK4QQwuRZWOEryVcIIYTps7QBV5J8hRBCmDxTvVNVdknyFUIIYfIsrfI1+k02hBBCiFeNJF8hhBAin0m3sxBCCJNnad3OknyFEEKYPBlwJYQQQuQzS6t85ZyvEEIIkc+k8hVCCGHyLKzwleQrhBDCDFhY9pXkK4QQwuRZ2oArOecrhBBC5DOpfIUQQpg8SxvtLMlXCCGEybOw3CvJVwghhBnI4+ybmJjIrFmzOHXqFAUKFODDDz+kXr16ebY/Sb5CCCFMXl4PuJo3bx7W1tbMnTuXK1euMGbMGHx8fPD29s6T/cmAKyGEEK+0lJQUDh06RIcOHdBqtZQuXZpq1aqxZ8+ePNunJF8hhBAmT6XK/uNFbt68iZWVFR4eHoZpPj4+XLt2Lc/aI93OOaCVV8/MWNqQDWGuoma2NnYIZicn37fJycmMGjXK8DwwMJDAwEDD85SUFOzs7DKtY29vT0pKSvZ3+gJS+ZqBoUOHGjuEPCHtMj+W2jZLbRdYdtuyys7OjrFjxxoejydeAK1WS3JycqZpycnJaLXaPItJkq8QQohXWrFixcjIyODmzZuGaZGRkXk22Aok+QohhHjFabVaatasyapVq0hJSeH8+fMcOXKE+vXr59k+Jfmagf92kVgKaZf5sdS2WWq7wLLblps+/vhj0tLS6NWrF1OmTKFXr155WvmqFEVR8mzrQgghhHiCVL5CCCFEPpPkK4QQQuQzSb5CiGyTs1ZCZI8kX2ESkpKSSEtLAyA2NtbI0eQfnU5n7BByJDEx0dgh5Btzf6+EaZHka4b0er2h4tDr9UaOJufS09MJDw9n586d/Pnnn2zZssWQiC3ZgwcPCA0NJSEhgaCgIE6dOmXskF7KqVOnGD58OA8ePLCIz+HzhISEsGvXLotMwI++SxITEzP9u5NejbwlN0g0M0ePHuXw4cM4Ojry3nvvUbhwYfR6PWq1+R5H2djY4Orqyh9//EFMTAxDhw5Fo9GYfbueJyEhAXt7e0JDQ/njjz+4e/cuw4cPN3ZYWXblyhU2bNhAnz59cHBwsOjke+nSJQ4dOkSDBg2wtrasr0xFUVCpVBw/fpz169fj6+tLamoq/fr1Q2Vpv15vYizzm81CXb9+nT/++IOAgACsra0ZN24ct27dQq1Wm+WX3+NH1levXkWn01GlShWOHz/OvXv3LDbx3r59m23btmFlZUX58uW5ffs25cuXR6VSmc37ePXqVS5cuMD169cBUKvVFlcp6fV6kpOT+fnnn7l+/TqlS5dGr9ebzXv0PI/aoFKpCAsLY/Xq1fTt2xc3NzcuXbqUp/c0Fg9Z5rebBYqIiGDNmjXUrl2bN998kw8//JBatWoxYcIEoqOjzTJRPTqyPnDgAPv27WPw4MG88847JCYmsnnzZgAuXrzIxYsXjRlmrtNoNDRp0oTLly9z584dfvjhB6ytrdmyZYshmd25c8fIUT7d6dOnCQsLo379+nTr1o1///2Xo0ePAg/fT0tLwHZ2dowYMYJr166xefNm1Gq12R9oxMfHs3PnTu7evWuY9v777xMdHc3Bgwf5+uuv0Wq1REREGDFKy2d+39ivKCcnJ5KTkwkPDyc+Ph54+A+matWqjBkzhrS0NLP8QggLC2Pv3r2UK1eOQoUKUbx4capWrYpOp2PUqFHMmDGDQoUKGTvMXPHo/SlYsCBWVlacOXOGEydOcO/ePdq2bcuDBw84ePAgixYtYsqUKSQlJRk54ifdunWL77//nvDwcAIDA3njjTfYuXMnhw4dArCYrsozZ86wZMkSgoODcXR05Mcff2TNmjVs374dMO92Xrp0iUuXLnHw4EHu37+PoijMmTOHFStWMHLkSNzd3Tl79iybNm0yfNeI3CfJ18SFhYVx7tw5kpOT+fLLL0lPT2f79u2GfxQdO3bkm2++QaPRmMUXwn8PENRqNQ4ODoSGhnL16lXUajVly5alSZMmvPvuuwwePBg3NzcjRZt7Hp1bA0hLS8PW1pb33nsPPz8/tm7dyo0bN/jggw9wcnIiNTWVnj17Ym9vb+So/ycpKQm9Xk+jRo3o06cPP/30E2FhYTRs2JBq1aoRFBRk+CI3dydPnmThwoW8/vrr7Ny5k40bN+Lt7c2IESNYuHChoVfGXFWuXJlq1aoRHR3N/v378fPzo23btiQlJREdHc2///7LggULqF27Nk5OTsYO12LJ7SVN2LFjx1i9ejVvvvkm27dv5+OPP8bd3Z358+fj5eVF8+bNzeofx+MJ6OzZs9jY2ODi4oJarebvv//G3t6eWrVq4eXlZeRIc9e1a9ewtbXF3d2djRs3cvr0aVJTU2nevDlly5Zl9+7dXLlyhTp16lChQgWTG2h248YNtm3bRs2aNSldujRqtZp//vmHhQsXMnz4cPz8/IiLi8PFxcXYoeaYTqfjr7/+okaNGqSkpDBv3jy+/vprXF1dgYcDzeLj46lQoYKRI315j//7g4ej1Q8ePIiXlxeBgYH8888/nDt3DrVaTYMGDahcufIT64jcY1lD9yzIgwcP2Lp1K99++y0hISHY29tTtGhRXFxc6NWrF7Nnz+bBgwdmlXwf/SPevn0727Zto0yZMhw9epQvvviCwMBAgoKC2L17N2+++SYeHh5Gjjb3/PXXXwDUqlWLkJAQevbsydWrV1m0aBFdu3blnXfe4e+//+bYsWP4+/vn6W+IZoezszNqtZrDhw9jZWVFyZIleeutt9i/fz8//fQTs2fPtojEC2BtbY2dnR0zZ84EYMiQIbi4uHD06FGSk5N54403gCcTmal7FO+ZM2e4cuUKGo2Ghg0botVq2b17N//88w+NGjWicePG6HQ6w6huc2qjuTGdw2sB/K9bVqVS4erqysGDB9m5cyf9+/fHxcWFI0eOYG1tzddff02xYsWMHO3Li4mJYffu3QwZMoSePXvSrVs3pkyZgk6no0GDBlhZWeHo6GjsMHPFo/eyf//+WFtbs2nTJnx8fPDw8KBWrVr07duX+fPnExsbyxtvvEG7du1MKvGeO3eO/fv3Ex4eTrdu3bC3t+fff//l7NmznDt3Dh8fH77//nvs7OyMHWqOXbt2jdOnT5OUlISfnx9ubm7Url0bFxcXLl68yLJlyyhYsKBheXNLSiqVilOnTrF48WJ0Oh1hYWEMHTqU4sWL06BBAy5fvsy2bdtIT083qV4XSyaVr4m5f/8+hQoVwt7enoIFC/L7778zceJEihUrxvnz51m9ejWffPKJ2VS8/60QChYsSNGiRdHr9eh0OmrVqkVMTAzBwcF07dqVYsWKodFojBhx7ni83Wq1mt69e7Ns2TIiIiKIiYnB1dWVcuXKUbFiRVJSUnB3dzdyxJmFh4czbdo06tatS2hoKPv376dfv35s2LCB/fv3c/bsWXr06EGpUqUA86sEHxcSEsLChQtxcXGhUKFC+Pn5UaZMGS5fvsyIESNITU2lU6dOZtnV/LgTJ07QuHFjGjVqBMDvv//OpEmT+Pbbb7l37x4eHh7Y2NgYOcpXhyRfE3L8+HFWr16Nh4cHbm5u1KhRA7VazfTp06lduzbBwcF07NiR4sWLGzvULHv0hRwbG4u9vT329vaoVCr++ecf2rVrBzy89OZRlWhpiXfPnj1kZGSg1Wrp0qULv/32G2vXriUgIAArKytOnz5N+/btjRxxZqGhofz777/06tWLKlWqADBs2DCWLVtGp06d0Ol03Lt3Dzc3N0NbzTXxXr9+nY0bNzJ48GC8vLzYs2cPN2/epGzZsrzzzjtER0ej1WpxdXU1qwOMp8VqY2PD/fv3Dc87dOjA3Llz0el01KhRI79DfOVJ/4KJCA8PZ8+ePXTt2tVwLmbjxo289957NGrUCDc3N3r06EG1atXMYkTp+fPnuXLlCgB///03o0ePZsGCBWzfvp3evXsTGRnJ7NmzmTNnjuE8r6V49KW3adMmdu3ahZ2dHcuXL+fw4cN8/PHH2NnZ8eeff3Ljxg2+//57kxrNHRMTw6FDh9i9ezcxMTGG6Z988gl37941nA98FLO5JKOnSU1N5fjx40RGRnL16lUA6tWrR0pKCgcOHMDKygpPT0/DYCtzauujWCMiIrhy5QoJCQk0aNCATZs2sX//fgAuX77MtWvXiI+PN4vvFEsjla8JSE5OZuHChdjY2FCmTBn0ej0eHh6sXbuWyMhI3nrrrUzLm8OXwIULF9i6dSvdu3fn+vXrfPHFFzx48ICNGzei0+kYMmQI58+fJzY2lpYtW1K0aFFjh5yrkpKSiIiIYMSIEfz55594enpSuXJl1Go13bt3x8bGhrffftukEu/Ro0dZs2YNQ4cOxcvLi02bNhEQEICvry+3bt3i2rVrpKSkWMQ5+fT0dGxtbWncuDFpaWmEhITg5OREuXLlqFy5Mv/88w8pKSkmdQ4+K+Li4pg5cybfffcdly9fZty4cfj7+2NnZ0ezZs34/vvvmTZtGqdPnyY8PJxOnToZDi5E/pJLjYwsOjqalJQUUlNTmTBhAh9++KEh2f72228UL16cxo0bGznKrHv8MpnVq1ezd+9eqlWrRrdu3UhPT+f69eusXbsWT09PPvzwQyNHm3v+ex2vSqVi8uTJODo6kpSUxKeffopGoyEoKIjSpUub3OVUV65cYcaMGXz22WeG2KZOnUpkZCT+/v6kpKRQq1YtatasaeRIc+7w4cOG5NqqVStcXFw4deoUwcHBVKhQgfPnz9OmTRuqVatm7FCzZdSoUSQnJ1OpUiVq1aqFq6srhw4d4syZM7Rq1YqiRYuSlJREcnIynp6eZtWdbkmk29mIDh8+zKRJk1iwYAFHjhyhUaNGrFu3jmXLlnHhwgUuXLhgcl/Sz6MoiiHxbt++HXd3d958800OHz7M1atXsbGxwcfHh9atWxMbG2sxd895/MsrODiYw4cPG3oxjh8/Tvv27dFoNOzevZstW7aYZDVlbW2Nr68voaGhrF27lh9//BG1Wo2joyOnTp3ijTfeoGbNmmZ/X+Pr16+zYcMGWrVqRcOGDdm4cSM3btygYcOGVK9endu3bxMYGGg2p3ce9+i9GTFiBF5eXmzZsgV7e3sKFChApUqVqFChAmvWrOHMmTO4uLjg6ekJmEdPmiWSytdIEhISmDp1Kl27dsXb25t//vmHBw8eULBgQZYuXUqRIkXo06cPXl5eJnfThRfZsWMHO3fu5Ouvv8bFxYU//viDQ4cO8cknnxjak5GRYXEjK7dt28Y///zDF198Yagu9uzZw8aNG6lcuTLh4eEMHDgQb29vY4f6hJSUFIKDg9m3bx/NmzfH09OT0NBQihQpQlRUFOvXr2fYsGFmNdjvv27cuMHq1atRq9V8+umnwMORzr/99hvfffcdGo2Gw4cPc/HiRRo3boy/v7+RI355j39XjB8/njt37jBu3Djg4aDHkJAQSpUqha+vrxGjFCCVr9FYWVmRkpJCQkICAPXr1ycqKoq4uDiGDh0KPLy1JGBWiTctLY0TJ07QsWNHrKys2LFjBxkZGSQlJTFu3DjDLSQtIfE+Om5VFIW4uDj27dvHZ599hpubGwcOHGDz5s2UKVOGIUOG8PbbbzN48GCTTLwAWq2Wxo0bM3LkSGrWrElKSorhhwTee+89WrVqZfYj0V1cXChSpAj37t3j3Llz6HQ6KlWqRJUqVbh16xZubm5UqlQJf39/ChcubOxws0WtVpOeng7A119/jaenJ8OGDQPAzc2NBg0aSOI1EVL5GtHff/9NSkoKNWrUoHjx4hw/fpyQkBC6d+/OmTNnWLduHYMHD8bBwcGsuoaCgoLYvn07rq6ueHp64u7uzoMHD7CysqJGjRoWN7jq0cCc1atXc+LECUN3XqFChdDr9XTt2tXIEWadXq/nypUrzJs3j9atW1O9enVjh5RjYWFh3L9/H61WS/ny5Vm9ejXx8fF4eHjg6+vLlClTGDRokKHSffwOT+bmUeV7584dzp8/T926dRk9ejTx8fGMGzdOzu+aEEm+RhQXF8f27dsJDw/H39+fPXv20LNnT8O1lWlpaWZZbaSlpXH16lWKFi2Ko6Mje/bsYdeuXQwbNsxsv9Se5dy5cyxbtowvvvgCtVrNmTNnKFu2LK6uruzatYvTp08zcOBAs+q9SElJIT4+Hnd390x3XDNHISEhLFmyhMqVK3P+/Hm8vLzo27cvf/zxB4cPH8bHx4fatWtTqVIlszu988jVq1exs7PDxsaGQoUKERsby5gxY2jatKlh8GZERAQlSpQwcqTicZJ8jSw5OZmwsDCio6Px9fXl9ddft5ijU71eT3BwMJs2beKzzz4z6/OFzzNnzhzu3r3Lxx9/bLh0aOfOnWzfvp0BAwZYbLtNnV6vZ8qUKdSpU8cwSnvYsGGUK1eODh06sGLFCnQ6HW+88Qa+vr5mlXgfHSicOXOGadOmUbp0aRwdHXnrrbewtrbm9OnTNGvWzGwPKF4FknxFnklNTeXAgQP4+fmZ1ajtrAgLCyMtLY1y5coBsGDBAq5evcrAgQOxsrJi+/bt1K5dWxKvkZw9e5b4+HhCQ0OpUqUKlSpVAv432rl///4kJyezdOlSHB0dadu2rVn0Mj2eTM+fP8+pU6eoXr06Dg4OHDlyhIiICFq2bGn43EnyNV3yrog8Y2trS8OGDS0i8T4+uCoxMZGDBw9y/Phxzp8/D0CPHj2wsbFhzJgx6PV62rZtK4nXSI4ePcrixYtxc3PDw8ODuXPnEhcXBzw81XP79m0SExOxs7OjS5cuNGnSxCwSb2xsLEFBQeh0OuDhdfRbtmyhaNGiuLu7U6VKFUqUKMHatWvNcrDmq0beGZGnLKH7/PHTAOnp6Tg6OtKmTRtsbW05ceIE586dA6BBgwYUKFAAtVptcee2zUVKSgq7du2iZ8+e+Pn50bhxYxo2bMjo0aP5/fffWbhwIc2bN8fR0RG9Xo9Wq830a0WmTKPR4O/vT0JCAhkZGQwfPhxPT0+mTp0KQLFixahcuTJ+fn5mcTDxqpNuZyGyaPPmzZw5c4bk5GTeffddSpcuzfbt24mJiUGlUhETE2O41EgYR0pKCqNHj+b999+nYsWKhgOn4OBgSpQogU6no0SJEmY3riIjIwMrKysAxo4di6enJx988AHW1tYMGzYMZ2dnvvrqK+Dh6R5bW1tjhiuyQCpfIbLg0KFD7Nu3j86dO9OyZUuWLVvGmTNnaNu2LQ0bNsTFxYU+ffpI4jUyrVZLnTp1uHDhAtevX0elUhEWFsaBAwdwcnIyjPg1p8QLD+8LcP78eY4fP06tWrWIiIhg06ZN6HQ6Ro8eTXR0NGPHjgWQxGsmpPIV4in+O1DlwIEDXLlyxXA/6osXLzJx4kS+/fZbObdrYuLi4tixYwdnz56ldOnS/Pvvv3z00UeGS/jMyaMK/cKFC8yePZvXXnuNQoUKERERQXp6OtWrV6d58+ZYWVlx4cIFXn/9dWOHLLJITkwJ8RSPEu/hw4extbXlypUrpKSkkJaWho2NDaVKlaJq1aoyoMUEubi40LJlS8qVK8f9+/epXr06fn5+xg4rW1QqFRcvXmTlypX069cPf39/oqOjOX78OFeuXOH48ePEx8fTtWtXSbxmRpKvEI95/Fzg/v37Wbx4MY0aNeLMmTPcuHEDjUZDmTJluHPnDufOnaN169ZGjlg8jVarpWzZssYOI1ckJSVx7tw5zpw5g7+/P25ubri7u3Pv3j06duzIvXv3jB2iyAY5bBfi/z2eeGNjY1GpVPzwww906NCBNm3aULhwYc6dO2eoPAYNGiTneEWeq1ChAl999RW7du1i3759WFtbY29vz8mTJ7G1tZU7V5kpqXyFIHPi3bx5M/v27SM5OZlmzZrh4uJCtWrV0Ov1LFy4kFKlSvHuu+8aRp8KkdeqV6+OSqVi2rRpHDp0CJVKRbt27XBwcDB2aCKbpPIVgv+Nfj18+DAREREMHDiQqlWrcvXqVcLDw8nIyKBGjRp07tyZggULSuIV+a5atWp88sknREdHU6pUKcNvDsuYWfMkyVeI/xcXF8fChQuxsrLCw8OD9u3bY2dnx6FDhzh79iwZGRnUrVuXIkWKGDtU8YqqVq0anTt3ZvPmzYYK2NwumxIPSfIV4v+5uLjQvXt3QkJC2LdvHxqNhnbt2mFlZUVISIjhtn5CGFPFihXp37+//C6vmZPrfIX4j+PHj7N8+XJatWpFvXr1yMjI4MGDBzg5ORk7NCGEhZABV0L8R5UqVVCpVPz2229YWVlRu3ZtSbxCiFwlla8Qz3Dq1CmKFCki53iFELlOkq8QQgiRz2TAlRBCCJHPJPkKIYQQ+UySrxBCCJHPJPkKIYQQ+UySrxB5ZMaMGaxcuRKA0NBQPvvss3zZb/v27YmOjs6z7R8+fJh+/frRpUsXLl++nGf7EcKSyXW+4pU2YMAA7t27h1qtRqvVUqlSJXr27IlWq83V/QQEBDBlypQXLhccHMzOnTv58ccfc3X/j4wcOZLw8HCsrKxQqVQULVqU2rVr07RpU2xsbLK0jSVLltCjRw+qV6+eo1jat2/P1KlTKVq0aI62I4Q5kuQrXnlDhgyhQoUKxMXFMXr0aNatW0enTp0yLZORkWExP6bQo0cPGjVqREpKCpcuXWLRokWcOnWK77//Pkv3Cb59+zbe3t75EKkQlkuSrxD/z8XFhUqVKnHt2jXgYWXWo0cPNm/eTEZGBjNmzODYsWOsXLmS27dv4+XlRa9evfDx8QHg8uXLzJ49m5s3b1K5cuVMiezs2bNMmzaN2bNnAw9/L3jRokWEhoaiKAp169bl3XffZe7cueh0Orp06YKVlRWLFi0iPT2dFStW8O+//6LT6ahevTrdu3dHo9EAsGHDBv7++29UKhUdOnTIcnsf/eD8kCFD+Pzzzzl+/DhVq1ZFr9ezYcMGdu7cyYMHDyhXrhy9e/fG1taWHj16oNfrGTx4MIUKFWLatGnExcWxYMECQkND0Wq1NG3alCZNmgCg1+tZv349u3bt4v79+xQrVozBgwczbdo0AAYPHgxAv379qFOnTg7fQSHMhyRfIf5fbGwsJ06coEaNGoZpR44c4eeff0aj0XD58mVmzZrFkCFDKFmyJHv27GH8+PH8+uuvqFQqJkyYQJMmTWjcuDFHjx5lypQptGzZ8on96PV6xo0bR9myZZkxYwZqtZqIiAhDMv9vt/OyZcuIiYlhwoQJWFlZMWXKFNauXcuHH35ISEgIGzdu5Pvvv8fd3Z05c+a8dLvd3NwoWbIkoaGhVK1ala1bt3LkyBFGjhyJk5MTCxcuZN68eXz++ecsWbKE9u3bM2HCBIoWLWpoS/Xq1fn888+5c+cOP/74Ix4eHlSqVIm///6b/fv3880331CsWDEiIyOxtbVl1KhRmbYjxKtGBlyJV96ECRPo3r07w4cPp0yZMrRp08Ywr3Xr1jg6OqLRaAgKCiIwMBA/Pz/UajUNGzbE2tqa8PBwwsLCyMjIoGnTplhbW1OrVi1Kliz51P1dvHiRuLg4unTpglarRaPRULp06acuqygKO3fupFu3bjg6OmJnZ0ebNm3Yv38/AAcOHKBhw4YUL14crVZLu3btsvUaODs7k5iYCMCOHTvo2LEjrq6u2NjY0K5dOw4dOkRGRsYT6126dIn4+Hjef/99rK2tKVKkCI0aNeLAgQMA7Ny5k44dO+Lh4YFKpcLX15cCBQpkK0YhLIlUvuKVN3jwYCpUqPDUea6uroa/Y2Nj2b17N1u3bjVM0+l0xMXFoVKpcHFxydTV7Obm9tRtxsbGUrhw4SydQ46Pjyc1NZWhQ4capimKgl6vB+Du3buUKFHCMK9w4cIv3ObTxMXF4e/vDzw8pztx4sRMbVGr1dy/fx8XF5dM692+fZu7d+/SvXt3wzS9Xk9AQAAAd+7ckXtjC/EUknyFeI7HE5Crqytt2rTJVBk/cu7cOeLi4lAUxbDOnTt3ntql6ubmRmxsbJYGcRUoUACNRsMvv/zyROKDhxXrnTt3DM9jY2Oz3LbH14mIiDB0kbu6utKvX79nVuOPc3Nzw93dnalTpz51vqurKzExMRQvXvyl4xLCkkm3sxBZ1KhRI3bs2EF4eDiKopCSksLx48dJTk7G398ftVrNli1b0Ol0HDp0iIsXLz51O6VKlcLZ2Zlly5aRkpJCWloa58+fB6BQoULExcWh0+mAhxVno0aNWLRoEffv3wceVqkhISEA1K5dm+DgYK5fv05qaipr1qzJcntSU1M5d+4cEyZMoFSpUlSuXBmAt99+2zCoDB5W30eOHHlmW+zs7Fi/fj1paWno9XquXr1qaHujRo1YtWoVN2/eRFEUIiMjSUhIAKBgwYLExMRkOV4hLIlUvkJkUcmSJenTpw8LFizg5s2bhnO1AQEBWFtb89VXXzFnzhxWrlxJ5cqVMw3cepxarWbIkCEsWLCA/v37o1KpqFu3LqVLl6ZcuXKGgVdqtZr58+fTqVMn1q5dy7Bhw0hISMDFxYW3336bSpUqUblyZZo2bcqoUaNQq9V06NCBffv2PbcdCxYsYPHixQAULVqUWrVq0axZM9Tqh8fij0Yq//TTT9y9e5eCBQtSu3btp17X+6gtv//+OwMGDECn0+Hh4WEYdd2sWTPS09P56aefSEhIwNPTk6+++gqAdu3aMWPGDNLS0ujdu7eMdhavFPlJQSGEECKfSbezEEIIkc8k+QohhBD5TJKvEEIIkc8k+QohhBD5TJKvEEIIkc8k+QohhBD5TJKvEEIIkc8k+QohhBD5TJKvEEIIkc/+D/aDgeXWQZHZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "predictions = list()\n",
    "for path in testGen.filepaths:\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    preds = model.predict(image)\n",
    "    predictions.append(preds.argmax(axis=1))\n",
    "\n",
    "print(classification_report(testGen.classes,\n",
    "\tpredictions, target_names=testGen.class_indices, digits=3))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.grid(False)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "font = {'size' : 12}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "cm = confusion_matrix(testGen.classes, predictions)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(testGen.class_indices))\n",
    "\n",
    "plt.xticks(tick_marks, testGen.class_indices, rotation=45)\n",
    "plt.yticks(tick_marks, testGen.class_indices)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Defect')\n",
    "plt.ylabel('True Defect')\n",
    "plt.title('Confusion matrix VGG16')\n",
    "plt.savefig('output/vgg_confusion_matrix.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c84cac0d85cf2b51a97d2bd7b0fa6585599b14f00604962e71b8ec1671851d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
