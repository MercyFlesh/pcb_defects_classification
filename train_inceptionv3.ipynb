{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools import config\n",
    "\n",
    "if not os.path.exists(config.DEFECTS_PATH):\n",
    "    !python \"tools/extracted_defetcs.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenAug = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "\tzoom_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tvalidation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 6 classes.\n",
      "Found 2001 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"training\")\n",
    "\n",
    "testGen = datagenAug.flow_from_directory(\n",
    "    config.DEFECTS_PATH, classes=config.CLASSES,\n",
    "    target_size=(224, 224), class_mode=\"categorical\",\n",
    "    batch_size=32, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = InceptionV3(weights='imagenet', include_top=False,  input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "for layer in resnet_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "head = resnet_model.output\n",
    "head = GlobalAveragePooling2D()(head)\n",
    "fc = Dense(1024, activation = \"relu\")(head)\n",
    "fc = Dropout(0.2)(fc)\n",
    "output = Dense(len(trainGen.class_indices), activation = \"softmax\")(fc)\n",
    "\n",
    "model = Model(inputs=resnet_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(os.path.sep.join([config.OUTPUT_PATH, \"inceptionV3.h5\"]), monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.15625, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 15:56 - loss: 33.3503 - accuracy: 0.1562\n",
      "Epoch 1: accuracy improved from 0.15625 to 0.21875, saving model to output\\inceptionV3.h5\n",
      "  2/250 [..............................] - ETA: 2:37 - loss: 28.0835 - accuracy: 0.2188 \n",
      "Epoch 1: accuracy did not improve from 0.21875\n",
      "  3/250 [..............................] - ETA: 1:27 - loss: 29.5696 - accuracy: 0.1771\n",
      "Epoch 1: accuracy did not improve from 0.21875\n",
      "  4/250 [..............................] - ETA: 1:22 - loss: 26.1665 - accuracy: 0.1953\n",
      "Epoch 1: accuracy did not improve from 0.21875\n",
      "  5/250 [..............................] - ETA: 1:19 - loss: 25.1650 - accuracy: 0.2062\n",
      "Epoch 1: accuracy did not improve from 0.21875\n",
      "  6/250 [..............................] - ETA: 1:17 - loss: 24.8630 - accuracy: 0.2083\n",
      "Epoch 1: accuracy did not improve from 0.21875\n",
      "  7/250 [..............................] - ETA: 1:15 - loss: 24.1714 - accuracy: 0.2143\n",
      "Epoch 1: accuracy improved from 0.21875 to 0.23828, saving model to output\\inceptionV3.h5\n",
      "  8/250 [..............................] - ETA: 1:31 - loss: 22.6938 - accuracy: 0.2383\n",
      "Epoch 1: accuracy improved from 0.23828 to 0.25347, saving model to output\\inceptionV3.h5\n",
      "  9/250 [>.............................] - ETA: 1:37 - loss: 22.2453 - accuracy: 0.2535\n",
      "Epoch 1: accuracy improved from 0.25347 to 0.25625, saving model to output\\inceptionV3.h5\n",
      " 10/250 [>.............................] - ETA: 1:43 - loss: 22.3255 - accuracy: 0.2562\n",
      "Epoch 1: accuracy improved from 0.25625 to 0.26420, saving model to output\\inceptionV3.h5\n",
      " 11/250 [>.............................] - ETA: 1:47 - loss: 22.1364 - accuracy: 0.2642\n",
      "Epoch 1: accuracy improved from 0.26420 to 0.26823, saving model to output\\inceptionV3.h5\n",
      " 12/250 [>.............................] - ETA: 1:50 - loss: 21.9418 - accuracy: 0.2682\n",
      "Epoch 1: accuracy improved from 0.26823 to 0.27644, saving model to output\\inceptionV3.h5\n",
      " 13/250 [>.............................] - ETA: 1:51 - loss: 21.8293 - accuracy: 0.2764\n",
      "Epoch 1: accuracy did not improve from 0.27644\n",
      " 14/250 [>.............................] - ETA: 1:44 - loss: 22.4082 - accuracy: 0.2723\n",
      "Epoch 1: accuracy improved from 0.27644 to 0.27917, saving model to output\\inceptionV3.h5\n",
      " 15/250 [>.............................] - ETA: 1:49 - loss: 21.7078 - accuracy: 0.2792\n",
      "Epoch 1: accuracy did not improve from 0.27917\n",
      " 16/250 [>.............................] - ETA: 1:42 - loss: 21.5194 - accuracy: 0.2773\n",
      "Epoch 1: accuracy improved from 0.27917 to 0.29044, saving model to output\\inceptionV3.h5\n",
      " 17/250 [=>............................] - ETA: 1:47 - loss: 21.2592 - accuracy: 0.2904\n",
      "Epoch 1: accuracy improved from 0.29044 to 0.29688, saving model to output\\inceptionV3.h5\n",
      " 18/250 [=>............................] - ETA: 1:48 - loss: 20.7358 - accuracy: 0.2969\n",
      "Epoch 1: accuracy improved from 0.29688 to 0.29934, saving model to output\\inceptionV3.h5\n",
      " 19/250 [=>............................] - ETA: 1:49 - loss: 20.3191 - accuracy: 0.2993\n",
      "Epoch 1: accuracy improved from 0.29934 to 0.31250, saving model to output\\inceptionV3.h5\n",
      " 20/250 [=>............................] - ETA: 1:49 - loss: 20.0170 - accuracy: 0.3125\n",
      "Epoch 1: accuracy improved from 0.31250 to 0.31548, saving model to output\\inceptionV3.h5\n",
      " 21/250 [=>............................] - ETA: 1:50 - loss: 19.7608 - accuracy: 0.3155\n",
      "Epoch 1: accuracy improved from 0.31548 to 0.32812, saving model to output\\inceptionV3.h5\n",
      " 22/250 [=>............................] - ETA: 1:51 - loss: 19.2188 - accuracy: 0.3281\n",
      "Epoch 1: accuracy improved from 0.32812 to 0.33424, saving model to output\\inceptionV3.h5\n",
      " 23/250 [=>............................] - ETA: 1:52 - loss: 19.0590 - accuracy: 0.3342\n",
      "Epoch 1: accuracy improved from 0.33424 to 0.34115, saving model to output\\inceptionV3.h5\n",
      " 24/250 [=>............................] - ETA: 1:52 - loss: 18.6093 - accuracy: 0.3411\n",
      "Epoch 1: accuracy improved from 0.34115 to 0.34500, saving model to output\\inceptionV3.h5\n",
      " 25/250 [==>...........................] - ETA: 1:54 - loss: 18.2568 - accuracy: 0.3450\n",
      "Epoch 1: accuracy improved from 0.34500 to 0.34736, saving model to output\\inceptionV3.h5\n",
      " 26/250 [==>...........................] - ETA: 1:54 - loss: 18.1081 - accuracy: 0.3474\n",
      "Epoch 1: accuracy improved from 0.34736 to 0.35069, saving model to output\\inceptionV3.h5\n",
      " 27/250 [==>...........................] - ETA: 1:55 - loss: 18.0082 - accuracy: 0.3507\n",
      "Epoch 1: accuracy improved from 0.35069 to 0.35603, saving model to output\\inceptionV3.h5\n",
      " 28/250 [==>...........................] - ETA: 1:55 - loss: 17.8467 - accuracy: 0.3560\n",
      "Epoch 1: accuracy improved from 0.35603 to 0.35884, saving model to output\\inceptionV3.h5\n",
      " 29/250 [==>...........................] - ETA: 1:54 - loss: 17.8198 - accuracy: 0.3588\n",
      "Epoch 1: accuracy improved from 0.35884 to 0.36667, saving model to output\\inceptionV3.h5\n",
      " 30/250 [==>...........................] - ETA: 1:54 - loss: 17.6045 - accuracy: 0.3667\n",
      "Epoch 1: accuracy improved from 0.36667 to 0.36794, saving model to output\\inceptionV3.h5\n",
      " 31/250 [==>...........................] - ETA: 1:54 - loss: 17.5128 - accuracy: 0.3679\n",
      "Epoch 1: accuracy improved from 0.36794 to 0.37012, saving model to output\\inceptionV3.h5\n",
      " 32/250 [==>...........................] - ETA: 1:55 - loss: 17.4644 - accuracy: 0.3701\n",
      "Epoch 1: accuracy improved from 0.37012 to 0.37500, saving model to output\\inceptionV3.h5\n",
      " 33/250 [==>...........................] - ETA: 1:57 - loss: 17.3349 - accuracy: 0.3750\n",
      "Epoch 1: accuracy improved from 0.37500 to 0.38051, saving model to output\\inceptionV3.h5\n",
      " 34/250 [===>..........................] - ETA: 1:57 - loss: 17.2043 - accuracy: 0.3805\n",
      "Epoch 1: accuracy did not improve from 0.38051\n",
      " 35/250 [===>..........................] - ETA: 1:53 - loss: 17.2085 - accuracy: 0.3804\n",
      "Epoch 1: accuracy did not improve from 0.38051\n",
      " 36/250 [===>..........................] - ETA: 1:51 - loss: 17.1656 - accuracy: 0.3793\n",
      "Epoch 1: accuracy improved from 0.38051 to 0.38345, saving model to output\\inceptionV3.h5\n",
      " 37/250 [===>..........................] - ETA: 1:52 - loss: 16.9201 - accuracy: 0.3834\n",
      "Epoch 1: accuracy improved from 0.38345 to 0.38980, saving model to output\\inceptionV3.h5\n",
      " 38/250 [===>..........................] - ETA: 1:51 - loss: 16.6758 - accuracy: 0.3898\n",
      "Epoch 1: accuracy improved from 0.38980 to 0.39744, saving model to output\\inceptionV3.h5\n",
      " 39/250 [===>..........................] - ETA: 1:51 - loss: 16.4364 - accuracy: 0.3974\n",
      "Epoch 1: accuracy improved from 0.39744 to 0.39922, saving model to output\\inceptionV3.h5\n",
      " 40/250 [===>..........................] - ETA: 1:51 - loss: 16.3253 - accuracy: 0.3992\n",
      "Epoch 1: accuracy improved from 0.39922 to 0.40168, saving model to output\\inceptionV3.h5\n",
      " 41/250 [===>..........................] - ETA: 1:50 - loss: 16.3373 - accuracy: 0.4017\n",
      "Epoch 1: accuracy improved from 0.40168 to 0.40253, saving model to output\\inceptionV3.h5\n",
      " 42/250 [====>.........................] - ETA: 1:51 - loss: 16.3047 - accuracy: 0.4025\n",
      "Epoch 1: accuracy improved from 0.40253 to 0.40262, saving model to output\\inceptionV3.h5\n",
      " 43/250 [====>.........................] - ETA: 1:50 - loss: 16.2476 - accuracy: 0.4026\n",
      "Epoch 1: accuracy improved from 0.40262 to 0.40412, saving model to output\\inceptionV3.h5\n",
      " 44/250 [====>.........................] - ETA: 1:50 - loss: 16.1065 - accuracy: 0.4041\n",
      "Epoch 1: accuracy improved from 0.40412 to 0.40556, saving model to output\\inceptionV3.h5\n",
      " 45/250 [====>.........................] - ETA: 1:49 - loss: 16.0094 - accuracy: 0.4056\n",
      "Epoch 1: accuracy did not improve from 0.40556\n",
      " 46/250 [====>.........................] - ETA: 1:47 - loss: 16.1610 - accuracy: 0.4035\n",
      "Epoch 1: accuracy improved from 0.40556 to 0.40824, saving model to output\\inceptionV3.h5\n",
      " 47/250 [====>.........................] - ETA: 1:48 - loss: 16.0146 - accuracy: 0.4082\n",
      "Epoch 1: accuracy improved from 0.40824 to 0.41276, saving model to output\\inceptionV3.h5\n",
      " 48/250 [====>.........................] - ETA: 1:47 - loss: 15.8481 - accuracy: 0.4128\n",
      "Epoch 1: accuracy improved from 0.41276 to 0.41709, saving model to output\\inceptionV3.h5\n",
      " 49/250 [====>.........................] - ETA: 1:47 - loss: 15.8023 - accuracy: 0.4171\n",
      "Epoch 1: accuracy improved from 0.41709 to 0.41875, saving model to output\\inceptionV3.h5\n",
      " 50/250 [=====>........................] - ETA: 1:47 - loss: 15.7444 - accuracy: 0.4187\n",
      "Epoch 1: accuracy improved from 0.41875 to 0.42157, saving model to output\\inceptionV3.h5\n",
      " 51/250 [=====>........................] - ETA: 1:46 - loss: 15.6045 - accuracy: 0.4216\n",
      "Epoch 1: accuracy improved from 0.42157 to 0.42428, saving model to output\\inceptionV3.h5\n",
      " 52/250 [=====>........................] - ETA: 1:46 - loss: 15.5676 - accuracy: 0.4243\n",
      "Epoch 1: accuracy improved from 0.42428 to 0.42807, saving model to output\\inceptionV3.h5\n",
      " 53/250 [=====>........................] - ETA: 1:45 - loss: 15.4543 - accuracy: 0.4281\n",
      "Epoch 1: accuracy improved from 0.42807 to 0.42940, saving model to output\\inceptionV3.h5\n",
      " 54/250 [=====>........................] - ETA: 1:45 - loss: 15.4574 - accuracy: 0.4294\n",
      "Epoch 1: accuracy improved from 0.42940 to 0.43011, saving model to output\\inceptionV3.h5\n",
      " 55/250 [=====>........................] - ETA: 1:45 - loss: 15.3911 - accuracy: 0.4301\n",
      "Epoch 1: accuracy improved from 0.43011 to 0.43080, saving model to output\\inceptionV3.h5\n",
      " 56/250 [=====>........................] - ETA: 1:44 - loss: 15.2888 - accuracy: 0.4308\n",
      "Epoch 1: accuracy improved from 0.43080 to 0.43311, saving model to output\\inceptionV3.h5\n",
      " 57/250 [=====>........................] - ETA: 1:44 - loss: 15.1784 - accuracy: 0.4331\n",
      "Epoch 1: accuracy improved from 0.43311 to 0.43588, saving model to output\\inceptionV3.h5\n",
      " 58/250 [=====>........................] - ETA: 1:43 - loss: 15.0249 - accuracy: 0.4359\n",
      "Epoch 1: accuracy improved from 0.43588 to 0.44068, saving model to output\\inceptionV3.h5\n",
      " 59/250 [======>.......................] - ETA: 1:43 - loss: 14.8712 - accuracy: 0.4407\n",
      "Epoch 1: accuracy improved from 0.44068 to 0.44219, saving model to output\\inceptionV3.h5\n",
      " 60/250 [======>.......................] - ETA: 1:43 - loss: 14.8031 - accuracy: 0.4422\n",
      "Epoch 1: accuracy improved from 0.44219 to 0.44365, saving model to output\\inceptionV3.h5\n",
      " 61/250 [======>.......................] - ETA: 1:42 - loss: 14.6834 - accuracy: 0.4436\n",
      "Epoch 1: accuracy improved from 0.44365 to 0.44657, saving model to output\\inceptionV3.h5\n",
      " 62/250 [======>.......................] - ETA: 1:42 - loss: 14.5793 - accuracy: 0.4466\n",
      "Epoch 1: accuracy did not improve from 0.44657\n",
      " 63/250 [======>.......................] - ETA: 1:40 - loss: 14.5501 - accuracy: 0.4464\n",
      "Epoch 1: accuracy improved from 0.44657 to 0.44873, saving model to output\\inceptionV3.h5\n",
      " 64/250 [======>.......................] - ETA: 1:40 - loss: 14.5029 - accuracy: 0.4487\n",
      "Epoch 1: accuracy improved from 0.44873 to 0.45000, saving model to output\\inceptionV3.h5\n",
      " 65/250 [======>.......................] - ETA: 1:40 - loss: 14.4024 - accuracy: 0.4500\n",
      "Epoch 1: accuracy improved from 0.45000 to 0.45265, saving model to output\\inceptionV3.h5\n",
      " 66/250 [======>.......................] - ETA: 1:39 - loss: 14.3115 - accuracy: 0.4527\n",
      "Epoch 1: accuracy improved from 0.45265 to 0.45336, saving model to output\\inceptionV3.h5\n",
      " 67/250 [=======>......................] - ETA: 1:39 - loss: 14.2303 - accuracy: 0.4534\n",
      "Epoch 1: accuracy improved from 0.45336 to 0.45358, saving model to output\\inceptionV3.h5\n",
      " 68/250 [=======>......................] - ETA: 1:38 - loss: 14.1724 - accuracy: 0.4536\n",
      "Epoch 1: accuracy improved from 0.45358 to 0.45607, saving model to output\\inceptionV3.h5\n",
      " 69/250 [=======>......................] - ETA: 1:39 - loss: 14.0628 - accuracy: 0.4561\n",
      "Epoch 1: accuracy improved from 0.45607 to 0.45759, saving model to output\\inceptionV3.h5\n",
      " 70/250 [=======>......................] - ETA: 1:38 - loss: 13.9623 - accuracy: 0.4576\n",
      "Epoch 1: accuracy improved from 0.45759 to 0.45863, saving model to output\\inceptionV3.h5\n",
      " 71/250 [=======>......................] - ETA: 1:38 - loss: 13.9440 - accuracy: 0.4586\n",
      "Epoch 1: accuracy improved from 0.45863 to 0.45920, saving model to output\\inceptionV3.h5\n",
      " 72/250 [=======>......................] - ETA: 1:37 - loss: 13.9101 - accuracy: 0.4592\n",
      "Epoch 1: accuracy improved from 0.45920 to 0.45976, saving model to output\\inceptionV3.h5\n",
      " 73/250 [=======>......................] - ETA: 1:36 - loss: 13.8720 - accuracy: 0.4598\n",
      "Epoch 1: accuracy improved from 0.45976 to 0.46242, saving model to output\\inceptionV3.h5\n",
      " 74/250 [=======>......................] - ETA: 1:36 - loss: 13.7570 - accuracy: 0.4624\n",
      "Epoch 1: accuracy improved from 0.46242 to 0.46583, saving model to output\\inceptionV3.h5\n",
      " 75/250 [========>.....................] - ETA: 1:36 - loss: 13.6684 - accuracy: 0.4658\n",
      "Epoch 1: accuracy improved from 0.46583 to 0.46793, saving model to output\\inceptionV3.h5\n",
      " 76/250 [========>.....................] - ETA: 1:35 - loss: 13.5694 - accuracy: 0.4679\n",
      "Epoch 1: accuracy improved from 0.46793 to 0.46794, saving model to output\\inceptionV3.h5\n",
      " 77/250 [========>.....................] - ETA: 1:35 - loss: 13.5295 - accuracy: 0.4679\n",
      "Epoch 1: accuracy improved from 0.46794 to 0.47075, saving model to output\\inceptionV3.h5\n",
      " 78/250 [========>.....................] - ETA: 1:34 - loss: 13.4097 - accuracy: 0.4708\n",
      "Epoch 1: accuracy did not improve from 0.47075\n",
      " 79/250 [========>.....................] - ETA: 1:33 - loss: 13.3929 - accuracy: 0.4699\n",
      "Epoch 1: accuracy did not improve from 0.47075\n",
      " 80/250 [========>.....................] - ETA: 1:32 - loss: 13.3297 - accuracy: 0.4707\n",
      "Epoch 1: accuracy improved from 0.47075 to 0.47145, saving model to output\\inceptionV3.h5\n",
      " 81/250 [========>.....................] - ETA: 1:32 - loss: 13.2530 - accuracy: 0.4715\n",
      "Epoch 1: accuracy improved from 0.47145 to 0.47218, saving model to output\\inceptionV3.h5\n",
      " 82/250 [========>.....................] - ETA: 1:31 - loss: 13.2129 - accuracy: 0.4722\n",
      "Epoch 1: accuracy improved from 0.47218 to 0.47553, saving model to output\\inceptionV3.h5\n",
      " 83/250 [========>.....................] - ETA: 1:31 - loss: 13.1190 - accuracy: 0.4755\n",
      "Epoch 1: accuracy improved from 0.47553 to 0.47656, saving model to output\\inceptionV3.h5\n",
      " 84/250 [=========>....................] - ETA: 1:30 - loss: 13.1128 - accuracy: 0.4766\n",
      "Epoch 1: accuracy improved from 0.47656 to 0.47904, saving model to output\\inceptionV3.h5\n",
      " 85/250 [=========>....................] - ETA: 1:30 - loss: 13.0277 - accuracy: 0.4790\n",
      "Epoch 1: accuracy improved from 0.47904 to 0.48001, saving model to output\\inceptionV3.h5\n",
      " 86/250 [=========>....................] - ETA: 1:29 - loss: 12.9676 - accuracy: 0.4800\n",
      "Epoch 1: accuracy did not improve from 0.48001\n",
      " 87/250 [=========>....................] - ETA: 1:28 - loss: 12.9550 - accuracy: 0.4799\n",
      "Epoch 1: accuracy improved from 0.48001 to 0.48224, saving model to output\\inceptionV3.h5\n",
      " 88/250 [=========>....................] - ETA: 1:28 - loss: 12.8848 - accuracy: 0.4822\n",
      "Epoch 1: accuracy improved from 0.48224 to 0.48244, saving model to output\\inceptionV3.h5\n",
      " 89/250 [=========>....................] - ETA: 1:27 - loss: 12.8783 - accuracy: 0.4824\n",
      "Epoch 1: accuracy improved from 0.48244 to 0.48542, saving model to output\\inceptionV3.h5\n",
      " 90/250 [=========>....................] - ETA: 1:27 - loss: 12.7753 - accuracy: 0.4854\n",
      "Epoch 1: accuracy improved from 0.48542 to 0.48764, saving model to output\\inceptionV3.h5\n",
      " 91/250 [=========>....................] - ETA: 1:27 - loss: 12.7176 - accuracy: 0.4876\n",
      "Epoch 1: accuracy did not improve from 0.48764\n",
      " 92/250 [==========>...................] - ETA: 1:25 - loss: 12.7000 - accuracy: 0.4874\n",
      "Epoch 1: accuracy improved from 0.48764 to 0.48992, saving model to output\\inceptionV3.h5\n",
      " 93/250 [==========>...................] - ETA: 1:25 - loss: 12.6140 - accuracy: 0.4899\n",
      "Epoch 1: accuracy improved from 0.48992 to 0.49136, saving model to output\\inceptionV3.h5\n",
      " 94/250 [==========>...................] - ETA: 1:25 - loss: 12.5626 - accuracy: 0.4914\n",
      "Epoch 1: accuracy improved from 0.49136 to 0.49243, saving model to output\\inceptionV3.h5\n",
      " 95/250 [==========>...................] - ETA: 1:24 - loss: 12.4937 - accuracy: 0.4924\n",
      "Epoch 1: accuracy improved from 0.49243 to 0.49316, saving model to output\\inceptionV3.h5\n",
      " 96/250 [==========>...................] - ETA: 1:24 - loss: 12.4849 - accuracy: 0.4932\n",
      "Epoch 1: accuracy improved from 0.49316 to 0.49356, saving model to output\\inceptionV3.h5\n",
      " 97/250 [==========>...................] - ETA: 1:23 - loss: 12.4328 - accuracy: 0.4936\n",
      "Epoch 1: accuracy improved from 0.49356 to 0.49458, saving model to output\\inceptionV3.h5\n",
      " 98/250 [==========>...................] - ETA: 1:23 - loss: 12.3830 - accuracy: 0.4946\n",
      "Epoch 1: accuracy improved from 0.49458 to 0.49653, saving model to output\\inceptionV3.h5\n",
      " 99/250 [==========>...................] - ETA: 1:22 - loss: 12.3025 - accuracy: 0.4965\n",
      "Epoch 1: accuracy improved from 0.49653 to 0.49719, saving model to output\\inceptionV3.h5\n",
      "100/250 [===========>..................] - ETA: 1:22 - loss: 12.2812 - accuracy: 0.4972\n",
      "Epoch 1: accuracy improved from 0.49719 to 0.49845, saving model to output\\inceptionV3.h5\n",
      "101/250 [===========>..................] - ETA: 1:21 - loss: 12.2173 - accuracy: 0.4985\n",
      "Epoch 1: accuracy did not improve from 0.49845\n",
      "102/250 [===========>..................] - ETA: 1:20 - loss: 12.2172 - accuracy: 0.4972\n",
      "Epoch 1: accuracy did not improve from 0.49845\n",
      "103/250 [===========>..................] - ETA: 1:19 - loss: 12.2076 - accuracy: 0.4967\n",
      "Epoch 1: accuracy did not improve from 0.49845\n",
      "104/250 [===========>..................] - ETA: 1:18 - loss: 12.1976 - accuracy: 0.4973\n",
      "Epoch 1: accuracy did not improve from 0.49845\n",
      "105/250 [===========>..................] - ETA: 1:17 - loss: 12.1428 - accuracy: 0.4982\n",
      "Epoch 1: accuracy improved from 0.49845 to 0.49882, saving model to output\\inceptionV3.h5\n",
      "106/250 [===========>..................] - ETA: 1:17 - loss: 12.0795 - accuracy: 0.4988\n",
      "Epoch 1: accuracy improved from 0.49882 to 0.50088, saving model to output\\inceptionV3.h5\n",
      "107/250 [===========>..................] - ETA: 1:17 - loss: 12.0045 - accuracy: 0.5009\n",
      "Epoch 1: accuracy improved from 0.50088 to 0.50174, saving model to output\\inceptionV3.h5\n",
      "108/250 [===========>..................] - ETA: 1:16 - loss: 11.9847 - accuracy: 0.5017\n",
      "Epoch 1: accuracy improved from 0.50174 to 0.50258, saving model to output\\inceptionV3.h5\n",
      "109/250 [============>.................] - ETA: 1:16 - loss: 11.9308 - accuracy: 0.5026\n",
      "Epoch 1: accuracy improved from 0.50258 to 0.50398, saving model to output\\inceptionV3.h5\n",
      "110/250 [============>.................] - ETA: 1:15 - loss: 11.8776 - accuracy: 0.5040\n",
      "Epoch 1: accuracy improved from 0.50398 to 0.50450, saving model to output\\inceptionV3.h5\n",
      "111/250 [============>.................] - ETA: 1:15 - loss: 11.8283 - accuracy: 0.5045\n",
      "Epoch 1: accuracy improved from 0.50450 to 0.50586, saving model to output\\inceptionV3.h5\n",
      "112/250 [============>.................] - ETA: 1:14 - loss: 11.7792 - accuracy: 0.5059\n",
      "Epoch 1: accuracy improved from 0.50586 to 0.50636, saving model to output\\inceptionV3.h5\n",
      "113/250 [============>.................] - ETA: 1:14 - loss: 11.7413 - accuracy: 0.5064\n",
      "Epoch 1: accuracy improved from 0.50636 to 0.50795, saving model to output\\inceptionV3.h5\n",
      "114/250 [============>.................] - ETA: 1:13 - loss: 11.6923 - accuracy: 0.5079\n",
      "Epoch 1: accuracy improved from 0.50795 to 0.50842, saving model to output\\inceptionV3.h5\n",
      "115/250 [============>.................] - ETA: 1:13 - loss: 11.6849 - accuracy: 0.5084\n",
      "Epoch 1: accuracy improved from 0.50842 to 0.51024, saving model to output\\inceptionV3.h5\n",
      "116/250 [============>.................] - ETA: 1:13 - loss: 11.6165 - accuracy: 0.5102\n",
      "Epoch 1: accuracy improved from 0.51024 to 0.51202, saving model to output\\inceptionV3.h5\n",
      "117/250 [=============>................] - ETA: 1:12 - loss: 11.5561 - accuracy: 0.5120\n",
      "Epoch 1: accuracy improved from 0.51202 to 0.51324, saving model to output\\inceptionV3.h5\n",
      "118/250 [=============>................] - ETA: 1:12 - loss: 11.5141 - accuracy: 0.5132\n",
      "Epoch 1: accuracy improved from 0.51324 to 0.51497, saving model to output\\inceptionV3.h5\n",
      "119/250 [=============>................] - ETA: 1:11 - loss: 11.4726 - accuracy: 0.5150\n",
      "Epoch 1: accuracy improved from 0.51497 to 0.51797, saving model to output\\inceptionV3.h5\n",
      "120/250 [=============>................] - ETA: 1:10 - loss: 11.3946 - accuracy: 0.5180\n",
      "Epoch 1: accuracy improved from 0.51797 to 0.52040, saving model to output\\inceptionV3.h5\n",
      "121/250 [=============>................] - ETA: 1:10 - loss: 11.3205 - accuracy: 0.5204\n",
      "Epoch 1: accuracy improved from 0.52040 to 0.52254, saving model to output\\inceptionV3.h5\n",
      "122/250 [=============>................] - ETA: 1:09 - loss: 11.2502 - accuracy: 0.5225\n",
      "Epoch 1: accuracy did not improve from 0.52254\n",
      "123/250 [=============>................] - ETA: 1:08 - loss: 11.2099 - accuracy: 0.5224\n",
      "Epoch 1: accuracy improved from 0.52254 to 0.52344, saving model to output\\inceptionV3.h5\n",
      "124/250 [=============>................] - ETA: 1:08 - loss: 11.1604 - accuracy: 0.5234\n",
      "Epoch 1: accuracy improved from 0.52344 to 0.52412, saving model to output\\inceptionV3.h5\n",
      "125/250 [==============>...............] - ETA: 1:08 - loss: 11.1351 - accuracy: 0.5241\n",
      "Epoch 1: accuracy improved from 0.52412 to 0.52592, saving model to output\\inceptionV3.h5\n",
      "126/250 [==============>...............] - ETA: 1:07 - loss: 11.0712 - accuracy: 0.5259\n",
      "Epoch 1: accuracy improved from 0.52592 to 0.52695, saving model to output\\inceptionV3.h5\n",
      "127/250 [==============>...............] - ETA: 1:07 - loss: 11.0316 - accuracy: 0.5270\n",
      "Epoch 1: accuracy improved from 0.52695 to 0.52821, saving model to output\\inceptionV3.h5\n",
      "128/250 [==============>...............] - ETA: 1:06 - loss: 10.9867 - accuracy: 0.5282\n",
      "Epoch 1: accuracy improved from 0.52821 to 0.52921, saving model to output\\inceptionV3.h5\n",
      "129/250 [==============>...............] - ETA: 1:06 - loss: 10.9218 - accuracy: 0.5292\n",
      "Epoch 1: accuracy improved from 0.52921 to 0.52923, saving model to output\\inceptionV3.h5\n",
      "130/250 [==============>...............] - ETA: 1:05 - loss: 10.8963 - accuracy: 0.5292\n",
      "Epoch 1: accuracy did not improve from 0.52923\n",
      "131/250 [==============>...............] - ETA: 1:04 - loss: 10.8899 - accuracy: 0.5288\n",
      "Epoch 1: accuracy improved from 0.52923 to 0.53045, saving model to output\\inceptionV3.h5\n",
      "132/250 [==============>...............] - ETA: 1:04 - loss: 10.8382 - accuracy: 0.5304\n",
      "Epoch 1: accuracy improved from 0.53045 to 0.53187, saving model to output\\inceptionV3.h5\n",
      "133/250 [==============>...............] - ETA: 1:03 - loss: 10.7968 - accuracy: 0.5319\n",
      "Epoch 1: accuracy improved from 0.53187 to 0.53421, saving model to output\\inceptionV3.h5\n",
      "134/250 [===============>..............] - ETA: 1:03 - loss: 10.7596 - accuracy: 0.5342\n",
      "Epoch 1: accuracy did not improve from 0.53421\n",
      "135/250 [===============>..............] - ETA: 1:02 - loss: 10.7591 - accuracy: 0.5340\n",
      "Epoch 1: accuracy improved from 0.53421 to 0.53440, saving model to output\\inceptionV3.h5\n",
      "136/250 [===============>..............] - ETA: 1:01 - loss: 10.7233 - accuracy: 0.5344\n",
      "Epoch 1: accuracy improved from 0.53440 to 0.53506, saving model to output\\inceptionV3.h5\n",
      "137/250 [===============>..............] - ETA: 1:01 - loss: 10.6891 - accuracy: 0.5351\n",
      "Epoch 1: accuracy improved from 0.53506 to 0.53526, saving model to output\\inceptionV3.h5\n",
      "138/250 [===============>..............] - ETA: 1:00 - loss: 10.6582 - accuracy: 0.5353\n",
      "Epoch 1: accuracy improved from 0.53526 to 0.53704, saving model to output\\inceptionV3.h5\n",
      "139/250 [===============>..............] - ETA: 1:00 - loss: 10.6241 - accuracy: 0.5370\n",
      "Epoch 1: accuracy improved from 0.53704 to 0.53767, saving model to output\\inceptionV3.h5\n",
      "140/250 [===============>..............] - ETA: 59s - loss: 10.6063 - accuracy: 0.5377 \n",
      "Epoch 1: accuracy improved from 0.53767 to 0.53851, saving model to output\\inceptionV3.h5\n",
      "141/250 [===============>..............] - ETA: 59s - loss: 10.5626 - accuracy: 0.5385\n",
      "Epoch 1: accuracy improved from 0.53851 to 0.53912, saving model to output\\inceptionV3.h5\n",
      "142/250 [================>.............] - ETA: 58s - loss: 10.5487 - accuracy: 0.5391\n",
      "Epoch 1: accuracy improved from 0.53912 to 0.53951, saving model to output\\inceptionV3.h5\n",
      "143/250 [================>.............] - ETA: 58s - loss: 10.5356 - accuracy: 0.5395\n",
      "Epoch 1: accuracy improved from 0.53951 to 0.54054, saving model to output\\inceptionV3.h5\n",
      "144/250 [================>.............] - ETA: 57s - loss: 10.4886 - accuracy: 0.5405\n",
      "Epoch 1: accuracy improved from 0.54054 to 0.54134, saving model to output\\inceptionV3.h5\n",
      "145/250 [================>.............] - ETA: 57s - loss: 10.4511 - accuracy: 0.5413\n",
      "Epoch 1: accuracy improved from 0.54134 to 0.54192, saving model to output\\inceptionV3.h5\n",
      "146/250 [================>.............] - ETA: 56s - loss: 10.4040 - accuracy: 0.5419\n",
      "Epoch 1: accuracy did not improve from 0.54192\n",
      "147/250 [================>.............] - ETA: 55s - loss: 10.3912 - accuracy: 0.5416\n",
      "Epoch 1: accuracy improved from 0.54192 to 0.54262, saving model to output\\inceptionV3.h5\n",
      "148/250 [================>.............] - ETA: 55s - loss: 10.3599 - accuracy: 0.5426\n",
      "Epoch 1: accuracy improved from 0.54262 to 0.54318, saving model to output\\inceptionV3.h5\n",
      "149/250 [================>.............] - ETA: 54s - loss: 10.3343 - accuracy: 0.5432\n",
      "Epoch 1: accuracy improved from 0.54318 to 0.54393, saving model to output\\inceptionV3.h5\n",
      "150/250 [=================>............] - ETA: 54s - loss: 10.3068 - accuracy: 0.5439\n",
      "Epoch 1: accuracy did not improve from 0.54393\n",
      "151/250 [=================>............] - ETA: 53s - loss: 10.2871 - accuracy: 0.5438\n",
      "Epoch 1: accuracy improved from 0.54393 to 0.54418, saving model to output\\inceptionV3.h5\n",
      "152/250 [=================>............] - ETA: 53s - loss: 10.2503 - accuracy: 0.5442\n",
      "Epoch 1: accuracy improved from 0.54418 to 0.54553, saving model to output\\inceptionV3.h5\n",
      "153/250 [=================>............] - ETA: 52s - loss: 10.2117 - accuracy: 0.5455\n",
      "Epoch 1: accuracy improved from 0.54553 to 0.54584, saving model to output\\inceptionV3.h5\n",
      "154/250 [=================>............] - ETA: 52s - loss: 10.1978 - accuracy: 0.5458\n",
      "Epoch 1: accuracy did not improve from 0.54584\n",
      "155/250 [=================>............] - ETA: 51s - loss: 10.2113 - accuracy: 0.5457\n",
      "Epoch 1: accuracy improved from 0.54584 to 0.54706, saving model to output\\inceptionV3.h5\n",
      "156/250 [=================>............] - ETA: 50s - loss: 10.1586 - accuracy: 0.5471\n",
      "Epoch 1: accuracy improved from 0.54706 to 0.54836, saving model to output\\inceptionV3.h5\n",
      "157/250 [=================>............] - ETA: 50s - loss: 10.1448 - accuracy: 0.5484\n",
      "Epoch 1: accuracy improved from 0.54836 to 0.54984, saving model to output\\inceptionV3.h5\n",
      "158/250 [=================>............] - ETA: 49s - loss: 10.1067 - accuracy: 0.5498\n",
      "Epoch 1: accuracy improved from 0.54984 to 0.55150, saving model to output\\inceptionV3.h5\n",
      "159/250 [==================>...........] - ETA: 49s - loss: 10.0792 - accuracy: 0.5515\n",
      "Epoch 1: accuracy improved from 0.55150 to 0.55176, saving model to output\\inceptionV3.h5\n",
      "160/250 [==================>...........] - ETA: 48s - loss: 10.0618 - accuracy: 0.5518\n",
      "Epoch 1: accuracy improved from 0.55176 to 0.55261, saving model to output\\inceptionV3.h5\n",
      "161/250 [==================>...........] - ETA: 48s - loss: 10.0282 - accuracy: 0.5526\n",
      "Epoch 1: accuracy improved from 0.55261 to 0.55306, saving model to output\\inceptionV3.h5\n",
      "162/250 [==================>...........] - ETA: 47s - loss: 9.9945 - accuracy: 0.5531 \n",
      "Epoch 1: accuracy improved from 0.55306 to 0.55312, saving model to output\\inceptionV3.h5\n",
      "163/250 [==================>...........] - ETA: 47s - loss: 9.9775 - accuracy: 0.5531\n",
      "Epoch 1: accuracy improved from 0.55312 to 0.55356, saving model to output\\inceptionV3.h5\n",
      "164/250 [==================>...........] - ETA: 46s - loss: 9.9558 - accuracy: 0.5536\n",
      "Epoch 1: accuracy improved from 0.55356 to 0.55399, saving model to output\\inceptionV3.h5\n",
      "165/250 [==================>...........] - ETA: 46s - loss: 9.9201 - accuracy: 0.5540\n",
      "Epoch 1: accuracy improved from 0.55399 to 0.55442, saving model to output\\inceptionV3.h5\n",
      "166/250 [==================>...........] - ETA: 45s - loss: 9.8939 - accuracy: 0.5544\n",
      "Epoch 1: accuracy improved from 0.55442 to 0.55485, saving model to output\\inceptionV3.h5\n",
      "167/250 [===================>..........] - ETA: 45s - loss: 9.8649 - accuracy: 0.5548\n",
      "Epoch 1: accuracy improved from 0.55485 to 0.55601, saving model to output\\inceptionV3.h5\n",
      "168/250 [===================>..........] - ETA: 44s - loss: 9.8187 - accuracy: 0.5560\n",
      "Epoch 1: accuracy improved from 0.55601 to 0.55754, saving model to output\\inceptionV3.h5\n",
      "169/250 [===================>..........] - ETA: 44s - loss: 9.7696 - accuracy: 0.5575\n",
      "Epoch 1: accuracy improved from 0.55754 to 0.55775, saving model to output\\inceptionV3.h5\n",
      "170/250 [===================>..........] - ETA: 43s - loss: 9.7709 - accuracy: 0.5577\n",
      "Epoch 1: accuracy improved from 0.55775 to 0.55888, saving model to output\\inceptionV3.h5\n",
      "171/250 [===================>..........] - ETA: 42s - loss: 9.7358 - accuracy: 0.5589\n",
      "Epoch 1: accuracy improved from 0.55888 to 0.55945, saving model to output\\inceptionV3.h5\n",
      "172/250 [===================>..........] - ETA: 42s - loss: 9.7152 - accuracy: 0.5594\n",
      "Epoch 1: accuracy improved from 0.55945 to 0.55983, saving model to output\\inceptionV3.h5\n",
      "173/250 [===================>..........] - ETA: 41s - loss: 9.6855 - accuracy: 0.5598\n",
      "Epoch 1: accuracy did not improve from 0.55983\n",
      "174/250 [===================>..........] - ETA: 41s - loss: 9.6726 - accuracy: 0.5597\n",
      "Epoch 1: accuracy improved from 0.55983 to 0.56004, saving model to output\\inceptionV3.h5\n",
      "175/250 [====================>.........] - ETA: 40s - loss: 9.6357 - accuracy: 0.5600\n",
      "Epoch 1: accuracy improved from 0.56004 to 0.56058, saving model to output\\inceptionV3.h5\n",
      "176/250 [====================>.........] - ETA: 40s - loss: 9.6305 - accuracy: 0.5606\n",
      "Epoch 1: accuracy did not improve from 0.56058\n",
      "177/250 [====================>.........] - ETA: 39s - loss: 9.6233 - accuracy: 0.5602\n",
      "Epoch 1: accuracy improved from 0.56058 to 0.56166, saving model to output\\inceptionV3.h5\n",
      "178/250 [====================>.........] - ETA: 38s - loss: 9.5940 - accuracy: 0.5617\n",
      "Epoch 1: accuracy improved from 0.56166 to 0.56237, saving model to output\\inceptionV3.h5\n",
      "179/250 [====================>.........] - ETA: 38s - loss: 9.5659 - accuracy: 0.5624\n",
      "Epoch 1: accuracy improved from 0.56237 to 0.56307, saving model to output\\inceptionV3.h5\n",
      "180/250 [====================>.........] - ETA: 37s - loss: 9.5293 - accuracy: 0.5631\n",
      "Epoch 1: accuracy improved from 0.56307 to 0.56376, saving model to output\\inceptionV3.h5\n",
      "181/250 [====================>.........] - ETA: 37s - loss: 9.4969 - accuracy: 0.5638\n",
      "Epoch 1: accuracy improved from 0.56376 to 0.56409, saving model to output\\inceptionV3.h5\n",
      "182/250 [====================>.........] - ETA: 36s - loss: 9.4687 - accuracy: 0.5641\n",
      "Epoch 1: accuracy improved from 0.56409 to 0.56443, saving model to output\\inceptionV3.h5\n",
      "183/250 [====================>.........] - ETA: 36s - loss: 9.4422 - accuracy: 0.5644\n",
      "Epoch 1: accuracy improved from 0.56443 to 0.56459, saving model to output\\inceptionV3.h5\n",
      "184/250 [=====================>........] - ETA: 35s - loss: 9.4262 - accuracy: 0.5646\n",
      "Epoch 1: accuracy improved from 0.56459 to 0.56576, saving model to output\\inceptionV3.h5\n",
      "185/250 [=====================>........] - ETA: 35s - loss: 9.3863 - accuracy: 0.5658\n",
      "Epoch 1: accuracy improved from 0.56576 to 0.56625, saving model to output\\inceptionV3.h5\n",
      "186/250 [=====================>........] - ETA: 34s - loss: 9.3552 - accuracy: 0.5663\n",
      "Epoch 1: accuracy improved from 0.56625 to 0.56724, saving model to output\\inceptionV3.h5\n",
      "187/250 [=====================>........] - ETA: 34s - loss: 9.3282 - accuracy: 0.5672\n",
      "Epoch 1: accuracy improved from 0.56724 to 0.56738, saving model to output\\inceptionV3.h5\n",
      "188/250 [=====================>........] - ETA: 33s - loss: 9.3028 - accuracy: 0.5674\n",
      "Epoch 1: accuracy improved from 0.56738 to 0.56752, saving model to output\\inceptionV3.h5\n",
      "189/250 [=====================>........] - ETA: 33s - loss: 9.2888 - accuracy: 0.5675\n",
      "Epoch 1: accuracy improved from 0.56752 to 0.56799, saving model to output\\inceptionV3.h5\n",
      "190/250 [=====================>........] - ETA: 32s - loss: 9.2640 - accuracy: 0.5680\n",
      "Epoch 1: accuracy improved from 0.56799 to 0.56911, saving model to output\\inceptionV3.h5\n",
      "191/250 [=====================>........] - ETA: 32s - loss: 9.2281 - accuracy: 0.5691\n",
      "Epoch 1: accuracy did not improve from 0.56911\n",
      "192/250 [======================>.......] - ETA: 31s - loss: 9.2209 - accuracy: 0.5689\n",
      "Epoch 1: accuracy improved from 0.56911 to 0.57001, saving model to output\\inceptionV3.h5\n",
      "193/250 [======================>.......] - ETA: 31s - loss: 9.1942 - accuracy: 0.5700\n",
      "Epoch 1: accuracy improved from 0.57001 to 0.57062, saving model to output\\inceptionV3.h5\n",
      "194/250 [======================>.......] - ETA: 30s - loss: 9.1883 - accuracy: 0.5706\n",
      "Epoch 1: accuracy improved from 0.57062 to 0.57203, saving model to output\\inceptionV3.h5\n",
      "195/250 [======================>.......] - ETA: 30s - loss: 9.1517 - accuracy: 0.5720\n",
      "Epoch 1: accuracy improved from 0.57203 to 0.57262, saving model to output\\inceptionV3.h5\n",
      "196/250 [======================>.......] - ETA: 29s - loss: 9.1314 - accuracy: 0.5726\n",
      "Epoch 1: accuracy improved from 0.57262 to 0.57288, saving model to output\\inceptionV3.h5\n",
      "197/250 [======================>.......] - ETA: 29s - loss: 9.0988 - accuracy: 0.5729\n",
      "Epoch 1: accuracy improved from 0.57288 to 0.57299, saving model to output\\inceptionV3.h5\n",
      "198/250 [======================>.......] - ETA: 28s - loss: 9.0800 - accuracy: 0.5730\n",
      "Epoch 1: accuracy improved from 0.57299 to 0.57325, saving model to output\\inceptionV3.h5\n",
      "199/250 [======================>.......] - ETA: 27s - loss: 9.0638 - accuracy: 0.5733\n",
      "Epoch 1: accuracy improved from 0.57325 to 0.57476, saving model to output\\inceptionV3.h5\n",
      "200/250 [=======================>......] - ETA: 27s - loss: 9.0290 - accuracy: 0.5748\n",
      "Epoch 1: accuracy improved from 0.57476 to 0.57517, saving model to output\\inceptionV3.h5\n",
      "201/250 [=======================>......] - ETA: 26s - loss: 8.9993 - accuracy: 0.5752\n",
      "Epoch 1: accuracy improved from 0.57517 to 0.57651, saving model to output\\inceptionV3.h5\n",
      "202/250 [=======================>......] - ETA: 26s - loss: 8.9695 - accuracy: 0.5765\n",
      "Epoch 1: accuracy improved from 0.57651 to 0.57721, saving model to output\\inceptionV3.h5\n",
      "203/250 [=======================>......] - ETA: 25s - loss: 8.9483 - accuracy: 0.5772\n",
      "Epoch 1: accuracy improved from 0.57721 to 0.57790, saving model to output\\inceptionV3.h5\n",
      "204/250 [=======================>......] - ETA: 25s - loss: 8.9198 - accuracy: 0.5779\n",
      "Epoch 1: accuracy improved from 0.57790 to 0.57890, saving model to output\\inceptionV3.h5\n",
      "205/250 [=======================>......] - ETA: 24s - loss: 8.8961 - accuracy: 0.5789\n",
      "Epoch 1: accuracy improved from 0.57890 to 0.57943, saving model to output\\inceptionV3.h5\n",
      "206/250 [=======================>......] - ETA: 24s - loss: 8.8751 - accuracy: 0.5794\n",
      "Epoch 1: accuracy improved from 0.57943 to 0.57965, saving model to output\\inceptionV3.h5\n",
      "207/250 [=======================>......] - ETA: 23s - loss: 8.8673 - accuracy: 0.5796\n",
      "Epoch 1: accuracy improved from 0.57965 to 0.58047, saving model to output\\inceptionV3.h5\n",
      "208/250 [=======================>......] - ETA: 23s - loss: 8.8423 - accuracy: 0.5805\n",
      "Epoch 1: accuracy improved from 0.58047 to 0.58128, saving model to output\\inceptionV3.h5\n",
      "209/250 [========================>.....] - ETA: 22s - loss: 8.8182 - accuracy: 0.5813\n",
      "Epoch 1: accuracy improved from 0.58128 to 0.58194, saving model to output\\inceptionV3.h5\n",
      "210/250 [========================>.....] - ETA: 22s - loss: 8.7918 - accuracy: 0.5819\n",
      "Epoch 1: accuracy improved from 0.58194 to 0.58259, saving model to output\\inceptionV3.h5\n",
      "211/250 [========================>.....] - ETA: 21s - loss: 8.7698 - accuracy: 0.5826\n",
      "Epoch 1: accuracy improved from 0.58259 to 0.58397, saving model to output\\inceptionV3.h5\n",
      "212/250 [========================>.....] - ETA: 20s - loss: 8.7434 - accuracy: 0.5840\n",
      "Epoch 1: accuracy improved from 0.58397 to 0.58431, saving model to output\\inceptionV3.h5\n",
      "213/250 [========================>.....] - ETA: 20s - loss: 8.7197 - accuracy: 0.5843\n",
      "Epoch 1: accuracy improved from 0.58431 to 0.58480, saving model to output\\inceptionV3.h5\n",
      "214/250 [========================>.....] - ETA: 19s - loss: 8.6976 - accuracy: 0.5848\n",
      "Epoch 1: accuracy improved from 0.58480 to 0.58586, saving model to output\\inceptionV3.h5\n",
      "215/250 [========================>.....] - ETA: 19s - loss: 8.6677 - accuracy: 0.5859\n",
      "Epoch 1: accuracy improved from 0.58586 to 0.58691, saving model to output\\inceptionV3.h5\n",
      "216/250 [========================>.....] - ETA: 18s - loss: 8.6437 - accuracy: 0.5869\n",
      "Epoch 1: accuracy improved from 0.58691 to 0.58738, saving model to output\\inceptionV3.h5\n",
      "217/250 [=========================>....] - ETA: 18s - loss: 8.6217 - accuracy: 0.5874\n",
      "Epoch 1: accuracy improved from 0.58738 to 0.58813, saving model to output\\inceptionV3.h5\n",
      "218/250 [=========================>....] - ETA: 17s - loss: 8.5978 - accuracy: 0.5881\n",
      "Epoch 1: accuracy improved from 0.58813 to 0.58829, saving model to output\\inceptionV3.h5\n",
      "219/250 [=========================>....] - ETA: 17s - loss: 8.5996 - accuracy: 0.5883\n",
      "Epoch 1: accuracy improved from 0.58829 to 0.58846, saving model to output\\inceptionV3.h5\n",
      "220/250 [=========================>....] - ETA: 16s - loss: 8.5967 - accuracy: 0.5885\n",
      "Epoch 1: accuracy did not improve from 0.58846\n",
      "221/250 [=========================>....] - ETA: 15s - loss: 8.5891 - accuracy: 0.5882\n",
      "Epoch 1: accuracy improved from 0.58846 to 0.58879, saving model to output\\inceptionV3.h5\n",
      "222/250 [=========================>....] - ETA: 15s - loss: 8.5742 - accuracy: 0.5888\n",
      "Epoch 1: accuracy improved from 0.58879 to 0.58924, saving model to output\\inceptionV3.h5\n",
      "223/250 [=========================>....] - ETA: 14s - loss: 8.5485 - accuracy: 0.5892\n",
      "Epoch 1: accuracy improved from 0.58924 to 0.58982, saving model to output\\inceptionV3.h5\n",
      "224/250 [=========================>....] - ETA: 14s - loss: 8.5196 - accuracy: 0.5898\n",
      "Epoch 1: accuracy did not improve from 0.58982\n",
      "225/250 [==========================>...] - ETA: 13s - loss: 8.5090 - accuracy: 0.5897\n",
      "Epoch 1: accuracy did not improve from 0.58982\n",
      "226/250 [==========================>...] - ETA: 13s - loss: 8.5121 - accuracy: 0.5897\n",
      "Epoch 1: accuracy improved from 0.58982 to 0.59028, saving model to output\\inceptionV3.h5\n",
      "227/250 [==========================>...] - ETA: 12s - loss: 8.4841 - accuracy: 0.5903\n",
      "Epoch 1: accuracy improved from 0.59028 to 0.59126, saving model to output\\inceptionV3.h5\n",
      "228/250 [==========================>...] - ETA: 12s - loss: 8.4570 - accuracy: 0.5913\n",
      "Epoch 1: accuracy improved from 0.59126 to 0.59209, saving model to output\\inceptionV3.h5\n",
      "229/250 [==========================>...] - ETA: 11s - loss: 8.4310 - accuracy: 0.5921\n",
      "Epoch 1: accuracy improved from 0.59209 to 0.59278, saving model to output\\inceptionV3.h5\n",
      "230/250 [==========================>...] - ETA: 11s - loss: 8.4174 - accuracy: 0.5928\n",
      "Epoch 1: accuracy improved from 0.59278 to 0.59278, saving model to output\\inceptionV3.h5\n",
      "231/250 [==========================>...] - ETA: 10s - loss: 8.4079 - accuracy: 0.5928\n",
      "Epoch 1: accuracy improved from 0.59278 to 0.59319, saving model to output\\inceptionV3.h5\n",
      "232/250 [==========================>...] - ETA: 9s - loss: 8.3894 - accuracy: 0.5932 \n",
      "Epoch 1: accuracy improved from 0.59319 to 0.59320, saving model to output\\inceptionV3.h5\n",
      "233/250 [==========================>...] - ETA: 9s - loss: 8.3852 - accuracy: 0.5932\n",
      "Epoch 1: accuracy improved from 0.59320 to 0.59347, saving model to output\\inceptionV3.h5\n",
      "234/250 [===========================>..] - ETA: 8s - loss: 8.3637 - accuracy: 0.5935\n",
      "Epoch 1: accuracy improved from 0.59347 to 0.59387, saving model to output\\inceptionV3.h5\n",
      "235/250 [===========================>..] - ETA: 8s - loss: 8.3446 - accuracy: 0.5939\n",
      "Epoch 1: accuracy improved from 0.59387 to 0.59493, saving model to output\\inceptionV3.h5\n",
      "236/250 [===========================>..] - ETA: 7s - loss: 8.3152 - accuracy: 0.5949\n",
      "Epoch 1: accuracy improved from 0.59493 to 0.59506, saving model to output\\inceptionV3.h5\n",
      "237/250 [===========================>..] - ETA: 7s - loss: 8.2964 - accuracy: 0.5951\n",
      "Epoch 1: accuracy did not improve from 0.59506\n",
      "238/250 [===========================>..] - ETA: 6s - loss: 8.2885 - accuracy: 0.5951\n",
      "Epoch 1: accuracy improved from 0.59506 to 0.59583, saving model to output\\inceptionV3.h5\n",
      "239/250 [===========================>..] - ETA: 6s - loss: 8.2682 - accuracy: 0.5958\n",
      "Epoch 1: accuracy did not improve from 0.59583\n",
      "240/250 [===========================>..] - ETA: 5s - loss: 8.2605 - accuracy: 0.5956\n",
      "Epoch 1: accuracy did not improve from 0.59583\n",
      "241/250 [===========================>..] - ETA: 4s - loss: 8.2443 - accuracy: 0.5957\n",
      "Epoch 1: accuracy improved from 0.59583 to 0.59632, saving model to output\\inceptionV3.h5\n",
      "242/250 [============================>.] - ETA: 4s - loss: 8.2322 - accuracy: 0.5963\n",
      "Epoch 1: accuracy improved from 0.59632 to 0.59657, saving model to output\\inceptionV3.h5\n",
      "243/250 [============================>.] - ETA: 3s - loss: 8.2221 - accuracy: 0.5966\n",
      "Epoch 1: accuracy improved from 0.59657 to 0.59746, saving model to output\\inceptionV3.h5\n",
      "244/250 [============================>.] - ETA: 3s - loss: 8.2006 - accuracy: 0.5975\n",
      "Epoch 1: accuracy improved from 0.59746 to 0.59770, saving model to output\\inceptionV3.h5\n",
      "245/250 [============================>.] - ETA: 2s - loss: 8.1839 - accuracy: 0.5977\n",
      "Epoch 1: accuracy improved from 0.59770 to 0.59806, saving model to output\\inceptionV3.h5\n",
      "246/250 [============================>.] - ETA: 2s - loss: 8.1595 - accuracy: 0.5981\n",
      "Epoch 1: accuracy improved from 0.59806 to 0.59868, saving model to output\\inceptionV3.h5\n",
      "247/250 [============================>.] - ETA: 1s - loss: 8.1368 - accuracy: 0.5987\n",
      "Epoch 1: accuracy improved from 0.59868 to 0.59929, saving model to output\\inceptionV3.h5\n",
      "248/250 [============================>.] - ETA: 1s - loss: 8.1196 - accuracy: 0.5993\n",
      "Epoch 1: accuracy improved from 0.59929 to 0.59965, saving model to output\\inceptionV3.h5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 8.1022 - accuracy: 0.5996\n",
      "Epoch 1: accuracy improved from 0.59965 to 0.60000, saving model to output\\inceptionV3.h5\n",
      "250/250 [==============================] - 159s 622ms/step - loss: 8.0945 - accuracy: 0.6000 - val_loss: 1.9097 - val_accuracy: 0.8291\n",
      "Epoch 2/15\n",
      "\n",
      "Epoch 2: accuracy improved from 0.60000 to 0.81250, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 3:35 - loss: 2.5957 - accuracy: 0.8125\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  2/250 [..............................] - ETA: 20s - loss: 4.0625 - accuracy: 0.7656 \n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  3/250 [..............................] - ETA: 48s - loss: 4.4739 - accuracy: 0.7500\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  4/250 [..............................] - ETA: 54s - loss: 3.9951 - accuracy: 0.7578\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  5/250 [..............................] - ETA: 57s - loss: 3.3292 - accuracy: 0.7812\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  6/250 [..............................] - ETA: 1:01 - loss: 3.3084 - accuracy: 0.7812\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  7/250 [..............................] - ETA: 1:02 - loss: 3.7040 - accuracy: 0.7634\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  8/250 [..............................] - ETA: 1:04 - loss: 4.0825 - accuracy: 0.7383\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "  9/250 [>.............................] - ETA: 1:04 - loss: 4.0977 - accuracy: 0.7257\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 10/250 [>.............................] - ETA: 1:05 - loss: 4.1192 - accuracy: 0.7250\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 11/250 [>.............................] - ETA: 1:05 - loss: 3.9347 - accuracy: 0.7301\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 12/250 [>.............................] - ETA: 1:05 - loss: 3.9029 - accuracy: 0.7292\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 3.9835 - accuracy: 0.7332\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 3.9532 - accuracy: 0.7321\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 3.8291 - accuracy: 0.7417\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 3.8058 - accuracy: 0.7402\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 3.7998 - accuracy: 0.7390\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 3.9552 - accuracy: 0.7378\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 3.8672 - accuracy: 0.7401\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 3.7705 - accuracy: 0.7437\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 21/250 [=>............................] - ETA: 1:03 - loss: 3.8657 - accuracy: 0.7411\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 3.7963 - accuracy: 0.7429\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 3.7742 - accuracy: 0.7391\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 24/250 [=>............................] - ETA: 1:02 - loss: 3.8942 - accuracy: 0.7344\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 3.8655 - accuracy: 0.7350\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 3.8275 - accuracy: 0.7344\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 27/250 [==>...........................] - ETA: 1:01 - loss: 3.7375 - accuracy: 0.7373\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 3.7482 - accuracy: 0.7355\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 3.7328 - accuracy: 0.7328\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 3.6890 - accuracy: 0.7292\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 3.7289 - accuracy: 0.7258\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 3.8830 - accuracy: 0.7197\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 3.8226 - accuracy: 0.7235\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 3.8547 - accuracy: 0.7206\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 3.8083 - accuracy: 0.7232 \n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 3.8217 - accuracy: 0.7222\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 3.7557 - accuracy: 0.7255\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 3.7323 - accuracy: 0.7270\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 3.7277 - accuracy: 0.7276\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 3.6838 - accuracy: 0.7289\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 3.6510 - accuracy: 0.7317\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 3.6418 - accuracy: 0.7299\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 3.6380 - accuracy: 0.7311\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 3.6021 - accuracy: 0.7308\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 45/250 [====>.........................] - ETA: 56s - loss: 3.6331 - accuracy: 0.7299\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 3.5913 - accuracy: 0.7310\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 3.5443 - accuracy: 0.7327\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 3.5560 - accuracy: 0.7324\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 3.5140 - accuracy: 0.7334\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 3.4889 - accuracy: 0.7337\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 3.4816 - accuracy: 0.7347\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 52/250 [=====>........................] - ETA: 54s - loss: 3.4704 - accuracy: 0.7332\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 53/250 [=====>........................] - ETA: 53s - loss: 3.4554 - accuracy: 0.7333\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 54/250 [=====>........................] - ETA: 53s - loss: 3.4325 - accuracy: 0.7354\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 55/250 [=====>........................] - ETA: 53s - loss: 3.4334 - accuracy: 0.7345\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 56/250 [=====>........................] - ETA: 53s - loss: 3.3810 - accuracy: 0.7376\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 57/250 [=====>........................] - ETA: 52s - loss: 3.3992 - accuracy: 0.7373\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 58/250 [=====>........................] - ETA: 52s - loss: 3.3648 - accuracy: 0.7369\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 59/250 [======>.......................] - ETA: 52s - loss: 3.3704 - accuracy: 0.7350\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 3.3465 - accuracy: 0.7363\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 61/250 [======>.......................] - ETA: 51s - loss: 3.3381 - accuracy: 0.7371\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 62/250 [======>.......................] - ETA: 51s - loss: 3.3565 - accuracy: 0.7347\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 63/250 [======>.......................] - ETA: 51s - loss: 3.3360 - accuracy: 0.7365\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 64/250 [======>.......................] - ETA: 51s - loss: 3.3356 - accuracy: 0.7367\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 65/250 [======>.......................] - ETA: 50s - loss: 3.3060 - accuracy: 0.7369\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 66/250 [======>.......................] - ETA: 50s - loss: 3.3088 - accuracy: 0.7371\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 67/250 [=======>......................] - ETA: 50s - loss: 3.3018 - accuracy: 0.7359\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 3.3093 - accuracy: 0.7352\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 69/250 [=======>......................] - ETA: 49s - loss: 3.2795 - accuracy: 0.7367\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 70/250 [=======>......................] - ETA: 49s - loss: 3.2662 - accuracy: 0.7378\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 3.2641 - accuracy: 0.7376\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 3.2643 - accuracy: 0.7373\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 73/250 [=======>......................] - ETA: 48s - loss: 3.2586 - accuracy: 0.7366\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 74/250 [=======>......................] - ETA: 48s - loss: 3.3002 - accuracy: 0.7364\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 3.2924 - accuracy: 0.7361\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 3.2663 - accuracy: 0.7380\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 77/250 [========>.....................] - ETA: 47s - loss: 3.2767 - accuracy: 0.7369\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 78/250 [========>.....................] - ETA: 47s - loss: 3.2748 - accuracy: 0.7367\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 3.2541 - accuracy: 0.7380\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 3.2352 - accuracy: 0.7390\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 81/250 [========>.....................] - ETA: 46s - loss: 3.2220 - accuracy: 0.7395\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 3.2378 - accuracy: 0.7381\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 3.2392 - accuracy: 0.7375\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 3.2169 - accuracy: 0.7380\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 85/250 [=========>....................] - ETA: 45s - loss: 3.1883 - accuracy: 0.7404\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 3.1890 - accuracy: 0.7405\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 3.1802 - accuracy: 0.7402\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 3.1859 - accuracy: 0.7393\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 3.1658 - accuracy: 0.7394\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 3.1556 - accuracy: 0.7399\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 3.1456 - accuracy: 0.7396\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 92/250 [==========>...................] - ETA: 43s - loss: 3.1310 - accuracy: 0.7408\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 3.1321 - accuracy: 0.7402\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 3.1224 - accuracy: 0.7400\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 3.1421 - accuracy: 0.7374\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 96/250 [==========>...................] - ETA: 42s - loss: 3.1377 - accuracy: 0.7369\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 3.1341 - accuracy: 0.7370\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 3.1143 - accuracy: 0.7375\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      " 99/250 [==========>...................] - ETA: 41s - loss: 3.1302 - accuracy: 0.7363\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 3.1260 - accuracy: 0.7368\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 3.1047 - accuracy: 0.7379\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 3.1133 - accuracy: 0.7367\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "103/250 [===========>..................] - ETA: 40s - loss: 3.1225 - accuracy: 0.7357\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 3.1402 - accuracy: 0.7340\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 3.1250 - accuracy: 0.7341\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 3.1032 - accuracy: 0.7352\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "107/250 [===========>..................] - ETA: 39s - loss: 3.1039 - accuracy: 0.7347\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 3.1005 - accuracy: 0.7349\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "109/250 [============>.................] - ETA: 39s - loss: 3.1156 - accuracy: 0.7341\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "110/250 [============>.................] - ETA: 38s - loss: 3.1167 - accuracy: 0.7337\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "111/250 [============>.................] - ETA: 38s - loss: 3.1006 - accuracy: 0.7341\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "112/250 [============>.................] - ETA: 38s - loss: 3.1066 - accuracy: 0.7334\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "113/250 [============>.................] - ETA: 38s - loss: 3.1227 - accuracy: 0.7328\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "114/250 [============>.................] - ETA: 37s - loss: 3.1052 - accuracy: 0.7335\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "115/250 [============>.................] - ETA: 37s - loss: 3.0914 - accuracy: 0.7342\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "116/250 [============>.................] - ETA: 37s - loss: 3.0760 - accuracy: 0.7356\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "117/250 [=============>................] - ETA: 36s - loss: 3.0847 - accuracy: 0.7352\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "118/250 [=============>................] - ETA: 36s - loss: 3.0791 - accuracy: 0.7351\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "119/250 [=============>................] - ETA: 36s - loss: 3.0822 - accuracy: 0.7347\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "120/250 [=============>................] - ETA: 36s - loss: 3.0703 - accuracy: 0.7359\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "121/250 [=============>................] - ETA: 35s - loss: 3.0567 - accuracy: 0.7370\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "122/250 [=============>................] - ETA: 35s - loss: 3.0422 - accuracy: 0.7376\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "123/250 [=============>................] - ETA: 35s - loss: 3.0304 - accuracy: 0.7385\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "124/250 [=============>................] - ETA: 35s - loss: 3.0173 - accuracy: 0.7394\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "125/250 [==============>...............] - ETA: 34s - loss: 3.0180 - accuracy: 0.7394\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 3.0156 - accuracy: 0.7395\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 3.0045 - accuracy: 0.7396\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 2.9981 - accuracy: 0.7395\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 2.9836 - accuracy: 0.7405\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 2.9778 - accuracy: 0.7401\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 2.9821 - accuracy: 0.7397\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 2.9779 - accuracy: 0.7400\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 2.9775 - accuracy: 0.7401\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 2.9612 - accuracy: 0.7413\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 2.9454 - accuracy: 0.7423\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 2.9385 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 2.9348 - accuracy: 0.7420\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 2.9322 - accuracy: 0.7420\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 2.9384 - accuracy: 0.7412\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 2.9286 - accuracy: 0.7415\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 2.9193 - accuracy: 0.7422\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "142/250 [================>.............] - ETA: 30s - loss: 2.9084 - accuracy: 0.7427\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "143/250 [================>.............] - ETA: 29s - loss: 2.9091 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "144/250 [================>.............] - ETA: 29s - loss: 2.9089 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "145/250 [================>.............] - ETA: 29s - loss: 2.9120 - accuracy: 0.7418\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "146/250 [================>.............] - ETA: 28s - loss: 2.8992 - accuracy: 0.7427\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "147/250 [================>.............] - ETA: 28s - loss: 2.9139 - accuracy: 0.7412\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "148/250 [================>.............] - ETA: 28s - loss: 2.9174 - accuracy: 0.7411\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "149/250 [================>.............] - ETA: 28s - loss: 2.9246 - accuracy: 0.7403\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "150/250 [=================>............] - ETA: 27s - loss: 2.9294 - accuracy: 0.7397\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "151/250 [=================>............] - ETA: 27s - loss: 2.9255 - accuracy: 0.7400\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "152/250 [=================>............] - ETA: 27s - loss: 2.9114 - accuracy: 0.7407\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "153/250 [=================>............] - ETA: 26s - loss: 2.8993 - accuracy: 0.7412\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "154/250 [=================>............] - ETA: 26s - loss: 2.8958 - accuracy: 0.7412\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "155/250 [=================>............] - ETA: 26s - loss: 2.8890 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "156/250 [=================>............] - ETA: 26s - loss: 2.8978 - accuracy: 0.7414\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "157/250 [=================>............] - ETA: 25s - loss: 2.9074 - accuracy: 0.7406\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "158/250 [=================>............] - ETA: 25s - loss: 2.9092 - accuracy: 0.7409\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 2.9045 - accuracy: 0.7409\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 2.8983 - accuracy: 0.7416\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 2.8923 - accuracy: 0.7424\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 2.8863 - accuracy: 0.7423\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 2.8843 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 2.8783 - accuracy: 0.7422\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 2.8716 - accuracy: 0.7420\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 2.8771 - accuracy: 0.7419\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 2.8730 - accuracy: 0.7415\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 2.8644 - accuracy: 0.7425\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 2.8587 - accuracy: 0.7424\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 2.8472 - accuracy: 0.7428\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "171/250 [===================>..........] - ETA: 21s - loss: 2.8434 - accuracy: 0.7434\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 2.8474 - accuracy: 0.7434\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 2.8448 - accuracy: 0.7435\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 2.8393 - accuracy: 0.7435\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 2.8395 - accuracy: 0.7434\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 2.8387 - accuracy: 0.7431\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 2.8338 - accuracy: 0.7433\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 2.8249 - accuracy: 0.7437\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 2.8220 - accuracy: 0.7433\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 2.8247 - accuracy: 0.7432\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 2.8247 - accuracy: 0.7432\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "182/250 [====================>.........] - ETA: 18s - loss: 2.8158 - accuracy: 0.7435\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 2.8170 - accuracy: 0.7435\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 2.8108 - accuracy: 0.7437\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 2.8053 - accuracy: 0.7437\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 2.7997 - accuracy: 0.7441\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 2.7951 - accuracy: 0.7440\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 2.7877 - accuracy: 0.7438\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "189/250 [=====================>........] - ETA: 16s - loss: 2.7846 - accuracy: 0.7439\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 2.7800 - accuracy: 0.7437\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 2.7732 - accuracy: 0.7443\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 2.7675 - accuracy: 0.7444\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 2.7563 - accuracy: 0.7453\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 2.7519 - accuracy: 0.7456\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 2.7477 - accuracy: 0.7455\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 2.7390 - accuracy: 0.7462\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 2.7330 - accuracy: 0.7465\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 2.7271 - accuracy: 0.7470\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 2.7247 - accuracy: 0.7472\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 2.7160 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 2.7159 - accuracy: 0.7477\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 2.7074 - accuracy: 0.7481\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 2.7062 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 2.6985 - accuracy: 0.7482\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 2.6934 - accuracy: 0.7485\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 2.6940 - accuracy: 0.7483\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 2.6938 - accuracy: 0.7477\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 2.6863 - accuracy: 0.7477\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 2.6925 - accuracy: 0.7470\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 2.6908 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 2.6827 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 2.6785 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 2.6740 - accuracy: 0.7468\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 2.6688 - accuracy: 0.7465\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 2.6637 - accuracy: 0.7466 \n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 2.6601 - accuracy: 0.7468\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 2.6638 - accuracy: 0.7465\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 2.6576 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 2.6560 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 2.6573 - accuracy: 0.7467\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 2.6570 - accuracy: 0.7463\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 2.6502 - accuracy: 0.7469\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 2.6544 - accuracy: 0.7469\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 2.6482 - accuracy: 0.7473\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 2.6493 - accuracy: 0.7475\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 2.6443 - accuracy: 0.7475\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 2.6381 - accuracy: 0.7479\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 2.6333 - accuracy: 0.7481\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 2.6277 - accuracy: 0.7482\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 2.6311 - accuracy: 0.7481\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 2.6317 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 2.6291 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 2.6305 - accuracy: 0.7476\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 2.6262 - accuracy: 0.7477\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 2.6218 - accuracy: 0.7476\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 2.6179 - accuracy: 0.7476\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 2.6121 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 2.6162 - accuracy: 0.7472\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 2.6139 - accuracy: 0.7471\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 2.6052 - accuracy: 0.7478\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 2.6023 - accuracy: 0.7482\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "242/250 [============================>.] - ETA: 2s - loss: 2.5956 - accuracy: 0.7484\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "243/250 [============================>.] - ETA: 1s - loss: 2.5915 - accuracy: 0.7488\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "244/250 [============================>.] - ETA: 1s - loss: 2.5893 - accuracy: 0.7488\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "245/250 [============================>.] - ETA: 1s - loss: 2.5828 - accuracy: 0.7491\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "246/250 [============================>.] - ETA: 1s - loss: 2.5851 - accuracy: 0.7490\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "247/250 [============================>.] - ETA: 0s - loss: 2.5884 - accuracy: 0.7486\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "248/250 [============================>.] - ETA: 0s - loss: 2.5826 - accuracy: 0.7490\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "249/250 [============================>.] - ETA: 0s - loss: 2.5780 - accuracy: 0.7492\n",
      "Epoch 2: accuracy did not improve from 0.81250\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 2.5764 - accuracy: 0.7494 - val_loss: 0.7443 - val_accuracy: 0.8831\n",
      "Epoch 3/15\n",
      "\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  1/250 [..............................] - ETA: 1:42 - loss: 0.9504 - accuracy: 0.8125\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  2/250 [..............................] - ETA: 1:05 - loss: 1.4170 - accuracy: 0.8125\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 2.0033 - accuracy: 0.7917\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  4/250 [..............................] - ETA: 1:08 - loss: 2.6188 - accuracy: 0.7422\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  5/250 [..............................] - ETA: 1:09 - loss: 2.3770 - accuracy: 0.7437\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 2.2335 - accuracy: 0.7552\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  7/250 [..............................] - ETA: 1:09 - loss: 2.0428 - accuracy: 0.7679\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  8/250 [..............................] - ETA: 1:10 - loss: 1.9149 - accuracy: 0.7734\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "  9/250 [>.............................] - ETA: 1:09 - loss: 1.9264 - accuracy: 0.7604\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 10/250 [>.............................] - ETA: 1:08 - loss: 2.0419 - accuracy: 0.7469\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 11/250 [>.............................] - ETA: 1:08 - loss: 2.0095 - accuracy: 0.7443\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 12/250 [>.............................] - ETA: 1:07 - loss: 1.9229 - accuracy: 0.7526\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 13/250 [>.............................] - ETA: 1:07 - loss: 1.8306 - accuracy: 0.7620\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 1.7651 - accuracy: 0.7656\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 15/250 [>.............................] - ETA: 1:06 - loss: 1.7863 - accuracy: 0.7688\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 16/250 [>.............................] - ETA: 1:06 - loss: 1.7322 - accuracy: 0.7734\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 17/250 [=>............................] - ETA: 1:05 - loss: 1.7490 - accuracy: 0.7721\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 1.7829 - accuracy: 0.7708\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 1.7512 - accuracy: 0.7714\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 1.7281 - accuracy: 0.7766\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 1.7037 - accuracy: 0.7812\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 1.6588 - accuracy: 0.7841\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 1.6417 - accuracy: 0.7826\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 1.6671 - accuracy: 0.7826\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 1.6364 - accuracy: 0.7850\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 1.5998 - accuracy: 0.7873\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 1.5994 - accuracy: 0.7836\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 28/250 [==>...........................] - ETA: 1:02 - loss: 1.5552 - accuracy: 0.7879\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 1.5340 - accuracy: 0.7899\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 1.5878 - accuracy: 0.7865\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 1.6287 - accuracy: 0.7823\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 1.6263 - accuracy: 0.7832\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 1.6193 - accuracy: 0.7812\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 1.6168 - accuracy: 0.7812\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 1.5939 - accuracy: 0.7812\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 1.5859 - accuracy: 0.7830 \n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 1.5801 - accuracy: 0.7829\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 1.5751 - accuracy: 0.7821\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 1.5818 - accuracy: 0.7837\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 1.5757 - accuracy: 0.7828\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 1.5539 - accuracy: 0.7851\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 42/250 [====>.........................] - ETA: 58s - loss: 1.5398 - accuracy: 0.7857\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 1.5367 - accuracy: 0.7849\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 1.5139 - accuracy: 0.7876\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 1.5237 - accuracy: 0.7861\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 1.5081 - accuracy: 0.7874\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 1.5292 - accuracy: 0.7859\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 1.5105 - accuracy: 0.7884\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 1.5117 - accuracy: 0.7889\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 1.5192 - accuracy: 0.7881\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 1.4903 - accuracy: 0.7917\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 1.5071 - accuracy: 0.7897\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 1.4952 - accuracy: 0.7907\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 1.5121 - accuracy: 0.7899\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 1.5023 - accuracy: 0.7903\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 1.4927 - accuracy: 0.7913\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 1.4763 - accuracy: 0.7939\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 1.4804 - accuracy: 0.7931\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 1.4709 - accuracy: 0.7940\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 1.4691 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 1.4518 - accuracy: 0.7951\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 1.4362 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 1.4317 - accuracy: 0.7961\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 1.4234 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 1.4382 - accuracy: 0.7962\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 1.4456 - accuracy: 0.7950\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 1.4511 - accuracy: 0.7943\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 1.4576 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 1.4499 - accuracy: 0.7930\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 1.4513 - accuracy: 0.7937\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 1.4595 - accuracy: 0.7936\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 1.4606 - accuracy: 0.7943\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 1.4555 - accuracy: 0.7945\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 1.4557 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 1.4596 - accuracy: 0.7921\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 1.4617 - accuracy: 0.7915\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 1.4782 - accuracy: 0.7910\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 1.4825 - accuracy: 0.7921\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 1.4939 - accuracy: 0.7907\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 1.4926 - accuracy: 0.7906\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 1.4916 - accuracy: 0.7901\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 1.4856 - accuracy: 0.7912\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 1.4884 - accuracy: 0.7910\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 1.4977 - accuracy: 0.7909\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 1.4862 - accuracy: 0.7923\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 1.5005 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 1.4994 - accuracy: 0.7920\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 1.4990 - accuracy: 0.7919\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 1.5023 - accuracy: 0.7914\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 1.5029 - accuracy: 0.7910\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 1.5047 - accuracy: 0.7905\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 1.5016 - accuracy: 0.7904\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 1.5036 - accuracy: 0.7910\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 1.5001 - accuracy: 0.7912\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 1.5155 - accuracy: 0.7891\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 1.5129 - accuracy: 0.7891\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 1.5145 - accuracy: 0.7893\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 1.5162 - accuracy: 0.7892\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 1.5167 - accuracy: 0.7901\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 1.5129 - accuracy: 0.7897\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 1.5064 - accuracy: 0.7902\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 1.5111 - accuracy: 0.7898\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 1.5073 - accuracy: 0.7900\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 1.5212 - accuracy: 0.7900\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 1.5173 - accuracy: 0.7905\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 1.5123 - accuracy: 0.7904\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "107/250 [===========>..................] - ETA: 39s - loss: 1.5028 - accuracy: 0.7915\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 1.5026 - accuracy: 0.7908\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "109/250 [============>.................] - ETA: 39s - loss: 1.5004 - accuracy: 0.7904\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "110/250 [============>.................] - ETA: 39s - loss: 1.4944 - accuracy: 0.7903\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "111/250 [============>.................] - ETA: 38s - loss: 1.4889 - accuracy: 0.7911\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "112/250 [============>.................] - ETA: 38s - loss: 1.4813 - accuracy: 0.7921\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "113/250 [============>.................] - ETA: 38s - loss: 1.4817 - accuracy: 0.7926\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "114/250 [============>.................] - ETA: 37s - loss: 1.4793 - accuracy: 0.7925\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "115/250 [============>.................] - ETA: 37s - loss: 1.4736 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "116/250 [============>.................] - ETA: 37s - loss: 1.4717 - accuracy: 0.7928\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "117/250 [=============>................] - ETA: 37s - loss: 1.4649 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "118/250 [=============>................] - ETA: 36s - loss: 1.4579 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "119/250 [=============>................] - ETA: 36s - loss: 1.4520 - accuracy: 0.7925\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "120/250 [=============>................] - ETA: 36s - loss: 1.4529 - accuracy: 0.7922\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "121/250 [=============>................] - ETA: 35s - loss: 1.4447 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "122/250 [=============>................] - ETA: 35s - loss: 1.4456 - accuracy: 0.7933\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "123/250 [=============>................] - ETA: 35s - loss: 1.4396 - accuracy: 0.7934\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "124/250 [=============>................] - ETA: 35s - loss: 1.4441 - accuracy: 0.7928\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "125/250 [==============>...............] - ETA: 34s - loss: 1.4404 - accuracy: 0.7935\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 1.4389 - accuracy: 0.7939\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 1.4431 - accuracy: 0.7936\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 1.4414 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 1.4350 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 1.4357 - accuracy: 0.7928\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 1.4444 - accuracy: 0.7925\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 1.4435 - accuracy: 0.7924\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 1.4533 - accuracy: 0.7916\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 1.4522 - accuracy: 0.7910\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 1.4594 - accuracy: 0.7903\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 1.4530 - accuracy: 0.7904\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 1.4575 - accuracy: 0.7890\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 1.4611 - accuracy: 0.7880\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 1.4582 - accuracy: 0.7875\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 1.4541 - accuracy: 0.7879\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 1.4522 - accuracy: 0.7879\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "142/250 [================>.............] - ETA: 30s - loss: 1.4487 - accuracy: 0.7879\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "143/250 [================>.............] - ETA: 29s - loss: 1.4422 - accuracy: 0.7885\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "144/250 [================>.............] - ETA: 29s - loss: 1.4366 - accuracy: 0.7886\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "145/250 [================>.............] - ETA: 29s - loss: 1.4323 - accuracy: 0.7890\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "146/250 [================>.............] - ETA: 29s - loss: 1.4316 - accuracy: 0.7885\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "147/250 [================>.............] - ETA: 28s - loss: 1.4254 - accuracy: 0.7891\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "148/250 [================>.............] - ETA: 28s - loss: 1.4211 - accuracy: 0.7901\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "149/250 [================>.............] - ETA: 28s - loss: 1.4178 - accuracy: 0.7903\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "150/250 [=================>............] - ETA: 27s - loss: 1.4144 - accuracy: 0.7906\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "151/250 [=================>............] - ETA: 27s - loss: 1.4077 - accuracy: 0.7914\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "152/250 [=================>............] - ETA: 27s - loss: 1.4073 - accuracy: 0.7917\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "153/250 [=================>............] - ETA: 27s - loss: 1.4028 - accuracy: 0.7913\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "154/250 [=================>............] - ETA: 26s - loss: 1.4026 - accuracy: 0.7912\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "155/250 [=================>............] - ETA: 26s - loss: 1.4024 - accuracy: 0.7915\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "156/250 [=================>............] - ETA: 26s - loss: 1.3982 - accuracy: 0.7918\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "157/250 [=================>............] - ETA: 25s - loss: 1.3999 - accuracy: 0.7920\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "158/250 [=================>............] - ETA: 25s - loss: 1.4003 - accuracy: 0.7917\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 1.3991 - accuracy: 0.7912\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 1.4070 - accuracy: 0.7908\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 1.4085 - accuracy: 0.7907\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 1.4033 - accuracy: 0.7914\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 1.4001 - accuracy: 0.7912\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 1.3963 - accuracy: 0.7915\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 1.3919 - accuracy: 0.7918\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 1.3918 - accuracy: 0.7914\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 1.3863 - accuracy: 0.7921\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 1.3786 - accuracy: 0.7929\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 1.3766 - accuracy: 0.7925\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 1.3760 - accuracy: 0.7928\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 1.3750 - accuracy: 0.7931\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 1.3726 - accuracy: 0.7930\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 1.3787 - accuracy: 0.7924\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 1.3792 - accuracy: 0.7927\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 1.3796 - accuracy: 0.7928\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 1.3738 - accuracy: 0.7937\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 1.3738 - accuracy: 0.7939\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 1.3694 - accuracy: 0.7944\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 1.3649 - accuracy: 0.7945\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 1.3636 - accuracy: 0.7946\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 1.3576 - accuracy: 0.7952\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "182/250 [====================>.........] - ETA: 18s - loss: 1.3586 - accuracy: 0.7951\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 1.3573 - accuracy: 0.7954\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 1.3560 - accuracy: 0.7953\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 1.3519 - accuracy: 0.7953\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 1.3506 - accuracy: 0.7953\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 1.3468 - accuracy: 0.7956\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 1.3508 - accuracy: 0.7954\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 1.3485 - accuracy: 0.7955\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 1.3432 - accuracy: 0.7962\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 1.3413 - accuracy: 0.7956\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 1.3370 - accuracy: 0.7956\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 1.3358 - accuracy: 0.7953\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 1.3294 - accuracy: 0.7962\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 1.3257 - accuracy: 0.7961\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 1.3227 - accuracy: 0.7959\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 1.3189 - accuracy: 0.7954\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 1.3173 - accuracy: 0.7946\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 1.3184 - accuracy: 0.7947\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 1.3170 - accuracy: 0.7955\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 1.3147 - accuracy: 0.7951\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 1.3129 - accuracy: 0.7952\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 1.3131 - accuracy: 0.7952\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 1.3085 - accuracy: 0.7958\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 1.3061 - accuracy: 0.7957\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 1.3039 - accuracy: 0.7961\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 1.3003 - accuracy: 0.7963\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 1.2959 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 1.2951 - accuracy: 0.7968\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 1.2953 - accuracy: 0.7967\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 1.2950 - accuracy: 0.7968\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 1.2934 - accuracy: 0.7973\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 1.2910 - accuracy: 0.7977\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 1.2932 - accuracy: 0.7976\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 1.2925 - accuracy: 0.7980 \n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 1.2923 - accuracy: 0.7977\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 1.2906 - accuracy: 0.7975\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 1.2874 - accuracy: 0.7976\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 1.2858 - accuracy: 0.7972\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 1.2866 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 1.2858 - accuracy: 0.7962\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 1.2831 - accuracy: 0.7964\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 1.2816 - accuracy: 0.7965\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 1.2823 - accuracy: 0.7962\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 1.2826 - accuracy: 0.7961\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 1.2783 - accuracy: 0.7966\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 1.2769 - accuracy: 0.7964\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 1.2738 - accuracy: 0.7965\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 1.2730 - accuracy: 0.7964\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 1.2690 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 1.2673 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 1.2666 - accuracy: 0.7973\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 1.2678 - accuracy: 0.7967\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 1.2647 - accuracy: 0.7967\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 1.2669 - accuracy: 0.7965\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 1.2665 - accuracy: 0.7965\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 1.2621 - accuracy: 0.7968\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 1.2636 - accuracy: 0.7966\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 1.2629 - accuracy: 0.7969\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 1.2589 - accuracy: 0.7974\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 1.2577 - accuracy: 0.7971\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "242/250 [============================>.] - ETA: 2s - loss: 1.2532 - accuracy: 0.7976\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "243/250 [============================>.] - ETA: 1s - loss: 1.2497 - accuracy: 0.7978\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "244/250 [============================>.] - ETA: 1s - loss: 1.2487 - accuracy: 0.7979\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "245/250 [============================>.] - ETA: 1s - loss: 1.2453 - accuracy: 0.7982\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "246/250 [============================>.] - ETA: 1s - loss: 1.2415 - accuracy: 0.7987\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.2385 - accuracy: 0.7991\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "248/250 [============================>.] - ETA: 0s - loss: 1.2353 - accuracy: 0.7991\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.2364 - accuracy: 0.7987\n",
      "Epoch 3: accuracy did not improve from 0.81250\n",
      "250/250 [==============================] - 88s 352ms/step - loss: 1.2412 - accuracy: 0.7981 - val_loss: 0.3227 - val_accuracy: 0.9199\n",
      "Epoch 4/15\n",
      "\n",
      "Epoch 4: accuracy improved from 0.81250 to 0.87500, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 3:34 - loss: 0.3664 - accuracy: 0.8750\n",
      "Epoch 4: accuracy did not improve from 0.87500\n",
      "  2/250 [..............................] - ETA: 20s - loss: 0.7997 - accuracy: 0.8750 \n",
      "Epoch 4: accuracy improved from 0.87500 to 0.89583, saving model to output\\inceptionV3.h5\n",
      "  3/250 [..............................] - ETA: 1:41 - loss: 0.7394 - accuracy: 0.8958\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  4/250 [..............................] - ETA: 1:14 - loss: 0.7604 - accuracy: 0.8828\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 1.0850 - accuracy: 0.8438\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  6/250 [..............................] - ETA: 1:10 - loss: 0.9856 - accuracy: 0.8385\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  7/250 [..............................] - ETA: 1:10 - loss: 1.0000 - accuracy: 0.8348\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  8/250 [..............................] - ETA: 1:09 - loss: 0.9658 - accuracy: 0.8398\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "  9/250 [>.............................] - ETA: 1:08 - loss: 0.9194 - accuracy: 0.8368\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 10/250 [>.............................] - ETA: 1:08 - loss: 0.9735 - accuracy: 0.8250\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 11/250 [>.............................] - ETA: 1:07 - loss: 0.9539 - accuracy: 0.8295\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 12/250 [>.............................] - ETA: 1:07 - loss: 0.9113 - accuracy: 0.8307\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.9133 - accuracy: 0.8293\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 0.9223 - accuracy: 0.8281\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 15/250 [>.............................] - ETA: 1:06 - loss: 0.8959 - accuracy: 0.8292\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 16/250 [>.............................] - ETA: 1:05 - loss: 0.8641 - accuracy: 0.8281\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 17/250 [=>............................] - ETA: 1:05 - loss: 0.8751 - accuracy: 0.8309\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 0.8580 - accuracy: 0.8299\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.8327 - accuracy: 0.8322\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.8829 - accuracy: 0.8297\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.8651 - accuracy: 0.8304\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.8392 - accuracy: 0.8352\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.8122 - accuracy: 0.8397\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.7998 - accuracy: 0.8398\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.7813 - accuracy: 0.8425\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.7837 - accuracy: 0.8413\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.7988 - accuracy: 0.8380\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.7911 - accuracy: 0.8382\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.8035 - accuracy: 0.8319\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.8362 - accuracy: 0.8271\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.8282 - accuracy: 0.8286\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.8271 - accuracy: 0.8262\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.8211 - accuracy: 0.8248\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 0.8264 - accuracy: 0.8244\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.8174 - accuracy: 0.8259 \n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.8227 - accuracy: 0.8264\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.8216 - accuracy: 0.8285\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.8058 - accuracy: 0.8314\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.8210 - accuracy: 0.8301\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.8322 - accuracy: 0.8281\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 0.8537 - accuracy: 0.8224\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.8482 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.8434 - accuracy: 0.8256\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.8469 - accuracy: 0.8260\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.8367 - accuracy: 0.8264\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 0.8351 - accuracy: 0.8274\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.8436 - accuracy: 0.8285\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.8350 - accuracy: 0.8288\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.8594 - accuracy: 0.8259\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.8768 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.8702 - accuracy: 0.8248\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.8622 - accuracy: 0.8263\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 53/250 [=====>........................] - ETA: 54s - loss: 0.8724 - accuracy: 0.8249\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.8753 - accuracy: 0.8241\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.8665 - accuracy: 0.8256\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.8628 - accuracy: 0.8259\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 57/250 [=====>........................] - ETA: 53s - loss: 0.8573 - accuracy: 0.8257\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.8636 - accuracy: 0.8244\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.8559 - accuracy: 0.8252\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 0.8724 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 0.8633 - accuracy: 0.8248\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.8618 - accuracy: 0.8246\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.8525 - accuracy: 0.8254\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 64/250 [======>.......................] - ETA: 51s - loss: 0.8515 - accuracy: 0.8257\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.8544 - accuracy: 0.8260\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.8641 - accuracy: 0.8258\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.8648 - accuracy: 0.8260\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.8628 - accuracy: 0.8263\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.8639 - accuracy: 0.8252\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.8632 - accuracy: 0.8246\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.8666 - accuracy: 0.8217\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.8614 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.8745 - accuracy: 0.8206\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.8791 - accuracy: 0.8193\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.8745 - accuracy: 0.8204\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.8709 - accuracy: 0.8215\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.8718 - accuracy: 0.8210\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.8728 - accuracy: 0.8209\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.8729 - accuracy: 0.8204\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.8670 - accuracy: 0.8215\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.8693 - accuracy: 0.8202\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.8664 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.8618 - accuracy: 0.8215\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.8529 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.8652 - accuracy: 0.8210\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.8620 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.8611 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.8627 - accuracy: 0.8201\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 0.8704 - accuracy: 0.8197\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.8663 - accuracy: 0.8206\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.8657 - accuracy: 0.8209\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.8679 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 0.8663 - accuracy: 0.8207\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.8679 - accuracy: 0.8196\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.8709 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.8696 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.8716 - accuracy: 0.8191\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.8742 - accuracy: 0.8187\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.8715 - accuracy: 0.8186\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.8663 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.8687 - accuracy: 0.8191\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.8724 - accuracy: 0.8181\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.8692 - accuracy: 0.8187\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.8733 - accuracy: 0.8180\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.8699 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.8674 - accuracy: 0.8200\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.8666 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.8630 - accuracy: 0.8204\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.8650 - accuracy: 0.8201\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.8634 - accuracy: 0.8203\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.8606 - accuracy: 0.8205\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.8640 - accuracy: 0.8201\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.8672 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.8648 - accuracy: 0.8200\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.8651 - accuracy: 0.8194\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.8662 - accuracy: 0.8183\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.8612 - accuracy: 0.8185\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.8587 - accuracy: 0.8179\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.8608 - accuracy: 0.8173\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.8624 - accuracy: 0.8170\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.8605 - accuracy: 0.8175\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.8647 - accuracy: 0.8175\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.8626 - accuracy: 0.8182\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.8593 - accuracy: 0.8186\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.8562 - accuracy: 0.8191\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.8618 - accuracy: 0.8178\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.8555 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.8546 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 0.8499 - accuracy: 0.8201\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.8480 - accuracy: 0.8203\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.8480 - accuracy: 0.8202\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.8500 - accuracy: 0.8202\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.8474 - accuracy: 0.8196\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.8446 - accuracy: 0.8198\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.8462 - accuracy: 0.8191\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 0.8550 - accuracy: 0.8188\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.8520 - accuracy: 0.8194\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.8506 - accuracy: 0.8194\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.8499 - accuracy: 0.8196\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 0.8508 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.8496 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.8502 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.8491 - accuracy: 0.8191\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.8477 - accuracy: 0.8189\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.8495 - accuracy: 0.8188\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.8463 - accuracy: 0.8194\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "147/250 [================>.............] - ETA: 28s - loss: 0.8440 - accuracy: 0.8198\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.8450 - accuracy: 0.8193\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.8409 - accuracy: 0.8199\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.8373 - accuracy: 0.8207\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.8392 - accuracy: 0.8202\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.8402 - accuracy: 0.8196\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.8372 - accuracy: 0.8199\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.8376 - accuracy: 0.8203\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.8428 - accuracy: 0.8198\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.8469 - accuracy: 0.8190\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.8450 - accuracy: 0.8193\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.8432 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.8453 - accuracy: 0.8195\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.8449 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.8467 - accuracy: 0.8182\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.8451 - accuracy: 0.8184\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.8421 - accuracy: 0.8189\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.8399 - accuracy: 0.8192\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.8373 - accuracy: 0.8200\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.8371 - accuracy: 0.8201\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.8366 - accuracy: 0.8199\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.8356 - accuracy: 0.8200\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.8359 - accuracy: 0.8203\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.8345 - accuracy: 0.8207\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.8348 - accuracy: 0.8206\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.8356 - accuracy: 0.8206\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.8321 - accuracy: 0.8211\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.8333 - accuracy: 0.8210\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.8315 - accuracy: 0.8211\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.8304 - accuracy: 0.8209\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.8302 - accuracy: 0.8210\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.8289 - accuracy: 0.8212\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.8340 - accuracy: 0.8204\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.8350 - accuracy: 0.8207\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.8346 - accuracy: 0.8209\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.8308 - accuracy: 0.8215\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.8325 - accuracy: 0.8213\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.8307 - accuracy: 0.8214\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.8311 - accuracy: 0.8214\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.8280 - accuracy: 0.8218\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.8260 - accuracy: 0.8219\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.8275 - accuracy: 0.8222\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.8237 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.8229 - accuracy: 0.8228\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.8221 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.8214 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.8232 - accuracy: 0.8228\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.8210 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.8174 - accuracy: 0.8235\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.8170 - accuracy: 0.8237\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.8181 - accuracy: 0.8242\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.8209 - accuracy: 0.8236\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.8208 - accuracy: 0.8236\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.8218 - accuracy: 0.8232\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.8199 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.8172 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.8198 - accuracy: 0.8227\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.8195 - accuracy: 0.8228\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.8191 - accuracy: 0.8226\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.8172 - accuracy: 0.8226\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.8156 - accuracy: 0.8224\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.8138 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.8126 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.8133 - accuracy: 0.8228\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.8162 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.8135 - accuracy: 0.8236\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.8148 - accuracy: 0.8236\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.8155 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.8156 - accuracy: 0.8232 \n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.8157 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.8155 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.8158 - accuracy: 0.8235\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.8145 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.8137 - accuracy: 0.8235\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.8144 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.8130 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.8099 - accuracy: 0.8238\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.8105 - accuracy: 0.8239\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.8102 - accuracy: 0.8240\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.8122 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.8114 - accuracy: 0.8229\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.8114 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.8094 - accuracy: 0.8232\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.8077 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.8054 - accuracy: 0.8237\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.8030 - accuracy: 0.8240\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.8030 - accuracy: 0.8240\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.8018 - accuracy: 0.8243\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.8024 - accuracy: 0.8243\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.8015 - accuracy: 0.8242\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.8070 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.8047 - accuracy: 0.8233\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.8035 - accuracy: 0.8234\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.8030 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.8013 - accuracy: 0.8232\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.8022 - accuracy: 0.8230\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.8036 - accuracy: 0.8225\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.8023 - accuracy: 0.8225\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.8039 - accuracy: 0.8225\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.8044 - accuracy: 0.8222\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.8031 - accuracy: 0.8227\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.8005 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.7998 - accuracy: 0.8231\n",
      "Epoch 4: accuracy did not improve from 0.89583\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 0.8001 - accuracy: 0.8233 - val_loss: 0.3406 - val_accuracy: 0.9002\n",
      "Epoch 5/15\n",
      "\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  1/250 [..............................] - ETA: 1:35 - loss: 1.2223 - accuracy: 0.7500\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  2/250 [..............................] - ETA: 1:13 - loss: 0.7883 - accuracy: 0.8438\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  3/250 [..............................] - ETA: 1:11 - loss: 1.0074 - accuracy: 0.7812\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  4/250 [..............................] - ETA: 1:12 - loss: 0.9621 - accuracy: 0.7891\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 0.8296 - accuracy: 0.8125\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 0.7257 - accuracy: 0.8229\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  7/250 [..............................] - ETA: 1:10 - loss: 0.7037 - accuracy: 0.8304\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  8/250 [..............................] - ETA: 1:10 - loss: 0.6569 - accuracy: 0.8359\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "  9/250 [>.............................] - ETA: 1:10 - loss: 0.6924 - accuracy: 0.8229\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 10/250 [>.............................] - ETA: 1:10 - loss: 0.7287 - accuracy: 0.8250\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 11/250 [>.............................] - ETA: 1:10 - loss: 0.7333 - accuracy: 0.8210\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 12/250 [>.............................] - ETA: 1:10 - loss: 0.6967 - accuracy: 0.8281\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 13/250 [>.............................] - ETA: 1:09 - loss: 0.6815 - accuracy: 0.8293\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 14/250 [>.............................] - ETA: 1:09 - loss: 0.7009 - accuracy: 0.8304\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 15/250 [>.............................] - ETA: 1:09 - loss: 0.6840 - accuracy: 0.8313\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 16/250 [>.............................] - ETA: 1:09 - loss: 0.7015 - accuracy: 0.8281\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 17/250 [=>............................] - ETA: 1:08 - loss: 0.7115 - accuracy: 0.8327\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 18/250 [=>............................] - ETA: 1:08 - loss: 0.7090 - accuracy: 0.8333\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 19/250 [=>............................] - ETA: 1:07 - loss: 0.6889 - accuracy: 0.8372\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 20/250 [=>............................] - ETA: 1:07 - loss: 0.6645 - accuracy: 0.8422\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 21/250 [=>............................] - ETA: 1:06 - loss: 0.6506 - accuracy: 0.8423\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 22/250 [=>............................] - ETA: 1:06 - loss: 0.6489 - accuracy: 0.8452\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 23/250 [=>............................] - ETA: 1:05 - loss: 0.6367 - accuracy: 0.8478\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 24/250 [=>............................] - ETA: 1:05 - loss: 0.6340 - accuracy: 0.8438\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.6226 - accuracy: 0.8475\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.6244 - accuracy: 0.8486\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.6257 - accuracy: 0.8472\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.6235 - accuracy: 0.8471\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.6266 - accuracy: 0.8491\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.6358 - accuracy: 0.8490\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.6348 - accuracy: 0.8508\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.6279 - accuracy: 0.8525\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.6420 - accuracy: 0.8494\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.6343 - accuracy: 0.8493\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.6298 - accuracy: 0.8500\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.6259 - accuracy: 0.8481\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.6283 - accuracy: 0.8454\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.6242 - accuracy: 0.8454\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.6243 - accuracy: 0.8454 \n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.6233 - accuracy: 0.8477\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.6154 - accuracy: 0.8498\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.6190 - accuracy: 0.8497\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 0.6160 - accuracy: 0.8496\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.6114 - accuracy: 0.8487\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.6135 - accuracy: 0.8486\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.6087 - accuracy: 0.8499\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.6025 - accuracy: 0.8511\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.6055 - accuracy: 0.8509\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.6195 - accuracy: 0.8482\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.6172 - accuracy: 0.8500\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.6166 - accuracy: 0.8499\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.6178 - accuracy: 0.8486\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.6182 - accuracy: 0.8485\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.6151 - accuracy: 0.8490\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.6134 - accuracy: 0.8477\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.6127 - accuracy: 0.8482\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.6039 - accuracy: 0.8498\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.6140 - accuracy: 0.8481\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.6232 - accuracy: 0.8469\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.6240 - accuracy: 0.8469\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.6290 - accuracy: 0.8443\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.6232 - accuracy: 0.8458\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.6279 - accuracy: 0.8452\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.6240 - accuracy: 0.8452\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.6344 - accuracy: 0.8433\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.6395 - accuracy: 0.8428\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.6346 - accuracy: 0.8442\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.6281 - accuracy: 0.8451\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.6292 - accuracy: 0.8451\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.6280 - accuracy: 0.8441\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.6274 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.6320 - accuracy: 0.8433\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.6394 - accuracy: 0.8420\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.6364 - accuracy: 0.8424\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.6349 - accuracy: 0.8424\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.6332 - accuracy: 0.8433\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.6322 - accuracy: 0.8433\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.6323 - accuracy: 0.8433\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.6279 - accuracy: 0.8445\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.6263 - accuracy: 0.8449\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.6286 - accuracy: 0.8445\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.6314 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.6331 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.6344 - accuracy: 0.8430\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.6293 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.6237 - accuracy: 0.8448\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.6247 - accuracy: 0.8448\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.6236 - accuracy: 0.8448\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.6235 - accuracy: 0.8444\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.6287 - accuracy: 0.8444\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.6300 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.6263 - accuracy: 0.8440\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.6249 - accuracy: 0.8447\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.6288 - accuracy: 0.8437\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.6269 - accuracy: 0.8444\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.6279 - accuracy: 0.8427\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.6331 - accuracy: 0.8418\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.6375 - accuracy: 0.8408\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.6362 - accuracy: 0.8412\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.6417 - accuracy: 0.8403\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.6382 - accuracy: 0.8409\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.6355 - accuracy: 0.8409\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.6343 - accuracy: 0.8413\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.6345 - accuracy: 0.8413\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.6343 - accuracy: 0.8407\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.6346 - accuracy: 0.8410\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.6337 - accuracy: 0.8414\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.6310 - accuracy: 0.8414\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.6304 - accuracy: 0.8414\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.6301 - accuracy: 0.8409\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.6314 - accuracy: 0.8406\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.6283 - accuracy: 0.8409\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.6275 - accuracy: 0.8407\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.6255 - accuracy: 0.8407\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.6267 - accuracy: 0.8402\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.6260 - accuracy: 0.8399\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.6242 - accuracy: 0.8402\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.6268 - accuracy: 0.8400\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.6264 - accuracy: 0.8398\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.6262 - accuracy: 0.8390\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.6274 - accuracy: 0.8388\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.6273 - accuracy: 0.8383\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.6286 - accuracy: 0.8373\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.6295 - accuracy: 0.8374\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.6310 - accuracy: 0.8374\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.6301 - accuracy: 0.8372\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.6292 - accuracy: 0.8378\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.6286 - accuracy: 0.8376\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 0.6277 - accuracy: 0.8374\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.6270 - accuracy: 0.8372\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.6336 - accuracy: 0.8360\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.6356 - accuracy: 0.8352\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.6364 - accuracy: 0.8340\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.6354 - accuracy: 0.8346\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.6368 - accuracy: 0.8344\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 0.6379 - accuracy: 0.8343\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.6422 - accuracy: 0.8334\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.6430 - accuracy: 0.8335\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.6460 - accuracy: 0.8331\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 0.6493 - accuracy: 0.8332\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.6474 - accuracy: 0.8335\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.6467 - accuracy: 0.8340\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.6474 - accuracy: 0.8338\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.6462 - accuracy: 0.8341\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.6441 - accuracy: 0.8348\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.6434 - accuracy: 0.8351\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "147/250 [================>.............] - ETA: 28s - loss: 0.6424 - accuracy: 0.8352\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.6413 - accuracy: 0.8350\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.6399 - accuracy: 0.8353\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.6378 - accuracy: 0.8356\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.6405 - accuracy: 0.8350\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.6443 - accuracy: 0.8340\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.6443 - accuracy: 0.8341\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "154/250 [=================>............] - ETA: 26s - loss: 0.6462 - accuracy: 0.8339\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.6514 - accuracy: 0.8332\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.6505 - accuracy: 0.8337\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.6543 - accuracy: 0.8331\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.6539 - accuracy: 0.8326\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.6556 - accuracy: 0.8323\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.6559 - accuracy: 0.8324\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.6554 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.6593 - accuracy: 0.8319\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.6563 - accuracy: 0.8326\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.6581 - accuracy: 0.8313\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.6556 - accuracy: 0.8319\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.6553 - accuracy: 0.8318\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.6546 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.6526 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.6507 - accuracy: 0.8326\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.6522 - accuracy: 0.8321\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.6529 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.6570 - accuracy: 0.8313\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.6546 - accuracy: 0.8318\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.6544 - accuracy: 0.8318\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.6570 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.6550 - accuracy: 0.8316\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.6536 - accuracy: 0.8319\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.6548 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.6538 - accuracy: 0.8315\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.6551 - accuracy: 0.8312\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.6530 - accuracy: 0.8319\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.6522 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.6531 - accuracy: 0.8321\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.6564 - accuracy: 0.8320\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.6575 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.6564 - accuracy: 0.8314\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.6553 - accuracy: 0.8320\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.6537 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.6530 - accuracy: 0.8320\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.6523 - accuracy: 0.8322\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.6514 - accuracy: 0.8326\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.6502 - accuracy: 0.8325\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.6484 - accuracy: 0.8325\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.6467 - accuracy: 0.8327\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.6466 - accuracy: 0.8326\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.6517 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.6516 - accuracy: 0.8312\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.6498 - accuracy: 0.8317\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.6475 - accuracy: 0.8321\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.6470 - accuracy: 0.8323\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.6482 - accuracy: 0.8319\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.6498 - accuracy: 0.8313\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.6511 - accuracy: 0.8308\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.6516 - accuracy: 0.8307\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.6526 - accuracy: 0.8301\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.6534 - accuracy: 0.8300\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.6525 - accuracy: 0.8303\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.6506 - accuracy: 0.8303\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.6504 - accuracy: 0.8301\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.6536 - accuracy: 0.8296\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.6551 - accuracy: 0.8292\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.6528 - accuracy: 0.8295\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.6560 - accuracy: 0.8292\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.6553 - accuracy: 0.8291\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.6545 - accuracy: 0.8290 \n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.6531 - accuracy: 0.8289\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.6519 - accuracy: 0.8290\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.6533 - accuracy: 0.8285\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.6533 - accuracy: 0.8286\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.6535 - accuracy: 0.8288\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.6524 - accuracy: 0.8286\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.6526 - accuracy: 0.8285\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.6529 - accuracy: 0.8280\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.6533 - accuracy: 0.8279\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.6559 - accuracy: 0.8276\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.6571 - accuracy: 0.8271\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.6578 - accuracy: 0.8270\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.6570 - accuracy: 0.8271\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.6550 - accuracy: 0.8274\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.6527 - accuracy: 0.8279\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.6520 - accuracy: 0.8283\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.6503 - accuracy: 0.8286\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.6519 - accuracy: 0.8288\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.6524 - accuracy: 0.8286\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.6509 - accuracy: 0.8287\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.6492 - accuracy: 0.8289\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.6494 - accuracy: 0.8289\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.6498 - accuracy: 0.8291\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.6514 - accuracy: 0.8289\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.6509 - accuracy: 0.8290\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.6499 - accuracy: 0.8292\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.6502 - accuracy: 0.8291\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.6480 - accuracy: 0.8296\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.6478 - accuracy: 0.8296\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.6482 - accuracy: 0.8293\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.6498 - accuracy: 0.8291\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.6484 - accuracy: 0.8294\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.8296\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.8296\n",
      "Epoch 5: accuracy did not improve from 0.89583\n",
      "250/250 [==============================] - 88s 352ms/step - loss: 0.6463 - accuracy: 0.8301 - val_loss: 0.2451 - val_accuracy: 0.9158\n",
      "Epoch 6/15\n",
      "\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  1/250 [..............................] - ETA: 1:31 - loss: 0.5629 - accuracy: 0.8438\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.4727 - accuracy: 0.8438\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  3/250 [..............................] - ETA: 1:09 - loss: 0.5066 - accuracy: 0.8333\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  4/250 [..............................] - ETA: 1:08 - loss: 0.4992 - accuracy: 0.8281\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  5/250 [..............................] - ETA: 1:07 - loss: 0.5154 - accuracy: 0.8125\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 0.5110 - accuracy: 0.8281\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.5111 - accuracy: 0.8304\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.5153 - accuracy: 0.8359\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "  9/250 [>.............................] - ETA: 1:07 - loss: 0.5164 - accuracy: 0.8368\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 10/250 [>.............................] - ETA: 1:07 - loss: 0.5079 - accuracy: 0.8375\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 11/250 [>.............................] - ETA: 1:07 - loss: 0.5172 - accuracy: 0.8352\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.5203 - accuracy: 0.8333\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.5220 - accuracy: 0.8341\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 0.5117 - accuracy: 0.8326\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 0.5186 - accuracy: 0.8292\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 16/250 [>.............................] - ETA: 1:05 - loss: 0.5170 - accuracy: 0.8320\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 17/250 [=>............................] - ETA: 1:05 - loss: 0.5202 - accuracy: 0.8346\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.5260 - accuracy: 0.8333\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.5097 - accuracy: 0.8372\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.5019 - accuracy: 0.8391\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 21/250 [=>............................] - ETA: 1:03 - loss: 0.4944 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.4889 - accuracy: 0.8395\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.4862 - accuracy: 0.8410\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 24/250 [=>............................] - ETA: 1:02 - loss: 0.4975 - accuracy: 0.8398\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.4978 - accuracy: 0.8400\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.5033 - accuracy: 0.8377\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 27/250 [==>...........................] - ETA: 1:01 - loss: 0.5117 - accuracy: 0.8345\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.5047 - accuracy: 0.8359\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.5075 - accuracy: 0.8351\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.5088 - accuracy: 0.8344\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 31/250 [==>...........................] - ETA: 1:00 - loss: 0.5224 - accuracy: 0.8296\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.5281 - accuracy: 0.8301\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.5282 - accuracy: 0.8324\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 34/250 [===>..........................] - ETA: 59s - loss: 0.5251 - accuracy: 0.8327 \n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.5363 - accuracy: 0.8321\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.5284 - accuracy: 0.8351\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 37/250 [===>..........................] - ETA: 58s - loss: 0.5250 - accuracy: 0.8353\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 0.5256 - accuracy: 0.8363\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.5334 - accuracy: 0.8333\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.5282 - accuracy: 0.8344\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 0.5253 - accuracy: 0.8346\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.5310 - accuracy: 0.8333\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.5336 - accuracy: 0.8343\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.5416 - accuracy: 0.8331\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 45/250 [====>.........................] - ETA: 56s - loss: 0.5351 - accuracy: 0.8354\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 0.5363 - accuracy: 0.8349\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.5448 - accuracy: 0.8358\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.5533 - accuracy: 0.8340\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 0.5451 - accuracy: 0.8361\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.5377 - accuracy: 0.8381\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.5389 - accuracy: 0.8376\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 52/250 [=====>........................] - ETA: 54s - loss: 0.5474 - accuracy: 0.8353\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 53/250 [=====>........................] - ETA: 54s - loss: 0.5418 - accuracy: 0.8379\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.5423 - accuracy: 0.8368\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.5356 - accuracy: 0.8386\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 56/250 [=====>........................] - ETA: 53s - loss: 0.5310 - accuracy: 0.8398\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 57/250 [=====>........................] - ETA: 53s - loss: 0.5312 - accuracy: 0.8394\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.5469 - accuracy: 0.8378\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.5399 - accuracy: 0.8395\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 0.5383 - accuracy: 0.8396\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 0.5353 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.5336 - accuracy: 0.8407\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 63/250 [======>.......................] - ETA: 51s - loss: 0.5320 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 64/250 [======>.......................] - ETA: 51s - loss: 0.5351 - accuracy: 0.8398\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.5354 - accuracy: 0.8399\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.5393 - accuracy: 0.8390\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 67/250 [=======>......................] - ETA: 50s - loss: 0.5382 - accuracy: 0.8382\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.5430 - accuracy: 0.8364\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.5425 - accuracy: 0.8356\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.5360 - accuracy: 0.8379\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.5332 - accuracy: 0.8389\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.5288 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.5246 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 74/250 [=======>......................] - ETA: 48s - loss: 0.5248 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.5257 - accuracy: 0.8404\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.5266 - accuracy: 0.8396\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.5293 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 78/250 [========>.....................] - ETA: 47s - loss: 0.5288 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.5326 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.5311 - accuracy: 0.8406\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 81/250 [========>.....................] - ETA: 46s - loss: 0.5282 - accuracy: 0.8418\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 0.5381 - accuracy: 0.8396\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.5343 - accuracy: 0.8407\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.5300 - accuracy: 0.8419\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 85/250 [=========>....................] - ETA: 45s - loss: 0.5261 - accuracy: 0.8426\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 86/250 [=========>....................] - ETA: 45s - loss: 0.5251 - accuracy: 0.8419\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 87/250 [=========>....................] - ETA: 45s - loss: 0.5271 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 88/250 [=========>....................] - ETA: 44s - loss: 0.5269 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 89/250 [=========>....................] - ETA: 44s - loss: 0.5218 - accuracy: 0.8430\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 90/250 [=========>....................] - ETA: 44s - loss: 0.5226 - accuracy: 0.8431\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 91/250 [=========>....................] - ETA: 44s - loss: 0.5218 - accuracy: 0.8431\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 92/250 [==========>...................] - ETA: 43s - loss: 0.5242 - accuracy: 0.8421\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 93/250 [==========>...................] - ETA: 43s - loss: 0.5240 - accuracy: 0.8417\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 94/250 [==========>...................] - ETA: 43s - loss: 0.5317 - accuracy: 0.8401\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 95/250 [==========>...................] - ETA: 42s - loss: 0.5305 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 96/250 [==========>...................] - ETA: 42s - loss: 0.5412 - accuracy: 0.8389\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 97/250 [==========>...................] - ETA: 42s - loss: 0.5387 - accuracy: 0.8396\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.5378 - accuracy: 0.8393\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      " 99/250 [==========>...................] - ETA: 41s - loss: 0.5350 - accuracy: 0.8400\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "100/250 [===========>..................] - ETA: 41s - loss: 0.5320 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.5336 - accuracy: 0.8410\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.5321 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "103/250 [===========>..................] - ETA: 40s - loss: 0.5300 - accuracy: 0.8416\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "104/250 [===========>..................] - ETA: 40s - loss: 0.5310 - accuracy: 0.8419\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.5324 - accuracy: 0.8417\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "106/250 [===========>..................] - ETA: 39s - loss: 0.5336 - accuracy: 0.8417\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "107/250 [===========>..................] - ETA: 39s - loss: 0.5352 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.5345 - accuracy: 0.8411\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.5329 - accuracy: 0.8417\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "110/250 [============>.................] - ETA: 38s - loss: 0.5350 - accuracy: 0.8406\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.5349 - accuracy: 0.8401\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.5353 - accuracy: 0.8407\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "113/250 [============>.................] - ETA: 37s - loss: 0.5358 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "114/250 [============>.................] - ETA: 37s - loss: 0.5422 - accuracy: 0.8388\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.5441 - accuracy: 0.8386\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.5437 - accuracy: 0.8381\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "117/250 [=============>................] - ETA: 36s - loss: 0.5489 - accuracy: 0.8371\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "118/250 [=============>................] - ETA: 36s - loss: 0.5505 - accuracy: 0.8366\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.5473 - accuracy: 0.8374\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.5443 - accuracy: 0.8380\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "121/250 [=============>................] - ETA: 35s - loss: 0.5463 - accuracy: 0.8378\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.5488 - accuracy: 0.8371\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.5480 - accuracy: 0.8377\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "124/250 [=============>................] - ETA: 34s - loss: 0.5498 - accuracy: 0.8369\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "125/250 [==============>...............] - ETA: 34s - loss: 0.5488 - accuracy: 0.8378\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.5468 - accuracy: 0.8380\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.5449 - accuracy: 0.8386\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 0.5431 - accuracy: 0.8391\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 0.5468 - accuracy: 0.8387\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.5442 - accuracy: 0.8392\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.5423 - accuracy: 0.8399\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 0.5424 - accuracy: 0.8395\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.5392 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.5367 - accuracy: 0.8410\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 0.5384 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 0.5364 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.5357 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.5338 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 0.5379 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 0.5376 - accuracy: 0.8411\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.5367 - accuracy: 0.8415\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "142/250 [================>.............] - ETA: 29s - loss: 0.5379 - accuracy: 0.8411\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.5368 - accuracy: 0.8416\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.5382 - accuracy: 0.8409\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "145/250 [================>.............] - ETA: 28s - loss: 0.5389 - accuracy: 0.8409\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "146/250 [================>.............] - ETA: 28s - loss: 0.5368 - accuracy: 0.8416\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "147/250 [================>.............] - ETA: 28s - loss: 0.5354 - accuracy: 0.8420\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.5373 - accuracy: 0.8418\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "149/250 [================>.............] - ETA: 27s - loss: 0.5410 - accuracy: 0.8410\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.5406 - accuracy: 0.8406\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.5402 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.5393 - accuracy: 0.8408\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "153/250 [=================>............] - ETA: 26s - loss: 0.5381 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "154/250 [=================>............] - ETA: 26s - loss: 0.5405 - accuracy: 0.8413\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.5425 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.5410 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.5393 - accuracy: 0.8407\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.5405 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.5403 - accuracy: 0.8400\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "160/250 [==================>...........] - ETA: 24s - loss: 0.5397 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.5385 - accuracy: 0.8400\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.5361 - accuracy: 0.8406\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.5373 - accuracy: 0.8405\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 0.5369 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.5348 - accuracy: 0.8407\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.5351 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.5348 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.5347 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.5356 - accuracy: 0.8395\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.5340 - accuracy: 0.8395\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.5316 - accuracy: 0.8402\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.5308 - accuracy: 0.8403\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.5285 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.5288 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.5311 - accuracy: 0.8412\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.5301 - accuracy: 0.8416\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.5293 - accuracy: 0.8418\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.5282 - accuracy: 0.8416\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.5272 - accuracy: 0.8422\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.5268 - accuracy: 0.8425\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.5251 - accuracy: 0.8429\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.5251 - accuracy: 0.8427\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.5234 - accuracy: 0.8432\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.5215 - accuracy: 0.8439\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.5194 - accuracy: 0.8444\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.5204 - accuracy: 0.8441\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.5193 - accuracy: 0.8442\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.5200 - accuracy: 0.8437\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.5224 - accuracy: 0.8426\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.5238 - accuracy: 0.8426\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.5238 - accuracy: 0.8429\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.5261 - accuracy: 0.8427\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.5251 - accuracy: 0.8428\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.5246 - accuracy: 0.8429\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.5240 - accuracy: 0.8431\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.5241 - accuracy: 0.8431\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.5241 - accuracy: 0.8431\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.5233 - accuracy: 0.8433\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.5223 - accuracy: 0.8434\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.5209 - accuracy: 0.8439\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.5195 - accuracy: 0.8442\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.5192 - accuracy: 0.8442\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.5179 - accuracy: 0.8443\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.5165 - accuracy: 0.8447\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.5145 - accuracy: 0.8453\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.5138 - accuracy: 0.8456\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.5128 - accuracy: 0.8455\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.5117 - accuracy: 0.8455\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.5122 - accuracy: 0.8455\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.5128 - accuracy: 0.8457\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.5124 - accuracy: 0.8458\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.5129 - accuracy: 0.8454\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.5118 - accuracy: 0.8458\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.5106 - accuracy: 0.8461\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.5111 - accuracy: 0.8458 \n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.5120 - accuracy: 0.8458\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.5118 - accuracy: 0.8458\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.5114 - accuracy: 0.8456\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.5106 - accuracy: 0.8460\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.5094 - accuracy: 0.8463\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.5089 - accuracy: 0.8463\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.5109 - accuracy: 0.8456\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.5107 - accuracy: 0.8456\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.5092 - accuracy: 0.8457\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.5076 - accuracy: 0.8461\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.5077 - accuracy: 0.8461\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.5092 - accuracy: 0.8459\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.5085 - accuracy: 0.8463\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.5090 - accuracy: 0.8463\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.5099 - accuracy: 0.8459\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.5086 - accuracy: 0.8463\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.5075 - accuracy: 0.8466\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.5070 - accuracy: 0.8470\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.5067 - accuracy: 0.8471\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.5074 - accuracy: 0.8468\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.5062 - accuracy: 0.8469\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.5058 - accuracy: 0.8470\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.5045 - accuracy: 0.8476\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.5035 - accuracy: 0.8478\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.5026 - accuracy: 0.8482\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.5029 - accuracy: 0.8484\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.5024 - accuracy: 0.8485\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.5035 - accuracy: 0.8485\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.5047 - accuracy: 0.8484\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.5044 - accuracy: 0.8483\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.5040 - accuracy: 0.8483\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.5034 - accuracy: 0.8482\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8484\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.5017 - accuracy: 0.8484\n",
      "Epoch 6: accuracy did not improve from 0.89583\n",
      "250/250 [==============================] - 87s 349ms/step - loss: 0.5031 - accuracy: 0.8477 - val_loss: 0.2090 - val_accuracy: 0.9259\n",
      "Epoch 7/15\n",
      "\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  1/250 [..............................] - ETA: 1:28 - loss: 0.4769 - accuracy: 0.8438\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  2/250 [..............................] - ETA: 1:12 - loss: 0.6342 - accuracy: 0.8438\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  3/250 [..............................] - ETA: 1:12 - loss: 0.4937 - accuracy: 0.8646\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  4/250 [..............................] - ETA: 1:11 - loss: 0.4412 - accuracy: 0.8672\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  5/250 [..............................] - ETA: 1:09 - loss: 0.4056 - accuracy: 0.8687\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  6/250 [..............................] - ETA: 1:08 - loss: 0.3885 - accuracy: 0.8750\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.4008 - accuracy: 0.8661\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.4595 - accuracy: 0.8555\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "  9/250 [>.............................] - ETA: 1:07 - loss: 0.4410 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 10/250 [>.............................] - ETA: 1:07 - loss: 0.4581 - accuracy: 0.8500\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.4762 - accuracy: 0.8523\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.4532 - accuracy: 0.8594\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.4285 - accuracy: 0.8678\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 0.4434 - accuracy: 0.8571\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 0.4467 - accuracy: 0.8583\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 16/250 [>.............................] - ETA: 1:05 - loss: 0.4394 - accuracy: 0.8594\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 17/250 [=>............................] - ETA: 1:05 - loss: 0.4498 - accuracy: 0.8548\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 0.4400 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.4323 - accuracy: 0.8586\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.4284 - accuracy: 0.8562\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.4349 - accuracy: 0.8527\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.4330 - accuracy: 0.8551\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.4436 - accuracy: 0.8533\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.4500 - accuracy: 0.8503\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.4716 - accuracy: 0.8475\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.4765 - accuracy: 0.8486\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.4682 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 28/250 [==>...........................] - ETA: 1:02 - loss: 0.4591 - accuracy: 0.8549\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.4630 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.4629 - accuracy: 0.8479\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.4666 - accuracy: 0.8478\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.4587 - accuracy: 0.8506\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.4535 - accuracy: 0.8523\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 0.4427 - accuracy: 0.8557\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.4404 - accuracy: 0.8554\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.4455 - accuracy: 0.8550 \n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.4419 - accuracy: 0.8564\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.4418 - accuracy: 0.8577\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.4393 - accuracy: 0.8582\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.4359 - accuracy: 0.8578\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 0.4350 - accuracy: 0.8582\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 42/250 [====>.........................] - ETA: 58s - loss: 0.4333 - accuracy: 0.8601\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.4249 - accuracy: 0.8626\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.4341 - accuracy: 0.8615\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.4360 - accuracy: 0.8618\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.4372 - accuracy: 0.8621\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 47/250 [====>.........................] - ETA: 56s - loss: 0.4441 - accuracy: 0.8597\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.4415 - accuracy: 0.8600\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.4379 - accuracy: 0.8610\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.4370 - accuracy: 0.8606\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.4357 - accuracy: 0.8597\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.4408 - accuracy: 0.8594\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.4486 - accuracy: 0.8585\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.4493 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.4487 - accuracy: 0.8574\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.4463 - accuracy: 0.8571\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.4497 - accuracy: 0.8558\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.4578 - accuracy: 0.8534\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.4555 - accuracy: 0.8554\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.4555 - accuracy: 0.8562\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 61/250 [======>.......................] - ETA: 52s - loss: 0.4550 - accuracy: 0.8561\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.4526 - accuracy: 0.8569\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 63/250 [======>.......................] - ETA: 51s - loss: 0.4501 - accuracy: 0.8582\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 64/250 [======>.......................] - ETA: 51s - loss: 0.4469 - accuracy: 0.8590\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 65/250 [======>.......................] - ETA: 51s - loss: 0.4470 - accuracy: 0.8597\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.4442 - accuracy: 0.8599\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 67/250 [=======>......................] - ETA: 50s - loss: 0.4451 - accuracy: 0.8597\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 68/250 [=======>......................] - ETA: 50s - loss: 0.4526 - accuracy: 0.8604\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.4545 - accuracy: 0.8588\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 70/250 [=======>......................] - ETA: 49s - loss: 0.4517 - accuracy: 0.8599\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 71/250 [=======>......................] - ETA: 49s - loss: 0.4522 - accuracy: 0.8588\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 72/250 [=======>......................] - ETA: 49s - loss: 0.4618 - accuracy: 0.8568\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 73/250 [=======>......................] - ETA: 49s - loss: 0.4617 - accuracy: 0.8571\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 74/250 [=======>......................] - ETA: 48s - loss: 0.4607 - accuracy: 0.8578\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 75/250 [========>.....................] - ETA: 48s - loss: 0.4585 - accuracy: 0.8584\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 76/250 [========>.....................] - ETA: 48s - loss: 0.4574 - accuracy: 0.8586\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.4601 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 78/250 [========>.....................] - ETA: 47s - loss: 0.4625 - accuracy: 0.8566\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 79/250 [========>.....................] - ETA: 47s - loss: 0.4574 - accuracy: 0.8585\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 80/250 [========>.....................] - ETA: 47s - loss: 0.4557 - accuracy: 0.8587\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.4582 - accuracy: 0.8593\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 82/250 [========>.....................] - ETA: 46s - loss: 0.4569 - accuracy: 0.8591\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 83/250 [========>.....................] - ETA: 46s - loss: 0.4598 - accuracy: 0.8577\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 84/250 [=========>....................] - ETA: 46s - loss: 0.4605 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.4624 - accuracy: 0.8578\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.4596 - accuracy: 0.8583\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.4573 - accuracy: 0.8585\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 88/250 [=========>....................] - ETA: 45s - loss: 0.4623 - accuracy: 0.8577\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.4616 - accuracy: 0.8582\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.4594 - accuracy: 0.8587\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.4603 - accuracy: 0.8582\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.4598 - accuracy: 0.8588\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.4567 - accuracy: 0.8599\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.4604 - accuracy: 0.8591\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 95/250 [==========>...................] - ETA: 43s - loss: 0.4607 - accuracy: 0.8589\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.4613 - accuracy: 0.8591\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.4650 - accuracy: 0.8577\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 98/250 [==========>...................] - ETA: 42s - loss: 0.4669 - accuracy: 0.8585\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.4663 - accuracy: 0.8583\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.4648 - accuracy: 0.8585\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "101/250 [===========>..................] - ETA: 41s - loss: 0.4652 - accuracy: 0.8580\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.4698 - accuracy: 0.8576\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.4747 - accuracy: 0.8562\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.4735 - accuracy: 0.8561\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "105/250 [===========>..................] - ETA: 40s - loss: 0.4754 - accuracy: 0.8554\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.4748 - accuracy: 0.8553\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.4743 - accuracy: 0.8558\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "108/250 [===========>..................] - ETA: 39s - loss: 0.4732 - accuracy: 0.8559\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.4742 - accuracy: 0.8555\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.4728 - accuracy: 0.8560\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "111/250 [============>.................] - ETA: 38s - loss: 0.4705 - accuracy: 0.8567\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "112/250 [============>.................] - ETA: 38s - loss: 0.4735 - accuracy: 0.8566\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.4763 - accuracy: 0.8562\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.4748 - accuracy: 0.8567\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "115/250 [============>.................] - ETA: 37s - loss: 0.4784 - accuracy: 0.8555\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.4773 - accuracy: 0.8554\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.4763 - accuracy: 0.8553\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "118/250 [=============>................] - ETA: 36s - loss: 0.4755 - accuracy: 0.8554\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "119/250 [=============>................] - ETA: 36s - loss: 0.4741 - accuracy: 0.8559\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.4739 - accuracy: 0.8558\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.4730 - accuracy: 0.8562\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "122/250 [=============>................] - ETA: 35s - loss: 0.4762 - accuracy: 0.8550\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.4780 - accuracy: 0.8547\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.4802 - accuracy: 0.8544\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "125/250 [==============>...............] - ETA: 34s - loss: 0.4795 - accuracy: 0.8540\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "126/250 [==============>...............] - ETA: 34s - loss: 0.4796 - accuracy: 0.8542\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.4806 - accuracy: 0.8539\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 0.4825 - accuracy: 0.8540\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "129/250 [==============>...............] - ETA: 33s - loss: 0.4816 - accuracy: 0.8542\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "130/250 [==============>...............] - ETA: 33s - loss: 0.4805 - accuracy: 0.8536\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.4829 - accuracy: 0.8535\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "132/250 [==============>...............] - ETA: 32s - loss: 0.4845 - accuracy: 0.8532\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "133/250 [==============>...............] - ETA: 32s - loss: 0.4834 - accuracy: 0.8539\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.4861 - accuracy: 0.8536\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 0.4846 - accuracy: 0.8540\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "136/250 [===============>..............] - ETA: 31s - loss: 0.4851 - accuracy: 0.8539\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "137/250 [===============>..............] - ETA: 31s - loss: 0.4845 - accuracy: 0.8538\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.4859 - accuracy: 0.8533\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "139/250 [===============>..............] - ETA: 30s - loss: 0.4850 - accuracy: 0.8534\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "140/250 [===============>..............] - ETA: 30s - loss: 0.4839 - accuracy: 0.8536\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.4852 - accuracy: 0.8535\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "142/250 [================>.............] - ETA: 29s - loss: 0.4857 - accuracy: 0.8537\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "143/250 [================>.............] - ETA: 29s - loss: 0.4880 - accuracy: 0.8532\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "144/250 [================>.............] - ETA: 29s - loss: 0.4863 - accuracy: 0.8537\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.4871 - accuracy: 0.8537\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "146/250 [================>.............] - ETA: 28s - loss: 0.4864 - accuracy: 0.8540\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "147/250 [================>.............] - ETA: 28s - loss: 0.4863 - accuracy: 0.8538\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.4859 - accuracy: 0.8533\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "149/250 [================>.............] - ETA: 27s - loss: 0.4840 - accuracy: 0.8536\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.4865 - accuracy: 0.8523\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "151/250 [=================>............] - ETA: 27s - loss: 0.4856 - accuracy: 0.8522\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.4865 - accuracy: 0.8520\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "153/250 [=================>............] - ETA: 26s - loss: 0.4860 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "154/250 [=================>............] - ETA: 26s - loss: 0.4843 - accuracy: 0.8525\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.4841 - accuracy: 0.8528\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.4841 - accuracy: 0.8526\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.4841 - accuracy: 0.8525\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "158/250 [=================>............] - ETA: 25s - loss: 0.4825 - accuracy: 0.8527\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.4848 - accuracy: 0.8522\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "160/250 [==================>...........] - ETA: 24s - loss: 0.4873 - accuracy: 0.8520\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.4885 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.4874 - accuracy: 0.8517\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.4856 - accuracy: 0.8522\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 0.4855 - accuracy: 0.8521\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "165/250 [==================>...........] - ETA: 23s - loss: 0.4860 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.4860 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.4884 - accuracy: 0.8518\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.4875 - accuracy: 0.8519\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.4909 - accuracy: 0.8508\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.4902 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "171/250 [===================>..........] - ETA: 21s - loss: 0.4896 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.4907 - accuracy: 0.8505\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.4915 - accuracy: 0.8506\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.4897 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.4887 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "176/250 [====================>.........] - ETA: 20s - loss: 0.4888 - accuracy: 0.8514\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.4892 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.4896 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.4891 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.4880 - accuracy: 0.8517\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.4879 - accuracy: 0.8515\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.4907 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.4907 - accuracy: 0.8509\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.4900 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.4950 - accuracy: 0.8500\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.4965 - accuracy: 0.8496\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.4967 - accuracy: 0.8496\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.4968 - accuracy: 0.8492\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.4974 - accuracy: 0.8490\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.4982 - accuracy: 0.8488\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.4980 - accuracy: 0.8485\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.4969 - accuracy: 0.8485\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.4978 - accuracy: 0.8484\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.4986 - accuracy: 0.8484\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.5001 - accuracy: 0.8479\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.5007 - accuracy: 0.8474\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.4995 - accuracy: 0.8479\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.5000 - accuracy: 0.8475\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.5005 - accuracy: 0.8475\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.5031 - accuracy: 0.8466\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.5022 - accuracy: 0.8468\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.5011 - accuracy: 0.8471\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.5006 - accuracy: 0.8474\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.5020 - accuracy: 0.8468\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.5014 - accuracy: 0.8469\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.5003 - accuracy: 0.8472\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.4989 - accuracy: 0.8478\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.4983 - accuracy: 0.8480\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.4981 - accuracy: 0.8481\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.4967 - accuracy: 0.8485\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.4949 - accuracy: 0.8489\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.4957 - accuracy: 0.8489\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.4951 - accuracy: 0.8487\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.4949 - accuracy: 0.8489\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.4953 - accuracy: 0.8487 \n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.4934 - accuracy: 0.8492\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.4924 - accuracy: 0.8495\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.4928 - accuracy: 0.8495\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.4910 - accuracy: 0.8499\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.4918 - accuracy: 0.8499\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.4916 - accuracy: 0.8498\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.4919 - accuracy: 0.8498\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.4924 - accuracy: 0.8501\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.4928 - accuracy: 0.8497\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.4927 - accuracy: 0.8499\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.4927 - accuracy: 0.8497\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.4916 - accuracy: 0.8502\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.4919 - accuracy: 0.8501\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.4923 - accuracy: 0.8500\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.4907 - accuracy: 0.8504\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.4896 - accuracy: 0.8507\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.4890 - accuracy: 0.8508\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.4879 - accuracy: 0.8513\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.4885 - accuracy: 0.8512\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.4891 - accuracy: 0.8511\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.4905 - accuracy: 0.8505\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.4910 - accuracy: 0.8503\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.4896 - accuracy: 0.8507\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.4890 - accuracy: 0.8506\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.4882 - accuracy: 0.8509\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.4909 - accuracy: 0.8508\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.4920 - accuracy: 0.8503\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.4926 - accuracy: 0.8501\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.4951 - accuracy: 0.8499\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.4950 - accuracy: 0.8499\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4943 - accuracy: 0.8501\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.4940 - accuracy: 0.8503\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.8503\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8500\n",
      "Epoch 7: accuracy did not improve from 0.89583\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.4949 - accuracy: 0.8499 - val_loss: 0.2232 - val_accuracy: 0.9264\n",
      "Epoch 8/15\n",
      "\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  1/250 [..............................] - ETA: 1:32 - loss: 0.3377 - accuracy: 0.8438\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  2/250 [..............................] - ETA: 1:10 - loss: 0.5495 - accuracy: 0.7969\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  3/250 [..............................] - ETA: 1:17 - loss: 0.7187 - accuracy: 0.7604\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  4/250 [..............................] - ETA: 1:12 - loss: 0.6598 - accuracy: 0.7812\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  5/250 [..............................] - ETA: 1:10 - loss: 0.5761 - accuracy: 0.8062\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 0.5858 - accuracy: 0.8021\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  7/250 [..............................] - ETA: 1:07 - loss: 0.5584 - accuracy: 0.8125\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.5248 - accuracy: 0.8281\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "  9/250 [>.............................] - ETA: 1:07 - loss: 0.5269 - accuracy: 0.8333\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 10/250 [>.............................] - ETA: 1:07 - loss: 0.5374 - accuracy: 0.8375\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 11/250 [>.............................] - ETA: 1:07 - loss: 0.5294 - accuracy: 0.8352\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.5366 - accuracy: 0.8307\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.5469 - accuracy: 0.8317\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 14/250 [>.............................] - ETA: 1:06 - loss: 0.5281 - accuracy: 0.8371\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 15/250 [>.............................] - ETA: 1:06 - loss: 0.5136 - accuracy: 0.8375\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 16/250 [>.............................] - ETA: 1:05 - loss: 0.5231 - accuracy: 0.8340\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 17/250 [=>............................] - ETA: 1:05 - loss: 0.5230 - accuracy: 0.8346\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.5334 - accuracy: 0.8333\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.5369 - accuracy: 0.8355\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.5357 - accuracy: 0.8375\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 21/250 [=>............................] - ETA: 1:02 - loss: 0.5251 - accuracy: 0.8363\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.5101 - accuracy: 0.8423\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.4989 - accuracy: 0.8451\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 24/250 [=>............................] - ETA: 1:02 - loss: 0.4934 - accuracy: 0.8477\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 25/250 [==>...........................] - ETA: 1:02 - loss: 0.4786 - accuracy: 0.8512\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.4764 - accuracy: 0.8522\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 27/250 [==>...........................] - ETA: 1:01 - loss: 0.4879 - accuracy: 0.8495\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.5224 - accuracy: 0.8460\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.5266 - accuracy: 0.8438\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.5213 - accuracy: 0.8458\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 31/250 [==>...........................] - ETA: 1:00 - loss: 0.5078 - accuracy: 0.8498\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 32/250 [==>...........................] - ETA: 1:00 - loss: 0.5190 - accuracy: 0.8516\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.5112 - accuracy: 0.8532\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 34/250 [===>..........................] - ETA: 59s - loss: 0.5371 - accuracy: 0.8502 \n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 35/250 [===>..........................] - ETA: 59s - loss: 0.5297 - accuracy: 0.8518\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.5405 - accuracy: 0.8490\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 37/250 [===>..........................] - ETA: 58s - loss: 0.5454 - accuracy: 0.8480\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 38/250 [===>..........................] - ETA: 58s - loss: 0.5493 - accuracy: 0.8495\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.5467 - accuracy: 0.8502\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 40/250 [===>..........................] - ETA: 57s - loss: 0.5364 - accuracy: 0.8531\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 0.5314 - accuracy: 0.8544\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.5345 - accuracy: 0.8534\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 43/250 [====>.........................] - ETA: 56s - loss: 0.5296 - accuracy: 0.8539\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 44/250 [====>.........................] - ETA: 56s - loss: 0.5361 - accuracy: 0.8537\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 45/250 [====>.........................] - ETA: 56s - loss: 0.5362 - accuracy: 0.8528\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 46/250 [====>.........................] - ETA: 55s - loss: 0.5333 - accuracy: 0.8526\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 47/250 [====>.........................] - ETA: 55s - loss: 0.5397 - accuracy: 0.8491\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 48/250 [====>.........................] - ETA: 55s - loss: 0.5391 - accuracy: 0.8490\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 0.5407 - accuracy: 0.8482\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 50/250 [=====>........................] - ETA: 54s - loss: 0.5451 - accuracy: 0.8481\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 51/250 [=====>........................] - ETA: 54s - loss: 0.5405 - accuracy: 0.8480\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 52/250 [=====>........................] - ETA: 54s - loss: 0.5389 - accuracy: 0.8486\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 53/250 [=====>........................] - ETA: 53s - loss: 0.5393 - accuracy: 0.8479\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 54/250 [=====>........................] - ETA: 53s - loss: 0.5386 - accuracy: 0.8478\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 55/250 [=====>........................] - ETA: 53s - loss: 0.5356 - accuracy: 0.8489\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 56/250 [=====>........................] - ETA: 52s - loss: 0.5339 - accuracy: 0.8493\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 57/250 [=====>........................] - ETA: 52s - loss: 0.5363 - accuracy: 0.8498\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 58/250 [=====>........................] - ETA: 52s - loss: 0.5363 - accuracy: 0.8491\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 59/250 [======>.......................] - ETA: 51s - loss: 0.5323 - accuracy: 0.8496\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 60/250 [======>.......................] - ETA: 51s - loss: 0.5295 - accuracy: 0.8490\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 61/250 [======>.......................] - ETA: 51s - loss: 0.5295 - accuracy: 0.8489\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 62/250 [======>.......................] - ETA: 51s - loss: 0.5296 - accuracy: 0.8473\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 63/250 [======>.......................] - ETA: 50s - loss: 0.5291 - accuracy: 0.8462\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 64/250 [======>.......................] - ETA: 50s - loss: 0.5280 - accuracy: 0.8452\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 65/250 [======>.......................] - ETA: 50s - loss: 0.5256 - accuracy: 0.8447\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 66/250 [======>.......................] - ETA: 49s - loss: 0.5281 - accuracy: 0.8433\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 67/250 [=======>......................] - ETA: 49s - loss: 0.5274 - accuracy: 0.8433\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 68/250 [=======>......................] - ETA: 49s - loss: 0.5244 - accuracy: 0.8442\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 69/250 [=======>......................] - ETA: 48s - loss: 0.5217 - accuracy: 0.8451\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 70/250 [=======>......................] - ETA: 48s - loss: 0.5193 - accuracy: 0.8460\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 71/250 [=======>......................] - ETA: 48s - loss: 0.5168 - accuracy: 0.8468\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 72/250 [=======>......................] - ETA: 47s - loss: 0.5134 - accuracy: 0.8472\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 73/250 [=======>......................] - ETA: 47s - loss: 0.5127 - accuracy: 0.8476\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 74/250 [=======>......................] - ETA: 47s - loss: 0.5123 - accuracy: 0.8476\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 75/250 [========>.....................] - ETA: 47s - loss: 0.5070 - accuracy: 0.8492\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 76/250 [========>.....................] - ETA: 46s - loss: 0.5066 - accuracy: 0.8495\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 77/250 [========>.....................] - ETA: 46s - loss: 0.5045 - accuracy: 0.8506\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 78/250 [========>.....................] - ETA: 46s - loss: 0.5092 - accuracy: 0.8506\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 79/250 [========>.....................] - ETA: 45s - loss: 0.5053 - accuracy: 0.8513\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 80/250 [========>.....................] - ETA: 45s - loss: 0.5064 - accuracy: 0.8504\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 81/250 [========>.....................] - ETA: 45s - loss: 0.5075 - accuracy: 0.8511\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 82/250 [========>.....................] - ETA: 44s - loss: 0.5058 - accuracy: 0.8518\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 83/250 [========>.....................] - ETA: 44s - loss: 0.5033 - accuracy: 0.8520\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 84/250 [=========>....................] - ETA: 44s - loss: 0.4992 - accuracy: 0.8534\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 85/250 [=========>....................] - ETA: 44s - loss: 0.5020 - accuracy: 0.8518\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 86/250 [=========>....................] - ETA: 43s - loss: 0.4986 - accuracy: 0.8528\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 87/250 [=========>....................] - ETA: 43s - loss: 0.4974 - accuracy: 0.8524\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 88/250 [=========>....................] - ETA: 43s - loss: 0.4931 - accuracy: 0.8537\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 89/250 [=========>....................] - ETA: 43s - loss: 0.4913 - accuracy: 0.8539\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 90/250 [=========>....................] - ETA: 42s - loss: 0.4884 - accuracy: 0.8545\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 91/250 [=========>....................] - ETA: 42s - loss: 0.4852 - accuracy: 0.8558\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 92/250 [==========>...................] - ETA: 42s - loss: 0.4842 - accuracy: 0.8560\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 93/250 [==========>...................] - ETA: 42s - loss: 0.4840 - accuracy: 0.8562\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 94/250 [==========>...................] - ETA: 41s - loss: 0.4845 - accuracy: 0.8561\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 95/250 [==========>...................] - ETA: 41s - loss: 0.4827 - accuracy: 0.8562\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 96/250 [==========>...................] - ETA: 41s - loss: 0.4809 - accuracy: 0.8561\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 97/250 [==========>...................] - ETA: 41s - loss: 0.4807 - accuracy: 0.8557\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 98/250 [==========>...................] - ETA: 40s - loss: 0.4791 - accuracy: 0.8562\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      " 99/250 [==========>...................] - ETA: 40s - loss: 0.4764 - accuracy: 0.8567\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "100/250 [===========>..................] - ETA: 40s - loss: 0.4739 - accuracy: 0.8575\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "101/250 [===========>..................] - ETA: 39s - loss: 0.4714 - accuracy: 0.8580\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "102/250 [===========>..................] - ETA: 39s - loss: 0.4773 - accuracy: 0.8572\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "103/250 [===========>..................] - ETA: 39s - loss: 0.4785 - accuracy: 0.8577\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "104/250 [===========>..................] - ETA: 39s - loss: 0.4787 - accuracy: 0.8576\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "105/250 [===========>..................] - ETA: 38s - loss: 0.4793 - accuracy: 0.8571\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "106/250 [===========>..................] - ETA: 38s - loss: 0.4780 - accuracy: 0.8576\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "107/250 [===========>..................] - ETA: 38s - loss: 0.4791 - accuracy: 0.8575\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "108/250 [===========>..................] - ETA: 38s - loss: 0.4793 - accuracy: 0.8573\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "109/250 [============>.................] - ETA: 37s - loss: 0.4773 - accuracy: 0.8578\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "110/250 [============>.................] - ETA: 37s - loss: 0.4764 - accuracy: 0.8571\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "111/250 [============>.................] - ETA: 37s - loss: 0.4739 - accuracy: 0.8581\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "112/250 [============>.................] - ETA: 36s - loss: 0.4735 - accuracy: 0.8577\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "113/250 [============>.................] - ETA: 36s - loss: 0.4734 - accuracy: 0.8581\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "114/250 [============>.................] - ETA: 36s - loss: 0.4717 - accuracy: 0.8591\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "115/250 [============>.................] - ETA: 36s - loss: 0.4711 - accuracy: 0.8595\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "116/250 [============>.................] - ETA: 35s - loss: 0.4694 - accuracy: 0.8602\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "117/250 [=============>................] - ETA: 35s - loss: 0.4669 - accuracy: 0.8608\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "118/250 [=============>................] - ETA: 35s - loss: 0.4673 - accuracy: 0.8610\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "119/250 [=============>................] - ETA: 34s - loss: 0.4662 - accuracy: 0.8613\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "120/250 [=============>................] - ETA: 34s - loss: 0.4654 - accuracy: 0.8620\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "121/250 [=============>................] - ETA: 34s - loss: 0.4647 - accuracy: 0.8621\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "122/250 [=============>................] - ETA: 34s - loss: 0.4643 - accuracy: 0.8617\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "123/250 [=============>................] - ETA: 33s - loss: 0.4631 - accuracy: 0.8615\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "124/250 [=============>................] - ETA: 33s - loss: 0.4651 - accuracy: 0.8606\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "125/250 [==============>...............] - ETA: 33s - loss: 0.4659 - accuracy: 0.8608\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "126/250 [==============>...............] - ETA: 33s - loss: 0.4639 - accuracy: 0.8614\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "127/250 [==============>...............] - ETA: 32s - loss: 0.4626 - accuracy: 0.8617\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "128/250 [==============>...............] - ETA: 32s - loss: 0.4618 - accuracy: 0.8613\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "129/250 [==============>...............] - ETA: 32s - loss: 0.4590 - accuracy: 0.8622\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "130/250 [==============>...............] - ETA: 31s - loss: 0.4586 - accuracy: 0.8623\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "131/250 [==============>...............] - ETA: 31s - loss: 0.4565 - accuracy: 0.8631\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "132/250 [==============>...............] - ETA: 31s - loss: 0.4579 - accuracy: 0.8627\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "133/250 [==============>...............] - ETA: 31s - loss: 0.4559 - accuracy: 0.8633\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "134/250 [===============>..............] - ETA: 30s - loss: 0.4552 - accuracy: 0.8629\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "135/250 [===============>..............] - ETA: 30s - loss: 0.4552 - accuracy: 0.8632\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "136/250 [===============>..............] - ETA: 30s - loss: 0.4523 - accuracy: 0.8642\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "137/250 [===============>..............] - ETA: 30s - loss: 0.4509 - accuracy: 0.8645\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "138/250 [===============>..............] - ETA: 29s - loss: 0.4502 - accuracy: 0.8644\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "139/250 [===============>..............] - ETA: 29s - loss: 0.4507 - accuracy: 0.8640\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "140/250 [===============>..............] - ETA: 29s - loss: 0.4510 - accuracy: 0.8643\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "141/250 [===============>..............] - ETA: 28s - loss: 0.4520 - accuracy: 0.8637\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "142/250 [================>.............] - ETA: 28s - loss: 0.4527 - accuracy: 0.8638\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "143/250 [================>.............] - ETA: 28s - loss: 0.4532 - accuracy: 0.8639\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "144/250 [================>.............] - ETA: 28s - loss: 0.4554 - accuracy: 0.8639\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "145/250 [================>.............] - ETA: 27s - loss: 0.4538 - accuracy: 0.8640\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "146/250 [================>.............] - ETA: 27s - loss: 0.4548 - accuracy: 0.8641\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "147/250 [================>.............] - ETA: 27s - loss: 0.4562 - accuracy: 0.8637\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "148/250 [================>.............] - ETA: 27s - loss: 0.4552 - accuracy: 0.8642\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "149/250 [================>.............] - ETA: 26s - loss: 0.4556 - accuracy: 0.8643\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "150/250 [=================>............] - ETA: 26s - loss: 0.4562 - accuracy: 0.8646\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "151/250 [=================>............] - ETA: 26s - loss: 0.4562 - accuracy: 0.8644\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "152/250 [=================>............] - ETA: 26s - loss: 0.4550 - accuracy: 0.8645\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "153/250 [=================>............] - ETA: 25s - loss: 0.4538 - accuracy: 0.8648\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "154/250 [=================>............] - ETA: 25s - loss: 0.4545 - accuracy: 0.8644\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "155/250 [=================>............] - ETA: 25s - loss: 0.4543 - accuracy: 0.8646\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "156/250 [=================>............] - ETA: 24s - loss: 0.4532 - accuracy: 0.8646\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "157/250 [=================>............] - ETA: 24s - loss: 0.4538 - accuracy: 0.8647\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "158/250 [=================>............] - ETA: 24s - loss: 0.4549 - accuracy: 0.8650\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "159/250 [==================>...........] - ETA: 24s - loss: 0.4545 - accuracy: 0.8648\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "160/250 [==================>...........] - ETA: 23s - loss: 0.4545 - accuracy: 0.8645\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "161/250 [==================>...........] - ETA: 23s - loss: 0.4542 - accuracy: 0.8642\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "162/250 [==================>...........] - ETA: 23s - loss: 0.4569 - accuracy: 0.8637\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "163/250 [==================>...........] - ETA: 23s - loss: 0.4575 - accuracy: 0.8637\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "164/250 [==================>...........] - ETA: 22s - loss: 0.4605 - accuracy: 0.8630\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "165/250 [==================>...........] - ETA: 22s - loss: 0.4593 - accuracy: 0.8637\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "166/250 [==================>...........] - ETA: 22s - loss: 0.4571 - accuracy: 0.8645\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "167/250 [===================>..........] - ETA: 21s - loss: 0.4554 - accuracy: 0.8648\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "168/250 [===================>..........] - ETA: 21s - loss: 0.4563 - accuracy: 0.8648\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "169/250 [===================>..........] - ETA: 21s - loss: 0.4545 - accuracy: 0.8654\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "170/250 [===================>..........] - ETA: 21s - loss: 0.4546 - accuracy: 0.8651\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "171/250 [===================>..........] - ETA: 20s - loss: 0.4546 - accuracy: 0.8654\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "172/250 [===================>..........] - ETA: 20s - loss: 0.4546 - accuracy: 0.8654\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "173/250 [===================>..........] - ETA: 20s - loss: 0.4535 - accuracy: 0.8657\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "174/250 [===================>..........] - ETA: 20s - loss: 0.4542 - accuracy: 0.8661\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "175/250 [====================>.........] - ETA: 19s - loss: 0.4555 - accuracy: 0.8661\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "176/250 [====================>.........] - ETA: 19s - loss: 0.4549 - accuracy: 0.8660\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "177/250 [====================>.........] - ETA: 19s - loss: 0.4551 - accuracy: 0.8661\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "178/250 [====================>.........] - ETA: 19s - loss: 0.4554 - accuracy: 0.8659\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "179/250 [====================>.........] - ETA: 18s - loss: 0.4566 - accuracy: 0.8656\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "180/250 [====================>.........] - ETA: 18s - loss: 0.4566 - accuracy: 0.8653\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "181/250 [====================>.........] - ETA: 18s - loss: 0.4569 - accuracy: 0.8647\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "182/250 [====================>.........] - ETA: 17s - loss: 0.4559 - accuracy: 0.8647\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "183/250 [====================>.........] - ETA: 17s - loss: 0.4547 - accuracy: 0.8650\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "184/250 [=====================>........] - ETA: 17s - loss: 0.4547 - accuracy: 0.8650\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "185/250 [=====================>........] - ETA: 17s - loss: 0.4531 - accuracy: 0.8654\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "186/250 [=====================>........] - ETA: 16s - loss: 0.4525 - accuracy: 0.8653\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "187/250 [=====================>........] - ETA: 16s - loss: 0.4509 - accuracy: 0.8659\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "188/250 [=====================>........] - ETA: 16s - loss: 0.4500 - accuracy: 0.8661\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "189/250 [=====================>........] - ETA: 16s - loss: 0.4491 - accuracy: 0.8663\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "190/250 [=====================>........] - ETA: 15s - loss: 0.4496 - accuracy: 0.8663\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "191/250 [=====================>........] - ETA: 15s - loss: 0.4490 - accuracy: 0.8669\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "192/250 [======================>.......] - ETA: 15s - loss: 0.4481 - accuracy: 0.8672\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.4475 - accuracy: 0.8674\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "194/250 [======================>.......] - ETA: 14s - loss: 0.4473 - accuracy: 0.8673\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "195/250 [======================>.......] - ETA: 14s - loss: 0.4503 - accuracy: 0.8670\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "196/250 [======================>.......] - ETA: 14s - loss: 0.4493 - accuracy: 0.8672\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.4476 - accuracy: 0.8678\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "198/250 [======================>.......] - ETA: 13s - loss: 0.4489 - accuracy: 0.8678\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "199/250 [======================>.......] - ETA: 13s - loss: 0.4480 - accuracy: 0.8678\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.4468 - accuracy: 0.8680\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "201/250 [=======================>......] - ETA: 12s - loss: 0.4466 - accuracy: 0.8682\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "202/250 [=======================>......] - ETA: 12s - loss: 0.4465 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "203/250 [=======================>......] - ETA: 12s - loss: 0.4461 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.4444 - accuracy: 0.8686\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "205/250 [=======================>......] - ETA: 11s - loss: 0.4436 - accuracy: 0.8690\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "206/250 [=======================>......] - ETA: 11s - loss: 0.4424 - accuracy: 0.8693\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 0.4426 - accuracy: 0.8693\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.4432 - accuracy: 0.8690\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "209/250 [========================>.....] - ETA: 10s - loss: 0.4440 - accuracy: 0.8689\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "210/250 [========================>.....] - ETA: 10s - loss: 0.4431 - accuracy: 0.8691\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.4426 - accuracy: 0.8690\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.4423 - accuracy: 0.8687\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "213/250 [========================>.....] - ETA: 9s - loss: 0.4433 - accuracy: 0.8685 \n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "214/250 [========================>.....] - ETA: 9s - loss: 0.4428 - accuracy: 0.8682\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.4432 - accuracy: 0.8679\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.4424 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "217/250 [=========================>....] - ETA: 8s - loss: 0.4426 - accuracy: 0.8680\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.4413 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.4404 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "220/250 [=========================>....] - ETA: 7s - loss: 0.4427 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "221/250 [=========================>....] - ETA: 7s - loss: 0.4417 - accuracy: 0.8683\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.4408 - accuracy: 0.8686\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.4403 - accuracy: 0.8686\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "224/250 [=========================>....] - ETA: 6s - loss: 0.4410 - accuracy: 0.8682\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.4398 - accuracy: 0.8687\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.4407 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.4413 - accuracy: 0.8678\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "228/250 [==========================>...] - ETA: 5s - loss: 0.4425 - accuracy: 0.8676\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.4408 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.4412 - accuracy: 0.8678\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.4414 - accuracy: 0.8676\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "232/250 [==========================>...] - ETA: 4s - loss: 0.4403 - accuracy: 0.8679\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.4408 - accuracy: 0.8677\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.4415 - accuracy: 0.8676\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "235/250 [===========================>..] - ETA: 3s - loss: 0.4403 - accuracy: 0.8679\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.4394 - accuracy: 0.8680\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.4379 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.4381 - accuracy: 0.8684\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "239/250 [===========================>..] - ETA: 2s - loss: 0.4378 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.4375 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.4380 - accuracy: 0.8682\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.4373 - accuracy: 0.8683\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.4394 - accuracy: 0.8680\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.4379 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.4372 - accuracy: 0.8687\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4367 - accuracy: 0.8688\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.8682\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4391 - accuracy: 0.8681\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.8685\n",
      "Epoch 8: accuracy did not improve from 0.89583\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 0.4380 - accuracy: 0.8683 - val_loss: 0.2225 - val_accuracy: 0.9299\n",
      "Epoch 9/15\n",
      "\n",
      "Epoch 9: accuracy improved from 0.89583 to 0.90625, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 3:20 - loss: 0.3113 - accuracy: 0.9062\n",
      "Epoch 9: accuracy improved from 0.90625 to 0.92188, saving model to output\\inceptionV3.h5\n",
      "  2/250 [..............................] - ETA: 2:12 - loss: 0.2654 - accuracy: 0.9219\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  3/250 [..............................] - ETA: 1:17 - loss: 0.3729 - accuracy: 0.8542\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  4/250 [..............................] - ETA: 1:16 - loss: 0.4111 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  5/250 [..............................] - ETA: 1:12 - loss: 0.3698 - accuracy: 0.8750\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  6/250 [..............................] - ETA: 1:10 - loss: 0.3623 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.3432 - accuracy: 0.8795\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  8/250 [..............................] - ETA: 1:07 - loss: 0.3231 - accuracy: 0.8828\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "  9/250 [>.............................] - ETA: 1:06 - loss: 0.3188 - accuracy: 0.8819\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.3621 - accuracy: 0.8719\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 11/250 [>.............................] - ETA: 1:06 - loss: 0.3443 - accuracy: 0.8778\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 12/250 [>.............................] - ETA: 1:06 - loss: 0.3645 - accuracy: 0.8750\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 13/250 [>.............................] - ETA: 1:06 - loss: 0.3929 - accuracy: 0.8726\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.3925 - accuracy: 0.8705\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 15/250 [>.............................] - ETA: 1:05 - loss: 0.3804 - accuracy: 0.8708\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 16/250 [>.............................] - ETA: 1:05 - loss: 0.3768 - accuracy: 0.8730\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.3677 - accuracy: 0.8750\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.3869 - accuracy: 0.8681\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.3740 - accuracy: 0.8734\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.3809 - accuracy: 0.8687\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.3968 - accuracy: 0.8646\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 23/250 [=>............................] - ETA: 1:03 - loss: 0.4062 - accuracy: 0.8655\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.4173 - accuracy: 0.8646\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.4192 - accuracy: 0.8687\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 26/250 [==>...........................] - ETA: 1:02 - loss: 0.4301 - accuracy: 0.8654\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.4307 - accuracy: 0.8657\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 28/250 [==>...........................] - ETA: 1:02 - loss: 0.4385 - accuracy: 0.8638\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.4360 - accuracy: 0.8642\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.4522 - accuracy: 0.8625\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.4475 - accuracy: 0.8619\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 32/250 [==>...........................] - ETA: 1:01 - loss: 0.4441 - accuracy: 0.8623\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 33/250 [==>...........................] - ETA: 1:00 - loss: 0.4406 - accuracy: 0.8636\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 34/250 [===>..........................] - ETA: 1:00 - loss: 0.4544 - accuracy: 0.8603\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.4466 - accuracy: 0.8625\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 36/250 [===>..........................] - ETA: 59s - loss: 0.4441 - accuracy: 0.8611 \n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.4379 - accuracy: 0.8623\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.4476 - accuracy: 0.8618\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 39/250 [===>..........................] - ETA: 58s - loss: 0.4399 - accuracy: 0.8638\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 40/250 [===>..........................] - ETA: 58s - loss: 0.4356 - accuracy: 0.8648\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 41/250 [===>..........................] - ETA: 57s - loss: 0.4340 - accuracy: 0.8643\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 42/250 [====>.........................] - ETA: 57s - loss: 0.4403 - accuracy: 0.8616\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 43/250 [====>.........................] - ETA: 57s - loss: 0.4396 - accuracy: 0.8612\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 44/250 [====>.........................] - ETA: 56s - loss: 0.4351 - accuracy: 0.8622\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 45/250 [====>.........................] - ETA: 56s - loss: 0.4316 - accuracy: 0.8639\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 46/250 [====>.........................] - ETA: 56s - loss: 0.4323 - accuracy: 0.8641\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 47/250 [====>.........................] - ETA: 55s - loss: 0.4374 - accuracy: 0.8630\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 48/250 [====>.........................] - ETA: 55s - loss: 0.4411 - accuracy: 0.8607\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 49/250 [====>.........................] - ETA: 55s - loss: 0.4362 - accuracy: 0.8622\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 50/250 [=====>........................] - ETA: 55s - loss: 0.4404 - accuracy: 0.8619\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 51/250 [=====>........................] - ETA: 54s - loss: 0.4379 - accuracy: 0.8621\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 52/250 [=====>........................] - ETA: 54s - loss: 0.4376 - accuracy: 0.8618\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 53/250 [=====>........................] - ETA: 54s - loss: 0.4368 - accuracy: 0.8620\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 54/250 [=====>........................] - ETA: 53s - loss: 0.4348 - accuracy: 0.8628\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 55/250 [=====>........................] - ETA: 53s - loss: 0.4316 - accuracy: 0.8642\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 56/250 [=====>........................] - ETA: 53s - loss: 0.4286 - accuracy: 0.8650\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 57/250 [=====>........................] - ETA: 52s - loss: 0.4263 - accuracy: 0.8657\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 58/250 [=====>........................] - ETA: 52s - loss: 0.4294 - accuracy: 0.8664\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 59/250 [======>.......................] - ETA: 52s - loss: 0.4315 - accuracy: 0.8660\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 60/250 [======>.......................] - ETA: 52s - loss: 0.4309 - accuracy: 0.8661\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 61/250 [======>.......................] - ETA: 51s - loss: 0.4317 - accuracy: 0.8653\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 62/250 [======>.......................] - ETA: 51s - loss: 0.4293 - accuracy: 0.8659\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 63/250 [======>.......................] - ETA: 51s - loss: 0.4311 - accuracy: 0.8661\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 64/250 [======>.......................] - ETA: 50s - loss: 0.4314 - accuracy: 0.8662\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 65/250 [======>.......................] - ETA: 50s - loss: 0.4339 - accuracy: 0.8659\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 66/250 [======>.......................] - ETA: 50s - loss: 0.4394 - accuracy: 0.8660\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 67/250 [=======>......................] - ETA: 50s - loss: 0.4355 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 68/250 [=======>......................] - ETA: 49s - loss: 0.4331 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 69/250 [=======>......................] - ETA: 49s - loss: 0.4293 - accuracy: 0.8687\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 70/250 [=======>......................] - ETA: 49s - loss: 0.4291 - accuracy: 0.8674\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 71/250 [=======>......................] - ETA: 48s - loss: 0.4288 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 72/250 [=======>......................] - ETA: 48s - loss: 0.4267 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 73/250 [=======>......................] - ETA: 48s - loss: 0.4271 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 74/250 [=======>......................] - ETA: 47s - loss: 0.4265 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 75/250 [========>.....................] - ETA: 47s - loss: 0.4273 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 76/250 [========>.....................] - ETA: 47s - loss: 0.4253 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 77/250 [========>.....................] - ETA: 47s - loss: 0.4296 - accuracy: 0.8673\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 78/250 [========>.....................] - ETA: 46s - loss: 0.4332 - accuracy: 0.8662\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 79/250 [========>.....................] - ETA: 46s - loss: 0.4392 - accuracy: 0.8651\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 80/250 [========>.....................] - ETA: 46s - loss: 0.4374 - accuracy: 0.8648\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 81/250 [========>.....................] - ETA: 45s - loss: 0.4337 - accuracy: 0.8657\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 82/250 [========>.....................] - ETA: 45s - loss: 0.4312 - accuracy: 0.8659\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 83/250 [========>.....................] - ETA: 45s - loss: 0.4286 - accuracy: 0.8667\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 84/250 [=========>....................] - ETA: 45s - loss: 0.4304 - accuracy: 0.8664\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 85/250 [=========>....................] - ETA: 44s - loss: 0.4351 - accuracy: 0.8665\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 86/250 [=========>....................] - ETA: 44s - loss: 0.4341 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 87/250 [=========>....................] - ETA: 44s - loss: 0.4303 - accuracy: 0.8687\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 88/250 [=========>....................] - ETA: 43s - loss: 0.4282 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 89/250 [=========>....................] - ETA: 43s - loss: 0.4294 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 90/250 [=========>....................] - ETA: 43s - loss: 0.4354 - accuracy: 0.8685\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 91/250 [=========>....................] - ETA: 43s - loss: 0.4328 - accuracy: 0.8696\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 92/250 [==========>...................] - ETA: 42s - loss: 0.4305 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 93/250 [==========>...................] - ETA: 42s - loss: 0.4302 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 94/250 [==========>...................] - ETA: 42s - loss: 0.4268 - accuracy: 0.8712\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 95/250 [==========>...................] - ETA: 42s - loss: 0.4291 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 96/250 [==========>...................] - ETA: 41s - loss: 0.4277 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 97/250 [==========>...................] - ETA: 41s - loss: 0.4257 - accuracy: 0.8706\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 98/250 [==========>...................] - ETA: 41s - loss: 0.4265 - accuracy: 0.8703\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      " 99/250 [==========>...................] - ETA: 41s - loss: 0.4252 - accuracy: 0.8704\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "100/250 [===========>..................] - ETA: 40s - loss: 0.4233 - accuracy: 0.8708\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "101/250 [===========>..................] - ETA: 40s - loss: 0.4206 - accuracy: 0.8717\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "102/250 [===========>..................] - ETA: 40s - loss: 0.4209 - accuracy: 0.8718\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "103/250 [===========>..................] - ETA: 39s - loss: 0.4201 - accuracy: 0.8718\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "104/250 [===========>..................] - ETA: 39s - loss: 0.4242 - accuracy: 0.8709\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "105/250 [===========>..................] - ETA: 39s - loss: 0.4240 - accuracy: 0.8704\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "106/250 [===========>..................] - ETA: 39s - loss: 0.4217 - accuracy: 0.8710\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "107/250 [===========>..................] - ETA: 38s - loss: 0.4211 - accuracy: 0.8710\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "108/250 [===========>..................] - ETA: 38s - loss: 0.4211 - accuracy: 0.8708\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "109/250 [============>.................] - ETA: 38s - loss: 0.4238 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "110/250 [============>.................] - ETA: 37s - loss: 0.4268 - accuracy: 0.8697\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "111/250 [============>.................] - ETA: 37s - loss: 0.4273 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "112/250 [============>.................] - ETA: 37s - loss: 0.4263 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "113/250 [============>.................] - ETA: 37s - loss: 0.4299 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "114/250 [============>.................] - ETA: 36s - loss: 0.4281 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "115/250 [============>.................] - ETA: 36s - loss: 0.4280 - accuracy: 0.8705\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "116/250 [============>.................] - ETA: 36s - loss: 0.4274 - accuracy: 0.8705\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "117/250 [=============>................] - ETA: 35s - loss: 0.4292 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "118/250 [=============>................] - ETA: 35s - loss: 0.4281 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "119/250 [=============>................] - ETA: 35s - loss: 0.4274 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "120/250 [=============>................] - ETA: 35s - loss: 0.4273 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "121/250 [=============>................] - ETA: 34s - loss: 0.4286 - accuracy: 0.8694\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "122/250 [=============>................] - ETA: 34s - loss: 0.4273 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "123/250 [=============>................] - ETA: 34s - loss: 0.4285 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "124/250 [=============>................] - ETA: 34s - loss: 0.4262 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "125/250 [==============>...............] - ETA: 33s - loss: 0.4262 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "126/250 [==============>...............] - ETA: 33s - loss: 0.4290 - accuracy: 0.8689\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "127/250 [==============>...............] - ETA: 33s - loss: 0.4269 - accuracy: 0.8692\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "128/250 [==============>...............] - ETA: 33s - loss: 0.4279 - accuracy: 0.8690\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "129/250 [==============>...............] - ETA: 32s - loss: 0.4269 - accuracy: 0.8693\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "130/250 [==============>...............] - ETA: 32s - loss: 0.4267 - accuracy: 0.8691\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "131/250 [==============>...............] - ETA: 32s - loss: 0.4297 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "132/250 [==============>...............] - ETA: 31s - loss: 0.4299 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "133/250 [==============>...............] - ETA: 31s - loss: 0.4272 - accuracy: 0.8687\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "134/250 [===============>..............] - ETA: 31s - loss: 0.4252 - accuracy: 0.8690\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "135/250 [===============>..............] - ETA: 31s - loss: 0.4256 - accuracy: 0.8691\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "136/250 [===============>..............] - ETA: 30s - loss: 0.4274 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "137/250 [===============>..............] - ETA: 30s - loss: 0.4276 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "138/250 [===============>..............] - ETA: 30s - loss: 0.4263 - accuracy: 0.8683\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "139/250 [===============>..............] - ETA: 29s - loss: 0.4292 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "140/250 [===============>..............] - ETA: 29s - loss: 0.4289 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "141/250 [===============>..............] - ETA: 29s - loss: 0.4288 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "142/250 [================>.............] - ETA: 29s - loss: 0.4273 - accuracy: 0.8685\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "143/250 [================>.............] - ETA: 28s - loss: 0.4252 - accuracy: 0.8692\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "144/250 [================>.............] - ETA: 28s - loss: 0.4278 - accuracy: 0.8694\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "145/250 [================>.............] - ETA: 28s - loss: 0.4268 - accuracy: 0.8697\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "146/250 [================>.............] - ETA: 28s - loss: 0.4254 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "147/250 [================>.............] - ETA: 27s - loss: 0.4253 - accuracy: 0.8693\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "148/250 [================>.............] - ETA: 27s - loss: 0.4257 - accuracy: 0.8685\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "149/250 [================>.............] - ETA: 27s - loss: 0.4267 - accuracy: 0.8684\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "150/250 [=================>............] - ETA: 27s - loss: 0.4264 - accuracy: 0.8686\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "151/250 [=================>............] - ETA: 26s - loss: 0.4254 - accuracy: 0.8689\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "152/250 [=================>............] - ETA: 26s - loss: 0.4250 - accuracy: 0.8689\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "153/250 [=================>............] - ETA: 26s - loss: 0.4256 - accuracy: 0.8685\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "154/250 [=================>............] - ETA: 25s - loss: 0.4260 - accuracy: 0.8686\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "155/250 [=================>............] - ETA: 25s - loss: 0.4286 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "156/250 [=================>............] - ETA: 25s - loss: 0.4271 - accuracy: 0.8685\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "157/250 [=================>............] - ETA: 25s - loss: 0.4300 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "158/250 [=================>............] - ETA: 24s - loss: 0.4286 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "159/250 [==================>...........] - ETA: 24s - loss: 0.4276 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "160/250 [==================>...........] - ETA: 24s - loss: 0.4281 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "161/250 [==================>...........] - ETA: 24s - loss: 0.4283 - accuracy: 0.8679\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "162/250 [==================>...........] - ETA: 23s - loss: 0.4289 - accuracy: 0.8679\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "163/250 [==================>...........] - ETA: 23s - loss: 0.4294 - accuracy: 0.8674\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "164/250 [==================>...........] - ETA: 23s - loss: 0.4282 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "165/250 [==================>...........] - ETA: 22s - loss: 0.4283 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "166/250 [==================>...........] - ETA: 22s - loss: 0.4270 - accuracy: 0.8681\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "167/250 [===================>..........] - ETA: 22s - loss: 0.4289 - accuracy: 0.8670\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "168/250 [===================>..........] - ETA: 22s - loss: 0.4271 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "169/250 [===================>..........] - ETA: 21s - loss: 0.4278 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "170/250 [===================>..........] - ETA: 21s - loss: 0.4276 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "171/250 [===================>..........] - ETA: 21s - loss: 0.4266 - accuracy: 0.8674\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "172/250 [===================>..........] - ETA: 21s - loss: 0.4259 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "173/250 [===================>..........] - ETA: 20s - loss: 0.4240 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "174/250 [===================>..........] - ETA: 20s - loss: 0.4241 - accuracy: 0.8682\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "175/250 [====================>.........] - ETA: 20s - loss: 0.4270 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "176/250 [====================>.........] - ETA: 19s - loss: 0.4280 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "177/250 [====================>.........] - ETA: 19s - loss: 0.4280 - accuracy: 0.8669\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "178/250 [====================>.........] - ETA: 19s - loss: 0.4277 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "179/250 [====================>.........] - ETA: 19s - loss: 0.4276 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "180/250 [====================>.........] - ETA: 18s - loss: 0.4263 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "181/250 [====================>.........] - ETA: 18s - loss: 0.4270 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "182/250 [====================>.........] - ETA: 18s - loss: 0.4268 - accuracy: 0.8673\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "183/250 [====================>.........] - ETA: 18s - loss: 0.4270 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "184/250 [=====================>........] - ETA: 17s - loss: 0.4269 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "185/250 [=====================>........] - ETA: 17s - loss: 0.4335 - accuracy: 0.8669\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "186/250 [=====================>........] - ETA: 17s - loss: 0.4319 - accuracy: 0.8675\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.4303 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "188/250 [=====================>........] - ETA: 16s - loss: 0.4301 - accuracy: 0.8679\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "189/250 [=====================>........] - ETA: 16s - loss: 0.4307 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "190/250 [=====================>........] - ETA: 16s - loss: 0.4313 - accuracy: 0.8675\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "191/250 [=====================>........] - ETA: 15s - loss: 0.4308 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "192/250 [======================>.......] - ETA: 15s - loss: 0.4293 - accuracy: 0.8681\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "193/250 [======================>.......] - ETA: 15s - loss: 0.4308 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "194/250 [======================>.......] - ETA: 15s - loss: 0.4305 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "195/250 [======================>.......] - ETA: 14s - loss: 0.4304 - accuracy: 0.8680\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "196/250 [======================>.......] - ETA: 14s - loss: 0.4316 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "197/250 [======================>.......] - ETA: 14s - loss: 0.4313 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.4320 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.4337 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "200/250 [=======================>......] - ETA: 13s - loss: 0.4329 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "201/250 [=======================>......] - ETA: 13s - loss: 0.4321 - accuracy: 0.8671\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.4322 - accuracy: 0.8669\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "203/250 [=======================>......] - ETA: 12s - loss: 0.4316 - accuracy: 0.8672\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "204/250 [=======================>......] - ETA: 12s - loss: 0.4308 - accuracy: 0.8675\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.4303 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.4297 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "207/250 [=======================>......] - ETA: 11s - loss: 0.4290 - accuracy: 0.8678\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "208/250 [=======================>......] - ETA: 11s - loss: 0.4298 - accuracy: 0.8677\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.4301 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "210/250 [========================>.....] - ETA: 10s - loss: 0.4296 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "211/250 [========================>.....] - ETA: 10s - loss: 0.4294 - accuracy: 0.8676\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.4286 - accuracy: 0.8681\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.4283 - accuracy: 0.8683\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "214/250 [========================>.....] - ETA: 9s - loss: 0.4272 - accuracy: 0.8686 \n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "215/250 [========================>.....] - ETA: 9s - loss: 0.4271 - accuracy: 0.8688\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.4264 - accuracy: 0.8688\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.4263 - accuracy: 0.8690\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "218/250 [=========================>....] - ETA: 8s - loss: 0.4254 - accuracy: 0.8692\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.4266 - accuracy: 0.8689\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.4254 - accuracy: 0.8694\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "221/250 [=========================>....] - ETA: 7s - loss: 0.4245 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "222/250 [=========================>....] - ETA: 7s - loss: 0.4230 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.4229 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.4220 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "225/250 [==========================>...] - ETA: 6s - loss: 0.4217 - accuracy: 0.8705\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.4221 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.4222 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.4229 - accuracy: 0.8696\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "229/250 [==========================>...] - ETA: 5s - loss: 0.4234 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.4221 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.4217 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "232/250 [==========================>...] - ETA: 4s - loss: 0.4223 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.4224 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.4223 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.4223 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "236/250 [===========================>..] - ETA: 3s - loss: 0.4224 - accuracy: 0.8696\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.4216 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.4230 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.4228 - accuracy: 0.8698\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.4215 - accuracy: 0.8701\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.4208 - accuracy: 0.8704\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.4204 - accuracy: 0.8707\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "243/250 [============================>.] - ETA: 1s - loss: 0.4201 - accuracy: 0.8706\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.4195 - accuracy: 0.8704\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.4204 - accuracy: 0.8702\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4219 - accuracy: 0.8700\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.4221 - accuracy: 0.8699\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8695\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4225 - accuracy: 0.8693\n",
      "Epoch 9: accuracy did not improve from 0.92188\n",
      "250/250 [==============================] - 86s 341ms/step - loss: 0.4215 - accuracy: 0.8695 - val_loss: 0.1948 - val_accuracy: 0.9415\n",
      "Epoch 10/15\n",
      "\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  1/250 [..............................] - ETA: 1:25 - loss: 0.3482 - accuracy: 0.8438\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.4438 - accuracy: 0.8438\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  3/250 [..............................] - ETA: 1:08 - loss: 0.3455 - accuracy: 0.8750\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  4/250 [..............................] - ETA: 1:06 - loss: 0.3792 - accuracy: 0.8594\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  5/250 [..............................] - ETA: 1:06 - loss: 0.3830 - accuracy: 0.8562\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  6/250 [..............................] - ETA: 1:08 - loss: 0.3678 - accuracy: 0.8698\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  7/250 [..............................] - ETA: 1:08 - loss: 0.4038 - accuracy: 0.8705\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  8/250 [..............................] - ETA: 1:08 - loss: 0.4570 - accuracy: 0.8672\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "  9/250 [>.............................] - ETA: 1:07 - loss: 0.4597 - accuracy: 0.8646\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 10/250 [>.............................] - ETA: 1:06 - loss: 0.4730 - accuracy: 0.8625\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 11/250 [>.............................] - ETA: 1:05 - loss: 0.4610 - accuracy: 0.8693\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 12/250 [>.............................] - ETA: 1:05 - loss: 0.4664 - accuracy: 0.8672\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 13/250 [>.............................] - ETA: 1:05 - loss: 0.4836 - accuracy: 0.8702\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.4849 - accuracy: 0.8705\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 15/250 [>.............................] - ETA: 1:04 - loss: 0.4943 - accuracy: 0.8667\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 0.5024 - accuracy: 0.8613\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.4923 - accuracy: 0.8621\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.4835 - accuracy: 0.8611\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 19/250 [=>............................] - ETA: 1:03 - loss: 0.4850 - accuracy: 0.8618\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 20/250 [=>............................] - ETA: 1:03 - loss: 0.5020 - accuracy: 0.8578\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 21/250 [=>............................] - ETA: 1:02 - loss: 0.4866 - accuracy: 0.8616\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 22/250 [=>............................] - ETA: 1:02 - loss: 0.4790 - accuracy: 0.8622\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 23/250 [=>............................] - ETA: 1:02 - loss: 0.4680 - accuracy: 0.8641\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 24/250 [=>............................] - ETA: 1:01 - loss: 0.4625 - accuracy: 0.8646\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 25/250 [==>...........................] - ETA: 1:01 - loss: 0.4514 - accuracy: 0.8675\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 26/250 [==>...........................] - ETA: 1:01 - loss: 0.4518 - accuracy: 0.8666\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 27/250 [==>...........................] - ETA: 1:00 - loss: 0.4501 - accuracy: 0.8657\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 28/250 [==>...........................] - ETA: 1:01 - loss: 0.4594 - accuracy: 0.8650\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 29/250 [==>...........................] - ETA: 1:01 - loss: 0.4515 - accuracy: 0.8664\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 30/250 [==>...........................] - ETA: 1:01 - loss: 0.4446 - accuracy: 0.8667\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.4429 - accuracy: 0.8669\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 32/250 [==>...........................] - ETA: 1:01 - loss: 0.4396 - accuracy: 0.8672\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.4375 - accuracy: 0.8665\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.4445 - accuracy: 0.8649\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.4502 - accuracy: 0.8625\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.4546 - accuracy: 0.8628\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.4462 - accuracy: 0.8666\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.4498 - accuracy: 0.8643\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.4516 - accuracy: 0.8638\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 40/250 [===>..........................] - ETA: 1:00 - loss: 0.4468 - accuracy: 0.8664\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 41/250 [===>..........................] - ETA: 59s - loss: 0.4488 - accuracy: 0.8651 \n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.4410 - accuracy: 0.8676\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.4394 - accuracy: 0.8685\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.4399 - accuracy: 0.8672\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.4492 - accuracy: 0.8639\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.4516 - accuracy: 0.8635\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.4487 - accuracy: 0.8637\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.4469 - accuracy: 0.8639\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.4480 - accuracy: 0.8642\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.4472 - accuracy: 0.8644\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.4426 - accuracy: 0.8652\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 52/250 [=====>........................] - ETA: 56s - loss: 0.4425 - accuracy: 0.8648\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 53/250 [=====>........................] - ETA: 56s - loss: 0.4406 - accuracy: 0.8650\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.4343 - accuracy: 0.8675\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.4342 - accuracy: 0.8676\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 56/250 [=====>........................] - ETA: 55s - loss: 0.4338 - accuracy: 0.8677\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 57/250 [=====>........................] - ETA: 55s - loss: 0.4328 - accuracy: 0.8684\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.4308 - accuracy: 0.8685\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.4295 - accuracy: 0.8702\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 60/250 [======>.......................] - ETA: 54s - loss: 0.4317 - accuracy: 0.8687\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 61/250 [======>.......................] - ETA: 54s - loss: 0.4312 - accuracy: 0.8683\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.4308 - accuracy: 0.8690\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 63/250 [======>.......................] - ETA: 53s - loss: 0.4266 - accuracy: 0.8700\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.4271 - accuracy: 0.8682\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.4261 - accuracy: 0.8683\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 66/250 [======>.......................] - ETA: 52s - loss: 0.4259 - accuracy: 0.8665\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 67/250 [=======>......................] - ETA: 52s - loss: 0.4224 - accuracy: 0.8675\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.4188 - accuracy: 0.8686\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 69/250 [=======>......................] - ETA: 51s - loss: 0.4146 - accuracy: 0.8705\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 70/250 [=======>......................] - ETA: 51s - loss: 0.4109 - accuracy: 0.8710\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.4116 - accuracy: 0.8719\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.4148 - accuracy: 0.8724\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.4135 - accuracy: 0.8729\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.4122 - accuracy: 0.8729\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.4139 - accuracy: 0.8717\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.4109 - accuracy: 0.8725\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 77/250 [========>.....................] - ETA: 49s - loss: 0.4097 - accuracy: 0.8730\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.4053 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.4027 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.4004 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 81/250 [========>.....................] - ETA: 48s - loss: 0.3972 - accuracy: 0.8758\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.3963 - accuracy: 0.8765\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.3945 - accuracy: 0.8773\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.3956 - accuracy: 0.8761\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 85/250 [=========>....................] - ETA: 47s - loss: 0.3974 - accuracy: 0.8757\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.3954 - accuracy: 0.8761\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.3949 - accuracy: 0.8763\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.3931 - accuracy: 0.8766\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.3975 - accuracy: 0.8759\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.4002 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.3997 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.3971 - accuracy: 0.8759\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.3964 - accuracy: 0.8762\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.3942 - accuracy: 0.8768\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.3918 - accuracy: 0.8775\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.3937 - accuracy: 0.8765\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.3907 - accuracy: 0.8774\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.3909 - accuracy: 0.8777\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.3925 - accuracy: 0.8767\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.3941 - accuracy: 0.8767\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.3918 - accuracy: 0.8770\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.3929 - accuracy: 0.8773\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.3937 - accuracy: 0.8761\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.3933 - accuracy: 0.8758\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.3957 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.3943 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.3960 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.3949 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.3926 - accuracy: 0.8763\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.3947 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.3968 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.3967 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.3957 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.3950 - accuracy: 0.8757\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.3995 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.3985 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.4050 - accuracy: 0.8741\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.4051 - accuracy: 0.8741\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.4055 - accuracy: 0.8735\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.4089 - accuracy: 0.8725\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.4092 - accuracy: 0.8725\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.4080 - accuracy: 0.8726\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.4086 - accuracy: 0.8721\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.4070 - accuracy: 0.8726\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.4067 - accuracy: 0.8731\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.4053 - accuracy: 0.8734\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.4030 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.4029 - accuracy: 0.8741\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.4009 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.4013 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.4009 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.4004 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.4018 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.4011 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.4006 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.4026 - accuracy: 0.8740\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.4017 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.4015 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.4014 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.4014 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.4008 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.4012 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.3999 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.3992 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.4001 - accuracy: 0.8740\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.4041 - accuracy: 0.8732\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.4046 - accuracy: 0.8732\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.4050 - accuracy: 0.8732\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.4054 - accuracy: 0.8732\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.4036 - accuracy: 0.8736\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.4037 - accuracy: 0.8734\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.4042 - accuracy: 0.8735\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.4053 - accuracy: 0.8728\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.4043 - accuracy: 0.8731\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.4057 - accuracy: 0.8727\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.4057 - accuracy: 0.8727\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.4046 - accuracy: 0.8727\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.4032 - accuracy: 0.8731\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.4015 - accuracy: 0.8737\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.3998 - accuracy: 0.8743\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.4000 - accuracy: 0.8741\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.3998 - accuracy: 0.8743\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.3987 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.4010 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.4002 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.4008 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.4002 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.3999 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.3997 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.4003 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.4010 - accuracy: 0.8740\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.3997 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.4001 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.3994 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.3995 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.4006 - accuracy: 0.8738\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.3999 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.4033 - accuracy: 0.8740\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.4033 - accuracy: 0.8740\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.4017 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.4035 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.4035 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.4046 - accuracy: 0.8741\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.4042 - accuracy: 0.8744\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.4048 - accuracy: 0.8742\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.4040 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.4035 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.4020 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.4015 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.4006 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.3996 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.3995 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.3997 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.3998 - accuracy: 0.8756\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.3987 - accuracy: 0.8759\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.3975 - accuracy: 0.8762\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.3974 - accuracy: 0.8760\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.3989 - accuracy: 0.8756\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.3996 - accuracy: 0.8757\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.3985 - accuracy: 0.8757\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.3985 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.3983 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.3990 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.3997 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.4003 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.4022 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.4018 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.4026 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.4017 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.4013 - accuracy: 0.8745\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.4029 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.4042 - accuracy: 0.8743\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.4039 - accuracy: 0.8746\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.4048 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.4043 - accuracy: 0.8748\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.4045 - accuracy: 0.8749 \n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.4039 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.4036 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.4029 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.4025 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.4045 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.4044 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.4038 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.4045 - accuracy: 0.8753\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.4042 - accuracy: 0.8753\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.4047 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.4053 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.4051 - accuracy: 0.8749\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.4039 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.4031 - accuracy: 0.8753\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.4023 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.4025 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.4022 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.4017 - accuracy: 0.8757\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.4024 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.4027 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.4025 - accuracy: 0.8751\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.4041 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.4049 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.4052 - accuracy: 0.8747\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.4037 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.4049 - accuracy: 0.8752\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.4046 - accuracy: 0.8755\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.4046 - accuracy: 0.8756\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.4049 - accuracy: 0.8754\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4048 - accuracy: 0.8756\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8758\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4037 - accuracy: 0.8761\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8758\n",
      "Epoch 10: accuracy did not improve from 0.92188\n",
      "250/250 [==============================] - 90s 359ms/step - loss: 0.4048 - accuracy: 0.8759 - val_loss: 0.2211 - val_accuracy: 0.9284\n",
      "Epoch 11/15\n",
      "\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  1/250 [..............................] - ETA: 1:41 - loss: 0.4486 - accuracy: 0.7812\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  2/250 [..............................] - ETA: 1:10 - loss: 0.2983 - accuracy: 0.8750\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  3/250 [..............................] - ETA: 1:12 - loss: 0.3534 - accuracy: 0.8542\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  4/250 [..............................] - ETA: 1:11 - loss: 0.2964 - accuracy: 0.8828\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 0.2710 - accuracy: 0.9000\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  6/250 [..............................] - ETA: 1:10 - loss: 0.3156 - accuracy: 0.8854\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  7/250 [..............................] - ETA: 1:10 - loss: 0.3226 - accuracy: 0.8750\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  8/250 [..............................] - ETA: 1:09 - loss: 0.3248 - accuracy: 0.8789\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "  9/250 [>.............................] - ETA: 1:09 - loss: 0.3590 - accuracy: 0.8715\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 10/250 [>.............................] - ETA: 1:08 - loss: 0.3626 - accuracy: 0.8750\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 11/250 [>.............................] - ETA: 1:08 - loss: 0.3519 - accuracy: 0.8835\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 12/250 [>.............................] - ETA: 1:08 - loss: 0.3430 - accuracy: 0.8854\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 13/250 [>.............................] - ETA: 1:07 - loss: 0.3372 - accuracy: 0.8894\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 14/250 [>.............................] - ETA: 1:07 - loss: 0.3541 - accuracy: 0.8839\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 15/250 [>.............................] - ETA: 1:08 - loss: 0.3456 - accuracy: 0.8875\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 16/250 [>.............................] - ETA: 1:07 - loss: 0.3376 - accuracy: 0.8926\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 17/250 [=>............................] - ETA: 1:07 - loss: 0.3466 - accuracy: 0.8897\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 18/250 [=>............................] - ETA: 1:06 - loss: 0.3639 - accuracy: 0.8872\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 19/250 [=>............................] - ETA: 1:06 - loss: 0.3515 - accuracy: 0.8882\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 20/250 [=>............................] - ETA: 1:06 - loss: 0.3503 - accuracy: 0.8891\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 21/250 [=>............................] - ETA: 1:05 - loss: 0.3500 - accuracy: 0.8884\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 22/250 [=>............................] - ETA: 1:05 - loss: 0.3521 - accuracy: 0.8849\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 23/250 [=>............................] - ETA: 1:05 - loss: 0.3468 - accuracy: 0.8859\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 24/250 [=>............................] - ETA: 1:04 - loss: 0.3463 - accuracy: 0.8854\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.3562 - accuracy: 0.8825\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.3479 - accuracy: 0.8858\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.3720 - accuracy: 0.8785\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.3766 - accuracy: 0.8806\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.3773 - accuracy: 0.8804\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.3686 - accuracy: 0.8833\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.3701 - accuracy: 0.8831\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.3734 - accuracy: 0.8838\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.3706 - accuracy: 0.8854\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 34/250 [===>..........................] - ETA: 1:02 - loss: 0.3783 - accuracy: 0.8833\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 35/250 [===>..........................] - ETA: 1:02 - loss: 0.3788 - accuracy: 0.8821\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 36/250 [===>..........................] - ETA: 1:02 - loss: 0.3814 - accuracy: 0.8819\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 37/250 [===>..........................] - ETA: 1:01 - loss: 0.3918 - accuracy: 0.8792\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 38/250 [===>..........................] - ETA: 1:01 - loss: 0.3873 - accuracy: 0.8816\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 39/250 [===>..........................] - ETA: 1:01 - loss: 0.3834 - accuracy: 0.8822\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 40/250 [===>..........................] - ETA: 1:00 - loss: 0.3868 - accuracy: 0.8813\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 41/250 [===>..........................] - ETA: 1:00 - loss: 0.3841 - accuracy: 0.8803\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 42/250 [====>.........................] - ETA: 1:00 - loss: 0.3788 - accuracy: 0.8817\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 43/250 [====>.........................] - ETA: 1:00 - loss: 0.3738 - accuracy: 0.8837\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.3815 - accuracy: 0.8828 \n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 45/250 [====>.........................] - ETA: 59s - loss: 0.3828 - accuracy: 0.8826\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 46/250 [====>.........................] - ETA: 59s - loss: 0.3844 - accuracy: 0.8818\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.3884 - accuracy: 0.8810\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 48/250 [====>.........................] - ETA: 58s - loss: 0.3846 - accuracy: 0.8822\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 49/250 [====>.........................] - ETA: 58s - loss: 0.3819 - accuracy: 0.8827\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 50/250 [=====>........................] - ETA: 58s - loss: 0.3768 - accuracy: 0.8831\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 51/250 [=====>........................] - ETA: 57s - loss: 0.3765 - accuracy: 0.8817\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 52/250 [=====>........................] - ETA: 57s - loss: 0.3833 - accuracy: 0.8804\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 53/250 [=====>........................] - ETA: 57s - loss: 0.3906 - accuracy: 0.8791\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.3972 - accuracy: 0.8773\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 55/250 [=====>........................] - ETA: 56s - loss: 0.3966 - accuracy: 0.8773\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 56/250 [=====>........................] - ETA: 56s - loss: 0.3950 - accuracy: 0.8778\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 57/250 [=====>........................] - ETA: 55s - loss: 0.3933 - accuracy: 0.8777\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 58/250 [=====>........................] - ETA: 55s - loss: 0.3915 - accuracy: 0.8777\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 59/250 [======>.......................] - ETA: 55s - loss: 0.3891 - accuracy: 0.8782\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 60/250 [======>.......................] - ETA: 55s - loss: 0.3878 - accuracy: 0.8786\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 61/250 [======>.......................] - ETA: 54s - loss: 0.3854 - accuracy: 0.8781\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 62/250 [======>.......................] - ETA: 54s - loss: 0.3835 - accuracy: 0.8785\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 63/250 [======>.......................] - ETA: 54s - loss: 0.3842 - accuracy: 0.8775\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.3837 - accuracy: 0.8784\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 65/250 [======>.......................] - ETA: 53s - loss: 0.3857 - accuracy: 0.8788\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 66/250 [======>.......................] - ETA: 53s - loss: 0.3888 - accuracy: 0.8769\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 67/250 [=======>......................] - ETA: 52s - loss: 0.3924 - accuracy: 0.8764\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.3900 - accuracy: 0.8768\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 69/250 [=======>......................] - ETA: 52s - loss: 0.3922 - accuracy: 0.8768\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.3912 - accuracy: 0.8763\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.3895 - accuracy: 0.8768\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 72/250 [=======>......................] - ETA: 51s - loss: 0.3867 - accuracy: 0.8776\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.3974 - accuracy: 0.8763\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.4005 - accuracy: 0.8746\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.4024 - accuracy: 0.8737\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 76/250 [========>.....................] - ETA: 50s - loss: 0.4012 - accuracy: 0.8738\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 77/250 [========>.....................] - ETA: 49s - loss: 0.3974 - accuracy: 0.8746\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.4049 - accuracy: 0.8734\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 79/250 [========>.....................] - ETA: 49s - loss: 0.4041 - accuracy: 0.8734\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.4042 - accuracy: 0.8732\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 81/250 [========>.....................] - ETA: 48s - loss: 0.4065 - accuracy: 0.8725\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 82/250 [========>.....................] - ETA: 48s - loss: 0.4083 - accuracy: 0.8721\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.4101 - accuracy: 0.8722\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.4139 - accuracy: 0.8722\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 85/250 [=========>....................] - ETA: 47s - loss: 0.4106 - accuracy: 0.8733\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.4121 - accuracy: 0.8715\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.4125 - accuracy: 0.8712\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.4163 - accuracy: 0.8705\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.4180 - accuracy: 0.8702\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.4153 - accuracy: 0.8710\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.4151 - accuracy: 0.8710\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.4115 - accuracy: 0.8718\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.4107 - accuracy: 0.8718\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.4085 - accuracy: 0.8725\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.4078 - accuracy: 0.8728\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.4085 - accuracy: 0.8732\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.4110 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.4129 - accuracy: 0.8723\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.4122 - accuracy: 0.8726\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.4135 - accuracy: 0.8730\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.4152 - accuracy: 0.8717\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.4169 - accuracy: 0.8715\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.4179 - accuracy: 0.8709\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.4170 - accuracy: 0.8715\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.4148 - accuracy: 0.8722\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.4169 - accuracy: 0.8722\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.4139 - accuracy: 0.8731\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.4137 - accuracy: 0.8734\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.4178 - accuracy: 0.8725\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.4173 - accuracy: 0.8726\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.4158 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.4148 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.4156 - accuracy: 0.8726\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.4136 - accuracy: 0.8732\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.4144 - accuracy: 0.8727\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.4152 - accuracy: 0.8730\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.4161 - accuracy: 0.8724\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.4172 - accuracy: 0.8727\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.4181 - accuracy: 0.8728\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.4165 - accuracy: 0.8730\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.4153 - accuracy: 0.8728\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.4146 - accuracy: 0.8733\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.4129 - accuracy: 0.8736\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.4134 - accuracy: 0.8731\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.4136 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.4149 - accuracy: 0.8724\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.4162 - accuracy: 0.8722\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.4153 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.4158 - accuracy: 0.8727\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.4165 - accuracy: 0.8720\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.4167 - accuracy: 0.8720\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.4184 - accuracy: 0.8708\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.4191 - accuracy: 0.8706\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.4195 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.4199 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.4172 - accuracy: 0.8717\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.4156 - accuracy: 0.8721\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.4151 - accuracy: 0.8724\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.4157 - accuracy: 0.8724\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.4165 - accuracy: 0.8724\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.4146 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.4144 - accuracy: 0.8729\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.4126 - accuracy: 0.8734\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.4150 - accuracy: 0.8727\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.4150 - accuracy: 0.8721\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.4164 - accuracy: 0.8719\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.4184 - accuracy: 0.8711\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.4178 - accuracy: 0.8711\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.4175 - accuracy: 0.8709\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.4164 - accuracy: 0.8711\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.4181 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.4181 - accuracy: 0.8708\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.4172 - accuracy: 0.8708\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.4165 - accuracy: 0.8708\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.4167 - accuracy: 0.8709\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.4180 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.4175 - accuracy: 0.8709\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.4197 - accuracy: 0.8705\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.4179 - accuracy: 0.8710\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.4186 - accuracy: 0.8708\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.4187 - accuracy: 0.8704\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.4174 - accuracy: 0.8704\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.4170 - accuracy: 0.8701\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.4163 - accuracy: 0.8705\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.4164 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.4168 - accuracy: 0.8707\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.4168 - accuracy: 0.8704\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.4210 - accuracy: 0.8699\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.4220 - accuracy: 0.8699\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.4223 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.4214 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.4209 - accuracy: 0.8691\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.4212 - accuracy: 0.8684\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.4194 - accuracy: 0.8688\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.4183 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.4172 - accuracy: 0.8696\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.4164 - accuracy: 0.8700\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.4163 - accuracy: 0.8700\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.4176 - accuracy: 0.8693\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.4191 - accuracy: 0.8688\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.4183 - accuracy: 0.8688\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.4184 - accuracy: 0.8689\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.4181 - accuracy: 0.8684\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.4189 - accuracy: 0.8683\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.4190 - accuracy: 0.8681\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.4185 - accuracy: 0.8680\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.4179 - accuracy: 0.8680\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.4189 - accuracy: 0.8681\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.4187 - accuracy: 0.8679\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.4182 - accuracy: 0.8685\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.4179 - accuracy: 0.8687\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.4165 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.4164 - accuracy: 0.8689\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.4158 - accuracy: 0.8689\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.4180 - accuracy: 0.8685\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.4174 - accuracy: 0.8685\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.4171 - accuracy: 0.8684\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.4184 - accuracy: 0.8684\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.4209 - accuracy: 0.8680\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.4199 - accuracy: 0.8683\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.4200 - accuracy: 0.8681\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.4192 - accuracy: 0.8684\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.4201 - accuracy: 0.8680\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.4194 - accuracy: 0.8683\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.4205 - accuracy: 0.8680\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.4198 - accuracy: 0.8682\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.4193 - accuracy: 0.8683\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.4183 - accuracy: 0.8687\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.4176 - accuracy: 0.8691\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.4174 - accuracy: 0.8693\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.4175 - accuracy: 0.8691\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.4161 - accuracy: 0.8695\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.4165 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.4163 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.4157 - accuracy: 0.8695\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.4159 - accuracy: 0.8691 \n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.4159 - accuracy: 0.8687\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.4177 - accuracy: 0.8687\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.4172 - accuracy: 0.8691\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.4164 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.4177 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.4176 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.4173 - accuracy: 0.8696\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.4168 - accuracy: 0.8693\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.4163 - accuracy: 0.8696\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.4159 - accuracy: 0.8698\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.4163 - accuracy: 0.8695\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.4163 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.4164 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.4159 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.4151 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.4156 - accuracy: 0.8693\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.4144 - accuracy: 0.8697\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.4151 - accuracy: 0.8697\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.4153 - accuracy: 0.8697\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.4147 - accuracy: 0.8699\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.4158 - accuracy: 0.8694\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.4143 - accuracy: 0.8699\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.4131 - accuracy: 0.8702\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.4122 - accuracy: 0.8704\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.4118 - accuracy: 0.8704\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.4118 - accuracy: 0.8703\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.4120 - accuracy: 0.8702\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.4115 - accuracy: 0.8703\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.4144 - accuracy: 0.8697\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.4149 - accuracy: 0.8692\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8688\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.8685\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8685\n",
      "Epoch 11: accuracy did not improve from 0.92188\n",
      "250/250 [==============================] - 89s 354ms/step - loss: 0.4141 - accuracy: 0.8688 - val_loss: 0.1990 - val_accuracy: 0.9370\n",
      "Epoch 12/15\n",
      "\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  1/250 [..............................] - ETA: 1:35 - loss: 0.5445 - accuracy: 0.8750\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  2/250 [..............................] - ETA: 1:08 - loss: 0.6826 - accuracy: 0.8438\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  3/250 [..............................] - ETA: 1:07 - loss: 0.5427 - accuracy: 0.8646\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  4/250 [..............................] - ETA: 1:09 - loss: 0.5255 - accuracy: 0.8750\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  5/250 [..............................] - ETA: 1:10 - loss: 0.4608 - accuracy: 0.8813\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  6/250 [..............................] - ETA: 1:09 - loss: 0.4196 - accuracy: 0.8906\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  7/250 [..............................] - ETA: 1:09 - loss: 0.3964 - accuracy: 0.8929\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  8/250 [..............................] - ETA: 1:09 - loss: 0.4008 - accuracy: 0.8906\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "  9/250 [>.............................] - ETA: 1:08 - loss: 0.4573 - accuracy: 0.8854\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 10/250 [>.............................] - ETA: 1:08 - loss: 0.4799 - accuracy: 0.8687\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 11/250 [>.............................] - ETA: 1:07 - loss: 0.4645 - accuracy: 0.8750\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 12/250 [>.............................] - ETA: 1:08 - loss: 0.4941 - accuracy: 0.8776\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 13/250 [>.............................] - ETA: 1:07 - loss: 0.4710 - accuracy: 0.8798\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 14/250 [>.............................] - ETA: 1:07 - loss: 0.4466 - accuracy: 0.8862\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 15/250 [>.............................] - ETA: 1:06 - loss: 0.4409 - accuracy: 0.8833\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 16/250 [>.............................] - ETA: 1:06 - loss: 0.4487 - accuracy: 0.8828\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 17/250 [=>............................] - ETA: 1:06 - loss: 0.4403 - accuracy: 0.8824\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 0.4321 - accuracy: 0.8802\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 19/250 [=>............................] - ETA: 1:05 - loss: 0.4209 - accuracy: 0.8832\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.4193 - accuracy: 0.8844\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.4222 - accuracy: 0.8824\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.4284 - accuracy: 0.8821\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.4216 - accuracy: 0.8804\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 24/250 [=>............................] - ETA: 1:04 - loss: 0.4123 - accuracy: 0.8815\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 25/250 [==>...........................] - ETA: 1:04 - loss: 0.4205 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 26/250 [==>...........................] - ETA: 1:04 - loss: 0.4198 - accuracy: 0.8786\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 27/250 [==>...........................] - ETA: 1:04 - loss: 0.4213 - accuracy: 0.8773\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 28/250 [==>...........................] - ETA: 1:03 - loss: 0.4208 - accuracy: 0.8761\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 29/250 [==>...........................] - ETA: 1:03 - loss: 0.4122 - accuracy: 0.8782\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 30/250 [==>...........................] - ETA: 1:03 - loss: 0.4095 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 31/250 [==>...........................] - ETA: 1:02 - loss: 0.4007 - accuracy: 0.8800\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 32/250 [==>...........................] - ETA: 1:02 - loss: 0.3965 - accuracy: 0.8809\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 33/250 [==>...........................] - ETA: 1:02 - loss: 0.3895 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 34/250 [===>..........................] - ETA: 1:02 - loss: 0.3843 - accuracy: 0.8833\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 35/250 [===>..........................] - ETA: 1:01 - loss: 0.3934 - accuracy: 0.8813\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 36/250 [===>..........................] - ETA: 1:01 - loss: 0.4016 - accuracy: 0.8785\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 37/250 [===>..........................] - ETA: 1:01 - loss: 0.3995 - accuracy: 0.8801\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 38/250 [===>..........................] - ETA: 1:00 - loss: 0.3982 - accuracy: 0.8799\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 39/250 [===>..........................] - ETA: 1:00 - loss: 0.3921 - accuracy: 0.8814\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 40/250 [===>..........................] - ETA: 1:00 - loss: 0.3926 - accuracy: 0.8820\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 41/250 [===>..........................] - ETA: 1:00 - loss: 0.3893 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 42/250 [====>.........................] - ETA: 59s - loss: 0.3860 - accuracy: 0.8839 \n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 43/250 [====>.........................] - ETA: 59s - loss: 0.3857 - accuracy: 0.8837\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.3858 - accuracy: 0.8828\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 45/250 [====>.........................] - ETA: 58s - loss: 0.3898 - accuracy: 0.8819\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 46/250 [====>.........................] - ETA: 58s - loss: 0.3835 - accuracy: 0.8838\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 47/250 [====>.........................] - ETA: 58s - loss: 0.3835 - accuracy: 0.8836\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.3934 - accuracy: 0.8841\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 49/250 [====>.........................] - ETA: 57s - loss: 0.3953 - accuracy: 0.8852\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 50/250 [=====>........................] - ETA: 57s - loss: 0.4014 - accuracy: 0.8838\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.4080 - accuracy: 0.8836\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 52/250 [=====>........................] - ETA: 56s - loss: 0.4102 - accuracy: 0.8828\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 53/250 [=====>........................] - ETA: 56s - loss: 0.4066 - accuracy: 0.8838\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.4068 - accuracy: 0.8837\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.4115 - accuracy: 0.8830\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 56/250 [=====>........................] - ETA: 55s - loss: 0.4061 - accuracy: 0.8845\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.4059 - accuracy: 0.8843\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.4049 - accuracy: 0.8842\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.4056 - accuracy: 0.8845\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 60/250 [======>.......................] - ETA: 54s - loss: 0.4123 - accuracy: 0.8833\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.4074 - accuracy: 0.8847\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.4053 - accuracy: 0.8856\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 63/250 [======>.......................] - ETA: 53s - loss: 0.4109 - accuracy: 0.8839\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.4085 - accuracy: 0.8848\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.4057 - accuracy: 0.8851\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 66/250 [======>.......................] - ETA: 52s - loss: 0.4078 - accuracy: 0.8830\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 67/250 [=======>......................] - ETA: 52s - loss: 0.4106 - accuracy: 0.8815\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.4100 - accuracy: 0.8814\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 69/250 [=======>......................] - ETA: 51s - loss: 0.4063 - accuracy: 0.8827\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 70/250 [=======>......................] - ETA: 51s - loss: 0.4053 - accuracy: 0.8821\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.4021 - accuracy: 0.8834\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.4015 - accuracy: 0.8832\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.4014 - accuracy: 0.8831\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.3982 - accuracy: 0.8834\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.3964 - accuracy: 0.8838\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.3946 - accuracy: 0.8840\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 77/250 [========>.....................] - ETA: 49s - loss: 0.3914 - accuracy: 0.8847\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.3939 - accuracy: 0.8838\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.3919 - accuracy: 0.8837\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.3953 - accuracy: 0.8820\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 81/250 [========>.....................] - ETA: 48s - loss: 0.3910 - accuracy: 0.8835\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.3950 - accuracy: 0.8815\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.3954 - accuracy: 0.8814\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.3947 - accuracy: 0.8821\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 85/250 [=========>....................] - ETA: 47s - loss: 0.3946 - accuracy: 0.8820\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.3970 - accuracy: 0.8808\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.3948 - accuracy: 0.8815\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.3953 - accuracy: 0.8817\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.3929 - accuracy: 0.8827\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.3926 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.3916 - accuracy: 0.8829\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.3889 - accuracy: 0.8835\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.3930 - accuracy: 0.8834\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.3918 - accuracy: 0.8830\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.3942 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.3960 - accuracy: 0.8818\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.3950 - accuracy: 0.8821\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.3960 - accuracy: 0.8817\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.3983 - accuracy: 0.8813\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.3965 - accuracy: 0.8819\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.4038 - accuracy: 0.8809\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.4003 - accuracy: 0.8820\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.3996 - accuracy: 0.8820\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.3989 - accuracy: 0.8821\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.4009 - accuracy: 0.8808\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.4018 - accuracy: 0.8808\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.4015 - accuracy: 0.8804\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.4000 - accuracy: 0.8810\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "109/250 [============>.................] - ETA: 39s - loss: 0.4003 - accuracy: 0.8812\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.3982 - accuracy: 0.8817\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.3971 - accuracy: 0.8822\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.3955 - accuracy: 0.8824\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.3935 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.3967 - accuracy: 0.8826\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.4000 - accuracy: 0.8817\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "116/250 [============>.................] - ETA: 37s - loss: 0.3997 - accuracy: 0.8816\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.4016 - accuracy: 0.8813\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.4036 - accuracy: 0.8805\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.4026 - accuracy: 0.8809\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.4037 - accuracy: 0.8806\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.4021 - accuracy: 0.8808\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.4034 - accuracy: 0.8798\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "123/250 [=============>................] - ETA: 35s - loss: 0.4021 - accuracy: 0.8797\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.4038 - accuracy: 0.8794\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.4035 - accuracy: 0.8794\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.4038 - accuracy: 0.8791\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.4018 - accuracy: 0.8798\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.4025 - accuracy: 0.8793\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.4014 - accuracy: 0.8795\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.4020 - accuracy: 0.8795\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.4015 - accuracy: 0.8792\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.4008 - accuracy: 0.8792\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.4013 - accuracy: 0.8789\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "134/250 [===============>..............] - ETA: 32s - loss: 0.4010 - accuracy: 0.8789\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.4000 - accuracy: 0.8791\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.4003 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.4017 - accuracy: 0.8776\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.4004 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.4006 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.4006 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "141/250 [===============>..............] - ETA: 30s - loss: 0.4003 - accuracy: 0.8780\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.3998 - accuracy: 0.8784\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.3978 - accuracy: 0.8793\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.3965 - accuracy: 0.8795\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.3987 - accuracy: 0.8784\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.3988 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.3975 - accuracy: 0.8787\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "148/250 [================>.............] - ETA: 28s - loss: 0.3984 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.3979 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.3966 - accuracy: 0.8787\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.3957 - accuracy: 0.8791\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.3973 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.3966 - accuracy: 0.8780\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.3978 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "155/250 [=================>............] - ETA: 26s - loss: 0.3998 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.3988 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.3987 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.3990 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "159/250 [==================>...........] - ETA: 25s - loss: 0.3990 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.4007 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.4022 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "162/250 [==================>...........] - ETA: 24s - loss: 0.4025 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.4025 - accuracy: 0.8768\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.4009 - accuracy: 0.8774\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.3999 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "166/250 [==================>...........] - ETA: 23s - loss: 0.4020 - accuracy: 0.8774\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.4015 - accuracy: 0.8773\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.4017 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "169/250 [===================>..........] - ETA: 22s - loss: 0.4014 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.4007 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.4010 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.4004 - accuracy: 0.8773\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "173/250 [===================>..........] - ETA: 21s - loss: 0.4005 - accuracy: 0.8769\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.3996 - accuracy: 0.8769\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.4012 - accuracy: 0.8769\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.4005 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.3999 - accuracy: 0.8774\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.3998 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.3997 - accuracy: 0.8770\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "180/250 [====================>.........] - ETA: 19s - loss: 0.3983 - accuracy: 0.8774\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.3989 - accuracy: 0.8766\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.3974 - accuracy: 0.8772\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.3966 - accuracy: 0.8771\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.3962 - accuracy: 0.8770\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.3964 - accuracy: 0.8769\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.3959 - accuracy: 0.8771\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "187/250 [=====================>........] - ETA: 17s - loss: 0.3945 - accuracy: 0.8774\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.3941 - accuracy: 0.8776\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.3932 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.3920 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.3930 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.3928 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.3926 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.3946 - accuracy: 0.8775\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.3933 - accuracy: 0.8780\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.3931 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.3922 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.3917 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.3911 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.3909 - accuracy: 0.8777\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.3904 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.3899 - accuracy: 0.8780\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.3885 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.3898 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.3893 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.3894 - accuracy: 0.8781\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.3894 - accuracy: 0.8780\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.3895 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.3892 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.3885 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.3879 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.3870 - accuracy: 0.8785\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.3872 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.3867 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.3878 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.3888 - accuracy: 0.8780 \n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.3894 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.3890 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.3896 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.3900 - accuracy: 0.8779\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.3898 - accuracy: 0.8778\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.3884 - accuracy: 0.8782\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.3885 - accuracy: 0.8783\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.3875 - accuracy: 0.8786\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.3868 - accuracy: 0.8786\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.3862 - accuracy: 0.8788\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.3867 - accuracy: 0.8787\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.3854 - accuracy: 0.8791\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.3853 - accuracy: 0.8789\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.3858 - accuracy: 0.8786\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.3855 - accuracy: 0.8790\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.3845 - accuracy: 0.8793\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.3846 - accuracy: 0.8794\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.3852 - accuracy: 0.8795\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.3866 - accuracy: 0.8792\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.3867 - accuracy: 0.8792\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.3871 - accuracy: 0.8790\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.3867 - accuracy: 0.8790\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.3871 - accuracy: 0.8787\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.3871 - accuracy: 0.8786\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.3872 - accuracy: 0.8787\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.3867 - accuracy: 0.8788\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.3865 - accuracy: 0.8791\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.3864 - accuracy: 0.8788\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.3866 - accuracy: 0.8785\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.3871 - accuracy: 0.8784\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8784\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8785\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8785\n",
      "Epoch 12: accuracy did not improve from 0.92188\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 0.3866 - accuracy: 0.8784 - val_loss: 0.1635 - val_accuracy: 0.9471\n",
      "Epoch 13/15\n",
      "\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  1/250 [..............................] - ETA: 1:28 - loss: 0.5021 - accuracy: 0.8750\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  2/250 [..............................] - ETA: 1:07 - loss: 0.5373 - accuracy: 0.8750\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  3/250 [..............................] - ETA: 1:11 - loss: 0.4948 - accuracy: 0.8542\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  4/250 [..............................] - ETA: 1:10 - loss: 0.4218 - accuracy: 0.8672\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  5/250 [..............................] - ETA: 1:11 - loss: 0.4272 - accuracy: 0.8687\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  6/250 [..............................] - ETA: 1:10 - loss: 0.4111 - accuracy: 0.8646\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  7/250 [..............................] - ETA: 1:10 - loss: 0.4231 - accuracy: 0.8571\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  8/250 [..............................] - ETA: 1:09 - loss: 0.4472 - accuracy: 0.8555\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "  9/250 [>.............................] - ETA: 1:10 - loss: 0.4429 - accuracy: 0.8576\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 10/250 [>.............................] - ETA: 1:09 - loss: 0.4125 - accuracy: 0.8687\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 11/250 [>.............................] - ETA: 1:09 - loss: 0.3969 - accuracy: 0.8722\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 12/250 [>.............................] - ETA: 1:08 - loss: 0.4316 - accuracy: 0.8620\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 13/250 [>.............................] - ETA: 1:08 - loss: 0.4145 - accuracy: 0.8630\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 14/250 [>.............................] - ETA: 1:07 - loss: 0.4498 - accuracy: 0.8527\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 15/250 [>.............................] - ETA: 1:07 - loss: 0.4498 - accuracy: 0.8500\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 16/250 [>.............................] - ETA: 1:06 - loss: 0.4569 - accuracy: 0.8477\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 17/250 [=>............................] - ETA: 1:06 - loss: 0.4628 - accuracy: 0.8438\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 18/250 [=>............................] - ETA: 1:05 - loss: 0.4589 - accuracy: 0.8455\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 19/250 [=>............................] - ETA: 1:05 - loss: 0.4531 - accuracy: 0.8470\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 20/250 [=>............................] - ETA: 1:05 - loss: 0.4391 - accuracy: 0.8500\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.4275 - accuracy: 0.8512\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 22/250 [=>............................] - ETA: 1:04 - loss: 0.4201 - accuracy: 0.8494\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.4144 - accuracy: 0.8505\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.4196 - accuracy: 0.8503\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.4203 - accuracy: 0.8500\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 26/250 [==>...........................] - ETA: 1:03 - loss: 0.4189 - accuracy: 0.8498\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 27/250 [==>...........................] - ETA: 1:02 - loss: 0.4104 - accuracy: 0.8519\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 28/250 [==>...........................] - ETA: 1:02 - loss: 0.4028 - accuracy: 0.8538\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 29/250 [==>...........................] - ETA: 1:02 - loss: 0.4014 - accuracy: 0.8556\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.3988 - accuracy: 0.8573\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.3995 - accuracy: 0.8589\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 32/250 [==>...........................] - ETA: 1:01 - loss: 0.4079 - accuracy: 0.8564\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.4078 - accuracy: 0.8542\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.4080 - accuracy: 0.8557\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.4109 - accuracy: 0.8536\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.4010 - accuracy: 0.8576\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 37/250 [===>..........................] - ETA: 59s - loss: 0.4100 - accuracy: 0.8539 \n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.4085 - accuracy: 0.8553\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.4092 - accuracy: 0.8558\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.4037 - accuracy: 0.8586\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 0.4067 - accuracy: 0.8567\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 42/250 [====>.........................] - ETA: 58s - loss: 0.4072 - accuracy: 0.8557\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 0.4085 - accuracy: 0.8539\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 44/250 [====>.........................] - ETA: 57s - loss: 0.4088 - accuracy: 0.8544\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.4113 - accuracy: 0.8521\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.4059 - accuracy: 0.8533\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.4057 - accuracy: 0.8537\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 48/250 [====>.........................] - ETA: 56s - loss: 0.4036 - accuracy: 0.8542\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.4017 - accuracy: 0.8552\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.4014 - accuracy: 0.8556\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 51/250 [=====>........................] - ETA: 55s - loss: 0.3985 - accuracy: 0.8572\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.4046 - accuracy: 0.8570\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.4048 - accuracy: 0.8573\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 54/250 [=====>........................] - ETA: 54s - loss: 0.4053 - accuracy: 0.8571\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 55/250 [=====>........................] - ETA: 54s - loss: 0.4034 - accuracy: 0.8574\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.3983 - accuracy: 0.8594\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.3966 - accuracy: 0.8596\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 58/250 [=====>........................] - ETA: 53s - loss: 0.3928 - accuracy: 0.8610\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 59/250 [======>.......................] - ETA: 53s - loss: 0.3904 - accuracy: 0.8618\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.3868 - accuracy: 0.8641\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.3902 - accuracy: 0.8637\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 62/250 [======>.......................] - ETA: 52s - loss: 0.3907 - accuracy: 0.8644\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.3913 - accuracy: 0.8646\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.3900 - accuracy: 0.8643\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.3975 - accuracy: 0.8644\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.4049 - accuracy: 0.8622\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.4056 - accuracy: 0.8619\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.4012 - accuracy: 0.8635\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 69/250 [=======>......................] - ETA: 51s - loss: 0.3991 - accuracy: 0.8641\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 70/250 [=======>......................] - ETA: 51s - loss: 0.3990 - accuracy: 0.8647\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.3961 - accuracy: 0.8653\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.3969 - accuracy: 0.8650\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.3985 - accuracy: 0.8647\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 74/250 [=======>......................] - ETA: 50s - loss: 0.3991 - accuracy: 0.8653\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.4039 - accuracy: 0.8637\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.4010 - accuracy: 0.8639\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 77/250 [========>.....................] - ETA: 49s - loss: 0.3964 - accuracy: 0.8657\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.3934 - accuracy: 0.8666\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.3913 - accuracy: 0.8679\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.3903 - accuracy: 0.8676\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 81/250 [========>.....................] - ETA: 48s - loss: 0.3896 - accuracy: 0.8684\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 82/250 [========>.....................] - ETA: 48s - loss: 0.3873 - accuracy: 0.8685\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.3866 - accuracy: 0.8686\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.3834 - accuracy: 0.8698\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 85/250 [=========>....................] - ETA: 47s - loss: 0.3848 - accuracy: 0.8691\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.3841 - accuracy: 0.8695\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.3811 - accuracy: 0.8707\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.3914 - accuracy: 0.8690\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.3902 - accuracy: 0.8690\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.3871 - accuracy: 0.8698\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.3858 - accuracy: 0.8705\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 92/250 [==========>...................] - ETA: 45s - loss: 0.3868 - accuracy: 0.8713\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.3860 - accuracy: 0.8713\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.3855 - accuracy: 0.8720\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.3867 - accuracy: 0.8714\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.3836 - accuracy: 0.8724\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.3842 - accuracy: 0.8727\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.3834 - accuracy: 0.8734\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      " 99/250 [==========>...................] - ETA: 43s - loss: 0.3827 - accuracy: 0.8734\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.3823 - accuracy: 0.8737\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.3797 - accuracy: 0.8744\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "102/250 [===========>..................] - ETA: 42s - loss: 0.3779 - accuracy: 0.8744\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.3803 - accuracy: 0.8744\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.3802 - accuracy: 0.8747\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.3820 - accuracy: 0.8741\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "106/250 [===========>..................] - ETA: 41s - loss: 0.3800 - accuracy: 0.8741\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.3780 - accuracy: 0.8747\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.3769 - accuracy: 0.8753\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.3778 - accuracy: 0.8753\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.3759 - accuracy: 0.8761\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.3759 - accuracy: 0.8756\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.3754 - accuracy: 0.8758\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "113/250 [============>.................] - ETA: 39s - loss: 0.3751 - accuracy: 0.8764\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.3754 - accuracy: 0.8761\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.3762 - accuracy: 0.8761\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.3750 - accuracy: 0.8766\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.3753 - accuracy: 0.8763\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.3727 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.3722 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.3719 - accuracy: 0.8766\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.3725 - accuracy: 0.8763\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.3729 - accuracy: 0.8765\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.3720 - accuracy: 0.8768\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.3754 - accuracy: 0.8763\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.3739 - accuracy: 0.8765\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.3720 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.3726 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.3738 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.3722 - accuracy: 0.8777\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.3739 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.3752 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.3730 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.3732 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.3755 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.3745 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.3735 - accuracy: 0.8791\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.3753 - accuracy: 0.8791\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.3781 - accuracy: 0.8779\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.3780 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.3787 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.3793 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.3790 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.3798 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.3789 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.3802 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.3804 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.3801 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.3786 - accuracy: 0.8775\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.3787 - accuracy: 0.8773\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.3780 - accuracy: 0.8773\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.3779 - accuracy: 0.8773\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.3775 - accuracy: 0.8775\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.3771 - accuracy: 0.8777\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.3774 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.3758 - accuracy: 0.8778\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.3747 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.3746 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.3731 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.3723 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.3738 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.3750 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.3747 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.3731 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.3728 - accuracy: 0.8787\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.3743 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.3730 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.3733 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.3719 - accuracy: 0.8786\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.3732 - accuracy: 0.8784\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.3731 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.3730 - accuracy: 0.8786\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.3725 - accuracy: 0.8786\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.3719 - accuracy: 0.8787\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.3713 - accuracy: 0.8789\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.3719 - accuracy: 0.8787\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.3714 - accuracy: 0.8790\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.3720 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.3722 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.3722 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.3720 - accuracy: 0.8786\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.3712 - accuracy: 0.8787\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.3745 - accuracy: 0.8778\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.3737 - accuracy: 0.8778\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.3737 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.3729 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.3741 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.3762 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.3755 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.3748 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.3745 - accuracy: 0.8777\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.3742 - accuracy: 0.8779\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.3743 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.3732 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.3734 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.3727 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.3730 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.3725 - accuracy: 0.8786\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.3727 - accuracy: 0.8784\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.3732 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.3741 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.3747 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.3749 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.3750 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.3749 - accuracy: 0.8785\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.3761 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.3757 - accuracy: 0.8784\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.3769 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.3760 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.3755 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.3751 - accuracy: 0.8781\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.3743 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.3730 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.3718 - accuracy: 0.8792\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.3720 - accuracy: 0.8790\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.3726 - accuracy: 0.8789\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.3732 - accuracy: 0.8783 \n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.3721 - accuracy: 0.8787\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.3713 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.3722 - accuracy: 0.8788\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.3732 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.3736 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.3731 - accuracy: 0.8783\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.3731 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.3738 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.3740 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.3729 - accuracy: 0.8778\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.3730 - accuracy: 0.8777\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.3742 - accuracy: 0.8773\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.3735 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.3732 - accuracy: 0.8774\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.3734 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.3734 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.3729 - accuracy: 0.8769\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.3727 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.3722 - accuracy: 0.8771\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.3715 - accuracy: 0.8773\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.3705 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.3693 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.3691 - accuracy: 0.8779\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.3700 - accuracy: 0.8778\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.3691 - accuracy: 0.8779\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.3691 - accuracy: 0.8780\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.3689 - accuracy: 0.8782\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.3695 - accuracy: 0.8779\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.3712 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.3709 - accuracy: 0.8775\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3719 - accuracy: 0.8776\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8772\n",
      "Epoch 13: accuracy did not improve from 0.92188\n",
      "250/250 [==============================] - 89s 356ms/step - loss: 0.3724 - accuracy: 0.8771 - val_loss: 0.1768 - val_accuracy: 0.9466\n",
      "Epoch 14/15\n",
      "\n",
      "Epoch 14: accuracy improved from 0.92188 to 0.93750, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 3:31 - loss: 0.1822 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.93750\n",
      "  2/250 [..............................] - ETA: 20s - loss: 0.1702 - accuracy: 0.9375 \n",
      "Epoch 14: accuracy improved from 0.93750 to 0.94792, saving model to output\\inceptionV3.h5\n",
      "  3/250 [..............................] - ETA: 1:43 - loss: 0.1896 - accuracy: 0.9479\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  4/250 [..............................] - ETA: 1:15 - loss: 0.2028 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  5/250 [..............................] - ETA: 1:14 - loss: 0.2008 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  6/250 [..............................] - ETA: 1:13 - loss: 0.1886 - accuracy: 0.9375\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  7/250 [..............................] - ETA: 1:11 - loss: 0.2013 - accuracy: 0.9330\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  8/250 [..............................] - ETA: 1:10 - loss: 0.2568 - accuracy: 0.9258\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "  9/250 [>.............................] - ETA: 1:09 - loss: 0.2666 - accuracy: 0.9201\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 10/250 [>.............................] - ETA: 1:09 - loss: 0.2671 - accuracy: 0.9156\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 11/250 [>.............................] - ETA: 1:09 - loss: 0.2640 - accuracy: 0.9176\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 12/250 [>.............................] - ETA: 1:08 - loss: 0.2586 - accuracy: 0.9167\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 13/250 [>.............................] - ETA: 1:07 - loss: 0.2594 - accuracy: 0.9207\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 14/250 [>.............................] - ETA: 1:07 - loss: 0.2700 - accuracy: 0.9196\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 15/250 [>.............................] - ETA: 1:07 - loss: 0.2775 - accuracy: 0.9146\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 16/250 [>.............................] - ETA: 1:07 - loss: 0.2768 - accuracy: 0.9141\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 17/250 [=>............................] - ETA: 1:07 - loss: 0.2942 - accuracy: 0.9099\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 18/250 [=>............................] - ETA: 1:07 - loss: 0.2985 - accuracy: 0.9115\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 19/250 [=>............................] - ETA: 1:06 - loss: 0.2991 - accuracy: 0.9112\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 20/250 [=>............................] - ETA: 1:06 - loss: 0.2888 - accuracy: 0.9141\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 21/250 [=>............................] - ETA: 1:06 - loss: 0.2946 - accuracy: 0.9137\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 22/250 [=>............................] - ETA: 1:06 - loss: 0.2968 - accuracy: 0.9134\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 23/250 [=>............................] - ETA: 1:05 - loss: 0.3196 - accuracy: 0.9062\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 24/250 [=>............................] - ETA: 1:05 - loss: 0.3352 - accuracy: 0.9023\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 25/250 [==>...........................] - ETA: 1:05 - loss: 0.3371 - accuracy: 0.9013\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 26/250 [==>...........................] - ETA: 1:05 - loss: 0.3328 - accuracy: 0.9014\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 27/250 [==>...........................] - ETA: 1:05 - loss: 0.3263 - accuracy: 0.9028\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 28/250 [==>...........................] - ETA: 1:05 - loss: 0.3279 - accuracy: 0.9018\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 29/250 [==>...........................] - ETA: 1:04 - loss: 0.3332 - accuracy: 0.8976\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 30/250 [==>...........................] - ETA: 1:04 - loss: 0.3340 - accuracy: 0.8979\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 31/250 [==>...........................] - ETA: 1:04 - loss: 0.3349 - accuracy: 0.8992\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 32/250 [==>...........................] - ETA: 1:04 - loss: 0.3330 - accuracy: 0.8975\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 33/250 [==>...........................] - ETA: 1:03 - loss: 0.3413 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 34/250 [===>..........................] - ETA: 1:03 - loss: 0.3519 - accuracy: 0.8943\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 35/250 [===>..........................] - ETA: 1:03 - loss: 0.3466 - accuracy: 0.8955\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 36/250 [===>..........................] - ETA: 1:02 - loss: 0.3436 - accuracy: 0.8967\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 37/250 [===>..........................] - ETA: 1:02 - loss: 0.3594 - accuracy: 0.8919\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 38/250 [===>..........................] - ETA: 1:02 - loss: 0.3559 - accuracy: 0.8923\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 39/250 [===>..........................] - ETA: 1:01 - loss: 0.3523 - accuracy: 0.8934\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 40/250 [===>..........................] - ETA: 1:01 - loss: 0.3581 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 41/250 [===>..........................] - ETA: 1:00 - loss: 0.3515 - accuracy: 0.8956\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 42/250 [====>.........................] - ETA: 1:00 - loss: 0.3483 - accuracy: 0.8966\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 43/250 [====>.........................] - ETA: 1:00 - loss: 0.3484 - accuracy: 0.8953\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 44/250 [====>.........................] - ETA: 59s - loss: 0.3500 - accuracy: 0.8963 \n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 45/250 [====>.........................] - ETA: 59s - loss: 0.3488 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 46/250 [====>.........................] - ETA: 59s - loss: 0.3447 - accuracy: 0.8954\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 47/250 [====>.........................] - ETA: 59s - loss: 0.3409 - accuracy: 0.8969\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 48/250 [====>.........................] - ETA: 58s - loss: 0.3371 - accuracy: 0.8978\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 49/250 [====>.........................] - ETA: 58s - loss: 0.3379 - accuracy: 0.8967\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 50/250 [=====>........................] - ETA: 58s - loss: 0.3362 - accuracy: 0.8963\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 51/250 [=====>........................] - ETA: 57s - loss: 0.3342 - accuracy: 0.8964\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 52/250 [=====>........................] - ETA: 57s - loss: 0.3407 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 53/250 [=====>........................] - ETA: 57s - loss: 0.3376 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 54/250 [=====>........................] - ETA: 56s - loss: 0.3363 - accuracy: 0.8929\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 55/250 [=====>........................] - ETA: 56s - loss: 0.3345 - accuracy: 0.8932\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 56/250 [=====>........................] - ETA: 56s - loss: 0.3349 - accuracy: 0.8934\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 57/250 [=====>........................] - ETA: 56s - loss: 0.3353 - accuracy: 0.8936\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 58/250 [=====>........................] - ETA: 55s - loss: 0.3330 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 59/250 [======>.......................] - ETA: 55s - loss: 0.3312 - accuracy: 0.8941\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 60/250 [======>.......................] - ETA: 55s - loss: 0.3323 - accuracy: 0.8932\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 61/250 [======>.......................] - ETA: 54s - loss: 0.3286 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 62/250 [======>.......................] - ETA: 54s - loss: 0.3265 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 63/250 [======>.......................] - ETA: 54s - loss: 0.3231 - accuracy: 0.8963\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 64/250 [======>.......................] - ETA: 53s - loss: 0.3287 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 65/250 [======>.......................] - ETA: 53s - loss: 0.3304 - accuracy: 0.8942\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 66/250 [======>.......................] - ETA: 53s - loss: 0.3352 - accuracy: 0.8920\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 67/250 [=======>......................] - ETA: 53s - loss: 0.3400 - accuracy: 0.8918\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 68/250 [=======>......................] - ETA: 52s - loss: 0.3381 - accuracy: 0.8915\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 69/250 [=======>......................] - ETA: 52s - loss: 0.3360 - accuracy: 0.8922\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 70/250 [=======>......................] - ETA: 52s - loss: 0.3337 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 71/250 [=======>......................] - ETA: 51s - loss: 0.3356 - accuracy: 0.8926\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 72/250 [=======>......................] - ETA: 51s - loss: 0.3366 - accuracy: 0.8919\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 73/250 [=======>......................] - ETA: 51s - loss: 0.3353 - accuracy: 0.8917\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 74/250 [=======>......................] - ETA: 51s - loss: 0.3347 - accuracy: 0.8919\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 75/250 [========>.....................] - ETA: 50s - loss: 0.3327 - accuracy: 0.8925\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 76/250 [========>.....................] - ETA: 50s - loss: 0.3324 - accuracy: 0.8923\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 77/250 [========>.....................] - ETA: 50s - loss: 0.3302 - accuracy: 0.8929\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 78/250 [========>.....................] - ETA: 49s - loss: 0.3315 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 79/250 [========>.....................] - ETA: 49s - loss: 0.3299 - accuracy: 0.8932\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 80/250 [========>.....................] - ETA: 49s - loss: 0.3290 - accuracy: 0.8941\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 81/250 [========>.....................] - ETA: 49s - loss: 0.3291 - accuracy: 0.8935\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 82/250 [========>.....................] - ETA: 48s - loss: 0.3284 - accuracy: 0.8937\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 83/250 [========>.....................] - ETA: 48s - loss: 0.3282 - accuracy: 0.8942\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 84/250 [=========>....................] - ETA: 48s - loss: 0.3274 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 85/250 [=========>....................] - ETA: 48s - loss: 0.3270 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 86/250 [=========>....................] - ETA: 47s - loss: 0.3244 - accuracy: 0.8957\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 87/250 [=========>....................] - ETA: 47s - loss: 0.3267 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 88/250 [=========>....................] - ETA: 47s - loss: 0.3256 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 89/250 [=========>....................] - ETA: 46s - loss: 0.3336 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 90/250 [=========>....................] - ETA: 46s - loss: 0.3304 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 91/250 [=========>....................] - ETA: 46s - loss: 0.3300 - accuracy: 0.8956\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 92/250 [==========>...................] - ETA: 46s - loss: 0.3307 - accuracy: 0.8954\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 93/250 [==========>...................] - ETA: 45s - loss: 0.3306 - accuracy: 0.8958\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 94/250 [==========>...................] - ETA: 45s - loss: 0.3297 - accuracy: 0.8963\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 95/250 [==========>...................] - ETA: 45s - loss: 0.3310 - accuracy: 0.8957\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 96/250 [==========>...................] - ETA: 44s - loss: 0.3316 - accuracy: 0.8955\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 97/250 [==========>...................] - ETA: 44s - loss: 0.3311 - accuracy: 0.8953\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 98/250 [==========>...................] - ETA: 44s - loss: 0.3305 - accuracy: 0.8954\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      " 99/250 [==========>...................] - ETA: 44s - loss: 0.3305 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "100/250 [===========>..................] - ETA: 43s - loss: 0.3298 - accuracy: 0.8950\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "101/250 [===========>..................] - ETA: 43s - loss: 0.3360 - accuracy: 0.8939\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "102/250 [===========>..................] - ETA: 43s - loss: 0.3355 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "103/250 [===========>..................] - ETA: 42s - loss: 0.3364 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "104/250 [===========>..................] - ETA: 42s - loss: 0.3356 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "105/250 [===========>..................] - ETA: 42s - loss: 0.3371 - accuracy: 0.8946\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "106/250 [===========>..................] - ETA: 42s - loss: 0.3388 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "107/250 [===========>..................] - ETA: 41s - loss: 0.3394 - accuracy: 0.8928\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "108/250 [===========>..................] - ETA: 41s - loss: 0.3387 - accuracy: 0.8929\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "109/250 [============>.................] - ETA: 41s - loss: 0.3395 - accuracy: 0.8928\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "110/250 [============>.................] - ETA: 40s - loss: 0.3389 - accuracy: 0.8929\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "111/250 [============>.................] - ETA: 40s - loss: 0.3377 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "112/250 [============>.................] - ETA: 40s - loss: 0.3405 - accuracy: 0.8926\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "113/250 [============>.................] - ETA: 40s - loss: 0.3427 - accuracy: 0.8916\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "114/250 [============>.................] - ETA: 39s - loss: 0.3442 - accuracy: 0.8909\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "115/250 [============>.................] - ETA: 39s - loss: 0.3447 - accuracy: 0.8913\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "116/250 [============>.................] - ETA: 39s - loss: 0.3457 - accuracy: 0.8912\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "117/250 [=============>................] - ETA: 38s - loss: 0.3454 - accuracy: 0.8910\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "118/250 [=============>................] - ETA: 38s - loss: 0.3442 - accuracy: 0.8914\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "119/250 [=============>................] - ETA: 38s - loss: 0.3437 - accuracy: 0.8915\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "120/250 [=============>................] - ETA: 37s - loss: 0.3426 - accuracy: 0.8919\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "121/250 [=============>................] - ETA: 37s - loss: 0.3414 - accuracy: 0.8923\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "122/250 [=============>................] - ETA: 37s - loss: 0.3420 - accuracy: 0.8922\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "123/250 [=============>................] - ETA: 37s - loss: 0.3409 - accuracy: 0.8925\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "124/250 [=============>................] - ETA: 36s - loss: 0.3407 - accuracy: 0.8924\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "125/250 [==============>...............] - ETA: 36s - loss: 0.3405 - accuracy: 0.8920\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "126/250 [==============>...............] - ETA: 36s - loss: 0.3413 - accuracy: 0.8916\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "127/250 [==============>...............] - ETA: 35s - loss: 0.3428 - accuracy: 0.8917\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "128/250 [==============>...............] - ETA: 35s - loss: 0.3443 - accuracy: 0.8916\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "129/250 [==============>...............] - ETA: 35s - loss: 0.3442 - accuracy: 0.8915\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "130/250 [==============>...............] - ETA: 35s - loss: 0.3441 - accuracy: 0.8911\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "131/250 [==============>...............] - ETA: 34s - loss: 0.3446 - accuracy: 0.8915\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "132/250 [==============>...............] - ETA: 34s - loss: 0.3439 - accuracy: 0.8916\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "133/250 [==============>...............] - ETA: 34s - loss: 0.3434 - accuracy: 0.8917\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.3428 - accuracy: 0.8913\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "135/250 [===============>..............] - ETA: 33s - loss: 0.3429 - accuracy: 0.8914\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "136/250 [===============>..............] - ETA: 33s - loss: 0.3408 - accuracy: 0.8922\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "137/250 [===============>..............] - ETA: 33s - loss: 0.3415 - accuracy: 0.8919\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "138/250 [===============>..............] - ETA: 32s - loss: 0.3399 - accuracy: 0.8924\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "139/250 [===============>..............] - ETA: 32s - loss: 0.3411 - accuracy: 0.8928\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "140/250 [===============>..............] - ETA: 32s - loss: 0.3404 - accuracy: 0.8926\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.3394 - accuracy: 0.8927\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "142/250 [================>.............] - ETA: 31s - loss: 0.3379 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "143/250 [================>.............] - ETA: 31s - loss: 0.3385 - accuracy: 0.8936\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "144/250 [================>.............] - ETA: 31s - loss: 0.3372 - accuracy: 0.8939\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "145/250 [================>.............] - ETA: 30s - loss: 0.3365 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "146/250 [================>.............] - ETA: 30s - loss: 0.3382 - accuracy: 0.8934\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "147/250 [================>.............] - ETA: 30s - loss: 0.3367 - accuracy: 0.8939\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.3358 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "149/250 [================>.............] - ETA: 29s - loss: 0.3355 - accuracy: 0.8937\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "150/250 [=================>............] - ETA: 29s - loss: 0.3356 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.3355 - accuracy: 0.8942\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "152/250 [=================>............] - ETA: 28s - loss: 0.3343 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "153/250 [=================>............] - ETA: 28s - loss: 0.3342 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "154/250 [=================>............] - ETA: 28s - loss: 0.3329 - accuracy: 0.8953\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.3319 - accuracy: 0.8958\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "156/250 [=================>............] - ETA: 27s - loss: 0.3309 - accuracy: 0.8960\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "157/250 [=================>............] - ETA: 27s - loss: 0.3291 - accuracy: 0.8967\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.3295 - accuracy: 0.8966\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.3287 - accuracy: 0.8968\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "160/250 [==================>...........] - ETA: 26s - loss: 0.3297 - accuracy: 0.8965\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "161/250 [==================>...........] - ETA: 26s - loss: 0.3310 - accuracy: 0.8965\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.3322 - accuracy: 0.8966\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "163/250 [==================>...........] - ETA: 25s - loss: 0.3313 - accuracy: 0.8967\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "164/250 [==================>...........] - ETA: 25s - loss: 0.3328 - accuracy: 0.8965\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.3356 - accuracy: 0.8968\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.3368 - accuracy: 0.8963\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "167/250 [===================>..........] - ETA: 24s - loss: 0.3363 - accuracy: 0.8963\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.3370 - accuracy: 0.8960\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.3366 - accuracy: 0.8959\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "170/250 [===================>..........] - ETA: 23s - loss: 0.3376 - accuracy: 0.8958\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "171/250 [===================>..........] - ETA: 23s - loss: 0.3370 - accuracy: 0.8960\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.3389 - accuracy: 0.8955\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.3395 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "174/250 [===================>..........] - ETA: 22s - loss: 0.3403 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.3399 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.3394 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "177/250 [====================>.........] - ETA: 21s - loss: 0.3396 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "178/250 [====================>.........] - ETA: 21s - loss: 0.3413 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.3407 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.3409 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "181/250 [====================>.........] - ETA: 20s - loss: 0.3402 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.3401 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.3408 - accuracy: 0.8946\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "184/250 [=====================>........] - ETA: 19s - loss: 0.3403 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.3407 - accuracy: 0.8946\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.3402 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.3401 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "188/250 [=====================>........] - ETA: 18s - loss: 0.3404 - accuracy: 0.8943\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.3402 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.3395 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "191/250 [=====================>........] - ETA: 17s - loss: 0.3391 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.3380 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.3386 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.3383 - accuracy: 0.8951\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "195/250 [======================>.......] - ETA: 16s - loss: 0.3373 - accuracy: 0.8953\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.3372 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.3370 - accuracy: 0.8953\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "198/250 [======================>.......] - ETA: 15s - loss: 0.3368 - accuracy: 0.8952\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.3368 - accuracy: 0.8949\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.3369 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.3368 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.3365 - accuracy: 0.8948\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.3368 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.3358 - accuracy: 0.8947\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "205/250 [=======================>......] - ETA: 13s - loss: 0.3361 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.3366 - accuracy: 0.8941\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.3360 - accuracy: 0.8943\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.3354 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.3346 - accuracy: 0.8946\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.3347 - accuracy: 0.8943\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.3344 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "212/250 [========================>.....] - ETA: 11s - loss: 0.3343 - accuracy: 0.8946\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.3349 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.3365 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.3363 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.3376 - accuracy: 0.8936 \n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.3375 - accuracy: 0.8937\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.3379 - accuracy: 0.8936\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "219/250 [=========================>....] - ETA: 9s - loss: 0.3376 - accuracy: 0.8938\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.3368 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.3364 - accuracy: 0.8942\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.3393 - accuracy: 0.8937\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.3400 - accuracy: 0.8935\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.3413 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.3403 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.3390 - accuracy: 0.8936\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.3383 - accuracy: 0.8937\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.3380 - accuracy: 0.8938\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.3370 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.3364 - accuracy: 0.8941\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.3357 - accuracy: 0.8943\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.3358 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.3359 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.3357 - accuracy: 0.8945\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.3353 - accuracy: 0.8944\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.3352 - accuracy: 0.8942\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.3384 - accuracy: 0.8938\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.3386 - accuracy: 0.8940\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.3384 - accuracy: 0.8941\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.3397 - accuracy: 0.8936\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.3414 - accuracy: 0.8931\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.3409 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.3419 - accuracy: 0.8929\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.3417 - accuracy: 0.8928\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.3407 - accuracy: 0.8931\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.3410 - accuracy: 0.8930\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8933\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3399 - accuracy: 0.8934\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.8934\n",
      "Epoch 14: accuracy did not improve from 0.94792\n",
      "250/250 [==============================] - 90s 358ms/step - loss: 0.3412 - accuracy: 0.8931 - val_loss: 0.1745 - val_accuracy: 0.9471\n",
      "Epoch 15/15\n",
      "\n",
      "Epoch 15: accuracy improved from 0.94792 to 0.96875, saving model to output\\inceptionV3.h5\n",
      "  1/250 [..............................] - ETA: 3:25 - loss: 0.1048 - accuracy: 0.9688\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  2/250 [..............................] - ETA: 27s - loss: 0.1043 - accuracy: 0.9531 \n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  3/250 [..............................] - ETA: 47s - loss: 0.2101 - accuracy: 0.9271\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  4/250 [..............................] - ETA: 55s - loss: 0.2391 - accuracy: 0.9141\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  5/250 [..............................] - ETA: 59s - loss: 0.2640 - accuracy: 0.9125\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  6/250 [..............................] - ETA: 1:00 - loss: 0.2574 - accuracy: 0.9219\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  7/250 [..............................] - ETA: 1:01 - loss: 0.2633 - accuracy: 0.9196\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  8/250 [..............................] - ETA: 1:01 - loss: 0.2898 - accuracy: 0.9102\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "  9/250 [>.............................] - ETA: 1:03 - loss: 0.3168 - accuracy: 0.9028\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 10/250 [>.............................] - ETA: 1:03 - loss: 0.3299 - accuracy: 0.8906\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 11/250 [>.............................] - ETA: 1:04 - loss: 0.3288 - accuracy: 0.8920\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 12/250 [>.............................] - ETA: 1:04 - loss: 0.3372 - accuracy: 0.8854\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 13/250 [>.............................] - ETA: 1:04 - loss: 0.3398 - accuracy: 0.8894\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 14/250 [>.............................] - ETA: 1:05 - loss: 0.3210 - accuracy: 0.8973\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 15/250 [>.............................] - ETA: 1:04 - loss: 0.3101 - accuracy: 0.9021\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 16/250 [>.............................] - ETA: 1:04 - loss: 0.3165 - accuracy: 0.9004\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 17/250 [=>............................] - ETA: 1:04 - loss: 0.3104 - accuracy: 0.8989\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 18/250 [=>............................] - ETA: 1:04 - loss: 0.3051 - accuracy: 0.8993\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 19/250 [=>............................] - ETA: 1:04 - loss: 0.2989 - accuracy: 0.9030\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 20/250 [=>............................] - ETA: 1:04 - loss: 0.3294 - accuracy: 0.8922\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 21/250 [=>............................] - ETA: 1:04 - loss: 0.3294 - accuracy: 0.8929\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 22/250 [=>............................] - ETA: 1:03 - loss: 0.3345 - accuracy: 0.8920\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 23/250 [=>............................] - ETA: 1:04 - loss: 0.3267 - accuracy: 0.8954\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 24/250 [=>............................] - ETA: 1:03 - loss: 0.3290 - accuracy: 0.8945\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 25/250 [==>...........................] - ETA: 1:03 - loss: 0.3437 - accuracy: 0.8913\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 26/250 [==>...........................] - ETA: 1:03 - loss: 0.3391 - accuracy: 0.8918\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 27/250 [==>...........................] - ETA: 1:03 - loss: 0.3389 - accuracy: 0.8912\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 28/250 [==>...........................] - ETA: 1:02 - loss: 0.3390 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 29/250 [==>...........................] - ETA: 1:02 - loss: 0.3399 - accuracy: 0.8901\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 30/250 [==>...........................] - ETA: 1:02 - loss: 0.3357 - accuracy: 0.8927\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 31/250 [==>...........................] - ETA: 1:01 - loss: 0.3386 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 32/250 [==>...........................] - ETA: 1:01 - loss: 0.3350 - accuracy: 0.8926\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 33/250 [==>...........................] - ETA: 1:01 - loss: 0.3424 - accuracy: 0.8892\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 34/250 [===>..........................] - ETA: 1:01 - loss: 0.3410 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 35/250 [===>..........................] - ETA: 1:00 - loss: 0.3477 - accuracy: 0.8875\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 36/250 [===>..........................] - ETA: 1:00 - loss: 0.3464 - accuracy: 0.8872\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 37/250 [===>..........................] - ETA: 1:00 - loss: 0.3503 - accuracy: 0.8851\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 38/250 [===>..........................] - ETA: 59s - loss: 0.3532 - accuracy: 0.8849 \n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 39/250 [===>..........................] - ETA: 59s - loss: 0.3491 - accuracy: 0.8854\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 40/250 [===>..........................] - ETA: 59s - loss: 0.3496 - accuracy: 0.8852\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 41/250 [===>..........................] - ETA: 58s - loss: 0.3517 - accuracy: 0.8841\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 42/250 [====>.........................] - ETA: 58s - loss: 0.3555 - accuracy: 0.8824\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 43/250 [====>.........................] - ETA: 58s - loss: 0.3587 - accuracy: 0.8823\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 44/250 [====>.........................] - ETA: 58s - loss: 0.3688 - accuracy: 0.8793\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 45/250 [====>.........................] - ETA: 57s - loss: 0.3679 - accuracy: 0.8799\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 46/250 [====>.........................] - ETA: 57s - loss: 0.3653 - accuracy: 0.8811\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 47/250 [====>.........................] - ETA: 57s - loss: 0.3645 - accuracy: 0.8816\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 48/250 [====>.........................] - ETA: 57s - loss: 0.3684 - accuracy: 0.8815\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 49/250 [====>.........................] - ETA: 56s - loss: 0.3651 - accuracy: 0.8820\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 50/250 [=====>........................] - ETA: 56s - loss: 0.3655 - accuracy: 0.8819\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 51/250 [=====>........................] - ETA: 56s - loss: 0.3613 - accuracy: 0.8830\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 52/250 [=====>........................] - ETA: 55s - loss: 0.3643 - accuracy: 0.8816\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 53/250 [=====>........................] - ETA: 55s - loss: 0.3593 - accuracy: 0.8827\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 54/250 [=====>........................] - ETA: 55s - loss: 0.3622 - accuracy: 0.8819\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 55/250 [=====>........................] - ETA: 55s - loss: 0.3655 - accuracy: 0.8818\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 56/250 [=====>........................] - ETA: 54s - loss: 0.3632 - accuracy: 0.8828\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 57/250 [=====>........................] - ETA: 54s - loss: 0.3604 - accuracy: 0.8827\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 58/250 [=====>........................] - ETA: 54s - loss: 0.3638 - accuracy: 0.8809\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 59/250 [======>.......................] - ETA: 54s - loss: 0.3638 - accuracy: 0.8808\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 60/250 [======>.......................] - ETA: 53s - loss: 0.3625 - accuracy: 0.8813\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 61/250 [======>.......................] - ETA: 53s - loss: 0.3705 - accuracy: 0.8801\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 62/250 [======>.......................] - ETA: 53s - loss: 0.3687 - accuracy: 0.8805\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 63/250 [======>.......................] - ETA: 52s - loss: 0.3680 - accuracy: 0.8808\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 64/250 [======>.......................] - ETA: 52s - loss: 0.3678 - accuracy: 0.8797\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 65/250 [======>.......................] - ETA: 52s - loss: 0.3655 - accuracy: 0.8811\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 66/250 [======>.......................] - ETA: 51s - loss: 0.3646 - accuracy: 0.8810\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 67/250 [=======>......................] - ETA: 51s - loss: 0.3628 - accuracy: 0.8818\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 68/250 [=======>......................] - ETA: 51s - loss: 0.3625 - accuracy: 0.8817\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 69/250 [=======>......................] - ETA: 50s - loss: 0.3580 - accuracy: 0.8835\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 70/250 [=======>......................] - ETA: 50s - loss: 0.3564 - accuracy: 0.8838\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 71/250 [=======>......................] - ETA: 50s - loss: 0.3537 - accuracy: 0.8845\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 72/250 [=======>......................] - ETA: 50s - loss: 0.3519 - accuracy: 0.8853\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 73/250 [=======>......................] - ETA: 50s - loss: 0.3513 - accuracy: 0.8851\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 74/250 [=======>......................] - ETA: 49s - loss: 0.3478 - accuracy: 0.8867\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 75/250 [========>.....................] - ETA: 49s - loss: 0.3525 - accuracy: 0.8857\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 76/250 [========>.....................] - ETA: 49s - loss: 0.3539 - accuracy: 0.8847\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 77/250 [========>.....................] - ETA: 48s - loss: 0.3519 - accuracy: 0.8846\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 78/250 [========>.....................] - ETA: 48s - loss: 0.3539 - accuracy: 0.8845\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 79/250 [========>.....................] - ETA: 48s - loss: 0.3532 - accuracy: 0.8848\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 80/250 [========>.....................] - ETA: 48s - loss: 0.3521 - accuracy: 0.8846\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 81/250 [========>.....................] - ETA: 47s - loss: 0.3535 - accuracy: 0.8845\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 82/250 [========>.....................] - ETA: 47s - loss: 0.3511 - accuracy: 0.8852\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 83/250 [========>.....................] - ETA: 47s - loss: 0.3532 - accuracy: 0.8851\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 84/250 [=========>....................] - ETA: 47s - loss: 0.3522 - accuracy: 0.8857\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 85/250 [=========>....................] - ETA: 46s - loss: 0.3498 - accuracy: 0.8863\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 86/250 [=========>....................] - ETA: 46s - loss: 0.3469 - accuracy: 0.8873\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 87/250 [=========>....................] - ETA: 46s - loss: 0.3449 - accuracy: 0.8875\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 88/250 [=========>....................] - ETA: 46s - loss: 0.3434 - accuracy: 0.8873\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 89/250 [=========>....................] - ETA: 45s - loss: 0.3508 - accuracy: 0.8847\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 90/250 [=========>....................] - ETA: 45s - loss: 0.3480 - accuracy: 0.8853\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 91/250 [=========>....................] - ETA: 45s - loss: 0.3464 - accuracy: 0.8859\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 92/250 [==========>...................] - ETA: 44s - loss: 0.3439 - accuracy: 0.8868\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 93/250 [==========>...................] - ETA: 44s - loss: 0.3421 - accuracy: 0.8877\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 94/250 [==========>...................] - ETA: 44s - loss: 0.3430 - accuracy: 0.8876\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 95/250 [==========>...................] - ETA: 44s - loss: 0.3427 - accuracy: 0.8868\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 96/250 [==========>...................] - ETA: 43s - loss: 0.3425 - accuracy: 0.8866\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 97/250 [==========>...................] - ETA: 43s - loss: 0.3451 - accuracy: 0.8865\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 98/250 [==========>...................] - ETA: 43s - loss: 0.3471 - accuracy: 0.8864\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      " 99/250 [==========>...................] - ETA: 42s - loss: 0.3456 - accuracy: 0.8866\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "100/250 [===========>..................] - ETA: 42s - loss: 0.3449 - accuracy: 0.8865\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "101/250 [===========>..................] - ETA: 42s - loss: 0.3432 - accuracy: 0.8870\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "102/250 [===========>..................] - ETA: 41s - loss: 0.3438 - accuracy: 0.8866\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "103/250 [===========>..................] - ETA: 41s - loss: 0.3419 - accuracy: 0.8871\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "104/250 [===========>..................] - ETA: 41s - loss: 0.3420 - accuracy: 0.8872\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "105/250 [===========>..................] - ETA: 41s - loss: 0.3400 - accuracy: 0.8877\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "106/250 [===========>..................] - ETA: 40s - loss: 0.3424 - accuracy: 0.8867\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "107/250 [===========>..................] - ETA: 40s - loss: 0.3435 - accuracy: 0.8866\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "108/250 [===========>..................] - ETA: 40s - loss: 0.3438 - accuracy: 0.8868\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "109/250 [============>.................] - ETA: 40s - loss: 0.3429 - accuracy: 0.8873\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "110/250 [============>.................] - ETA: 39s - loss: 0.3448 - accuracy: 0.8871\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "111/250 [============>.................] - ETA: 39s - loss: 0.3479 - accuracy: 0.8862\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "112/250 [============>.................] - ETA: 39s - loss: 0.3498 - accuracy: 0.8855\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "113/250 [============>.................] - ETA: 38s - loss: 0.3507 - accuracy: 0.8857\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "114/250 [============>.................] - ETA: 38s - loss: 0.3503 - accuracy: 0.8859\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "115/250 [============>.................] - ETA: 38s - loss: 0.3492 - accuracy: 0.8861\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "116/250 [============>.................] - ETA: 38s - loss: 0.3505 - accuracy: 0.8860\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "117/250 [=============>................] - ETA: 37s - loss: 0.3509 - accuracy: 0.8856\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "118/250 [=============>................] - ETA: 37s - loss: 0.3501 - accuracy: 0.8860\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "119/250 [=============>................] - ETA: 37s - loss: 0.3485 - accuracy: 0.8867\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "120/250 [=============>................] - ETA: 36s - loss: 0.3460 - accuracy: 0.8877\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "121/250 [=============>................] - ETA: 36s - loss: 0.3442 - accuracy: 0.8881\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "122/250 [=============>................] - ETA: 36s - loss: 0.3456 - accuracy: 0.8885\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "123/250 [=============>................] - ETA: 36s - loss: 0.3460 - accuracy: 0.8882\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "124/250 [=============>................] - ETA: 35s - loss: 0.3455 - accuracy: 0.8880\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "125/250 [==============>...............] - ETA: 35s - loss: 0.3445 - accuracy: 0.8882\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "126/250 [==============>...............] - ETA: 35s - loss: 0.3428 - accuracy: 0.8888\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "127/250 [==============>...............] - ETA: 34s - loss: 0.3440 - accuracy: 0.8882\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "128/250 [==============>...............] - ETA: 34s - loss: 0.3428 - accuracy: 0.8886\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "129/250 [==============>...............] - ETA: 34s - loss: 0.3433 - accuracy: 0.8883\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "130/250 [==============>...............] - ETA: 34s - loss: 0.3448 - accuracy: 0.8884\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "131/250 [==============>...............] - ETA: 33s - loss: 0.3468 - accuracy: 0.8876\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "132/250 [==============>...............] - ETA: 33s - loss: 0.3464 - accuracy: 0.8875\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "133/250 [==============>...............] - ETA: 33s - loss: 0.3464 - accuracy: 0.8874\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "134/250 [===============>..............] - ETA: 33s - loss: 0.3449 - accuracy: 0.8878\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "135/250 [===============>..............] - ETA: 32s - loss: 0.3448 - accuracy: 0.8877\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "136/250 [===============>..............] - ETA: 32s - loss: 0.3442 - accuracy: 0.8880\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "137/250 [===============>..............] - ETA: 32s - loss: 0.3461 - accuracy: 0.8875\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "138/250 [===============>..............] - ETA: 31s - loss: 0.3449 - accuracy: 0.8879\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "139/250 [===============>..............] - ETA: 31s - loss: 0.3437 - accuracy: 0.8882\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "140/250 [===============>..............] - ETA: 31s - loss: 0.3437 - accuracy: 0.8881\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "141/250 [===============>..............] - ETA: 31s - loss: 0.3445 - accuracy: 0.8878\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "142/250 [================>.............] - ETA: 30s - loss: 0.3436 - accuracy: 0.8879\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "143/250 [================>.............] - ETA: 30s - loss: 0.3427 - accuracy: 0.8883\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "144/250 [================>.............] - ETA: 30s - loss: 0.3460 - accuracy: 0.8880\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "145/250 [================>.............] - ETA: 29s - loss: 0.3456 - accuracy: 0.8879\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "146/250 [================>.............] - ETA: 29s - loss: 0.3462 - accuracy: 0.8880\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "147/250 [================>.............] - ETA: 29s - loss: 0.3442 - accuracy: 0.8888\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "148/250 [================>.............] - ETA: 29s - loss: 0.3435 - accuracy: 0.8891\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "149/250 [================>.............] - ETA: 28s - loss: 0.3445 - accuracy: 0.8888\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "150/250 [=================>............] - ETA: 28s - loss: 0.3460 - accuracy: 0.8889\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "151/250 [=================>............] - ETA: 28s - loss: 0.3459 - accuracy: 0.8890\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "152/250 [=================>............] - ETA: 27s - loss: 0.3450 - accuracy: 0.8893\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "153/250 [=================>............] - ETA: 27s - loss: 0.3447 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "154/250 [=================>............] - ETA: 27s - loss: 0.3439 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "155/250 [=================>............] - ETA: 27s - loss: 0.3427 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "156/250 [=================>............] - ETA: 26s - loss: 0.3432 - accuracy: 0.8894\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "157/250 [=================>............] - ETA: 26s - loss: 0.3425 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "158/250 [=================>............] - ETA: 26s - loss: 0.3419 - accuracy: 0.8898\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "159/250 [==================>...........] - ETA: 26s - loss: 0.3404 - accuracy: 0.8903\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "160/250 [==================>...........] - ETA: 25s - loss: 0.3406 - accuracy: 0.8900\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "161/250 [==================>...........] - ETA: 25s - loss: 0.3403 - accuracy: 0.8901\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "162/250 [==================>...........] - ETA: 25s - loss: 0.3393 - accuracy: 0.8902\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "163/250 [==================>...........] - ETA: 24s - loss: 0.3412 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "164/250 [==================>...........] - ETA: 24s - loss: 0.3403 - accuracy: 0.8900\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "165/250 [==================>...........] - ETA: 24s - loss: 0.3402 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "166/250 [==================>...........] - ETA: 24s - loss: 0.3393 - accuracy: 0.8902\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "167/250 [===================>..........] - ETA: 23s - loss: 0.3395 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "168/250 [===================>..........] - ETA: 23s - loss: 0.3390 - accuracy: 0.8902\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "169/250 [===================>..........] - ETA: 23s - loss: 0.3375 - accuracy: 0.8907\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "170/250 [===================>..........] - ETA: 22s - loss: 0.3375 - accuracy: 0.8910\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "171/250 [===================>..........] - ETA: 22s - loss: 0.3375 - accuracy: 0.8909\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "172/250 [===================>..........] - ETA: 22s - loss: 0.3377 - accuracy: 0.8906\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "173/250 [===================>..........] - ETA: 22s - loss: 0.3378 - accuracy: 0.8903\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "174/250 [===================>..........] - ETA: 21s - loss: 0.3391 - accuracy: 0.8902\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "175/250 [====================>.........] - ETA: 21s - loss: 0.3385 - accuracy: 0.8907\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "176/250 [====================>.........] - ETA: 21s - loss: 0.3398 - accuracy: 0.8904\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "177/250 [====================>.........] - ETA: 20s - loss: 0.3391 - accuracy: 0.8905\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "178/250 [====================>.........] - ETA: 20s - loss: 0.3393 - accuracy: 0.8904\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "179/250 [====================>.........] - ETA: 20s - loss: 0.3391 - accuracy: 0.8905\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "180/250 [====================>.........] - ETA: 20s - loss: 0.3391 - accuracy: 0.8908\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "181/250 [====================>.........] - ETA: 19s - loss: 0.3396 - accuracy: 0.8905\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "182/250 [====================>.........] - ETA: 19s - loss: 0.3381 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "183/250 [====================>.........] - ETA: 19s - loss: 0.3373 - accuracy: 0.8914\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "184/250 [=====================>........] - ETA: 18s - loss: 0.3372 - accuracy: 0.8913\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "185/250 [=====================>........] - ETA: 18s - loss: 0.3379 - accuracy: 0.8908\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "186/250 [=====================>........] - ETA: 18s - loss: 0.3394 - accuracy: 0.8906\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "187/250 [=====================>........] - ETA: 18s - loss: 0.3396 - accuracy: 0.8908\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "188/250 [=====================>........] - ETA: 17s - loss: 0.3396 - accuracy: 0.8908\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "189/250 [=====================>........] - ETA: 17s - loss: 0.3387 - accuracy: 0.8912\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "190/250 [=====================>........] - ETA: 17s - loss: 0.3393 - accuracy: 0.8904\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "191/250 [=====================>........] - ETA: 16s - loss: 0.3379 - accuracy: 0.8908\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "192/250 [======================>.......] - ETA: 16s - loss: 0.3369 - accuracy: 0.8912\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "193/250 [======================>.......] - ETA: 16s - loss: 0.3361 - accuracy: 0.8913\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "194/250 [======================>.......] - ETA: 16s - loss: 0.3367 - accuracy: 0.8912\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "195/250 [======================>.......] - ETA: 15s - loss: 0.3366 - accuracy: 0.8915\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "196/250 [======================>.......] - ETA: 15s - loss: 0.3373 - accuracy: 0.8912\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "197/250 [======================>.......] - ETA: 15s - loss: 0.3380 - accuracy: 0.8910\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "198/250 [======================>.......] - ETA: 14s - loss: 0.3376 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "199/250 [======================>.......] - ETA: 14s - loss: 0.3370 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "200/250 [=======================>......] - ETA: 14s - loss: 0.3356 - accuracy: 0.8917\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "201/250 [=======================>......] - ETA: 14s - loss: 0.3354 - accuracy: 0.8916\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "202/250 [=======================>......] - ETA: 13s - loss: 0.3354 - accuracy: 0.8918\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "203/250 [=======================>......] - ETA: 13s - loss: 0.3349 - accuracy: 0.8919\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "204/250 [=======================>......] - ETA: 13s - loss: 0.3362 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "205/250 [=======================>......] - ETA: 12s - loss: 0.3359 - accuracy: 0.8913\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "206/250 [=======================>......] - ETA: 12s - loss: 0.3358 - accuracy: 0.8911\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "207/250 [=======================>......] - ETA: 12s - loss: 0.3360 - accuracy: 0.8910\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "208/250 [=======================>......] - ETA: 12s - loss: 0.3365 - accuracy: 0.8907\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "209/250 [========================>.....] - ETA: 11s - loss: 0.3372 - accuracy: 0.8904\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "210/250 [========================>.....] - ETA: 11s - loss: 0.3375 - accuracy: 0.8903\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "211/250 [========================>.....] - ETA: 11s - loss: 0.3368 - accuracy: 0.8905\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "212/250 [========================>.....] - ETA: 10s - loss: 0.3375 - accuracy: 0.8904\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "213/250 [========================>.....] - ETA: 10s - loss: 0.3375 - accuracy: 0.8902\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "214/250 [========================>.....] - ETA: 10s - loss: 0.3385 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "215/250 [========================>.....] - ETA: 10s - loss: 0.3381 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "216/250 [========================>.....] - ETA: 9s - loss: 0.3392 - accuracy: 0.8897 \n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "217/250 [=========================>....] - ETA: 9s - loss: 0.3386 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "218/250 [=========================>....] - ETA: 9s - loss: 0.3392 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "219/250 [=========================>....] - ETA: 8s - loss: 0.3391 - accuracy: 0.8898\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "220/250 [=========================>....] - ETA: 8s - loss: 0.3388 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "221/250 [=========================>....] - ETA: 8s - loss: 0.3392 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "222/250 [=========================>....] - ETA: 8s - loss: 0.3407 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "223/250 [=========================>....] - ETA: 7s - loss: 0.3405 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "224/250 [=========================>....] - ETA: 7s - loss: 0.3406 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "225/250 [==========================>...] - ETA: 7s - loss: 0.3414 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "226/250 [==========================>...] - ETA: 6s - loss: 0.3437 - accuracy: 0.8894\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "227/250 [==========================>...] - ETA: 6s - loss: 0.3429 - accuracy: 0.8894\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "228/250 [==========================>...] - ETA: 6s - loss: 0.3424 - accuracy: 0.8894\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "229/250 [==========================>...] - ETA: 6s - loss: 0.3418 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "230/250 [==========================>...] - ETA: 5s - loss: 0.3428 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "231/250 [==========================>...] - ETA: 5s - loss: 0.3427 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "232/250 [==========================>...] - ETA: 5s - loss: 0.3436 - accuracy: 0.8890\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "233/250 [==========================>...] - ETA: 4s - loss: 0.3437 - accuracy: 0.8891\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "234/250 [===========================>..] - ETA: 4s - loss: 0.3449 - accuracy: 0.8889\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "235/250 [===========================>..] - ETA: 4s - loss: 0.3439 - accuracy: 0.8892\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "236/250 [===========================>..] - ETA: 4s - loss: 0.3434 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "237/250 [===========================>..] - ETA: 3s - loss: 0.3431 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "238/250 [===========================>..] - ETA: 3s - loss: 0.3438 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "239/250 [===========================>..] - ETA: 3s - loss: 0.3437 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "240/250 [===========================>..] - ETA: 2s - loss: 0.3434 - accuracy: 0.8899\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "241/250 [===========================>..] - ETA: 2s - loss: 0.3446 - accuracy: 0.8896\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "242/250 [============================>.] - ETA: 2s - loss: 0.3451 - accuracy: 0.8897\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "243/250 [============================>.] - ETA: 2s - loss: 0.3450 - accuracy: 0.8898\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "244/250 [============================>.] - ETA: 1s - loss: 0.3446 - accuracy: 0.8898\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "245/250 [============================>.] - ETA: 1s - loss: 0.3458 - accuracy: 0.8895\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "246/250 [============================>.] - ETA: 1s - loss: 0.3469 - accuracy: 0.8891\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "247/250 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.8885\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "248/250 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.8885\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8884\n",
      "Epoch 15: accuracy did not improve from 0.96875\n",
      "250/250 [==============================] - 90s 356ms/step - loss: 0.3476 - accuracy: 0.8883 - val_loss: 0.1828 - val_accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    trainGen, steps_per_epoch=trainGen.samples // 32,\n",
    "\tvalidation_data=testGen, validation_steps=testGen.samples // 32,\n",
    "\tepochs=15, callbacks=[checkpoint, early])\n",
    "\n",
    "model.save(os.path.sep.join([config.OUTPUT_PATH, \"inceptionV3.model\"]), save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = np.arange(0, 15)\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"inception_losses.png\"]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(N, hist.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, hist.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.sep.join([config.OUTPUT_PATH, \"inception_accuracy.png\"]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(os.path.sep.join([config.OUTPUT_PATH, \"inceptionV3.model\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        open      0.934     0.835     0.882       388\n",
      "       short      0.690     0.904     0.783       301\n",
      "    mousebit      0.906     0.687     0.781       393\n",
      "        spur      0.638     0.895     0.745       325\n",
      "      copper      0.957     0.905     0.930       294\n",
      "    pin-hole      0.974     0.740     0.841       300\n",
      "\n",
      "    accuracy                          0.822      2001\n",
      "   macro avg      0.850     0.828     0.827      2001\n",
      "weighted avg      0.853     0.822     0.826      2001\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "predictions = list()\n",
    "for path in testGen.filepaths:\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    preds = model.predict(image)\n",
    "    predictions.append(preds.argmax(axis=1))\n",
    "\n",
    "print(classification_report(testGen.classes,\n",
    "\tpredictions, target_names=testGen.class_indices, digits=3))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.grid(False)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "font = {'size' : 12}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "cm = confusion_matrix(testGen.classes, predictions)\n",
    "\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(testGen.class_indices))\n",
    "\n",
    "plt.xticks(tick_marks, testGen.class_indices, rotation=45)\n",
    "plt.yticks(tick_marks, testGen.class_indices)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Defect')\n",
    "plt.ylabel('True Defect')\n",
    "plt.title('Confusion matrix Inception v3')\n",
    "plt.savefig('output/inception_confusion_matrix.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c84cac0d85cf2b51a97d2bd7b0fa6585599b14f00604962e71b8ec1671851d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
